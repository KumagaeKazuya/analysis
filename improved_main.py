"""
YOLO11 åºƒè§’ã‚«ãƒ¡ãƒ©åˆ†æã‚·ã‚¹ãƒ†ãƒ  - æ”¹è‰¯ç‰ˆï¼ˆçµ±ä¸€ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚° + æ·±åº¦æ¨å®šçµ±åˆå¯¾å¿œç‰ˆï¼‰

ğŸ”§ ä¸»ãªæ”¹å–„ç‚¹:
1. çµ±ä¸€ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°å¯¾å¿œ
2. æ·±åº¦æ¨å®šï¼ˆMiDaSï¼‰çµ±åˆæ©Ÿèƒ½
3. æ·±åº¦å¯¾å¿œè©•ä¾¡å™¨ã®è‡ªå‹•é¸æŠ
4. è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®è‡ªå‹•åˆ‡ã‚Šæ›¿ãˆ
5. ã‚¨ãƒ©ãƒ¼åé›†ã¨ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
6. ğŸ”§ ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ä¸è¶³å¯¾å¿œã¨ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æ©Ÿèƒ½
7. ğŸ”§ ErrorCategory.EVALUATION å¯¾å¿œï¼ˆStage 5ä¿®æ­£ï¼‰
8. ğŸ”§ æ¡ä»¶ä»˜ãã‚¤ãƒ³ãƒãƒ¼ãƒˆã®å¼·åŒ–ï¼ˆStage 6ä¿®æ­£ï¼‰
9. ğŸ”§ ç›´æ¥ã‚¤ãƒ³ãƒãƒ¼ãƒˆå‰Šé™¤ã¨ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å®Œå…¨çµ±åˆ
"""
import argparse
import os
import sys
import json
import logging
from datetime import datetime
from pathlib import Path
import argparse
from typing import Dict, Any, Optional, List
import time
from datetime import datetime  # ğŸ”§ è¿½åŠ 
import traceback

# ğŸ”§ æ¡ä»¶ä»˜ãã‚¤ãƒ³ãƒãƒ¼ãƒˆ - å¿…é ˆãƒ©ã‚¤ãƒ–ãƒ©ãƒª
try:
    import cv2
    import numpy as np
    import pandas as pd
    from ultralytics import YOLO
    import torch
    import matplotlib.pyplot as plt
    from tqdm import tqdm
    import yaml
    print("âœ… å¿…é ˆãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆæˆåŠŸ")
except ImportError as e:
    print(f"âŒ å¿…é ˆãƒ©ã‚¤ãƒ–ãƒ©ãƒªä¸è¶³: {e}")
    print("ğŸ“¦ ä»¥ä¸‹ã§ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¦ãã ã•ã„:")
    print("pip install ultralytics opencv-python numpy pandas matplotlib tqdm pyyaml torch")
    sys.exit(1)

# ğŸ”§ æ¡ä»¶ä»˜ãã‚¤ãƒ³ãƒãƒ¼ãƒˆ - çµ±ä¸€ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ï¼ˆå®Œå…¨çµ±åˆç‰ˆï¼‰
ERROR_HANDLER_AVAILABLE = False
try:
    from utils.error_handler import (
        BaseYOLOError,
        ConfigurationError,
        VideoProcessingError,
        ResponseBuilder,
        handle_errors,
        ErrorContext,
        ErrorCategory,
        ErrorReporter,
        ErrorSeverity
    )
    ERROR_HANDLER_AVAILABLE = True
    print("âœ… çµ±ä¸€ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ãŒåˆ©ç”¨å¯èƒ½ã§ã™")
except ImportError as e:
    print(f"âš ï¸ çµ±ä¸€ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {e}")
    print("ğŸ”§ åŸºæœ¬ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã‚’ä½¿ç”¨ã—ã¾ã™")
    ERROR_HANDLER_AVAILABLE = False
    
    # ğŸ”§ åŸºæœ¬ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã‚¯ãƒ©ã‚¹ï¼ˆå®Œå…¨ç‰ˆï¼‰
    class BaseYOLOError(Exception):
        def __init__(self, message, details=None):
            super().__init__(message)
            self.message = message
            self.details = details or {}
    
    class ConfigurationError(BaseYOLOError):
        pass
    
    class VideoProcessingError(BaseYOLOError):
        pass
    
    # ğŸ”§ ErrorCategory ã®å®Œå…¨å®Ÿè£…
    class ErrorCategory:
        INITIALIZATION = "initialization"
        VIDEO_PROCESSING = "video_processing"
        EVALUATION = "evaluation"  # ğŸ”§ Stage 5ã‚¨ãƒ©ãƒ¼è§£æ±ºç”¨
        EXPERIMENT = "experiment"
        CONFIGURATION = "configuration"
        MODEL_LOADING = "model_loading"
        MODEL = "model"  # ğŸ”§ è¿½åŠ 
        DEPTH_PROCESSING = "depth_processing"
        PROCESSING = "processing"
        IO_OPERATIONS = "io_operations"
    
    # ğŸ”§ ErrorSeverity ã®å®Œå…¨å®Ÿè£…
    class ErrorSeverity:
        LOW = "low"
        MEDIUM = "medium"
        HIGH = "high"
        CRITICAL = "critical"
    
    # Line 89-250ä»˜è¿‘ã®ResponseBuilderã‚¯ãƒ©ã‚¹ã‚’ä»¥ä¸‹ã§å®Œå…¨ç½®æ›:

    class ResponseBuilder:
        """çµ±ä¸€ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãƒ“ãƒ«ãƒ€ãƒ¼ï¼ˆå®Œå…¨å¾Œæ–¹äº’æ›ç‰ˆï¼‰"""

        @staticmethod
        def success(data=None, message=""):
            """æˆåŠŸãƒ¬ã‚¹ãƒãƒ³ã‚¹"""
            return {"success": True, "data": data, "message": message}

        @staticmethod
        def error(
            error=None,
            include_traceback: bool = True,
            suggestions=None,
            message=None,                         # ğŸ”§ yolopose_analyzerç”¨
            details=None,                         # ğŸ”§ yolopose_analyzerç”¨
            exception=None,                       # ğŸ”§ å¾Œæ–¹äº’æ›æ€§
            **kwargs                              # ğŸ”§ å®Œå…¨äº’æ›ã®ãŸã‚
        ):
            """ã‚¨ãƒ©ãƒ¼ãƒ¬ã‚¹ãƒãƒ³ã‚¹ï¼ˆå®Œå…¨äº’æ›APIï¼‰"""
    
            # å¼•æ•°ã®æ­£è¦åŒ–ï¼ˆè¤‡æ•°ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã«å¯¾å¿œï¼‰
            target_error = error or exception
    
            if message:
                # messageãŒç›´æ¥æŒ‡å®šã•ã‚ŒãŸå ´åˆï¼ˆyolopose_analyzerç”¨ï¼‰
                response = {
                    "success": False,
                    "error": {
                        "error_type": "CustomError",
                        "message": message,
                        "category": "unknown",
                        "severity": "error",
                        "timestamp": datetime.now().isoformat()
                    }
                }
            elif hasattr(target_error, 'to_dict') and callable(getattr(target_error, 'to_dict')):
                # BaseYOLOErrorã®å ´åˆ
                response = {
                    "success": False,
                    "error": target_error.to_dict()
                }
            elif isinstance(target_error, Exception):
                # æ¨™æº–Exceptionã®å ´åˆ
                response = {
                    "success": False,
                    "error": {
                        "error_type": type(target_error).__name__,
                        "message": str(target_error),
                        "category": "unknown",
                        "severity": "error",
                        "timestamp": datetime.now().isoformat()
                    }
                }
        
                if include_traceback:
                    import traceback
                    response["error"]["traceback"] = traceback.format_exc()
            elif isinstance(target_error, str):
                # æ–‡å­—åˆ—ã‚¨ãƒ©ãƒ¼ã®å ´åˆ
                response = {
                    "success": False,
                    "error": {
                        "error_type": "StringError",
                        "message": target_error,
                        "category": "unknown", 
                        "severity": "error",
                        "timestamp": datetime.now().isoformat()
                    }
                }
            else:
                # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
                response = {
                    "success": False,
                    "error": {
                        "error_type": "UnknownError",
                        "message": "ä¸æ˜ãªã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ",
                        "category": "unknown",
                        "severity": "error",
                        "timestamp": datetime.now().isoformat()
                    }
                }
    
            # suggestionsè¿½åŠ 
            if suggestions:
                response["suggestions"] = suggestions
        
            # detailsè¿½åŠ ï¼ˆé‡è¦ï¼ï¼‰
            if details:
                response["details"] = details
        
            # ãã®ä»–ã®kwargså¯¾å¿œ
            for key, value in kwargs.items():
                if key not in response:
                    response[key] = value
        
            return response

        @staticmethod
        def validation_error(field=None, message=None, details=None, **kwargs):
            """ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã‚¨ãƒ©ãƒ¼ï¼ˆå®Œå…¨å¾Œæ–¹äº’æ›ï¼‰"""
            if message:
                error_message = message
            elif field:
                error_message = f"ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã‚¨ãƒ©ãƒ¼: {field}"
            else:
                error_message = "ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã‚¨ãƒ©ãƒ¼"
            
            response = {
                "success": False,
                "error": {
                    "error_type": "ValidationError",
                    "message": error_message,
                    "field": field,
                    "category": "validation",
                    "severity": "error",
                    "timestamp": datetime.now().isoformat()
                }
            }
        
            # detailså¼•æ•°ã®ã‚µãƒãƒ¼ãƒˆï¼ˆé‡è¦ï¼ï¼‰
            if details:
                response["details"] = details
            
            # ãã®ä»–ã®kwargså¯¾å¿œ
            for key, value in kwargs.items():
                if key not in response:
                    response[key] = value
            
            return response

        @staticmethod
        def processing_error(step=None, message=None, details=None, **kwargs):
            """å‡¦ç†ã‚¨ãƒ©ãƒ¼ï¼ˆå®Œå…¨äº’æ›ï¼‰"""
            error_message = message or f"å‡¦ç†ã‚¨ãƒ©ãƒ¼: {step}"
            result = {
                "success": False,
                "error": {
                    "error_type": "ProcessingError", 
                    "message": error_message,
                    "step": step,
                    "category": "processing",
                    "severity": "error",
                    "timestamp": datetime.now().isoformat()
               }
            }
        
            if details:
                result["details"] = details
            
            # ãã®ä»–ã®kwargså¯¾å¿œ
            for key, value in kwargs.items():
                if key not in result:
                    result[key] = value
            
            return result

        @staticmethod
        def configuration_error(config_key=None, message=None, details=None, **kwargs):
            """è¨­å®šã‚¨ãƒ©ãƒ¼ï¼ˆå®Œå…¨äº’æ›ï¼‰"""
            error_message = message or f"è¨­å®šã‚¨ãƒ©ãƒ¼: {config_key}"
            result = {
                "success": False,
                "error": {
                    "error_type": "ConfigurationError",
                    "message": error_message,
                    "config_key": config_key,
                    "category": "configuration",
                    "severity": "error",
                    "timestamp": datetime.now().isoformat()
                }
            }
        
            if details:
                result["details"] = details
            
            # ãã®ä»–ã®kwargså¯¾å¿œ
            for key, value in kwargs.items():
                if key not in result:
                    result[key] = value
            
            return result

        @staticmethod
        def model_error(model_path=None, message=None, details=None, **kwargs):
            """ãƒ¢ãƒ‡ãƒ«ã‚¨ãƒ©ãƒ¼ï¼ˆå®Œå…¨äº’æ›ï¼‰"""
            error_message = message or f"ãƒ¢ãƒ‡ãƒ«ã‚¨ãƒ©ãƒ¼: {model_path}"
            result = {
                "success": False,
                "error": {
                    "error_type": "ModelError",
                    "message": error_message,
                    "model_path": model_path,
                    "category": "model",
                    "severity": "error",
                    "timestamp": datetime.now().isoformat()
                }
            }
        
            if details:
                result["details"] = details
            
            # ãã®ä»–ã®kwargså¯¾å¿œ
            for key, value in kwargs.items():
                if key not in result:
                    result[key] = value
            
            return result
    
    class ErrorContext:
        def __init__(self, name, logger=None, raise_on_error=False):
            self.name = name
            self.logger = logger or logging.getLogger(__name__)
            self.raise_on_error = raise_on_error
            
        def __enter__(self):
            self.logger.debug(f"ğŸ” ã‚¨ãƒ©ãƒ¼ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆé–‹å§‹: {self.name}")
            return self
            
        def __exit__(self, exc_type, exc_val, exc_tb):
            if exc_type and self.logger:
                self.logger.error(f"âŒ ã‚¨ãƒ©ãƒ¼ in {self.name}: {exc_val}")
            elif self.logger:
                self.logger.debug(f"âœ… ã‚¨ãƒ©ãƒ¼ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæ­£å¸¸çµ‚äº†: {self.name}")
            return not self.raise_on_error
        
        def add_info(self, key, value):
            self.logger.debug(f"ğŸ“ {self.name} - {key}: {value}")

    class ErrorReporter:
        def __init__(self):
            self.errors = []
        
        def add_error(self, error, context=None):
            self.errors.append({"error": str(error), "context": context, "timestamp": datetime.now().isoformat()})

# ğŸ”§ æ¡ä»¶ä»˜ãã‚¤ãƒ³ãƒãƒ¼ãƒˆ - è©•ä¾¡å™¨ï¼ˆå®Œå…¨çµ±åˆç‰ˆï¼‰
EVALUATOR_AVAILABLE = False
DEPTH_EVALUATOR_AVAILABLE = False
COMPREHENSIVE_EVALUATOR_AVAILABLE = False
ComprehensiveEvaluator = None
DepthEnhancedEvaluator = None

try:
    # evaluatorsãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®æ®µéšçš„ãƒã‚§ãƒƒã‚¯
    import evaluators
    print("âœ… evaluators ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸ")
    
    try:
        from evaluators.comprehensive_evaluator import ComprehensiveEvaluator
        COMPREHENSIVE_EVALUATOR_AVAILABLE = True
        EVALUATOR_AVAILABLE = True
        print("âœ… ComprehensiveEvaluator ãŒåˆ©ç”¨å¯èƒ½ã§ã™")
        
        try:
            from evaluators.comprehensive_evaluator import DepthEnhancedEvaluator
            DEPTH_EVALUATOR_AVAILABLE = True
            print("âœ… DepthEnhancedEvaluator ãŒåˆ©ç”¨å¯èƒ½ã§ã™")
        except (ImportError, AttributeError) as e:
            print(f"âš ï¸ DepthEnhancedEvaluator ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“: {e}")
            DEPTH_EVALUATOR_AVAILABLE = False
            
    except ImportError as e:
        print(f"âš ï¸ ComprehensiveEvaluator ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆã«å¤±æ•—: {e}")
        COMPREHENSIVE_EVALUATOR_AVAILABLE = False
        EVALUATOR_AVAILABLE = False
        
except ImportError as e:
    print(f"âš ï¸ evaluators ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {e}")
    EVALUATOR_AVAILABLE = False
    COMPREHENSIVE_EVALUATOR_AVAILABLE = False
    DEPTH_EVALUATOR_AVAILABLE = False

# ğŸ”§ æ¡ä»¶ä»˜ãã‚¤ãƒ³ãƒãƒ¼ãƒˆ - è¨­å®šç®¡ç†ï¼ˆå®Œå…¨çµ±åˆç‰ˆï¼‰
CONFIG_AVAILABLE = False
Config = None

try:
    from utils.config import Config
    CONFIG_AVAILABLE = True
    print("âœ… Config ãŒåˆ©ç”¨å¯èƒ½ã§ã™")
except ImportError as e:
    print(f"âš ï¸ Config ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {e}")
    print("ğŸ”§ åŸºæœ¬è¨­å®šæ©Ÿèƒ½ã‚’ä½¿ç”¨ã—ã¾ã™")
    CONFIG_AVAILABLE = False

# ğŸ”§ BasicEvaluatorï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”¨ãƒ»å®Œå…¨ç‰ˆï¼‰
if not EVALUATOR_AVAILABLE:
    print("ğŸ”§ åŸºæœ¬è©•ä¾¡æ©Ÿèƒ½ã‚’ä½¿ç”¨ã—ã¾ã™")
    
    class BasicEvaluator:
        def __init__(self, config=None):
            self.config = config or {}
            self.results = {}
            self.logger = logging.getLogger(__name__)
        
        def evaluate_comprehensive(self, video_path, detection_results, video_name):
            """åŸºæœ¬çš„ãªè©•ä¾¡ï¼ˆå®Œå…¨ç‰ˆï¼‰"""
            try:
                self.logger.info(f"ğŸ” åŸºæœ¬è©•ä¾¡é–‹å§‹: {video_name}")
                
                # ãƒ‡ãƒ¼ã‚¿æŠ½å‡ºã®æ”¹å–„
                if isinstance(detection_results, dict):
                    if detection_results.get("success", False):
                        data = detection_results.get("data", {})
                    else:
                        self.logger.warning("detection_results ãŒå¤±æ•—çŠ¶æ…‹ã§ã™")
                        data = {}
                else:
                    data = {}
                
                csv_path = data.get("csv_path") or data.get("enhanced_csv_path")
                
                basic_metrics = {
                    "video_name": video_name,
                    "video_path": str(video_path),
                    "detection_count": data.get("detection_count", 0),
                    "frame_count": data.get("frame_count", 0),
                    "processing_time": data.get("processing_time", 0),
                    "timestamp": datetime.now().isoformat(),
                    "evaluator_type": "BasicEvaluator",
                    "depth_enabled": data.get("depth_enabled", False),
                    "processing_stats": data.get("processing_stats", {})
                }
                
                # CSVãƒ•ã‚¡ã‚¤ãƒ«åˆ†æã®æ”¹å–„
                if csv_path and Path(csv_path).exists():
                    try:
                        df = pd.read_csv(csv_path)
                        self.logger.info(f"ğŸ“Š CSVåˆ†æ: {len(df)}è¡Œã®ãƒ‡ãƒ¼ã‚¿")
                        
                        csv_metrics = {
                            "total_detections": len(df),
                            "detection_success": True,
                            "csv_path": str(csv_path)
                        }
                        
                        # ã‚«ãƒ©ãƒ ãƒ™ãƒ¼ã‚¹ã®è©³ç´°åˆ†æ
                        available_columns = df.columns.tolist()
                        csv_metrics["available_columns"] = available_columns
                        
                        if 'track_id' in df.columns:
                            csv_metrics["unique_track_ids"] = df['track_id'].nunique()
                        
                        if 'confidence' in df.columns:
                            csv_metrics["confidence_mean"] = float(df['confidence'].mean())
                            csv_metrics["confidence_std"] = float(df['confidence'].std())
                            csv_metrics["confidence_min"] = float(df['confidence'].min())
                            csv_metrics["confidence_max"] = float(df['confidence'].max())
                        
                        # æ·±åº¦é–¢é€£ã‚«ãƒ©ãƒ ã®è©³ç´°ç¢ºèª
                        depth_columns = [col for col in df.columns if 'depth' in col.lower()]
                        if depth_columns:
                            csv_metrics["depth_columns"] = depth_columns
                            csv_metrics["depth_analysis_available"] = True
                            # æ·±åº¦ãƒ‡ãƒ¼ã‚¿ã®çµ±è¨ˆ
                            for depth_col in depth_columns:
                                if df[depth_col].dtype in ['float64', 'int64']:
                                    csv_metrics[f"{depth_col}_mean"] = float(df[depth_col].mean())
                        
                        basic_metrics.update(csv_metrics)
                        
                    except Exception as e:
                        self.logger.warning(f"CSVåˆ†æã‚¨ãƒ©ãƒ¼: {e}")
                        basic_metrics.update({
                            "detection_success": False,
                            "csv_error": str(e),
                            "csv_path": str(csv_path) if csv_path else None
                        })
                else:
                    self.logger.warning(f"CSV ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {csv_path}")
                    basic_metrics["csv_available"] = False
                
                self.logger.info(f"âœ… åŸºæœ¬è©•ä¾¡å®Œäº†: {video_name}")
                return ResponseBuilder.success(data=basic_metrics)
                
            except Exception as e:
                self.logger.error(f"âŒ åŸºæœ¬è©•ä¾¡ã‚¨ãƒ©ãƒ¼: {e}")
                return ResponseBuilder.error(e, suggestions=[
                    "è©•ä¾¡ãƒ‡ãƒ¼ã‚¿ã®å½¢å¼ã‚’ç¢ºèªã—ã¦ãã ã•ã„",
                    "CSVãƒ•ã‚¡ã‚¤ãƒ«ãŒæ­£ã—ãç”Ÿæˆã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„",
                    "å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ã®å‹ã‚’ç¢ºèªã—ã¦ãã ã•ã„"
                ])
        
        def evaluate_with_depth(self, video_path, detection_results, video_name):
            """æ·±åº¦å¯¾å¿œè©•ä¾¡ï¼ˆBasicEvaluatorç‰ˆï¼‰"""
            self.logger.info(f"ğŸ” æ·±åº¦å¯¾å¿œåŸºæœ¬è©•ä¾¡: {video_name}")
            result = self.evaluate_comprehensive(video_path, detection_results, video_name)
            
            if result.get("success", False):
                result["data"]["depth_evaluator_type"] = "BasicEvaluator"
                result["data"]["depth_support"] = "limited"
            
            return result

# ğŸ”§ æ¡ä»¶ä»˜ãã‚¤ãƒ³ãƒãƒ¼ãƒˆ - ãƒ—ãƒ­ã‚»ãƒƒã‚µãƒ¼ï¼ˆå®Œå…¨çµ±åˆç‰ˆï¼‰
VIDEO_PROCESSOR_AVAILABLE = False
VideoProcessor = None

try:
    from processors.video_processor import VideoProcessor
    VIDEO_PROCESSOR_AVAILABLE = True
    print("âœ… VideoProcessor ãŒåˆ©ç”¨å¯èƒ½ã§ã™")
except ImportError as e:
    print(f"âš ï¸ VideoProcessor ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {e}")
    print("ğŸ”§ åŸºæœ¬å‹•ç”»å‡¦ç†ã‚’ä½¿ç”¨ã—ã¾ã™")
    VIDEO_PROCESSOR_AVAILABLE = False

# ğŸ”§ BasicVideoProcessorï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”¨ãƒ»å®Œå…¨ç‰ˆï¼‰
if not VIDEO_PROCESSOR_AVAILABLE:
    class BasicVideoProcessor:
        def __init__(self, config):
            """åŸºæœ¬å‹•ç”»ãƒ—ãƒ­ã‚»ãƒƒã‚µãƒ¼åˆæœŸåŒ–ï¼ˆå®Œå…¨ç‰ˆï¼‰"""
            self.config = config
            self.logger = logging.getLogger(__name__)
            self.processing_stats = {}  # ğŸ”§ çµ±è¨ˆæƒ…å ±è¾æ›¸ã‚’åˆæœŸåŒ–
    
            if hasattr(config, 'get'):
                self.output_dir = Path(config.get('output_dir', 'outputs'))
                self.max_frames = config.get('processing.max_frames', 100)
            else:
                self.output_dir = Path('outputs')
                self.max_frames = 100
    
            self.output_dir.mkdir(exist_ok=True)
            self.logger.info(f"ğŸ¬ åŸºæœ¬å‹•ç”»ãƒ—ãƒ­ã‚»ãƒƒã‚µãƒ¼åˆæœŸåŒ–å®Œäº†")
        
        def load_models(self):
            """ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰ï¼ˆæ”¹å–„ç‰ˆï¼‰"""
            try:
                if hasattr(self.config, 'get'):
                    models_config = self.config.get('models', {})
                elif isinstance(self.config, dict):
                    models_config = self.config.get('models', {})
                else:
                    models_config = {}
                
                detection_path = models_config.get('detection', 'models/yolo/yolo11x.pt')
                pose_path = models_config.get('pose', 'models/yolo/yolo11x-pose.pt')
                
                self.logger.info(f"ğŸ” ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰é–‹å§‹")
                
                # æ¤œå‡ºãƒ¢ãƒ‡ãƒ«
                if Path(detection_path).exists():
                    self.detection_model = YOLO(detection_path)
                    self.logger.info(f"âœ… æ¤œå‡ºãƒ¢ãƒ‡ãƒ«: {detection_path}")
                else:
                    self.logger.warning(f"âš ï¸ æ¤œå‡ºãƒ¢ãƒ‡ãƒ«æœªç™ºè¦‹: {detection_path}")
                
                # ãƒãƒ¼ã‚ºãƒ¢ãƒ‡ãƒ«
                if Path(pose_path).exists():
                    self.pose_model = YOLO(pose_path)
                    self.logger.info(f"âœ… ãƒãƒ¼ã‚ºãƒ¢ãƒ‡ãƒ«: {pose_path}")
                else:
                    self.logger.warning(f"âš ï¸ ãƒãƒ¼ã‚ºãƒ¢ãƒ‡ãƒ«æœªç™ºè¦‹: {pose_path}")
                    
            except Exception as e:
                self.logger.error(f"âŒ ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼: {e}")
        
        # BasicVideoProcessor ã® extract_frames ãƒ¡ã‚½ãƒƒãƒ‰ã‚’ä¿®æ­£:

        def extract_frames(self, video_path, frame_dir, max_frames=1000):
            """ãƒ•ãƒ¬ãƒ¼ãƒ æŠ½å‡ºï¼ˆçµ±è¨ˆä¿®æ­£ç‰ˆï¼‰"""
            try:
                # ğŸ”§ processing_statsã®ç¢ºå®ŸãªåˆæœŸåŒ–
                if not hasattr(self, 'processing_stats'):
                    self.processing_stats = {}
            
                self.logger.info(f"ğŸ“¸ ãƒ•ãƒ¬ãƒ¼ãƒ æŠ½å‡ºé–‹å§‹: {video_path}")
                frame_dir = Path(frame_dir)
                frame_dir.mkdir(parents=True, exist_ok=True)

                # å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã®å­˜åœ¨ç¢ºèª
                if not Path(video_path).exists():
                    self.logger.error(f"âŒ å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ã¾ã›ã‚“: {video_path}")
                    return {"success": False, "error": f"å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ã¾ã›ã‚“: {video_path}"}

                # ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºãƒã‚§ãƒƒã‚¯
                file_size = Path(video_path).stat().st_size
                if file_size == 0:
                    self.logger.error(f"âŒ å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ãŒç©ºã§ã™: {video_path}")
                    return {"success": False, "error": f"å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ãŒç©ºã§ã™: {video_path}"}

                self.logger.info(f"ğŸ“¹ å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: {file_size / (1024*1024):.1f}MB")

                # ğŸ”§ OpenCVã§ãƒ•ãƒ¬ãƒ¼ãƒ æŠ½å‡º
                cap = cv2.VideoCapture(str(video_path))
                if not cap.isOpened():
                    self.logger.error(f"âŒ å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é–‹ã‘ã¾ã›ã‚“: {video_path}")
                    return {"success": False, "error": f"å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é–‹ã‘ã¾ã›ã‚“: {video_path}"}

                # å‹•ç”»æƒ…å ±å–å¾—
                frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
                fps = cap.get(cv2.CAP_PROP_FPS)
                width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
                height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
                duration = frame_count / fps if fps > 0 else 0

                self.logger.info(f"ğŸ“¹ å‹•ç”»æƒ…å ±: {width}x{height}, {frame_count}ãƒ•ãƒ¬ãƒ¼ãƒ , {fps:.1f}FPS, {duration:.1f}ç§’")

                # ãƒ•ãƒ¬ãƒ¼ãƒ æ•°ãŒ0ã®å ´åˆã®ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°
                if frame_count <= 0:
                    cap.release()
                    self.logger.error(f"âŒ æœ‰åŠ¹ãªãƒ•ãƒ¬ãƒ¼ãƒ ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {video_path}")
                    return {"success": False, "error": "æœ‰åŠ¹ãªãƒ•ãƒ¬ãƒ¼ãƒ ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“"}

                # æŠ½å‡ºé–“éš”è¨ˆç®—
                interval = max(1, frame_count // max_frames)
                self.logger.info(f"ğŸ”¢ æŠ½å‡ºé–“éš”: {interval} (æœ€å¤§{max_frames}ãƒ•ãƒ¬ãƒ¼ãƒ )")

                # ãƒ•ãƒ¬ãƒ¼ãƒ æŠ½å‡ºãƒ«ãƒ¼ãƒ—
                extracted = 0
                frame_number = 0

                while True:
                    ret, frame = cap.read()
                    if not ret:
                        break

                    if frame_number % interval == 0:
                        frame_path = frame_dir / f"frame_{frame_number:06d}.jpg"
                        success = cv2.imwrite(str(frame_path), frame)

                        if success:
                            extracted += 1
                            if extracted >= max_frames:
                                break
                        else:
                            self.logger.warning(f"âš ï¸ ãƒ•ãƒ¬ãƒ¼ãƒ ä¿å­˜å¤±æ•—: {frame_path}")
            
                    frame_number += 1

                cap.release()

                # ğŸ”§ å®Ÿéš›ã«ä¿å­˜ã•ã‚ŒãŸãƒ•ãƒ¬ãƒ¼ãƒ æ•°ã‚’å†ç¢ºèªï¼ˆé‡è¦ï¼ï¼‰
                saved_frames = len(list(frame_dir.glob("frame_*.jpg")))
                self.logger.info(f"ğŸ“Š OpenCVã§æŠ½å‡º: {extracted}å€‹")
                self.logger.info(f"ğŸ“Š å®Ÿéš›ã«ä¿å­˜: {saved_frames}å€‹")

                # ğŸ”§ æœ€å¤§å€¤ã‚’æ¡ç”¨ï¼ˆç¢ºå®Ÿã«ãƒ•ãƒ¬ãƒ¼ãƒ æ•°ã‚’å–å¾—ï¼‰
                final_extracted = max(extracted, saved_frames)

                # çµ±è¨ˆæƒ…å ±ã®æ›´æ–°
                self.processing_stats["frame_extraction"] = {
                    "total_frames": frame_count,
                    "extracted_frames": final_extracted,  # â† ç¢ºå®Ÿãªå€¤
                    "video_fps": fps,
                    "video_duration": duration,
                    "resolution": [width, height],
                    "extraction_interval": interval
                }

                self.logger.info(f"âœ… ãƒ•ãƒ¬ãƒ¼ãƒ æŠ½å‡ºå®Œäº†: {final_extracted}ãƒ•ãƒ¬ãƒ¼ãƒ ")

                if final_extracted == 0:
                    self.logger.error("âŒ ãƒ•ãƒ¬ãƒ¼ãƒ æŠ½å‡ºã«å¤±æ•—ã—ã¾ã—ãŸ")
                    return {"success": False, "error": "ãƒ•ãƒ¬ãƒ¼ãƒ æŠ½å‡ºã«å¤±æ•—ã—ã¾ã—ãŸ"}

                # ğŸ”§ ç¢ºå®Ÿã«extracted_framesã‚’è¿”ã™
                return {
                    "success": True, 
                    "extracted_frames": final_extracted,  # â† é‡è¦ï¼šã“ã®å€¤ãŒ0ã«ãªã£ã¦ã¯ã„ã‘ãªã„
                    "video_info": self.processing_stats["frame_extraction"]
                }

            except Exception as e:
                self.logger.error(f"âŒ ãƒ•ãƒ¬ãƒ¼ãƒ æŠ½å‡ºã‚¨ãƒ©ãƒ¼: {e}")
                return {"success": False, "error": str(e)}
        
        def run_detection_tracking(self, frame_dir, video_name):
            """åŸºæœ¬æ¤œå‡ºãƒ»è¿½è·¡å‡¦ç†ï¼ˆå®‰å®šåŒ–ç‰ˆï¼‰"""
            try:
                self.logger.info(f"ğŸ‘ï¸ åŸºæœ¬æ¤œå‡ºãƒ»è¿½è·¡å‡¦ç†é–‹å§‹: {video_name}")
                frame_files = sorted(list(Path(frame_dir).glob("*.jpg")))
        
                if not frame_files:
                    raise VideoProcessingError(f"ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {frame_dir}")
        
                self.logger.info(f"ğŸ“¸ å‡¦ç†å¯¾è±¡ãƒ•ãƒ¬ãƒ¼ãƒ : {len(frame_files)}å€‹")
        
                # ãƒ¢ãƒ‡ãƒ«ã®äº‹å‰ãƒ­ãƒ¼ãƒ‰ç¢ºèª
                if not hasattr(self, 'detection_model') and not hasattr(self, 'pose_model'):
                    self.load_models()
        
                detection_count = 0
                frame_stats = []
        
                # ä¿¡é ¼åº¦ã—ãã„å€¤ï¼ˆã‚ˆã‚Šä½ãè¨­å®šã—ã¦æ¤œå‡ºç‡å‘ä¸Šï¼‰
                conf_threshold = 0.25
        
                # ğŸ”§ ç°¡ç•¥åŒ–ã•ã‚ŒãŸå‡¦ç†ãƒ«ãƒ¼ãƒ—
                for i, frame_file in enumerate(frame_files):
                    try:
                        # ãƒ•ãƒ¬ãƒ¼ãƒ èª­ã¿è¾¼ã¿
                        frame = cv2.imread(str(frame_file))
                        if frame is None:
                            self.logger.warning(f"âš ï¸ ãƒ•ãƒ¬ãƒ¼ãƒ èª­ã¿è¾¼ã¿å¤±æ•—: {frame_file}")
                            continue
                
                        frame_detections = 0
                
                        # ğŸ”§ ãƒãƒ¼ã‚ºãƒ¢ãƒ‡ãƒ«å„ªå…ˆï¼ˆã‚ˆã‚Šç¢ºå®Ÿï¼‰
                        if hasattr(self, 'pose_model') and self.pose_model:
                            try:
                                results = self.pose_model(frame, verbose=False, conf=conf_threshold)
                                if results and len(results[0].boxes) > 0:
                                    frame_detections = len(results[0].boxes)
                                    detection_count += frame_detections
                            except Exception as e:
                                self.logger.debug(f"ãƒ•ãƒ¬ãƒ¼ãƒ {i}ãƒãƒ¼ã‚ºæ¤œå‡ºã‚¨ãƒ©ãƒ¼: {e}")
                
                        # ãƒ•ãƒ¬ãƒ¼ãƒ çµ±è¨ˆè¨˜éŒ²ï¼ˆç°¡ç•¥åŒ–ï¼‰
                        frame_stats.append({
                            "frame_id": i,
                            "frame_file": frame_file.name,
                            "detections": frame_detections,
                            "conf": conf_threshold,  # å›ºå®šå€¤
                            "track_id": i,  # ç°¡æ˜“ID
                            "timestamp": datetime.now().isoformat()
                        })
                
                    except Exception as e:
                        self.logger.warning(f"ãƒ•ãƒ¬ãƒ¼ãƒ {i}å‡¦ç†ã‚¨ãƒ©ãƒ¼ï¼ˆç¶šè¡Œï¼‰: {e}")
                        continue
        
                # çµæœCSVä½œæˆ
                output_dir = Path("outputs/temp") / video_name
                output_dir.mkdir(parents=True, exist_ok=True)
                csv_path = output_dir / f"{video_name}_results.csv"
        
                if frame_stats:
                    df = pd.DataFrame(frame_stats)
                    df.to_csv(csv_path, index=False)
                    self.logger.info(f"ğŸ“Š çµæœCSVä¿å­˜: {csv_path}")
                else:
                    # ğŸ”§ ç©ºã®å ´åˆã§ã‚‚CSVã‚’ä½œæˆ
                    empty_df = pd.DataFrame(columns=["frame_id", "frame_file", "detections", "conf", "track_id", "timestamp"])
                    empty_df.to_csv(csv_path, index=False)
                    self.logger.warning("âš ï¸ æ¤œå‡ºçµæœãªã— - ç©ºã®CSVã‚’ä½œæˆ")
        
                # çµ±è¨ˆæƒ…å ±
                self.processing_stats = {
                    "detection_tracking": {
                        "total_frames": len(frame_files),
                        "processed_frames": len(frame_stats),
                        "total_detections": detection_count,
                        "success_rate": len(frame_stats) / len(frame_files) if frame_files else 0
                    }
                }
        
                self.logger.info(f"âœ… åŸºæœ¬æ¤œå‡ºãƒ»è¿½è·¡å®Œäº†: {detection_count}å€‹æ¤œå‡º / {len(frame_stats)}ãƒ•ãƒ¬ãƒ¼ãƒ å‡¦ç†")
        
                return {
                    "success": True,
                    "data": {
                        "csv_path": str(csv_path),
                        "detection_count": detection_count,
                        "frame_count": len(frame_files),
                        "processed_frames": len(frame_stats),
                        "processing_stats": self.processing_stats["detection_tracking"]
                    }
                }
        
            except Exception as e:
                self.logger.error(f"âŒ åŸºæœ¬æ¤œå‡ºãƒ»è¿½è·¡ã‚¨ãƒ©ãƒ¼: {e}")
                return {"success": False, "error": str(e)}
        
        def run_detection_tracking_with_depth(self, frame_dir, video_name):
            """æ·±åº¦çµ±åˆæ¤œå‡ºãƒ»è¿½è·¡å‡¦ç†ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç‰ˆï¼‰"""
            self.logger.warning("ğŸ”§ æ·±åº¦çµ±åˆå‡¦ç†ã¯åˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚é€šå¸¸å‡¦ç†ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã—ã¾ã™")
            result = self.run_detection_tracking(frame_dir, video_name)
            
            if result.get("success", False):
                result["data"]["depth_enabled"] = False
                result["data"]["depth_fallback"] = True
                result["data"]["enhanced_csv_path"] = result["data"]["csv_path"]
                self.logger.info("âœ… ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç†å®Œäº†ï¼ˆæ·±åº¦æ©Ÿèƒ½ç„¡åŠ¹ï¼‰")
            
            return result

# ğŸ”§ æ¡ä»¶ä»˜ãã‚¤ãƒ³ãƒãƒ¼ãƒˆ - ã‚¢ãƒŠãƒ©ã‚¤ã‚¶ãƒ¼ï¼ˆå®Œå…¨çµ±åˆç‰ˆï¼‰
METRICS_ANALYZER_AVAILABLE = False
MetricsAnalyzer = None

try:
    from analyzers.metrics_analyzer import MetricsAnalyzer
    METRICS_ANALYZER_AVAILABLE = True
    print("âœ… MetricsAnalyzer ãŒåˆ©ç”¨å¯èƒ½ã§ã™")
except ImportError as e:
    print(f"âš ï¸ MetricsAnalyzer ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {e}")
    print("ğŸ”§ åŸºæœ¬åˆ†ææ©Ÿèƒ½ã‚’ä½¿ç”¨ã—ã¾ã™")
    METRICS_ANALYZER_AVAILABLE = False

# ğŸ”§ BasicMetricsAnalyzerï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”¨ãƒ»å®Œå…¨ç‰ˆï¼‰
if not METRICS_ANALYZER_AVAILABLE:
    class BasicMetricsAnalyzer:
        def __init__(self, config):
            self.config = config
            self.logger = logging.getLogger(__name__)
        
        def analyze_improvements(self, comparison_results):
            """åŸºæœ¬æ”¹å–„åˆ†æï¼ˆå®Œå…¨ç‰ˆï¼‰"""
            self.logger.info("ğŸ“Š åŸºæœ¬æ”¹å–„åˆ†æé–‹å§‹")
            
            try:
                baseline = comparison_results.get("baseline", {})
                experiment = comparison_results.get("experiment", {})
                
                analysis = {
                    "analyzer_type": "BasicMetricsAnalyzer",
                    "comparison_available": bool(baseline and experiment),
                    "timestamp": datetime.now().isoformat()
                }
                
                if baseline and experiment:
                    # å‡¦ç†æ™‚é–“æ¯”è¼ƒ
                    baseline_time = baseline.get("processing_time", 0)
                    experiment_time = experiment.get("processing_time", 0)
                    
                    if baseline_time > 0:
                        time_improvement = ((baseline_time - experiment_time) / baseline_time) * 100
                        analysis["time_improvement_percent"] = time_improvement
                        analysis["time_comparison"] = {
                            "baseline_time": baseline_time,
                            "experiment_time": experiment_time,
                            "improvement": time_improvement
                        }
                    
                    # æ¤œå‡ºæ•°æ¯”è¼ƒ
                    baseline_detections = baseline.get("detection_count", 0)
                    experiment_detections = experiment.get("detection_count", 0)
                    
                    analysis["detection_comparison"] = {
                        "baseline": baseline_detections,
                        "experiment": experiment_detections,
                        "difference": experiment_detections - baseline_detections,
                        "improvement_rate": ((experiment_detections - baseline_detections) / baseline_detections * 100) if baseline_detections > 0 else 0
                    }
                    
                    # å“è³ªæ¯”è¼ƒ
                    analysis["quality_comparison"] = {
                        "baseline_success": baseline.get("success", False),
                        "experiment_success": experiment.get("success", False)
                    }
                
                self.logger.info("âœ… åŸºæœ¬æ”¹å–„åˆ†æå®Œäº†")
                return analysis
                
            except Exception as e:
                self.logger.error(f"âŒ æ”¹å–„åˆ†æã‚¨ãƒ©ãƒ¼: {e}")
                return {"basic_analysis": f"ã‚¨ãƒ©ãƒ¼: {e}", "error": True}
        
        # Line 845ä»˜è¿‘ã® create_visualizations ãƒ¡ã‚½ãƒƒãƒ‰ã‚’å®Œå…¨ç½®æ›:

        def create_visualizations(self, detection_results, vis_dir):
            """åŸºæœ¬å¯è¦–åŒ–ï¼ˆå®Œå…¨ç‰ˆãƒ»ç¢ºå®Ÿãªæˆ»ã‚Šå€¤ä»˜ãï¼‰"""
            self.logger.info(f"ğŸ“ˆ åŸºæœ¬å¯è¦–åŒ–ç”Ÿæˆ: {vis_dir}")
    
            # ğŸ”§ å¿…ãšæˆ»ã‚Šå€¤ã‚’è¿”ã™ã‚ˆã†ã«ã™ã‚‹
            result = {
                "success": False,
                "error": "åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼",
                "basic_stats_file": None,
                "graphs_generated": 0,
                "total_files": 0
            }
    
            try:
                from pathlib import Path
                import json
                from datetime import datetime
        
                # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
                vis_path = Path(str(vis_dir))
                vis_path.mkdir(parents=True, exist_ok=True)
                self.logger.info(f"ğŸ“ å¯è¦–åŒ–ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ: {vis_path}")
        
                # detection_results ã®è©³ç´°ãƒ­ã‚°
                self.logger.info(f"ğŸ”§ detection_results type: {type(detection_results)}")
        
                # CSVãƒ‘ã‚¹æŠ½å‡º
                csv_path = None
                data = {}
        
                if isinstance(detection_results, dict):
                    if detection_results.get("success", False):
                        data = detection_results.get("data", {})
                        csv_path = data.get("csv_path")
                
                        # ãƒã‚¹ãƒˆæ§‹é€ å¯¾å¿œ
                        if not csv_path and "detection_result" in data:
                            nested_data = data["detection_result"].get("data", {})
                            csv_path = nested_data.get("csv_path")
                    
                self.logger.info(f"ğŸ”§ æ¤œå‡ºã•ã‚ŒãŸCSVãƒ‘ã‚¹: {csv_path}")
        
                # åŸºæœ¬çµ±è¨ˆãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆï¼ˆå¿…ãšä½œæˆï¼‰
                stats_file = vis_path / "basic_stats.json"
                basic_stats = {
                    "visualization_type": "BasicVisualization",
                    "detection_count": data.get("detection_count", 0),
                    "frame_count": data.get("frame_count", 0),
                    "processing_time": data.get("processing_time", 0),
                    "processing_stats": data.get("processing_stats", {}),
                    "timestamp": datetime.now().isoformat(),
                    "csv_path": str(csv_path) if csv_path else None,
                    "success": detection_results.get("success", False) if isinstance(detection_results, dict) else False
                }
        
                with open(stats_file, 'w', encoding='utf-8') as f:
                    json.dump(basic_stats, f, indent=2, ensure_ascii=False)
                self.logger.info(f"âœ… åŸºæœ¬çµ±è¨ˆä¿å­˜: {stats_file}")
        
                # æˆ»ã‚Šå€¤æ›´æ–°
                result["basic_stats_file"] = str(stats_file)
                result["total_files"] = 1
        
                # çµ±è¨ˆã‚°ãƒ©ãƒ•ç”Ÿæˆ
                graphs_generated = 0
        
                try:
                    # matplotlib/pandas ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
                    import matplotlib
                    matplotlib.use('Agg')
                    import matplotlib.pyplot as plt
                    import pandas as pd
            
                    # ç°¡æ˜“ãƒ•ã‚©ãƒ³ãƒˆè¨­å®š
                    try:
                        plt.rcParams['font.family'] = 'Hiragino Sans'
                    except:
                        plt.rcParams['font.family'] = 'DejaVu Sans'
            
                    # CSV ãƒ•ã‚¡ã‚¤ãƒ«ã®å‡¦ç†
                    if csv_path and Path(csv_path).exists():
                        self.logger.info(f"ğŸ“Š CSVãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿: {csv_path}")
                        df = pd.read_csv(csv_path)
                        self.logger.info(f"ğŸ“Š ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿: {len(df)}è¡Œ, ã‚«ãƒ©ãƒ : {list(df.columns)}")
                
                        if not df.empty:
                            # 1. ãƒ•ãƒ¬ãƒ¼ãƒ åˆ¥æ¤œå‡ºæ•°ã‚°ãƒ©ãƒ•
                            if 'frame' in df.columns:
                                try:
                                    plt.figure(figsize=(12, 6))
                                    frame_counts = df['frame'].value_counts().sort_index()
                                    plt.plot(frame_counts.index, frame_counts.values, 
                                    marker='o', linewidth=2, markersize=4, color='blue')
                                    plt.title('Detection Count by Frame', fontsize=16, pad=20)
                                    plt.xlabel('Frame Number', fontsize=12)
                                    plt.ylabel('Detection Count', fontsize=12)
                                    plt.grid(True, alpha=0.3)
                                    plt.tight_layout()
                            
                                    timeline_path = vis_path / "detection_timeline.png"
                                    plt.savefig(timeline_path, dpi=300, bbox_inches='tight')
                                    plt.close()
                                    graphs_generated += 1
                                    self.logger.info(f"âœ… æ™‚ç³»åˆ—ã‚°ãƒ©ãƒ•ç”Ÿæˆ: {timeline_path}")
                                except Exception as e:
                                    self.logger.error(f"âŒ æ™‚ç³»åˆ—ã‚°ãƒ©ãƒ•ã‚¨ãƒ©ãƒ¼: {e}")
                    
                            # 2. ä¿¡é ¼åº¦åˆ†å¸ƒã‚°ãƒ©ãƒ•
                            if 'conf' in df.columns:
                                try:
                                    plt.figure(figsize=(10, 6))
                                    conf_data = df['conf'].dropna()
                                    plt.hist(conf_data, bins=30, alpha=0.7, color='green', edgecolor='black')
                                    plt.axvline(conf_data.mean(), color='red', linestyle='--', 
                                        label=f'Average: {conf_data.mean():.3f}')
                                    plt.title('Confidence Distribution', fontsize=16, pad=20)
                                    plt.xlabel('Confidence', fontsize=12)
                                    plt.ylabel('Frequency', fontsize=12)
                                    plt.legend()
                                    plt.grid(True, alpha=0.3)
                                    plt.tight_layout()
                            
                                    conf_path = vis_path / "confidence_distribution.png"
                                    plt.savefig(conf_path, dpi=300, bbox_inches='tight')
                                    plt.close()
                                    graphs_generated += 1
                                    self.logger.info(f"âœ… ä¿¡é ¼åº¦åˆ†å¸ƒã‚°ãƒ©ãƒ•ç”Ÿæˆ: {conf_path}")
                                except Exception as e:
                                    self.logger.error(f"âŒ ä¿¡é ¼åº¦åˆ†å¸ƒã‚°ãƒ©ãƒ•ã‚¨ãƒ©ãƒ¼: {e}")
                    
                            # 3. ã‚¯ãƒ©ã‚¹åˆ†å¸ƒã‚°ãƒ©ãƒ•
                            if 'class_name' in df.columns:
                                try:
                                    plt.figure(figsize=(12, 8))
                                    class_counts = df['class_name'].value_counts()
                                    class_counts.plot(kind='bar', color='skyblue', edgecolor='black')
                                    plt.title('Class Distribution', fontsize=16, pad=20)
                                    plt.xlabel('Class Name', fontsize=12)
                                    plt.ylabel('Detection Count', fontsize=12)
                                    plt.xticks(rotation=45)
                                    plt.tight_layout()
                            
                                    class_path = vis_path / "class_distribution.png"
                                    plt.savefig(class_path, dpi=300, bbox_inches='tight')
                                    plt.close()
                                    graphs_generated += 1
                                    self.logger.info(f"âœ… ã‚¯ãƒ©ã‚¹åˆ†å¸ƒã‚°ãƒ©ãƒ•ç”Ÿæˆ: {class_path}")
                                except Exception as e:
                                    self.logger.error(f"âŒ ã‚¯ãƒ©ã‚¹åˆ†å¸ƒã‚°ãƒ©ãƒ•ã‚¨ãƒ©ãƒ¼: {e}")
                
                        else:
                            self.logger.warning("âš ï¸ CSVãƒ‡ãƒ¼ã‚¿ãŒç©ºã§ã™")
                    else:
                        self.logger.warning(f"âš ï¸ CSVãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚‰ãªã„: {csv_path}")
                
                except ImportError as e:
                    self.logger.warning(f"âš ï¸ matplotlib/pandasã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
                except Exception as plot_error:
                    self.logger.error(f"âŒ ã‚°ãƒ©ãƒ•ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {plot_error}", exc_info=True)
        
                # æœ€çµ‚çµæœæ›´æ–°
                total_files = 1 + graphs_generated
                result.update({
                    "success": True,
                    "error": None,
                    "graphs_generated": graphs_generated,
                    "total_files": total_files
                })
        
                self.logger.info(f"ğŸ¨ å¯è¦–åŒ–ç”Ÿæˆå®Œäº†: åŸºæœ¬çµ±è¨ˆ1å€‹ + ã‚°ãƒ©ãƒ•{graphs_generated}å€‹ = åˆè¨ˆ{total_files}å€‹")
        
                # ğŸ”§ å¿…ãšè¾æ›¸ã‚’è¿”ã™
                return result
        
            except Exception as e:
                self.logger.error(f"âŒ å¯è¦–åŒ–ç”Ÿæˆå…¨ä½“ã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
                # ğŸ”§ ã‚¨ãƒ©ãƒ¼æ™‚ã‚‚è¾æ›¸ã‚’è¿”ã™
                result.update({
                    "success": False,
                    "error": str(e)
                })
                return result
                
        def _create_detection_charts(self, data, vis_path):
            """æ¤œå‡ºçµæœã®ãƒãƒ£ãƒ¼ãƒˆç”Ÿæˆ"""
            try:
                import matplotlib.pyplot as plt
                import pandas as pd
                import seaborn as sns
                
                # çµ±è¨ˆãƒ‡ãƒ¼ã‚¿ã®ç¢ºèª
                processing_stats = data.get("processing_stats", {})
                detection_count = data.get("detection_count", 0)
                
                # 1. åŸºæœ¬çµ±è¨ˆã‚°ãƒ©ãƒ•
                fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 12))
                
                # æ¤œå‡ºæ•°ã‚°ãƒ©ãƒ•
                ax1.bar(['æ¤œå‡ºæ•°'], [detection_count], color='skyblue')
                ax1.set_title('ç·æ¤œå‡ºæ•°')
                ax1.set_ylabel('ä»¶æ•°')
                
                # å‡¦ç†çµ±è¨ˆ
                if processing_stats:
                    stats_keys = list(processing_stats.keys())[:5]  # æœ€å¤§5é …ç›®
                    stats_values = [processing_stats[k] for k in stats_keys]
                    ax2.barh(stats_keys, stats_values, color='lightcoral')
                    ax2.set_title('å‡¦ç†çµ±è¨ˆ')
                    ax2.set_xlabel('å€¤')
                
                # ãƒ•ãƒ¬ãƒ¼ãƒ æ•°
                frame_count = data.get("frame_count", 0)
                ax3.pie([frame_count, max(1, 120 - frame_count)], 
                       labels=['å‡¦ç†æ¸ˆã¿', 'æœªå‡¦ç†'], autopct='%1.1f%%',
                       colors=['lightgreen', 'lightgray'])
                ax3.set_title('ãƒ•ãƒ¬ãƒ¼ãƒ å‡¦ç†çŠ¶æ³')
                
                # å‡¦ç†æ™‚é–“
                processing_time = data.get("processing_time", 0)
                ax4.bar(['å‡¦ç†æ™‚é–“'], [processing_time], color='gold')
                ax4.set_title('å‡¦ç†æ™‚é–“ (ç§’)')
                ax4.set_ylabel('ç§’')
                
                plt.tight_layout()
                plt.savefig(vis_path / "detection_summary.png", dpi=300, bbox_inches='tight')
                plt.close()
                
                self.logger.info(f"âœ… ã‚µãƒãƒªãƒ¼ãƒãƒ£ãƒ¼ãƒˆç”Ÿæˆ: detection_summary.png")
                
            except ImportError:
                self.logger.warning("âš ï¸ matplotlibæœªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ« - åŸºæœ¬çµ±è¨ˆã®ã¿ä¿å­˜")
            except Exception as e:
                self.logger.error(f"âŒ ãƒãƒ£ãƒ¼ãƒˆç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")

# ğŸ”§ BasicConfigï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”¨ãƒ»å®Œå…¨ç‰ˆï¼‰
if not CONFIG_AVAILABLE:
    class BasicConfig:
        def __init__(self, config_path=None):
            self.config_path = config_path
            self.data = self.load_config()
            self.logger = logging.getLogger(__name__)
        
        def load_config(self):
            """è¨­å®šãƒ­ãƒ¼ãƒ‰ï¼ˆå®Œå…¨ç‰ˆï¼‰"""
            logger = logging.getLogger(__name__)
            logger.info(f"âš™ï¸ è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿: {self.config_path}")
            
            if self.config_path and Path(self.config_path).exists():
                try:
                    with open(self.config_path, 'r', encoding='utf-8') as f:
                        if self.config_path.endswith(('.yaml', '.yml')):
                            config_data = yaml.safe_load(f)
                            logger.info("âœ… YAMLè¨­å®šãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿æˆåŠŸ")
                        else:
                            config_data = json.load(f)
                            logger.info("âœ… JSONè¨­å®šãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿æˆåŠŸ")
                    
                    return config_data
                    
                except Exception as e:
                    logger.warning(f"âš ï¸ è¨­å®šèª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
                    logger.info("ğŸ”§ ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šã‚’ä½¿ç”¨ã—ã¾ã™")
            else:
                logger.warning(f"âš ï¸ è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {self.config_path}")
                logger.info("ğŸ”§ ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šã‚’ä½¿ç”¨ã—ã¾ã™")
            
            # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šï¼ˆå®Œå…¨ç‰ˆï¼‰
            default_config = {
                "models": {
                    "detection": "models/yolo/yolo11x.pt",
                    "pose": "models/yolo/yolo11x-pose.pt"
                },
                "processing": {
                    "detection": {
                        "confidence_threshold": 0.3, 
                        "iou_threshold": 0.45,
                        "max_detections": 1000
                    },
                    "depth_estimation": {
                        "enabled": False,
                        "model": "midas_v21_small_256",
                        "model_path": "models/depth/midas_v21_small_256.pt"
                    },
                    "tile_inference": {
                        "enabled": False,
                        "tile_size": [640, 640],
                        "overlap": 0.1
                    }
                },
                "video_dir": "videos",
                "output_dir": "outputs",
                "logging": {
                    "level": "INFO",
                    "file": "logs/analysis.log"
                },
                "experiments": {
                    "comparison": {"type": "comparison", "description": "åŸºæœ¬æ¯”è¼ƒå®Ÿé¨“"},
                    "model_test": {"type": "model_test", "description": "ãƒ¢ãƒ‡ãƒ«æ€§èƒ½ãƒ†ã‚¹ãƒˆ"},
                    "tile_inference": {"type": "tile_inference", "description": "ã‚¿ã‚¤ãƒ«æ¨è«–ãƒ†ã‚¹ãƒˆ"}
                }
            }
            
            logger.info("âœ… ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šã‚’é©ç”¨ã—ã¾ã—ãŸ")
            return default_config
        
        def get(self, key, default=None):
            """è¨­å®šå€¤å–å¾—ï¼ˆãƒ‰ãƒƒãƒˆè¨˜æ³•å¯¾å¿œãƒ»å®Œå…¨ç‰ˆï¼‰"""
            keys = key.split('.')
            value = self.data
            for k in keys:
                if isinstance(value, dict) and k in value:
                    value = value[k]
                else:
                    return default
            return value
        
        def get_experiment_config(self, experiment_type):
            """å®Ÿé¨“è¨­å®šå–å¾—ï¼ˆå®Œå…¨ç‰ˆï¼‰"""
            experiment_configs = self.get("experiments", {})
            if experiment_type in experiment_configs:
                return experiment_configs[experiment_type]
            
            # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå®Ÿé¨“è¨­å®š
            return {
                "type": experiment_type,
                "basic_mode": True,
                "description": f"åŸºæœ¬å®Ÿé¨“: {experiment_type}",
                "enabled": True
            }
        
        @property
        def video_dir(self):
            return self.get("video_dir", "videos")

LOGGER_AVAILABLE = False
setup_logger = None

try:
    from utils.logger import setup_logger
    LOGGER_AVAILABLE = True
    print("âœ… setup_logger ãŒåˆ©ç”¨å¯èƒ½ã§ã™")
except ImportError as e:
    print(f"âš ï¸ setup_logger ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {e}")
    print("ğŸ”§ åŸºæœ¬ãƒ­ã‚°æ©Ÿèƒ½ã‚’ä½¿ç”¨ã—ã¾ã™")
    LOGGER_AVAILABLE = False

# ğŸ”§ åŸºæœ¬ãƒ­ã‚°è¨­å®šï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”¨ãƒ»å®Œå…¨ç‰ˆï¼‰
if not LOGGER_AVAILABLE:
    def setup_logger():
        """åŸºæœ¬ãƒ­ã‚°è¨­å®šï¼ˆå®Œå…¨ç‰ˆï¼‰"""
        # ãƒ­ã‚°ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
        log_dir = Path("logs")
        log_dir.mkdir(exist_ok=True)
        
        # ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«å
        log_file = log_dir / f"analysis_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log"
        
        # æ—¢å­˜ã®ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ã‚’ã‚¯ãƒªã‚¢
        logger = logging.getLogger()
        for handler in logger.handlers[:]:
            logger.removeHandler(handler)
        
        # ãƒ­ã‚°è¨­å®š
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler(log_file, encoding='utf-8'),
                logging.StreamHandler(sys.stdout)
            ]
        )
        
        logger = logging.getLogger(__name__)
        logger.info(f"ğŸ”§ åŸºæœ¬ãƒ­ã‚°æ©Ÿèƒ½ã‚’åˆæœŸåŒ–ã—ã¾ã—ãŸ: {log_file}")
        return logger

# âœ… ã“ã“ã§ã‚¯ãƒ©ã‚¹å®šç¾©é–‹å§‹ï¼ˆifæ–‡ã®å¤–ã€ã‚¤ãƒ³ãƒ‡ãƒ³ãƒˆ0ï¼‰
class ImprovedYOLOAnalyzer:
    """
    YOLO11 åºƒè§’ã‚«ãƒ¡ãƒ©åˆ†æã‚·ã‚¹ãƒ†ãƒ ï¼ˆå®Œå…¨çµ±åˆç‰ˆï¼‰
    - æ·±åº¦æ¨å®šçµ±åˆå¯¾å¿œ
    - ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ä¸è¶³å®Œå…¨å¯¾å¿œ
    - Stage 5/6ä¿®æ­£å®Œäº†
    - ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æ©Ÿèƒ½å®Œå…¨çµ±åˆ
    """

    # Line 834-854ã‚’ä¿®æ­£:

    def __init__(self, config_path: str = "configs/default.yaml"):
        """
        åˆæœŸåŒ–ï¼ˆå®Œå…¨çµ±åˆç‰ˆï¼‰

        Args:
            config_path: è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
        """
        # ğŸ”§ ãƒ­ã‚¬ãƒ¼ã‚’æœ€åˆã«åˆæœŸåŒ–
        self.logger = setup_logger()
    
        # ã‚¨ãƒ©ãƒ¼ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆè¨­å®š
        if ERROR_HANDLER_AVAILABLE:
            context_manager = ErrorContext("ImprovedYOLOAnalyzeråˆæœŸåŒ–", logger=self.logger)
        else:
            context_manager = self._basic_context("ImprovedYOLOAnalyzeråˆæœŸåŒ–")
        
        with context_manager as ctx:
            # è¨­å®šåˆæœŸåŒ–
            self.config = self._initialize_config(config_path)

            # æ·±åº¦æ¨å®šæœ‰åŠ¹æ€§ã®ç¢ºèª
            self.depth_enabled = self.config.get('processing.depth_estimation.enabled', False)
            self.logger.info(f"ğŸ” æ·±åº¦æ¨å®š: {'æœ‰åŠ¹' if self.depth_enabled else 'ç„¡åŠ¹'}")

            # è©•ä¾¡å™¨ã®é¸æŠã¨åˆæœŸåŒ–
            self._initialize_evaluator(ctx)
        
            # ãƒ—ãƒ­ã‚»ãƒƒã‚µãƒ¼ã¨ã‚¢ãƒŠãƒ©ã‚¤ã‚¶ãƒ¼åˆæœŸåŒ–
            self._initialize_processor_analyzer(ctx)

            # ã‚¨ãƒ©ãƒ¼åé›†ç”¨
            self.error_collector = []

            # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
            self._setup_directories()

            # åˆæœŸåŒ–å®Œäº†å ±å‘Š
            self._report_initialization(ctx)

    def _basic_context(self, name):
        """åŸºæœ¬ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼"""
        class BasicContext:
            def __init__(self, name):
                self.name = name
                self.logger = logging.getLogger(__name__)
            def __enter__(self):
                self.logger.debug(f"ğŸ” å‡¦ç†é–‹å§‹: {self.name}")
                return self
            def __exit__(self, exc_type, exc_val, exc_tb):
                if exc_type:
                    self.logger.error(f"âŒ ã‚¨ãƒ©ãƒ¼ in {self.name}: {exc_val}")
                else:
                    self.logger.debug(f"âœ… å‡¦ç†å®Œäº†: {self.name}")
                return False
            def add_info(self, key, value):
                self.logger.debug(f"ğŸ“ {self.name} - {key}: {value}")
        return BasicContext(name)

    # Line 857ã®_initialize_configãƒ¡ã‚½ãƒƒãƒ‰ã‚’ä¿®æ­£:

    def _initialize_config(self, config_path: str):
        """è¨­å®šåˆæœŸåŒ–ï¼ˆå®Œå…¨ç‰ˆï¼‰"""
        depth_config_path = "configs/depth_config.yaml"
    
        # âš ï¸ ã“ã“ã§ self.logger ã‚’ä½¿ã†å‰ã«ã€ãƒ­ã‚¬ãƒ¼ã‚’åˆæœŸåŒ–ã™ã‚‹å¿…è¦ãŒã‚ã‚‹
        logger = logging.getLogger(__name__)  # ğŸ”§ ä¸€æ™‚çš„ãªãƒ­ã‚¬ãƒ¼ä½¿ç”¨
        logger.info(f"âš™ï¸ è¨­å®šåˆæœŸåŒ–é–‹å§‹: {config_path}")
    
        # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®å„ªå…ˆé †ä½æ±ºå®š
        if Path(config_path).exists():
            primary_config = config_path
            logger.info(f"ğŸ“„ æŒ‡å®šè¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ä½¿ç”¨: {config_path}")
        elif Path(depth_config_path).exists():
            primary_config = depth_config_path
            logger.info(f"ğŸ” æ·±åº¦è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«è‡ªå‹•æ¤œå‡º: {depth_config_path}")
        else:
            primary_config = config_path
            logger.warning(f"âš ï¸ è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {config_path}")

        # è¨­å®šã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆåˆæœŸåŒ–
        if CONFIG_AVAILABLE and Config:
            return Config(primary_config)
        else:
            return BasicConfig(primary_config)

    def _initialize_evaluator(self, ctx):
        """è©•ä¾¡å™¨åˆæœŸåŒ–ï¼ˆå®Œå…¨ç‰ˆï¼‰"""
        if self.depth_enabled and DEPTH_EVALUATOR_AVAILABLE and DepthEnhancedEvaluator:
            try:
                self.evaluator = DepthEnhancedEvaluator(self.config)
                self.logger.info("ğŸ” æ·±åº¦çµ±åˆè©•ä¾¡å™¨ã‚’åˆæœŸåŒ–")
                if hasattr(ctx, 'add_info'):
                    ctx.add_info("evaluator_type", "DepthEnhancedEvaluator")
            except Exception as e:
                self.logger.warning(f"DepthEnhancedEvaluator åˆæœŸåŒ–å¤±æ•—: {e}")
                self._fallback_to_basic_evaluator(ctx)
        elif COMPREHENSIVE_EVALUATOR_AVAILABLE and ComprehensiveEvaluator:
            try:
                self.evaluator = ComprehensiveEvaluator(self.config)
                self.logger.info("ğŸ“Š æ¨™æº–è©•ä¾¡å™¨ã‚’åˆæœŸåŒ–")
                if hasattr(ctx, 'add_info'):
                    ctx.add_info("evaluator_type", "ComprehensiveEvaluator")
            except Exception as e:
                self.logger.warning(f"ComprehensiveEvaluator åˆæœŸåŒ–å¤±æ•—: {e}")
                self._fallback_to_basic_evaluator(ctx)
        else:
            self._fallback_to_basic_evaluator(ctx)

    def _fallback_to_basic_evaluator(self, ctx):
        """åŸºæœ¬è©•ä¾¡å™¨ã¸ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯"""
        self.evaluator = BasicEvaluator(self.config)
        self.logger.info("ğŸ”§ åŸºæœ¬è©•ä¾¡å™¨ã‚’åˆæœŸåŒ–")
        if hasattr(ctx, 'add_info'):
            ctx.add_info("evaluator_type", "BasicEvaluator")

    def _initialize_processor_analyzer(self, ctx):
        """ãƒ—ãƒ­ã‚»ãƒƒã‚µãƒ¼ãƒ»ã‚¢ãƒŠãƒ©ã‚¤ã‚¶ãƒ¼åˆæœŸåŒ–ï¼ˆå®Œå…¨ç‰ˆï¼‰"""
        # ãƒ—ãƒ­ã‚»ãƒƒã‚µãƒ¼åˆæœŸåŒ–
        if VIDEO_PROCESSOR_AVAILABLE and VideoProcessor:
            try:
                self.processor = VideoProcessor(self.config)
                self.logger.info("ğŸ¥ é«˜åº¦å‹•ç”»ãƒ—ãƒ­ã‚»ãƒƒã‚µãƒ¼ã‚’åˆæœŸåŒ–")
            except Exception as e:
                self.logger.warning(f"VideoProcessor åˆæœŸåŒ–å¤±æ•—: {e}")
                self.processor = BasicVideoProcessor(self.config)
                self.logger.info("ğŸ”§ åŸºæœ¬å‹•ç”»ãƒ—ãƒ­ã‚»ãƒƒã‚µãƒ¼ã‚’åˆæœŸåŒ–")
        else:
            self.processor = BasicVideoProcessor(self.config)
            self.logger.info("ğŸ”§ åŸºæœ¬å‹•ç”»ãƒ—ãƒ­ã‚»ãƒƒã‚µãƒ¼ã‚’åˆæœŸåŒ–")
            
        # ã‚¢ãƒŠãƒ©ã‚¤ã‚¶ãƒ¼åˆæœŸåŒ–
        if METRICS_ANALYZER_AVAILABLE and MetricsAnalyzer:
            try:
                self.analyzer = MetricsAnalyzer(self.config)
                self.logger.info("ğŸ“Š é«˜åº¦ãƒ¡ãƒˆãƒªã‚¯ã‚¹åˆ†æå™¨ã‚’åˆæœŸåŒ–")
            except Exception as e:
                self.logger.warning(f"MetricsAnalyzer åˆæœŸåŒ–å¤±æ•—: {e}")
                self.analyzer = BasicMetricsAnalyzer(self.config)
                self.logger.info("ğŸ”§ åŸºæœ¬ãƒ¡ãƒˆãƒªã‚¯ã‚¹åˆ†æå™¨ã‚’åˆæœŸåŒ–")
        else:
            self.analyzer = BasicMetricsAnalyzer(self.config)
            self.logger.info("ğŸ”§ åŸºæœ¬ãƒ¡ãƒˆãƒªã‚¯ã‚¹åˆ†æå™¨ã‚’åˆæœŸåŒ–")

    def _setup_directories(self):
        """ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ï¼ˆå®Œå…¨ç‰ˆï¼‰"""
        directories = [
            "outputs/baseline",
            "outputs/experiments", 
            "outputs/visualizations",
            "outputs/temp",
            "logs",
            "models/yolo",
            "models/depth"
        ]
        
        self.logger.info("ğŸ“ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—é–‹å§‹")
        
        for directory in directories:
            dir_path = Path(directory)
            dir_path.mkdir(parents=True, exist_ok=True)
            self.logger.debug(f"ğŸ“ ä½œæˆ/ç¢ºèª: {directory}")
        
        self.logger.info("âœ… ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—å®Œäº†")

    def _report_initialization(self, ctx):
        """åˆæœŸåŒ–å®Œäº†å ±å‘Šï¼ˆå®Œå…¨ç‰ˆï¼‰"""
        features = []
        if self.depth_enabled:
            features.append("æ·±åº¦æ¨å®š")
        if self.config.get('processing.tile_inference.enabled', False):
            features.append("ã‚¿ã‚¤ãƒ«æ¨è«–")
        
        # ä½¿ç”¨ä¸­ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æ©Ÿèƒ½ã®è¡¨ç¤º
        fallbacks = []
        if not COMPREHENSIVE_EVALUATOR_AVAILABLE:
            fallbacks.append("åŸºæœ¬è©•ä¾¡å™¨")
        if not VIDEO_PROCESSOR_AVAILABLE:
            fallbacks.append("åŸºæœ¬å‹•ç”»å‡¦ç†")
        if not METRICS_ANALYZER_AVAILABLE:
            fallbacks.append("åŸºæœ¬åˆ†æ")
        if not CONFIG_AVAILABLE:
            fallbacks.append("åŸºæœ¬è¨­å®š")
        if not LOGGER_AVAILABLE:
            fallbacks.append("åŸºæœ¬ãƒ­ã‚°")

        if features:
            self.logger.info(f"ğŸš€ ImprovedYOLOAnalyzeråˆæœŸåŒ–å®Œäº† (æ©Ÿèƒ½: {', '.join(features)})")
        else:
            self.logger.info("ğŸ“‹ ImprovedYOLOAnalyzeråˆæœŸåŒ–å®Œäº† (æ¨™æº–ãƒ¢ãƒ¼ãƒ‰)")
            
        if fallbacks:
            self.logger.info(f"ğŸ”§ ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æ©Ÿèƒ½ä½¿ç”¨ä¸­: {', '.join(fallbacks)}")

        if hasattr(ctx, 'add_info'):
            ctx.add_info("depth_enabled", self.depth_enabled)
            ctx.add_info("fallback_count", len(fallbacks))

    @handle_errors(error_category=ErrorCategory.VIDEO_PROCESSING)
    def run_baseline_analysis(self, video_path: str) -> Dict[str, Any]:
        """
        ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³åˆ†æå®Ÿè¡Œï¼ˆå®Œå…¨çµ±åˆç‰ˆï¼‰

        Args:
            video_path: åˆ†æå¯¾è±¡å‹•ç”»ã®ãƒ‘ã‚¹

        Returns:
            åˆ†æçµæœè¾æ›¸
        """
        if ERROR_HANDLER_AVAILABLE:
            context_manager = ErrorContext(f"ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³åˆ†æ: {Path(video_path).name}",
                                        logger=self.logger, raise_on_error=False)
        else:
            context_manager = self._basic_context(f"ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³åˆ†æ: {Path(video_path).name}")

        with context_manager as ctx:
            video_path = Path(video_path)
            video_name = video_path.stem

            self.logger.info(f"ğŸ¯ ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³åˆ†æé–‹å§‹: {video_name}")

            if hasattr(ctx, 'add_info'):
                ctx.add_info("video_path", str(video_path))
                ctx.add_info("video_name", video_name)
                ctx.add_info("depth_enabled", self.depth_enabled)

            # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæº–å‚™
            output_dir = Path("outputs/baseline") / video_name
            frame_dir = output_dir / "frames"
            
            output_dir.mkdir(parents=True, exist_ok=True)
            frame_dir.mkdir(parents=True, exist_ok=True)

            self.logger.info(f"ğŸ“ å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {output_dir}")

            try:
                # Step 1: ãƒ•ãƒ¬ãƒ¼ãƒ æŠ½å‡º
                self.logger.info("ğŸ“¸ Step 1: ãƒ•ãƒ¬ãƒ¼ãƒ æŠ½å‡ºé–‹å§‹")
                
                # ãƒ•ãƒ¬ãƒ¼ãƒ æŠ½å‡ºå®Ÿè¡Œ
                frame_result = self.processor.extract_frames(video_path, frame_dir)
                
                # ğŸ”§ åŸºæœ¬çš„ãªæˆåŠŸ/å¤±æ•—ãƒã‚§ãƒƒã‚¯
                if not frame_result.get("success", False):
                    error_msg = f"ãƒ•ãƒ¬ãƒ¼ãƒ æŠ½å‡ºå¤±æ•—: {frame_result.get('error', 'ä¸æ˜ãªã‚¨ãƒ©ãƒ¼')}"
                    self.error_collector.append(error_msg)
                    self.logger.error(f"âŒ {error_msg}")
                    raise VideoProcessingError(error_msg)

                # ğŸ”§ ãƒ•ãƒ¬ãƒ¼ãƒ æ•°ã®å¤šé‡ç¢ºèªã‚·ã‚¹ãƒ†ãƒ 
                
                # æ–¹æ³•1: APIã‹ã‚‰è¿”å´ã•ã‚ŒãŸå€¤
                api_extracted_frames = frame_result.get("extracted_frames", 0)
                self.logger.debug(f"ğŸ“Š APIè¿”å´ãƒ•ãƒ¬ãƒ¼ãƒ æ•°: {api_extracted_frames}")
                
                # æ–¹æ³•2: ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ç›´æ¥ç¢ºèª
                frame_files_jpg = list(frame_dir.glob("frame_*.jpg"))
                frame_files_jpeg = list(frame_dir.glob("frame_*.jpeg"))
                frame_files_png = list(frame_dir.glob("frame_*.png"))
                
                # ã™ã¹ã¦ã®ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã‚’çµ±åˆ
                all_frame_files = frame_files_jpg + frame_files_jpeg + frame_files_png
                actual_frame_count = len(all_frame_files)
                
                self.logger.debug(f"ğŸ“Š ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…ãƒ•ã‚¡ã‚¤ãƒ«æ•°:")
                self.logger.debug(f"  - JPGãƒ•ã‚¡ã‚¤ãƒ«: {len(frame_files_jpg)}å€‹")
                self.logger.debug(f"  - JPEGãƒ•ã‚¡ã‚¤ãƒ«: {len(frame_files_jpeg)}å€‹") 
                self.logger.debug(f"  - PNGãƒ•ã‚¡ã‚¤ãƒ«: {len(frame_files_png)}å€‹")
                self.logger.debug(f"  - åˆè¨ˆ: {actual_frame_count}å€‹")
                
                # æ–¹æ³•3: processing_statsã‹ã‚‰ã®å–å¾—
                stats_frames = 0
                if hasattr(self.processor, 'processing_stats') and self.processor.processing_stats:
                    frame_extraction_stats = self.processor.processing_stats.get("frame_extraction", {})
                    stats_frames = frame_extraction_stats.get("extracted_frames", 0)
                
                self.logger.debug(f"ğŸ“Š çµ±è¨ˆæƒ…å ±ãƒ•ãƒ¬ãƒ¼ãƒ æ•°: {stats_frames}")
                
                # ğŸ”§ æœ€ã‚‚ä¿¡é ¼ã§ãã‚‹å€¤ã‚’æ¡ç”¨
                frame_counts = [api_extracted_frames, actual_frame_count, stats_frames]
                valid_counts = [count for count in frame_counts if count > 0]
                
                if valid_counts:
                    # æœ‰åŠ¹ãªå€¤ãŒã‚ã‚‹å ´åˆã¯æœ€å¤§å€¤ã‚’æ¡ç”¨
                    final_frame_count = max(valid_counts)
                    self.logger.info(f"ğŸ“Š ãƒ•ãƒ¬ãƒ¼ãƒ æ•°ç¢ºå®š: {final_frame_count}å€‹ï¼ˆå€™è£œ: {frame_counts}ï¼‰")
                else:
                    # ã™ã¹ã¦0ã®å ´åˆã¯è©³ç´°èª¿æŸ»
                    self.logger.warning("âš ï¸ å…¨ã¦ã®æ–¹æ³•ã§ãƒ•ãƒ¬ãƒ¼ãƒ æ•°ãŒ0ã§ã™ã€‚è©³ç´°èª¿æŸ»ã‚’å®Ÿè¡Œ...")
                    
                    # æ–¹æ³•4: ã‚ˆã‚Šåºƒç¯„å›²ãªãƒ•ã‚¡ã‚¤ãƒ«ç¢ºèª
                    all_files = list(frame_dir.glob("*"))
                    image_extensions = ['.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.webp']
                    image_files = []
                    
                    for file_path in all_files:
                        if file_path.suffix.lower() in image_extensions:
                            image_files.append(file_path)
                    
                    final_frame_count = len(image_files)
                    
                    if final_frame_count > 0:
                        self.logger.info(f"ğŸ” åºƒç¯„å›²ç¢ºèªã§ç™ºè¦‹: {final_frame_count}å€‹ã®ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«")
                        # ãƒ•ã‚¡ã‚¤ãƒ«åã®ä¾‹ã‚’è¡¨ç¤º
                        sample_files = [f.name for f in image_files[:3]]
                        self.logger.debug(f"  ã‚µãƒ³ãƒ—ãƒ«: {sample_files}")
                    else:
                        # æ–¹æ³•5: æœ€å¾Œã®æ‰‹æ®µ - ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…å®¹ã®å®Œå…¨ãƒã‚§ãƒƒã‚¯
                        self.logger.error("ğŸ” æœ€çµ‚ç¢ºèª - ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…å®¹:")
                        self.logger.error(f"  - ãƒ‘ã‚¹: {frame_dir}")
                        self.logger.error(f"  - å­˜åœ¨ç¢ºèª: {frame_dir.exists()}")
                        self.logger.error(f"  - ã‚¢ã‚¯ã‚»ã‚¹æ¨©é™: {frame_dir.is_dir() if frame_dir.exists() else 'N/A'}")
                        
                        if frame_dir.exists():
                            all_content = list(frame_dir.glob("*"))
                            self.logger.error(f"  - å…¨ãƒ•ã‚¡ã‚¤ãƒ«({len(all_content)}å€‹): {[f.name for f in all_content[:10]]}")
                            
                            # ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºç¢ºèª
                            for file_path in all_content[:5]:
                                if file_path.is_file():
                                    size_mb = file_path.stat().st_size / (1024 * 1024)
                                    self.logger.error(f"    {file_path.name}: {size_mb:.2f}MB")
                
                # ğŸ”§ çµæœã®è©³ç´°ãƒ­ã‚°å‡ºåŠ›
                self.logger.info(f"âœ… Step 1å®Œäº†: {final_frame_count}ãƒ•ãƒ¬ãƒ¼ãƒ æŠ½å‡º")
                
                if final_frame_count > 0:
                    # æˆåŠŸæ™‚ã®çµ±è¨ˆæƒ…å ±
                    if actual_frame_count > 0 and len(all_frame_files) > 0:
                        # ãƒ•ã‚¡ã‚¤ãƒ«ã‚µãƒ³ãƒ—ãƒ«ã®è¡¨ç¤º
                        sample_count = min(3, len(all_frame_files))
                        sample_files = [f.name for f in all_frame_files[:sample_count]]
                        self.logger.info(f"ğŸ“ ä¿å­˜ãƒ•ã‚¡ã‚¤ãƒ«ä¾‹: {sample_files}")
                        
                        # ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºçµ±è¨ˆ
                        total_size = sum(f.stat().st_size for f in all_frame_files[:10])  # æœ€åˆã®10ãƒ•ã‚¡ã‚¤ãƒ«
                        avg_size_kb = (total_size / min(10, len(all_frame_files))) / 1024 if all_frame_files else 0
                        self.logger.debug(f"ğŸ“Š å¹³å‡ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: {avg_size_kb:.1f}KB")
                    
                    # ãƒ•ãƒ¬ãƒ¼ãƒ æŠ½å‡ºç‡ã®è¨ˆç®—
                    if hasattr(self.processor, 'processing_stats') and self.processor.processing_stats:
                        extraction_stats = self.processor.processing_stats.get("frame_extraction", {})
                        total_frames = extraction_stats.get("total_frames", 0)
                        if total_frames > 0:
                            extraction_rate = (final_frame_count / total_frames) * 100
                            self.logger.info(f"ğŸ“Š æŠ½å‡ºç‡: {extraction_rate:.1f}% ({final_frame_count}/{total_frames})")
                
                # ğŸ”§ ã‚¼ãƒ­ãƒ•ãƒ¬ãƒ¼ãƒ ã®å ´åˆã®ã‚¨ãƒ©ãƒ¼å‡¦ç†
                if final_frame_count == 0:
                    error_msg = "ãƒ•ãƒ¬ãƒ¼ãƒ æŠ½å‡ºæ•°ãŒ0ã§ã™ã€‚å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã¨å‡¦ç†ã‚’ç¢ºèªã—ã¦ãã ã•ã„"
                    self.error_collector.append(error_msg)
                    self.logger.error(f"âŒ {error_msg}")
                    
                    # ğŸ”§ è©³ç´°ãªãƒ‡ãƒãƒƒã‚°æƒ…å ±ã‚’å‡ºåŠ›
                    self.logger.error(f"ğŸ” ãƒ‡ãƒãƒƒã‚°æƒ…å ±è©³ç´°:")
                    self.logger.error(f"  å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«:")
                    self.logger.error(f"    - ãƒ‘ã‚¹: {video_path}")
                    self.logger.error(f"    - å­˜åœ¨: {Path(video_path).exists()}")
                    if Path(video_path).exists():
                        video_size = Path(video_path).stat().st_size / (1024 * 1024)
                        self.logger.error(f"    - ã‚µã‚¤ã‚º: {video_size:.1f}MB")
                    
                    self.logger.error(f"  å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª:")
                    self.logger.error(f"    - ãƒ‘ã‚¹: {frame_dir}")
                    self.logger.error(f"    - å­˜åœ¨: {frame_dir.exists()}")
                    self.logger.error(f"    - æ¨©é™: {oct(frame_dir.stat().st_mode)[-3:] if frame_dir.exists() else 'N/A'}")
                    
                    self.logger.error(f"  ãƒ—ãƒ­ã‚»ãƒƒã‚µæƒ…å ±:")
                    self.logger.error(f"    - ã‚¿ã‚¤ãƒ—: {type(self.processor).__name__}")
                    self.logger.error(f"    - è¨­å®š: {getattr(self.processor, 'config', 'N/A')}")
                    
                    # frame_resultã®è©³ç´°
                    self.logger.error(f"  APIå¿œç­”:")
                    self.logger.error(f"    - frame_result: {frame_result}")
                    
                    raise VideoProcessingError(error_msg)
                
                # âœ… å‡¦ç†ç¶™ç¶šã®ãŸã‚ã®ãƒ•ãƒ¬ãƒ¼ãƒ æ•°è¨˜éŒ²
                # å¾Œç¶šå‡¦ç†ã§ä½¿ç”¨ã™ã‚‹ãŸã‚ã€ç¢ºå®šã—ãŸãƒ•ãƒ¬ãƒ¼ãƒ æ•°ã‚’ä¿å­˜
                if not hasattr(self, 'current_analysis_stats'):
                    self.current_analysis_stats = {}
                self.current_analysis_stats['extracted_frame_count'] = final_frame_count
                self.current_analysis_stats['frame_directory'] = str(frame_dir)
                
                self.logger.debug(f"ğŸ“ ç¾åœ¨ã®è§£æçµ±è¨ˆã‚’æ›´æ–°: {self.current_analysis_stats}")

                # Step 2: æ¤œå‡ºãƒ»è¿½è·¡å‡¦ç†ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å¯¾å¿œï¼‰
                if self.depth_enabled:
                    self.logger.info("ğŸ” Step 2: æ·±åº¦çµ±åˆæ¤œå‡ºãƒ»è¿½è·¡å‡¦ç†é–‹å§‹")
                    if hasattr(self.processor, 'run_detection_tracking_with_depth'):
                        detection_result = self.processor.run_detection_tracking_with_depth(frame_dir, video_name)
                    else:
                        self.logger.warning("æ·±åº¦çµ±åˆå‡¦ç†ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚æ¨™æº–å‡¦ç†ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯")
                        detection_result = self.processor.run_detection_tracking(frame_dir, video_name)
                    processing_type = "æ·±åº¦çµ±åˆ"
                else:
                    self.logger.info("ğŸ‘ï¸ Step 2: æ¨™æº–æ¤œå‡ºãƒ»è¿½è·¡å‡¦ç†é–‹å§‹")
                    detection_result = self.processor.run_detection_tracking(frame_dir, video_name)
                    processing_type = "æ¨™æº–"

                # ğŸ”§ æ¤œå‡ºå‡¦ç†ãŒå¤±æ•—ã—ãŸå ´åˆã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
                if not detection_result.get("success", False):
                    error_msg = detection_result.get("error", "ä¸æ˜ãªã‚¨ãƒ©ãƒ¼")
                    self.logger.warning(f"âš ï¸ {processing_type}å‡¦ç†ã‚¨ãƒ©ãƒ¼: {error_msg}")
                    
                    # BasicVideoProcessorã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç†ã‚’è©¦è¡Œ
                    if VIDEO_PROCESSOR_AVAILABLE and not isinstance(self.processor, BasicVideoProcessor):
                        self.logger.info("ğŸ”„ BasicVideoProcessorã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯")
                        fallback_processor = BasicVideoProcessor(self.config)
                        fallback_processor.load_models()
                        detection_result = fallback_processor.run_detection_tracking(frame_dir, video_name)
                        
                        if detection_result.get("success", False):
                            self.logger.info("âœ… ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç†æˆåŠŸ")
                            processing_type = "ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯"
                        else:
                            self.error_collector.append(f"{processing_type}å‡¦ç†å¤±æ•—: {error_msg}")
                            self.logger.error(f"âŒ ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç†ã‚‚å¤±æ•—")
                            raise VideoProcessingError(error_msg)
                    else:
                        self.error_collector.append(f"{processing_type}å‡¦ç†å¤±æ•—: {error_msg}")
                        self.logger.error(f"âŒ {error_msg}")
                        raise VideoProcessingError(error_msg)

                self.logger.info(f"âœ… Step 2å®Œäº†: {processing_type}å‡¦ç†")

                # ğŸ¯ Step 2.5: 4ç‚¹ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆå‡¦ç†ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
                use_4point_keypoints = self.config.get('processing.use_4point_keypoints', False)
                
                if use_4point_keypoints and detection_result.get("success", False):
                    self.logger.info("ğŸ¯ Step 2.5: 4ç‚¹ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆå‡¦ç†é–‹å§‹")
                    
                    try:
                        original_csv = detection_result["data"]["csv_path"]
                        filtered_csv = self.filter_keypoints_to_4points(original_csv, output_dir)
                        
                        # çµæœã«4ç‚¹æƒ…å ±è¿½åŠ 
                        detection_result["data"]["filtered_csv_path"] = filtered_csv
                        detection_result["data"]["keypoint_mode"] = "4_points"
                        
                        # 4ç‚¹å°‚ç”¨å¯è¦–åŒ–
                        vis_result = self.create_4point_visualization(filtered_csv, video_path, output_dir)
                        if vis_result.get("success", False):
                            detection_result["data"]["visualization_4points"] = vis_result
                            self.logger.info("âœ… 4ç‚¹å°‚ç”¨å¯è¦–åŒ–å®Œäº†")
                        
                        self.logger.info("âœ… Step 2.5å®Œäº†: 4ç‚¹ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆå‡¦ç†")
                        
                    except Exception as e:
                        self.logger.warning(f"âš ï¸ Step 2.5è­¦å‘Š: 4ç‚¹å‡¦ç†ã‚¨ãƒ©ãƒ¼ï¼ˆå‡¦ç†ç¶™ç¶šï¼‰: {e}")
                        self.error_collector.append(f"4ç‚¹ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆå‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")

                # Step 3: åŒ…æ‹¬çš„è©•ä¾¡
                self.logger.info("ğŸ“Š Step 3: åŒ…æ‹¬çš„è©•ä¾¡é–‹å§‹")
                
                # è©•ä¾¡ãƒ¡ã‚½ãƒƒãƒ‰ã®é¸æŠ
                if hasattr(self.evaluator, 'evaluate_with_depth') and self.depth_enabled:
                    evaluation_result = self.evaluator.evaluate_with_depth(
                        video_path, detection_result, video_name
                    )
                else:
                    evaluation_result = self.evaluator.evaluate_comprehensive(
                        video_path, detection_result, video_name
                    )

                if not evaluation_result.get("success", False):
                    error_msg = f"è©•ä¾¡å‡¦ç†å¤±æ•—: {evaluation_result.get('error', {}).get('message', 'ä¸æ˜ãªã‚¨ãƒ©ãƒ¼')}"
                    self.error_collector.append(error_msg)
                    self.logger.warning(f"âš ï¸ {error_msg}")
                    # è©•ä¾¡å¤±æ•—ã¯è­¦å‘Šã«ç•™ã‚ã‚‹
                    evaluation_result = ResponseBuilder.success(data={
                        "basic_evaluation": True, 
                        "fallback": True,
                        "evaluator_type": type(self.evaluator).__name__
                    })

                self.logger.info("âœ… Step 3å®Œäº†: åŒ…æ‹¬çš„è©•ä¾¡")

                # Step 4: å¯è¦–åŒ–ç”Ÿæˆ
                self.logger.info("ğŸ“ˆ Step 4: å¯è¦–åŒ–ç”Ÿæˆé–‹å§‹")
                vis_dir = output_dir / "visualizations"
                vis_dir.mkdir(exist_ok=True)

                try:
                    # ğŸ”§ æˆ»ã‚Šå€¤ã‚’å—ã‘å–ã£ã¦è©³ç´°ãƒ­ã‚°å‡ºåŠ›
                    vis_result = self.analyzer.create_visualizations(detection_result, vis_dir)
    
                    if vis_result.get("success", False):
                        total_files = vis_result.get("total_files", 0)
                        graphs_count = vis_result.get("graphs_generated", 0)
                        self.logger.info(f"âœ… Step 4å®Œäº†: å¯è¦–åŒ–ç”Ÿæˆ ({total_files}å€‹ã®ãƒ•ã‚¡ã‚¤ãƒ«, {graphs_count}å€‹ã®ã‚°ãƒ©ãƒ•)")
                    else:
                        error_msg = vis_result.get("error", "ä¸æ˜ãªã‚¨ãƒ©ãƒ¼")
                        self.logger.warning(f"âš ï¸ Step 4è­¦å‘Š: å¯è¦–åŒ–ç”Ÿæˆã‚¨ãƒ©ãƒ¼ï¼ˆå‡¦ç†ç¶™ç¶šï¼‰: {error_msg}")
                        self.error_collector.append(f"å¯è¦–åŒ–ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {error_msg}")
        
                except Exception as e:
                    self.logger.warning(f"âš ï¸ Step 4è­¦å‘Š: å¯è¦–åŒ–ç”Ÿæˆã‚¨ãƒ©ãƒ¼ï¼ˆå‡¦ç†ç¶™ç¶šï¼‰: {e}")
                    self.logger.error(f"ğŸ”§ Step 4è©³ç´°ã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
                    self.error_collector.append(f"å¯è¦–åŒ–ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")

                # çµ±åˆçµæœã®æ§‹ç¯‰
                integrated_result = {
                    "success": True,
                    "video_name": video_name,
                    "video_path": str(video_path),
                    "processing_type": processing_type,
                    "depth_enabled": self.depth_enabled,
                    "output_directory": str(output_dir),
                    "frame_extraction": frame_result,
                    "detection_tracking": detection_result,
                    "evaluation": evaluation_result,
                    "visualization_path": str(vis_dir),
                    "processing_timestamp": datetime.now().isoformat(),
                    "errors": self.error_collector.copy() if self.error_collector else [],
                    "system_info": {
                        "evaluator_type": type(self.evaluator).__name__,
                        "processor_type": type(self.processor).__name__,
                        "analyzer_type": type(self.analyzer).__name__,
                        "config_type": type(self.config).__name__,
                        "module_availability": {
                            "error_handler": ERROR_HANDLER_AVAILABLE,
                            "comprehensive_evaluator": COMPREHENSIVE_EVALUATOR_AVAILABLE,
                            "depth_evaluator": DEPTH_EVALUATOR_AVAILABLE,
                            "video_processor": VIDEO_PROCESSOR_AVAILABLE,
                            "metrics_analyzer": METRICS_ANALYZER_AVAILABLE,
                            "config": CONFIG_AVAILABLE,
                            "logger": LOGGER_AVAILABLE
                        }
                    }
                }

                # çµæœãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
                result_file = output_dir / f"{video_name}_baseline_result.json"
                with open(result_file, 'w', encoding='utf-8') as f:
                    json.dump(integrated_result, f, indent=2, ensure_ascii=False)

                if hasattr(ctx, 'add_info'):
                    ctx.add_info("result_file", str(result_file))
                    ctx.add_info("processing_success", True)

                self.logger.info(f"ğŸ‰ ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³åˆ†æå®Œäº†: {video_name}")
                self.logger.info(f"ğŸ“ çµæœä¿å­˜å…ˆ: {output_dir}")
                self.logger.info(f"ğŸ“„ çµæœãƒ•ã‚¡ã‚¤ãƒ«: {result_file}")

                return ResponseBuilder.success(data=integrated_result)

            except VideoProcessingError as e:
                self.logger.error(f"âŒ å‹•ç”»å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
                if hasattr(ctx, 'add_info'):
                    ctx.add_info("error_type", "VideoProcessingError")
                    ctx.add_info("error_message", str(e))
                return ResponseBuilder.error(e, suggestions=[
                    "å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã®å½¢å¼ã‚’ç¢ºèªã—ã¦ãã ã•ã„",
                    "å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ãŒç ´æã—ã¦ã„ãªã„ã‹ç¢ºèªã—ã¦ãã ã•ã„",
                    f"å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª {output_dir} ã¸ã®æ›¸ãè¾¼ã¿æ¨©é™ã‚’ç¢ºèªã—ã¦ãã ã•ã„"
                ])
            
            except Exception as e:
                self.logger.error(f"âŒ äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼: {e}")
                if hasattr(ctx, 'add_info'):
                    ctx.add_info("error_type", "UnexpectedError")
                    ctx.add_info("error_message", str(e))
                return ResponseBuilder.error(e, suggestions=[
                    "ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã§è©³ç´°ãªã‚¨ãƒ©ãƒ¼æƒ…å ±ã‚’ç¢ºèªã—ã¦ãã ã•ã„",
                    "è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãŒæ­£ã—ãè¨­å®šã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„",
                    "å¿…è¦ãªãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã™ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„"
                ])
    
    # Line 1100ä»˜è¿‘ï¼ˆrun_baseline_analysisãƒ¡ã‚½ãƒƒãƒ‰ã®ç›´å¾Œï¼‰ã«è¿½åŠ :

    # ğŸ¯ 4ç‚¹ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆæ©Ÿèƒ½ã®è¿½åŠ 
    def filter_keypoints_to_4points(self, csv_path, output_dir):
        """
        17ç‚¹ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆã‚’4ç‚¹ï¼ˆä¸¡è€³ãƒ»ä¸¡è‚©ï¼‰ã«ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
        
        Args:
            csv_path: å…ƒã®17ç‚¹ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆCSV
            output_dir: å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
            
        Returns:
            filtered_csv_path: 4ç‚¹ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°æ¸ˆã¿CSV
        """
        try:
            import pandas as pd
            import numpy as np
            
            self.logger.info("ğŸ¯ 4ç‚¹ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°é–‹å§‹")
            
            # CSVèª­ã¿è¾¼ã¿
            df = pd.read_csv(csv_path)
            
            # 4ç‚¹ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆï¼ˆä¸¡è€³ãƒ»ä¸¡è‚©ï¼‰ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
            target_keypoints = {
                "left_ear": 3,
                "right_ear": 4, 
                "left_shoulder": 5,
                "right_shoulder": 6
            }
            
            # 4ç‚¹ç”¨ã®æ–°ã—ã„ã‚«ãƒ©ãƒ ä½œæˆ
            for name, idx in target_keypoints.items():
                x_col = f"keypoint_{idx}_x"
                y_col = f"keypoint_{idx}_y"
                conf_col = f"keypoint_{idx}_conf"
                
                if x_col in df.columns:
                    df[f"kpt4_{name}_x"] = df[x_col]
                    df[f"kpt4_{name}_y"] = df[y_col]
                    df[f"kpt4_{name}_conf"] = df[conf_col]
            
            # å…ƒã®17ç‚¹ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆã‚«ãƒ©ãƒ ã‚’å‰Šé™¤
            original_kpt_cols = [col for col in df.columns if 'keypoint_' in col and 'kpt4_' not in col]
            df = df.drop(columns=original_kpt_cols)
            
            # 4ç‚¹å°‚ç”¨ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¿½åŠ 
            self.add_4point_metrics(df)
            
            # ä¿å­˜
            filtered_csv = Path(output_dir) / "detections_4points.csv"
            df.to_csv(filtered_csv, index=False)
            
            self.logger.info(f"âœ… 4ç‚¹ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°å®Œäº†: {filtered_csv}")
            return str(filtered_csv)
            
        except Exception as e:
            self.logger.error(f"âŒ 4ç‚¹ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã‚¨ãƒ©ãƒ¼: {e}")
            return csv_path

    def add_4point_metrics(self, df):
        """4ç‚¹ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆå°‚ç”¨ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨ˆç®—"""
        try:
            import numpy as np
            
            # è‚©å¹…è¨ˆç®—
            if ('kpt4_left_shoulder_x' in df.columns and 
                'kpt4_right_shoulder_x' in df.columns):
                
                df['shoulder_width'] = np.sqrt(
                    (df['kpt4_left_shoulder_x'] - df['kpt4_right_shoulder_x'])**2 + 
                    (df['kpt4_left_shoulder_y'] - df['kpt4_right_shoulder_y'])**2
                )
            
            # é ­éƒ¨ä¸­å¿ƒä½ç½®
            if ('kpt4_left_ear_x' in df.columns and 
                'kpt4_right_ear_x' in df.columns):
                
                df['head_center_x'] = (df['kpt4_left_ear_x'] + df['kpt4_right_ear_x']) / 2
                df['head_center_y'] = (df['kpt4_left_ear_y'] + df['kpt4_right_ear_y']) / 2
            
            # è‚©è§’åº¦è¨ˆç®—
            if 'shoulder_width' in df.columns:
                df['shoulder_angle'] = np.arctan2(
                    df['kpt4_right_shoulder_y'] - df['kpt4_left_shoulder_y'],
                    df['kpt4_right_shoulder_x'] - df['kpt4_left_shoulder_x']
                ) * 180 / np.pi
            
            # 4ç‚¹å“è³ªã‚¹ã‚³ã‚¢
            conf_cols = [col for col in df.columns if 'kpt4_' in col and '_conf' in col]
            if conf_cols:
                df['avg_4point_confidence'] = df[conf_cols].mean(axis=1)
                df['valid_4point_count'] = (df[conf_cols] > 0.3).sum(axis=1)
                df['keypoint_quality_score'] = df['avg_4point_confidence'] * (df['valid_4point_count'] / 4)
            
            self.logger.info("âœ… 4ç‚¹ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨ˆç®—å®Œäº†")
            
        except Exception as e:
            self.logger.error(f"âŒ 4ç‚¹ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨ˆç®—ã‚¨ãƒ©ãƒ¼: {e}")

    def create_4point_visualization(self, csv_path, video_path, output_dir):
        """4ç‚¹ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆå°‚ç”¨å¯è¦–åŒ–ç”Ÿæˆ"""
        try:
            import cv2
            import pandas as pd
            
            self.logger.info("ğŸ¨ 4ç‚¹å¯è¦–åŒ–ç”Ÿæˆé–‹å§‹")
            
            # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
            vis_dir = Path(output_dir) / "visualized_frames_4points"
            vis_dir.mkdir(exist_ok=True)
            
            # CSVèª­ã¿è¾¼ã¿
            df = pd.read_csv(csv_path)
            
            # å‹•ç”»èª­ã¿è¾¼ã¿
            cap = cv2.VideoCapture(str(video_path))
            if not cap.isOpened():
                raise ValueError(f"å‹•ç”»ã‚’é–‹ã‘ã¾ã›ã‚“: {video_path}")
            
            frame_count = 0
            saved_count = 0
            
            while True:
                ret, frame = cap.read()
                if not ret:
                    break
                
                # è©²å½“ãƒ•ãƒ¬ãƒ¼ãƒ ã®ãƒ‡ãƒ¼ã‚¿
                frame_data = df[df['frame'] == frame_count]
                
                if not frame_data.empty:
                    # 4ç‚¹ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆæç”»
                    for _, row in frame_data.iterrows():
                        frame = self.draw_4point_keypoints(frame, row)
                    
                    # ãƒ•ãƒ¬ãƒ¼ãƒ ä¿å­˜
                    frame_file = vis_dir / f"frame_{frame_count:06d}.jpg"
                    cv2.imwrite(str(frame_file), frame)
                    saved_count += 1
                
                frame_count += 1
                
                # é€²æ—è¡¨ç¤º
                if frame_count % 50 == 0:
                    self.logger.info(f"ğŸ¨ 4ç‚¹å¯è¦–åŒ–é€²æ—: {frame_count}ãƒ•ãƒ¬ãƒ¼ãƒ ")
            
            cap.release()
            
            self.logger.info(f"âœ… 4ç‚¹å¯è¦–åŒ–å®Œäº†: {saved_count}ãƒ•ãƒ¬ãƒ¼ãƒ ä¿å­˜")
            return {"success": True, "frames_saved": saved_count, "output_dir": str(vis_dir)}
            
        except Exception as e:
            self.logger.error(f"âŒ 4ç‚¹å¯è¦–åŒ–ã‚¨ãƒ©ãƒ¼: {e}")
            return {"success": False, "error": str(e)}

    def draw_4point_keypoints(self, frame, row):
        """ãƒ•ãƒ¬ãƒ¼ãƒ ã«4ç‚¹ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆæç”»"""
        try:
            import cv2
            
            # è‰²å®šç¾©
            ear_color = (0, 255, 0)      # ç·‘ï¼ˆè€³ï¼‰
            shoulder_color = (255, 0, 0)  # é’ï¼ˆè‚©ï¼‰
            line_color = (0, 255, 255)    # é»„ï¼ˆç·šï¼‰
            text_color = (255, 255, 255)  # ç™½ï¼ˆãƒ†ã‚­ã‚¹ãƒˆï¼‰
            
            # 4ç‚¹ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆå–å¾—
            keypoints = {}
            for name in ['left_ear', 'right_ear', 'left_shoulder', 'right_shoulder']:
                x = row.get(f'kpt4_{name}_x', 0)
                y = row.get(f'kpt4_{name}_y', 0)
                conf = row.get(f'kpt4_{name}_conf', 0)
                
                if conf > 0.3 and x > 0 and y > 0:
                    keypoints[name] = (int(x), int(y), conf)
            
            # ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆæç”»
            ear_points = []
            shoulder_points = []
            
            for name, (x, y, conf) in keypoints.items():
                color = ear_color if 'ear' in name else shoulder_color
                
                # ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆå††
                cv2.circle(frame, (x, y), 6, color, -1)
                cv2.circle(frame, (x, y), 8, text_color, 2)
                
                # ãƒ©ãƒ™ãƒ«
                cv2.putText(frame, f"{name}:{conf:.2f}", (x + 10, y - 10),
                           cv2.FONT_HERSHEY_SIMPLEX, 0.4, color, 1)
                
                # ç‚¹ã‚’åˆ†é¡
                if 'ear' in name:
                    ear_points.append((x, y))
                elif 'shoulder' in name:
                    shoulder_points.append((x, y))
            
            # è‚©ãƒ©ã‚¤ãƒ³æç”»
            if len(shoulder_points) == 2:
                cv2.line(frame, shoulder_points[0], shoulder_points[1], line_color, 3)
                
                # è‚©å¹…è¡¨ç¤º
                if 'shoulder_width' in row and not pd.isna(row['shoulder_width']):
                    mid_x = (shoulder_points[0][0] + shoulder_points[1][0]) // 2
                    mid_y = (shoulder_points[0][1] + shoulder_points[1][1]) // 2
                    cv2.putText(frame, f"SW:{row['shoulder_width']:.1f}", 
                               (mid_x, mid_y), cv2.FONT_HERSHEY_SIMPLEX, 0.5, line_color, 2)
            
            # é ­éƒ¨ä¸­å¿ƒæç”»
            if len(ear_points) == 2:
                head_x = (ear_points[0][0] + ear_points[1][0]) // 2
                head_y = (ear_points[0][1] + ear_points[1][1]) // 2
                cv2.circle(frame, (head_x, head_y), 4, line_color, -1)
            
            # äººç‰©IDè¡¨ç¤º
            person_id = row.get('person_id', -1)
            if person_id != -1 and keypoints:
                all_points = list(keypoints.values())
                center_x = int(np.mean([p[0] for p in all_points]))
                center_y = int(np.mean([p[1] for p in all_points])) - 30
                
                quality_score = row.get('keypoint_quality_score', 0)
                text = f"ID:{person_id} Q:{quality_score:.2f}"
                cv2.putText(frame, text, (center_x, center_y),
                           cv2.FONT_HERSHEY_SIMPLEX, 0.6, text_color, 2)
            
            return frame
            
        except Exception as e:
            self.logger.warning(f"ãƒ•ãƒ¬ãƒ¼ãƒ æç”»ã‚¨ãƒ©ãƒ¼: {e}")
            return frame

    @handle_errors(error_category=ErrorCategory.EXPERIMENT)
    def run_experiment(self, video_path: str, experiment_type: str) -> Dict[str, Any]:
        """
        å®Ÿé¨“åˆ†æå®Ÿè¡Œï¼ˆå®Œå…¨çµ±åˆç‰ˆï¼‰

        Args:
            video_path: åˆ†æå¯¾è±¡å‹•ç”»ã®ãƒ‘ã‚¹
            experiment_type: å®Ÿé¨“ã‚¿ã‚¤ãƒ—

        Returns:
            å®Ÿé¨“çµæœè¾æ›¸
        """
        if ERROR_HANDLER_AVAILABLE:
            context_manager = ErrorContext(f"å®Ÿé¨“åˆ†æ: {experiment_type}", 
                                        logger=self.logger, raise_on_error=False)
        else:
            context_manager = self._basic_context(f"å®Ÿé¨“åˆ†æ: {experiment_type}")

        with context_manager as ctx:
            video_path = Path(video_path)
            video_name = video_path.stem

            self.logger.info(f"ğŸ§ª å®Ÿé¨“åˆ†æé–‹å§‹: {experiment_type} - {video_name}")

            if hasattr(ctx, 'add_info'):
                ctx.add_info("video_path", str(video_path))
                ctx.add_info("experiment_type", experiment_type)
                ctx.add_info("depth_enabled", self.depth_enabled)

            try:
                # å®Ÿé¨“ç”¨å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
                output_dir = Path("outputs/experiments") / experiment_type / video_name
                output_dir.mkdir(parents=True, exist_ok=True)

                self.logger.info(f"ğŸ“ å®Ÿé¨“å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {output_dir}")

                # å®Ÿé¨“è¨­å®šã®å–å¾—
                if hasattr(self.config, 'get_experiment_config'):
                    experiment_config = self.config.get_experiment_config(experiment_type)
                else:
                    experiment_config = {"type": experiment_type, "basic_mode": True}

                self.logger.info(f"âš™ï¸ å®Ÿé¨“è¨­å®š: {experiment_config}")

                # ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³çµæœã¨ã®æ¯”è¼ƒç”¨ã«ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³å®Ÿè¡Œ
                self.logger.info("ğŸ“Š ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³çµæœå–å¾—ä¸­...")
                baseline_result = self.run_baseline_analysis(video_path)
                
                if not baseline_result.get("success", False):
                    raise VideoProcessingError("ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³åˆ†æã«å¤±æ•—ã—ã¾ã—ãŸ")

                self.logger.info("âœ… ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³çµæœå–å¾—å®Œäº†")

                # å®Ÿé¨“ç‰¹æœ‰ã®å‡¦ç†
                experiment_result = {
                    "success": True,
                    "experiment_type": experiment_type,
                    "video_name": video_name,
                    "baseline_comparison": baseline_result.get("data", {}),
                    "experiment_config": experiment_config,
                    "depth_enabled": self.depth_enabled,
                    "output_directory": str(output_dir),
                    "processing_timestamp": datetime.now().isoformat(),
                    "system_info": {
                        "evaluator_type": type(self.evaluator).__name__,
                        "processor_type": type(self.processor).__name__,
                        "analyzer_type": type(self.analyzer).__name__
                    }
                }

                # æ”¹å–„åˆ†æ
                try:
                    self.logger.info("ğŸ“ˆ æ”¹å–„åˆ†æé–‹å§‹...")
                    improvement_analysis = self.analyzer.analyze_improvements({
                        "baseline": baseline_result.get("data", {}),
                        "experiment": experiment_result
                    })
                    experiment_result["improvement_analysis"] = improvement_analysis
                    self.logger.info("âœ… æ”¹å–„åˆ†æå®Œäº†")
                except Exception as e:
                    self.logger.warning(f"âš ï¸ æ”¹å–„åˆ†æã‚¨ãƒ©ãƒ¼ï¼ˆå‡¦ç†ç¶™ç¶šï¼‰: {e}")
                    experiment_result["improvement_analysis"] = {"error": str(e)}

                # çµæœä¿å­˜
                result_file = output_dir / f"{video_name}_{experiment_type}_result.json"
                with open(result_file, 'w', encoding='utf-8') as f:
                    json.dump(experiment_result, f, indent=2, ensure_ascii=False)

                if hasattr(ctx, 'add_info'):
                    ctx.add_info("result_file", str(result_file))

                self.logger.info(f"ğŸ‰ å®Ÿé¨“åˆ†æå®Œäº†: {experiment_type} - {video_name}")
                self.logger.info(f"ğŸ“„ çµæœãƒ•ã‚¡ã‚¤ãƒ«: {result_file}")
                return ResponseBuilder.success(data=experiment_result)

            except Exception as e:
                self.logger.error(f"âŒ å®Ÿé¨“åˆ†æã‚¨ãƒ©ãƒ¼: {e}")
                if hasattr(ctx, 'add_info'):
                    ctx.add_info("error_type", type(e).__name__)
                    ctx.add_info("error_message", str(e))
                return ResponseBuilder.error(e, suggestions=[
                    f"å®Ÿé¨“ã‚¿ã‚¤ãƒ— '{experiment_type}' ã®è¨­å®šã‚’ç¢ºèªã—ã¦ãã ã•ã„",
                    "ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³åˆ†æãŒæ­£å¸¸ã«å‹•ä½œã™ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„"
                ])

    def generate_error_report(self) -> Dict[str, Any]:
        """ã‚¨ãƒ©ãƒ¼ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆï¼ˆå®Œå…¨ç‰ˆï¼‰"""
        try:
            self.logger.info("ğŸ“‹ ã‚¨ãƒ©ãƒ¼ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆé–‹å§‹")
            
            error_report = {
                "timestamp": datetime.now().isoformat(),
                "total_errors": len(self.error_collector),
                "errors": self.error_collector.copy(),
                "system_info": {
                    "depth_enabled": self.depth_enabled,
                    "evaluator_type": type(self.evaluator).__name__,
                    "processor_type": type(self.processor).__name__,
                    "analyzer_type": type(self.analyzer).__name__,
                    "config_type": type(self.config).__name__
                },
                "module_availability": {
                    "error_handler": ERROR_HANDLER_AVAILABLE,
                    "evaluator": EVALUATOR_AVAILABLE,
                    "comprehensive_evaluator": COMPREHENSIVE_EVALUATOR_AVAILABLE,
                    "depth_evaluator": DEPTH_EVALUATOR_AVAILABLE,
                    "video_processor": VIDEO_PROCESSOR_AVAILABLE,
                    "metrics_analyzer": METRICS_ANALYZER_AVAILABLE,
                    "config": CONFIG_AVAILABLE,
                    "logger": LOGGER_AVAILABLE
                },
                "performance_info": {
                    "processing_stats": getattr(self.processor, 'processing_stats', {}),
                    "error_count_by_type": self._categorize_errors()
                }
            }
            
            # ã‚¨ãƒ©ãƒ¼ãƒ¬ãƒãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
            report_file = Path("logs") / f"error_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
            report_file.parent.mkdir(exist_ok=True)
            
            with open(report_file, 'w', encoding='utf-8') as f:
                json.dump(error_report, f, indent=2, ensure_ascii=False)
                
            self.logger.info(f"âœ… ã‚¨ãƒ©ãƒ¼ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆå®Œäº†: {report_file}")
            return error_report
            
        except Exception as e:
            self.logger.error(f"âŒ ã‚¨ãƒ©ãƒ¼ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆå¤±æ•—: {e}")
            return {"error": str(e)}

    def _categorize_errors(self) -> Dict[str, int]:
        """ã‚¨ãƒ©ãƒ¼ã®åˆ†é¡ï¼ˆå®Œå…¨ç‰ˆï¼‰"""
        categories = {
            "video_processing": 0,
            "model_loading": 0,
            "evaluation": 0,
            "configuration": 0,
            "depth_processing": 0,
            "io_operations": 0,
            "other": 0
        }
        
        for error in self.error_collector:
            error_lower = error.lower()
            if any(keyword in error_lower for keyword in ["video", "frame", "opencv", "mp4", "avi"]):
                categories["video_processing"] += 1
            elif any(keyword in error_lower for keyword in ["model", "yolo", "loading", "pt", "weights"]):
                categories["model_loading"] += 1
            elif any(keyword in error_lower for keyword in ["evaluation", "csv", "analysis", "metrics"]):
                categories["evaluation"] += 1
            elif any(keyword in error_lower for keyword in ["config", "setting", "yaml", "json"]):
                categories["configuration"] += 1
            elif any(keyword in error_lower for keyword in ["depth", "midas", "disparity"]):
                categories["depth_processing"] += 1
            elif any(keyword in error_lower for keyword in ["file", "directory", "path", "permission"]):
                categories["io_operations"] += 1
            else:
                categories["other"] += 1
        
        return categories

    def get_video_files(self) -> List[Path]:
        """å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«å–å¾—ï¼ˆä¿®æ­£ç‰ˆãƒ»åŸºæœ¬æ¨è«–å„ªå…ˆï¼‰"""
        try:
            # ğŸ”§ --video ã‚ªãƒ—ã‚·ãƒ§ãƒ³ãŒæŒ‡å®šã•ã‚ŒãŸå ´åˆã¯ã€ãã®ãƒ•ã‚¡ã‚¤ãƒ«ã®ã¿å‡¦ç†
            if hasattr(sys, 'argv') and '--video' in ' '.join(sys.argv):
                # ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°ã‹ã‚‰å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç›´æ¥å–å¾—ã™ã‚‹å ´åˆã¯
                # ãƒ¡ã‚¤ãƒ³é–¢æ•°ã§å‡¦ç†ã•ã‚Œã‚‹ã®ã§ã€ã“ã“ã§ã¯ç©ºãƒªã‚¹ãƒˆã‚’è¿”ã™
                return []
        
            # é€šå¸¸ã®å‹•ç”»ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ¤œç´¢
            if hasattr(self.config, 'video_dir'):
                video_dir = Path(self.config.video_dir)
            else:
                video_dir = Path(self.config.get("video_dir", "videos"))
            
            self.logger.info(f"ğŸ¥ å‹•ç”»ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ¤œç´¢: {video_dir}")
            
            if not video_dir.exists():
                self.logger.warning(f"âš ï¸ å‹•ç”»ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒå­˜åœ¨ã—ã¾ã›ã‚“: {video_dir}")
                return []
            
            # ã‚µãƒãƒ¼ãƒˆã™ã‚‹å‹•ç”»å½¢å¼
            video_extensions = ['.mp4', '.avi', '.mov', '.mkv', '.wmv', '.flv', '.webm']
            video_files = []
        
            for ext in video_extensions:
                found_files = list(video_dir.glob(f"*{ext}"))
                found_files.extend(video_dir.glob(f"*{ext.upper()}"))
                video_files.extend(found_files)
            
            video_files = sorted(set(video_files))
        
            if not video_files:
                self.logger.warning(f"âš ï¸ å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {video_dir}")
                return []
        
            self.logger.info(f"âœ… å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ç™ºè¦‹: {len(video_files)}å€‹")
            for video_file in video_files:
                file_size_mb = video_file.stat().st_size / 1024 / 1024
                self.logger.debug(f"  ğŸ“¹ {video_file.name} ({file_size_mb:.1f}MB)")
            
            return video_files
        
        except Exception as e:
            self.logger.error(f"âŒ å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            return []

def main():
    """
    ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°ï¼ˆå®Œå…¨çµ±åˆç‰ˆï¼‰
    """
    # ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°ã®è§£æ
    parser = argparse.ArgumentParser(
        description="YOLO11 åºƒè§’ã‚«ãƒ¡ãƒ©åˆ†æã‚·ã‚¹ãƒ†ãƒ ï¼ˆå®Œå…¨çµ±åˆç‰ˆãƒ»ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å¯¾å¿œï¼‰",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ğŸ¯ ä½¿ç”¨ä¾‹:
  # ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³åˆ†æï¼ˆæ¨™æº–ãƒ¢ãƒ¼ãƒ‰ï¼‰
  python improved_main.py --mode baseline --config configs/default.yaml
  
  # ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³åˆ†æï¼ˆæ·±åº¦æ¨å®šãƒ¢ãƒ¼ãƒ‰ï¼‰
  python improved_main.py --mode baseline --config configs/depth_config.yaml
  
  # ğŸ¯ 4ç‚¹ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆãƒ¢ãƒ¼ãƒ‰
  python improved_main.py --mode baseline --use-4points --keypoint-threshold 0.4
  
  # å®Ÿé¨“åˆ†æ
  python improved_main.py --mode experiment --experiment-type tile_inference
  
  # ç‰¹å®šå‹•ç”»ã®åˆ†æ
  python improved_main.py --mode baseline --video path/to/video.mp4
  
  # è©³ç´°ãƒ­ã‚° + ã‚¨ãƒ©ãƒ¼ãƒ¬ãƒãƒ¼ãƒˆ
  python improved_main.py --mode baseline --verbose --generate-report
        """
    )
    
    parser.add_argument(
        "--mode", 
        choices=["baseline", "experiment"], 
        default="baseline",
        help="å®Ÿè¡Œãƒ¢ãƒ¼ãƒ‰: baseline=ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³åˆ†æ, experiment=å®Ÿé¨“åˆ†æ"
    )
    
    parser.add_argument(
        "--config", 
        default="configs/default.yaml",
        help="è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: configs/default.yamlï¼‰"
    )
    
    parser.add_argument(
        "--video",
        help="åˆ†æå¯¾è±¡å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ï¼ˆæŒ‡å®šã—ãªã„å ´åˆã¯è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®video_dirã‹ã‚‰è‡ªå‹•é¸æŠï¼‰"
    )
    
    parser.add_argument(
        "--experiment-type",
        default="comparison",
        help="å®Ÿé¨“ã‚¿ã‚¤ãƒ—ï¼ˆmode=experimentã®å ´åˆã®ã¿æœ‰åŠ¹ï¼‰"
    )
    
    # ğŸ¯ 4ç‚¹ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆå°‚ç”¨å¼•æ•°ã‚’ã“ã“ã«è¿½åŠ 
    parser.add_argument(
        "--use-4points",
        action="store_true",
        help="4ç‚¹ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆãƒ¢ãƒ¼ãƒ‰ã‚’æœ‰åŠ¹åŒ–ï¼ˆä¸¡è€³ãƒ»ä¸¡è‚©ã®ã¿ï¼‰"
    )
    
    parser.add_argument(
        "--keypoint-threshold",
        type=float,
        default=0.3,
        help="ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆä¿¡é ¼åº¦é–¾å€¤ï¼ˆ0.0-1.0ã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 0.3ï¼‰"
    )
    
    parser.add_argument(
        "--disable-shoulder-metrics",
        action="store_true",
        help="è‚©å¹…ãƒ»å§¿å‹¢è§£æã‚’ç„¡åŠ¹åŒ–"
    )
    
    parser.add_argument(
        "--disable-head-tracking",
        action="store_true",
        help="é ­éƒ¨ä½ç½®è¿½è·¡ã‚’ç„¡åŠ¹åŒ–"
    )
    
    parser.add_argument(
        "--verbose", "-v",
        action="store_true",
        help="è©³ç´°ãƒ­ã‚°å‡ºåŠ›"
    )
    
    parser.add_argument(
        "--generate-report",
        action="store_true", 
        help="å‡¦ç†å¾Œã«ã‚¨ãƒ©ãƒ¼ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ"
    )

    args = parser.parse_args()

    # ğŸ¯ 4ç‚¹ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆè¨­å®šã®å‹•çš„æ›´æ–°ã‚’ã“ã“ã«è¿½åŠ 
    if args.use_4points:
        print("ğŸ¯ 4ç‚¹ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆãƒ¢ãƒ¼ãƒ‰ã‚’å¼·åˆ¶æœ‰åŠ¹åŒ–")
        print(f"ğŸ“Š ä¿¡é ¼åº¦é–¾å€¤: {args.keypoint_threshold}")
        
        if args.disable_shoulder_metrics:
            print("ğŸ“ è‚©å¹…ãƒ»å§¿å‹¢è§£æã‚’ç„¡åŠ¹åŒ–")
        
        if args.disable_head_tracking:
            print("ğŸ‘¤ é ­éƒ¨ä½ç½®è¿½è·¡ã‚’ç„¡åŠ¹åŒ–")

    # ãƒ­ã‚°ãƒ¬ãƒ™ãƒ«è¨­å®š
    if args.verbose:
        logging.getLogger().setLevel(logging.DEBUG)
    
    # ãƒ­ã‚¬ãƒ¼åˆæœŸåŒ–
    logger = setup_logger()

    logger.info("ğŸš€ YOLO11 åºƒè§’ã‚«ãƒ¡ãƒ©åˆ†æã‚·ã‚¹ãƒ†ãƒ  é–‹å§‹ï¼ˆå®Œå…¨çµ±åˆç‰ˆï¼‰")
    logger.info(f"ğŸ“‹ å®Ÿè¡Œãƒ¢ãƒ¼ãƒ‰: {args.mode}")
    logger.info(f"âš™ï¸ è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«: {args.config}")
    logger.info(f"ğŸ“Š è©³ç´°ãƒ­ã‚°: {'æœ‰åŠ¹' if args.verbose else 'ç„¡åŠ¹'}")
    
    # ğŸ¯ 4ç‚¹ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆãƒ¢ãƒ¼ãƒ‰ã®ãƒ­ã‚°å‡ºåŠ›
    if args.use_4points:
        logger.info("ğŸ¯ 4ç‚¹ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆãƒ¢ãƒ¼ãƒ‰æœ‰åŠ¹")
        logger.info(f"ğŸ“Š ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆä¿¡é ¼åº¦é–¾å€¤: {args.keypoint_threshold}")
        if args.disable_shoulder_metrics:
            logger.info("ğŸ“ è‚©å¹…ãƒ»å§¿å‹¢è§£æ: ç„¡åŠ¹")
        if args.disable_head_tracking:
            logger.info("ğŸ‘¤ é ­éƒ¨ä½ç½®è¿½è·¡: ç„¡åŠ¹")
    
    # ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«å¯ç”¨æ€§ã®è©³ç´°å ±å‘Š
    available_modules = []
    fallback_modules = []
    
    module_status = {
        "çµ±ä¸€ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒ©ãƒ¼": ERROR_HANDLER_AVAILABLE,
        "åŒ…æ‹¬çš„è©•ä¾¡å™¨": COMPREHENSIVE_EVALUATOR_AVAILABLE,
        "æ·±åº¦çµ±åˆè©•ä¾¡å™¨": DEPTH_EVALUATOR_AVAILABLE,
        "é«˜åº¦å‹•ç”»å‡¦ç†": VIDEO_PROCESSOR_AVAILABLE,
        "é«˜åº¦ãƒ¡ãƒˆãƒªã‚¯ã‚¹åˆ†æ": METRICS_ANALYZER_AVAILABLE,
        "é«˜åº¦è¨­å®šç®¡ç†": CONFIG_AVAILABLE,
        "é«˜åº¦ãƒ­ã‚°æ©Ÿèƒ½": LOGGER_AVAILABLE
    }
    
    for module_name, available in module_status.items():
        if available:
            available_modules.append(module_name)
        else:
            fallback_modules.append(module_name.replace("é«˜åº¦", "åŸºæœ¬").replace("çµ±ä¸€", "åŸºæœ¬").replace("åŒ…æ‹¬çš„", "åŸºæœ¬").replace("æ·±åº¦çµ±åˆ", "åŸºæœ¬"))
        
    if available_modules:
        logger.info(f"âœ… åˆ©ç”¨å¯èƒ½ãªé«˜åº¦æ©Ÿèƒ½: {', '.join(available_modules)}")
    if fallback_modules:
        logger.info(f"ğŸ”§ ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æ©Ÿèƒ½ä½¿ç”¨: {', '.join(fallback_modules)}")

    try:
        # åˆ†æå™¨åˆæœŸåŒ–
        logger.info("âš™ï¸ åˆ†æå™¨åˆæœŸåŒ–é–‹å§‹...")
        analyzer = ImprovedYOLOAnalyzer(args.config)
        logger.info("âœ… åˆ†æå™¨åˆæœŸåŒ–å®Œäº†")
        
        # ğŸ¯ 4ç‚¹ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆè¨­å®šã®å¼·åˆ¶é©ç”¨
        if args.use_4points:
            # è¨­å®šã‚ªãƒ¼ãƒãƒ¼ãƒ©ã‚¤ãƒ‰
            if hasattr(analyzer.config, 'data') and isinstance(analyzer.config.data, dict):
                analyzer.config.data.setdefault('processing', {})
                analyzer.config.data['processing']['use_4point_keypoints'] = True
                analyzer.config.data['processing']['keypoint_confidence_threshold'] = args.keypoint_threshold
                
                if args.disable_shoulder_metrics:
                    analyzer.config.data['processing']['enable_shoulder_metrics'] = False
                    
                if args.disable_head_tracking:
                    analyzer.config.data['processing']['enable_head_tracking'] = False
                    
                logger.info("ğŸ”§ è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’4ç‚¹ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆãƒ¢ãƒ¼ãƒ‰ç”¨ã«å‹•çš„æ›´æ–°")
            else:
                logger.warning("âš ï¸ è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®å‹•çš„æ›´æ–°ã«å¤±æ•—ã—ã¾ã—ãŸ")
        
        # å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«æ±ºå®š
        if args.video:
            video_path = Path(args.video)
            if not video_path.exists():
                raise FileNotFoundError(f"æŒ‡å®šã•ã‚ŒãŸå‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ã¾ã›ã‚“: {video_path}")
            video_files = [video_path]
            logger.info(f"ğŸ¬ æŒ‡å®šå‹•ç”»: {video_path.name}")
        else:
            video_files = analyzer.get_video_files()
            if not video_files:
                raise FileNotFoundError(f"å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚{analyzer.config.get('video_dir', 'videos')}ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é…ç½®ã—ã¦ãã ã•ã„")

        logger.info(f"ğŸ¥ å‡¦ç†å¯¾è±¡å‹•ç”»: {len(video_files)}ãƒ•ã‚¡ã‚¤ãƒ«")
        
        # 4ç‚¹ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆæƒ…å ±ã®è©³ç´°è¡¨ç¤º
        if args.use_4points:
            logger.info("ğŸ¯ 4ç‚¹ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆå‡¦ç†è¨­å®š:")
            logger.info("   - å¯¾è±¡ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆ: left_ear, right_ear, left_shoulder, right_shoulder")
            logger.info(f"   - ä¿¡é ¼åº¦é–¾å€¤: {args.keypoint_threshold}")
            logger.info(f"   - è‚©å¹…è§£æ: {'ç„¡åŠ¹' if args.disable_shoulder_metrics else 'æœ‰åŠ¹'}")
            logger.info(f"   - é ­éƒ¨è¿½è·¡: {'ç„¡åŠ¹' if args.disable_head_tracking else 'æœ‰åŠ¹'}")
        
        # åˆ†æå®Ÿè¡Œ
        all_results = []
        successful_count = 0
        
        for i, video_file in enumerate(video_files, 1):
            logger.info(f"ğŸ“¹ å‡¦ç†é–‹å§‹ ({i}/{len(video_files)}): {video_file.name}")
            
            # ğŸ¯ 4ç‚¹ãƒ¢ãƒ¼ãƒ‰ã®å ´åˆã®ç‰¹åˆ¥è¡¨ç¤º
            if args.use_4points:
                logger.info(f"ğŸ¯ 4ç‚¹ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆãƒ¢ãƒ¼ãƒ‰ã§å‡¦ç†ä¸­: {video_file.name}")
            
            try:
                if args.mode == "baseline":
                    result = analyzer.run_baseline_analysis(str(video_file))
                elif args.mode == "experiment":
                    result = analyzer.run_experiment(str(video_file), args.experiment_type)
                else:
                    raise ValueError(f"ä¸æ­£ãªå®Ÿè¡Œãƒ¢ãƒ¼ãƒ‰: {args.mode}")
                
                all_results.append({
                    "video_file": str(video_file),
                    "video_name": video_file.name,
                    "result": result,
                    "keypoint_mode": "4_points" if args.use_4points else "17_points"  # ğŸ¯ è¿½åŠ 
                })
                
                if result.get("success", False):
                    successful_count += 1
                    # ğŸ¯ 4ç‚¹ãƒ¢ãƒ¼ãƒ‰æˆåŠŸã®ç‰¹åˆ¥è¡¨ç¤º
                    if args.use_4points:
                        logger.info(f"âœ… 4ç‚¹ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆå‡¦ç†å®Œäº† ({i}/{len(video_files)}): {video_file.name}")
                        
                        # 4ç‚¹å°‚ç”¨çµæœã®è¡¨ç¤º
                        data = result.get("data", {})
                        if "filtered_csv_path" in data:
                            logger.info(f"ğŸ“Š 4ç‚¹ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°æ¸ˆã¿CSV: {Path(data['filtered_csv_path']).name}")
                        if "visualization_4points" in data:
                            vis_info = data["visualization_4points"]
                            logger.info(f"ğŸ¨ 4ç‚¹å¯è¦–åŒ–: {vis_info.get('frames_saved', 0)}ãƒ•ãƒ¬ãƒ¼ãƒ ç”Ÿæˆ")
                    else:
                        logger.info(f"âœ… å‡¦ç†å®Œäº† ({i}/{len(video_files)}): {video_file.name}")
                else:
                    logger.error(f"âŒ å‡¦ç†å¤±æ•— ({i}/{len(video_files)}): {video_file.name}")
                    if result.get("error"):
                        logger.error(f"  ã‚¨ãƒ©ãƒ¼è©³ç´°: {result['error'].get('message', 'ä¸æ˜')}")
                        
            except Exception as e:
                logger.error(f"âŒ å‹•ç”»å‡¦ç†ã‚¨ãƒ©ãƒ¼ ({video_file.name}): {e}")
                all_results.append({
                    "video_file": str(video_file),
                    "video_name": video_file.name,
                    "result": ResponseBuilder.error(e),
                    "keypoint_mode": "4_points" if args.use_4points else "17_points"  # ğŸ¯ è¿½åŠ 
                })

        # å…¨ä½“çµæœã‚µãƒãƒªãƒ¼ï¼ˆ4ç‚¹ãƒ¢ãƒ¼ãƒ‰å¯¾å¿œï¼‰
        total = len(all_results)
        success_rate = (successful_count / total) * 100 if total > 0 else 0
        
        logger.info(f"ğŸ“Š å‡¦ç†çµæœã‚µãƒãƒªãƒ¼: {successful_count}/{total} æˆåŠŸ ({success_rate:.1f}%)")
        
        # ğŸ¯ 4ç‚¹ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆãƒ¢ãƒ¼ãƒ‰ç‰¹æœ‰ã®ã‚µãƒãƒªãƒ¼
        if args.use_4points:
            logger.info("ğŸ¯ 4ç‚¹ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆãƒ¢ãƒ¼ãƒ‰å‡¦ç†ã‚µãƒãƒªãƒ¼:")
            fourpoint_success = 0
            for result_entry in all_results:
                result = result_entry["result"]
                if result.get("success", False) and result_entry.get("keypoint_mode") == "4_points":
                    fourpoint_success += 1
            
            logger.info(f"   - 4ç‚¹å‡¦ç†æˆåŠŸ: {fourpoint_success}/{total}")
            logger.info(f"   - ä¿¡é ¼åº¦é–¾å€¤: {args.keypoint_threshold}")
            logger.info(f"   - æœ‰åŠ¹æ©Ÿèƒ½: è‚©å¹…è§£æ={'â—‹' if not args.disable_shoulder_metrics else 'Ã—'}, é ­éƒ¨è¿½è·¡={'â—‹' if not args.disable_head_tracking else 'Ã—'}")

        # ã‚¨ãƒ©ãƒ¼ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
        if args.generate_report or analyzer.error_collector:
            logger.info("ğŸ“‹ ã‚¨ãƒ©ãƒ¼ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆä¸­...")
            error_report = analyzer.generate_error_report()
            logger.info(f"ğŸ“‹ ã‚¨ãƒ©ãƒ¼ãƒ¬ãƒãƒ¼ãƒˆ: {error_report.get('total_errors', 0)}ä»¶ã®ã‚¨ãƒ©ãƒ¼")

        # çµ±åˆçµæœãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
        summary_result = {
            "execution_mode": args.mode,
            "config_file": args.config,
            "keypoint_mode": "4_points" if args.use_4points else "17_points",  # ğŸ¯ è¿½åŠ 
            "keypoint_settings": {  # ğŸ¯ è¿½åŠ 
                "use_4points": args.use_4points,
                "threshold": args.keypoint_threshold,
                "shoulder_metrics": not args.disable_shoulder_metrics,
                "head_tracking": not args.disable_head_tracking
            } if args.use_4points else None,
            "execution_timestamp": datetime.now().isoformat(),
            "total_videos": total,
            "successful_videos": successful_count,
            "success_rate": success_rate,
            "video_results": all_results,
            "system_info": {
                "depth_enabled": analyzer.depth_enabled,
                "module_availability": module_status,
                "fallback_count": len(fallback_modules),
                "evaluator_type": type(analyzer.evaluator).__name__,
                "processor_type": type(analyzer.processor).__name__,
                "analyzer_type": type(analyzer.analyzer).__name__
            },
            "command_line_args": vars(args)
        }
        
        # ğŸ¯ 4ç‚¹ãƒ¢ãƒ¼ãƒ‰ç”¨ã®ãƒ•ã‚¡ã‚¤ãƒ«å
        mode_suffix = f"{args.mode}_4points" if args.use_4points else args.mode
        summary_file = Path("outputs") / f"summary_{mode_suffix}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        with open(summary_file, 'w', encoding='utf-8') as f:
            json.dump(summary_result, f, indent=2, ensure_ascii=False)
        
        logger.info(f"ğŸ“ çµ±åˆçµæœä¿å­˜: {summary_file}")

        # å‡¦ç†å®Œäº†
        if successful_count == total:
            logger.info("ğŸ‰ å…¨ã¦ã®å‹•ç”»å‡¦ç†ãŒæˆåŠŸã—ã¾ã—ãŸ")
            print(f"\nâœ… å‡¦ç†å®Œäº†: {successful_count}/{total} æˆåŠŸ (æˆåŠŸç‡: 100%)")
            print(f"ğŸ“ çµæœä¿å­˜å…ˆ: outputs/{args.mode}/")
            
            # ğŸ¯ 4ç‚¹ãƒ¢ãƒ¼ãƒ‰ç‰¹æœ‰ã®å®Œäº†ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
            if args.use_4points:
                print("ğŸ¯ 4ç‚¹ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆãƒ¢ãƒ¼ãƒ‰å‡¦ç†å®Œäº†!")
                print("   - å‡ºåŠ›: è‚©å¹…ã€é ­éƒ¨ä½ç½®ã€å§¿å‹¢è§’åº¦ãƒ‡ãƒ¼ã‚¿ã‚’å«ã‚€CSV")
                print("   - å¯è¦–åŒ–: 4ç‚¹å°‚ç”¨ã®è¦‹ã‚„ã™ã„å¯è¦–åŒ–ãƒ•ãƒ¬ãƒ¼ãƒ ")
                print(f"   - ä¿¡é ¼åº¦: {args.keypoint_threshold}ä»¥ä¸Šã®ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆã®ã¿ä½¿ç”¨")
            
            if fallback_modules:
                print(f"ğŸ”§ ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æ©Ÿèƒ½ä½¿ç”¨: {len(fallback_modules)}å€‹")
            return True
        elif successful_count > 0:
            logger.warning(f"âš ï¸ ä¸€éƒ¨ã®å‹•ç”»å‡¦ç†ãŒå¤±æ•—ã—ã¾ã—ãŸ ({successful_count}/{total})")
            print(f"\nâš ï¸ éƒ¨åˆ†çš„æˆåŠŸ: {successful_count}/{total} (æˆåŠŸç‡: {success_rate:.1f}%)")
            print(f"ğŸ“‹ è©³ç´°ã¯ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç¢ºèªã—ã¦ãã ã•ã„")
            print(f"ğŸ“ çµæœä¿å­˜å…ˆ: outputs/{args.mode}/")
            return True
        else:
            logger.error("âŒ å…¨ã¦ã®å‹•ç”»å‡¦ç†ãŒå¤±æ•—ã—ã¾ã—ãŸ")
            print(f"\nâŒ å…¨ã¦å¤±æ•—: 0/{total}")
            print(f"ğŸ“‹ è©³ç´°ã¯ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã¨ã‚¨ãƒ©ãƒ¼ãƒ¬ãƒãƒ¼ãƒˆã‚’ç¢ºèªã—ã¦ãã ã•ã„")
            return False

    except ConfigurationError as e:
        logger.error(f"âŒ è¨­å®šã‚¨ãƒ©ãƒ¼: {e}")
        print(f"âŒ è¨­å®šã‚¨ãƒ©ãƒ¼: {e}")
        return False
        
    except FileNotFoundError as e:
        logger.error(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«ã‚¨ãƒ©ãƒ¼: {e}")
        print(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«ã‚¨ãƒ©ãƒ¼: {e}")
        print("ğŸ’¡ å¯¾å‡¦æ³•:")
        print("  1. å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ãŒæ­£ã—ã„ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«é…ç½®ã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèª")
        print("  2. è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã™ã‚‹ã‹ç¢ºèª")
        print("  3. ãƒ‘ã‚¹ã®æŒ‡å®šãŒæ­£ã—ã„ã‹ç¢ºèª")
        return False
        
    except KeyboardInterrupt:
        logger.info("âŒ ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ã‚ˆã£ã¦å‡¦ç†ãŒä¸­æ–­ã•ã‚Œã¾ã—ãŸ")
        print("\nâŒ å‡¦ç†ãŒä¸­æ–­ã•ã‚Œã¾ã—ãŸ")
        return False
        
    except Exception as e:
        logger.error(f"âŒ äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼: {e}")
        print(f"âŒ äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼: {e}")
        print("ğŸ’¡ å¯¾å‡¦æ³•:")
        print("  1. ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆlogs/ï¼‰ã§è©³ç´°ã‚’ç¢ºèª")
        print("  2. è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®å†…å®¹ã‚’ç¢ºèª")
        print("  3. å¿…è¦ãªãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã™ã‚‹ã‹ç¢ºèª")
        print("  4. --verbose ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã§è©³ç´°ãƒ­ã‚°ã‚’å‡ºåŠ›")
        print("  5. --generate-report ã§ã‚¨ãƒ©ãƒ¼ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ")
        return False


if __name__ == "__main__":
    try:
        success = main()
        sys.exit(0 if success else 1)
    except Exception as e:
        print(f"âŒ ã‚·ã‚¹ãƒ†ãƒ ã‚¨ãƒ©ãƒ¼: {e}")
        logging.error(f"ã‚·ã‚¹ãƒ†ãƒ ã‚¨ãƒ©ãƒ¼: {e}")
        sys.exit(1)