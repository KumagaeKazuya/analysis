"""
YOLO11 åºƒè§’ã‚«ãƒ¡ãƒ©åˆ†æã‚·ã‚¹ãƒ†ãƒ  - æ”¹è‰¯ç‰ˆï¼ˆçµ±ä¸€ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚° + æ·±åº¦æ¨å®šçµ±åˆå¯¾å¿œç‰ˆï¼‰

ğŸ”§ ä¸»ãªæ”¹å–„ç‚¹:
1. çµ±ä¸€ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°å¯¾å¿œ
2. æ·±åº¦æ¨å®šï¼ˆMiDaSï¼‰çµ±åˆæ©Ÿèƒ½
3. æ·±åº¦å¯¾å¿œè©•ä¾¡å™¨ã®è‡ªå‹•é¸æŠ
4. è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®è‡ªå‹•åˆ‡ã‚Šæ›¿ãˆ
5. ã‚¨ãƒ©ãƒ¼åé›†ã¨ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
6. ğŸ”§ ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ä¸è¶³å¯¾å¿œã¨ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æ©Ÿèƒ½
7. ğŸ”§ ErrorCategory.EVALUATION å¯¾å¿œï¼ˆStage 5ä¿®æ­£ï¼‰
8. ğŸ”§ æ¡ä»¶ä»˜ãã‚¤ãƒ³ãƒãƒ¼ãƒˆã®å¼·åŒ–ï¼ˆStage 6ä¿®æ­£ï¼‰
9. ğŸ”§ ç›´æ¥ã‚¤ãƒ³ãƒãƒ¼ãƒˆå‰Šé™¤ã¨ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å®Œå…¨çµ±åˆ
"""
import argparse
import os
import sys
import json
import logging
from datetime import datetime
from pathlib import Path
import argparse
from typing import Dict, Any, Optional, List
import time
from datetime import datetime  # ğŸ”§ è¿½åŠ 
import traceback
import platform

# ğŸ”§ æ¡ä»¶ä»˜ãã‚¤ãƒ³ãƒãƒ¼ãƒˆ - å¿…é ˆãƒ©ã‚¤ãƒ–ãƒ©ãƒª
try:
    import cv2
    import numpy as np
    import pandas as pd
    from ultralytics import YOLO
    import torch
    import matplotlib.pyplot as plt
    from tqdm import tqdm
    import yaml
    print("âœ… å¿…é ˆãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆæˆåŠŸ")
except ImportError as e:
    print(f"âŒ å¿…é ˆãƒ©ã‚¤ãƒ–ãƒ©ãƒªä¸è¶³: {e}")
    print("ğŸ“¦ ä»¥ä¸‹ã§ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¦ãã ã•ã„:")
    print("pip install ultralytics opencv-python numpy pandas matplotlib tqdm pyyaml torch")
    sys.exit(1)

# ğŸ”§ æ¡ä»¶ä»˜ãã‚¤ãƒ³ãƒãƒ¼ãƒˆ - çµ±ä¸€ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ï¼ˆå®Œå…¨çµ±åˆç‰ˆï¼‰
ERROR_HANDLER_AVAILABLE = False
try:
    from utils.error_handler import (
        BaseYOLOError,
        ConfigurationError,
        VideoProcessingError,
        ResponseBuilder,
        handle_errors,
        ErrorContext,
        ErrorCategory,
        ErrorReporter,
        ErrorSeverity
    )
    ERROR_HANDLER_AVAILABLE = True
    print("âœ… çµ±ä¸€ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ãŒåˆ©ç”¨å¯èƒ½ã§ã™")
except ImportError as e:
    print(f"âš ï¸ çµ±ä¸€ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {e}")
    print("ğŸ”§ åŸºæœ¬ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã‚’ä½¿ç”¨ã—ã¾ã™")
    ERROR_HANDLER_AVAILABLE = False

# ğŸ”§ æ¡ä»¶ä»˜ãã‚¤ãƒ³ãƒãƒ¼ãƒˆ - yolopose_analyzerï¼ˆXLargeãƒ¢ãƒ‡ãƒ«ç¢ºå®Ÿä½¿ç”¨ç‰ˆï¼‰
YOLOPOSE_ANALYZER_AVAILABLE = False

try:
    from yolopose_analyzer import analyze_frames_with_tracking_enhanced
    YOLOPOSE_ANALYZER_AVAILABLE = True
    print("âœ… yolopose_analyzer ãŒåˆ©ç”¨å¯èƒ½ã§ã™")
except ImportError as e:
    print(f"âš ï¸ yolopose_analyzer ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {e}")
    YOLOPOSE_ANALYZER_AVAILABLE = False
    
    # ğŸ”§ åŸºæœ¬ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã‚¯ãƒ©ã‚¹ï¼ˆå®Œå…¨ç‰ˆï¼‰
    class BaseYOLOError(Exception):
        def __init__(self, message, details=None):
            super().__init__(message)
            self.message = message
            self.details = details or {}
    
    class ConfigurationError(BaseYOLOError):
        pass
    
    class VideoProcessingError(BaseYOLOError):
        pass
    
    # ğŸ”§ ErrorCategory ã®å®Œå…¨å®Ÿè£…
    class ErrorCategory:
        INITIALIZATION = "initialization"
        VIDEO_PROCESSING = "video_processing"
        EVALUATION = "evaluation"  # ğŸ”§ Stage 5ã‚¨ãƒ©ãƒ¼è§£æ±ºç”¨
        EXPERIMENT = "experiment"
        CONFIGURATION = "configuration"
        MODEL_LOADING = "model_loading"
        MODEL = "model"  # ğŸ”§ è¿½åŠ 
        DEPTH_PROCESSING = "depth_processing"
        PROCESSING = "processing"
        IO_OPERATIONS = "io_operations"
    
    # ğŸ”§ ErrorSeverity ã®å®Œå…¨å®Ÿè£…
    class ErrorSeverity:
        LOW = "low"
        MEDIUM = "medium"
        HIGH = "high"
        CRITICAL = "critical"
    
    # Line 89-250ä»˜è¿‘ã®ResponseBuilderã‚¯ãƒ©ã‚¹ã‚’ä»¥ä¸‹ã§å®Œå…¨ç½®æ›:

    class ResponseBuilder:
        """çµ±ä¸€ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãƒ“ãƒ«ãƒ€ãƒ¼ï¼ˆå®Œå…¨å¾Œæ–¹äº’æ›ç‰ˆï¼‰"""

        @staticmethod
        def success(data=None, message=""):
            """æˆåŠŸãƒ¬ã‚¹ãƒãƒ³ã‚¹"""
            return {"success": True, "data": data, "message": message}

        @staticmethod
        def error(
            error=None,
            include_traceback: bool = True,
            suggestions=None,
            message=None,                         # ğŸ”§ yolopose_analyzerç”¨
            details=None,                         # ğŸ”§ yolopose_analyzerç”¨
            exception=None,                       # ğŸ”§ å¾Œæ–¹äº’æ›æ€§
            **kwargs                              # ğŸ”§ å®Œå…¨äº’æ›ã®ãŸã‚
        ):
            """ã‚¨ãƒ©ãƒ¼ãƒ¬ã‚¹ãƒãƒ³ã‚¹ï¼ˆå®Œå…¨äº’æ›APIï¼‰"""
    
            # å¼•æ•°ã®æ­£è¦åŒ–ï¼ˆè¤‡æ•°ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã«å¯¾å¿œï¼‰
            target_error = error or exception
    
            if message:
                # messageãŒç›´æ¥æŒ‡å®šã•ã‚ŒãŸå ´åˆï¼ˆyolopose_analyzerç”¨ï¼‰
                response = {
                    "success": False,
                    "error": {
                        "error_type": "CustomError",
                        "message": message,
                        "category": "unknown",
                        "severity": "error",
                        "timestamp": datetime.now().isoformat()
                    }
                }
            elif hasattr(target_error, 'to_dict') and callable(getattr(target_error, 'to_dict')):
                # BaseYOLOErrorã®å ´åˆ
                response = {
                    "success": False,
                    "error": target_error.to_dict()
                }
            elif isinstance(target_error, Exception):
                # æ¨™æº–Exceptionã®å ´åˆ
                response = {
                    "success": False,
                    "error": {
                        "error_type": type(target_error).__name__,
                        "message": str(target_error),
                        "category": "unknown",
                        "severity": "error",
                        "timestamp": datetime.now().isoformat()
                    }
                }
        
                if include_traceback:
                    import traceback
                    response["error"]["traceback"] = traceback.format_exc()
            elif isinstance(target_error, str):
                # æ–‡å­—åˆ—ã‚¨ãƒ©ãƒ¼ã®å ´åˆ
                response = {
                    "success": False,
                    "error": {
                        "error_type": "StringError",
                        "message": target_error,
                        "category": "unknown", 
                        "severity": "error",
                        "timestamp": datetime.now().isoformat()
                    }
                }
            else:
                # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
                response = {
                    "success": False,
                    "error": {
                        "error_type": "UnknownError",
                        "message": "ä¸æ˜ãªã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ",
                        "category": "unknown",
                        "severity": "error",
                        "timestamp": datetime.now().isoformat()
                    }
                }
    
            # suggestionsè¿½åŠ 
            if suggestions:
                response["suggestions"] = suggestions
        
            # detailsè¿½åŠ ï¼ˆé‡è¦ï¼ï¼‰
            if details:
                response["details"] = details
        
            # ãã®ä»–ã®kwargså¯¾å¿œ
            for key, value in kwargs.items():
                if key not in response:
                    response[key] = value
        
            return response

        @staticmethod
        def validation_error(field=None, message=None, details=None, **kwargs):
            """ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã‚¨ãƒ©ãƒ¼ï¼ˆå®Œå…¨å¾Œæ–¹äº’æ›ï¼‰"""
            if message:
                error_message = message
            elif field:
                error_message = f"ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã‚¨ãƒ©ãƒ¼: {field}"
            else:
                error_message = "ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã‚¨ãƒ©ãƒ¼"
            
            response = {
                "success": False,
                "error": {
                    "error_type": "ValidationError",
                    "message": error_message,
                    "field": field,
                    "category": "validation",
                    "severity": "error",
                    "timestamp": datetime.now().isoformat()
                }
            }
        
            # detailså¼•æ•°ã®ã‚µãƒãƒ¼ãƒˆï¼ˆé‡è¦ï¼ï¼‰
            if details:
                response["details"] = details
            
            # ãã®ä»–ã®kwargså¯¾å¿œ
            for key, value in kwargs.items():
                if key not in response:
                    response[key] = value
            
            return response

        @staticmethod
        def processing_error(step=None, message=None, details=None, **kwargs):
            """å‡¦ç†ã‚¨ãƒ©ãƒ¼ï¼ˆå®Œå…¨äº’æ›ï¼‰"""
            error_message = message or f"å‡¦ç†ã‚¨ãƒ©ãƒ¼: {step}"
            result = {
                "success": False,
                "error": {
                    "error_type": "ProcessingError", 
                    "message": error_message,
                    "step": step,
                    "category": "processing",
                    "severity": "error",
                    "timestamp": datetime.now().isoformat()
               }
            }
        
            if details:
                result["details"] = details
            
            # ãã®ä»–ã®kwargså¯¾å¿œ
            for key, value in kwargs.items():
                if key not in result:
                    result[key] = value
            
            return result

        @staticmethod
        def configuration_error(config_key=None, message=None, details=None, **kwargs):
            """è¨­å®šã‚¨ãƒ©ãƒ¼ï¼ˆå®Œå…¨äº’æ›ï¼‰"""
            error_message = message or f"è¨­å®šã‚¨ãƒ©ãƒ¼: {config_key}"
            result = {
                "success": False,
                "error": {
                    "error_type": "ConfigurationError",
                    "message": error_message,
                    "config_key": config_key,
                    "category": "configuration",
                    "severity": "error",
                    "timestamp": datetime.now().isoformat()
                }
            }
        
            if details:
                result["details"] = details
            
            # ãã®ä»–ã®kwargså¯¾å¿œ
            for key, value in kwargs.items():
                if key not in result:
                    result[key] = value
            
            return result

        @staticmethod
        def model_error(model_path=None, message=None, details=None, **kwargs):
            """ãƒ¢ãƒ‡ãƒ«ã‚¨ãƒ©ãƒ¼ï¼ˆå®Œå…¨äº’æ›ï¼‰"""
            error_message = message or f"ãƒ¢ãƒ‡ãƒ«ã‚¨ãƒ©ãƒ¼: {model_path}"
            result = {
                "success": False,
                "error": {
                    "error_type": "ModelError",
                    "message": error_message,
                    "model_path": model_path,
                    "category": "model",
                    "severity": "error",
                    "timestamp": datetime.now().isoformat()
                }
            }
        
            if details:
                result["details"] = details
            
            # ãã®ä»–ã®kwargså¯¾å¿œ
            for key, value in kwargs.items():
                if key not in result:
                    result[key] = value
            
            return result
    
    class ErrorContext:
        def __init__(self, name, logger=None, raise_on_error=False):
            self.name = name
            self.logger = logger or logging.getLogger(__name__)
            self.raise_on_error = raise_on_error
            
        def __enter__(self):
            self.logger.debug(f"ğŸ” ã‚¨ãƒ©ãƒ¼ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆé–‹å§‹: {self.name}")
            return self
            
        def __exit__(self, exc_type, exc_val, exc_tb):
            if exc_type and self.logger:
                self.logger.error(f"âŒ ã‚¨ãƒ©ãƒ¼ in {self.name}: {exc_val}")
            elif self.logger:
                self.logger.debug(f"âœ… ã‚¨ãƒ©ãƒ¼ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæ­£å¸¸çµ‚äº†: {self.name}")
            return not self.raise_on_error
        
        def add_info(self, key, value):
            self.logger.debug(f"ğŸ“ {self.name} - {key}: {value}")

    class ErrorReporter:
        def __init__(self):
            self.errors = []
        
        def add_error(self, error, context=None):
            self.errors.append({"error": str(error), "context": context, "timestamp": datetime.now().isoformat()})

# ğŸ”§ æ¡ä»¶ä»˜ãã‚¤ãƒ³ãƒãƒ¼ãƒˆ - è©•ä¾¡å™¨ï¼ˆå®Œå…¨çµ±åˆç‰ˆï¼‰
EVALUATOR_AVAILABLE = False
DEPTH_EVALUATOR_AVAILABLE = False
COMPREHENSIVE_EVALUATOR_AVAILABLE = False
ComprehensiveEvaluator = None
DepthEnhancedEvaluator = None

try:
    # evaluatorsãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®æ®µéšçš„ãƒã‚§ãƒƒã‚¯
    import evaluators
    print("âœ… evaluators ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸ")
    
    try:
        from evaluators.comprehensive_evaluator import ComprehensiveEvaluator
        COMPREHENSIVE_EVALUATOR_AVAILABLE = True
        EVALUATOR_AVAILABLE = True
        print("âœ… ComprehensiveEvaluator ãŒåˆ©ç”¨å¯èƒ½ã§ã™")
        
        try:
            from evaluators.comprehensive_evaluator import DepthEnhancedEvaluator
            DEPTH_EVALUATOR_AVAILABLE = True
            print("âœ… DepthEnhancedEvaluator ãŒåˆ©ç”¨å¯èƒ½ã§ã™")
        except (ImportError, AttributeError) as e:
            print(f"âš ï¸ DepthEnhancedEvaluator ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“: {e}")
            DEPTH_EVALUATOR_AVAILABLE = False
            
    except ImportError as e:
        print(f"âš ï¸ ComprehensiveEvaluator ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆã«å¤±æ•—: {e}")
        COMPREHENSIVE_EVALUATOR_AVAILABLE = False
        EVALUATOR_AVAILABLE = False
        
except ImportError as e:
    print(f"âš ï¸ evaluators ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {e}")
    EVALUATOR_AVAILABLE = False
    COMPREHENSIVE_EVALUATOR_AVAILABLE = False
    DEPTH_EVALUATOR_AVAILABLE = False

# ğŸ”§ æ¡ä»¶ä»˜ãã‚¤ãƒ³ãƒãƒ¼ãƒˆ - è¨­å®šç®¡ç†ï¼ˆå®Œå…¨çµ±åˆç‰ˆï¼‰
CONFIG_AVAILABLE = False
Config = None

try:
    from utils.config import Config
    CONFIG_AVAILABLE = True
    print("âœ… Config ãŒåˆ©ç”¨å¯èƒ½ã§ã™")
except ImportError as e:
    print(f"âš ï¸ Config ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {e}")
    print("ğŸ”§ åŸºæœ¬è¨­å®šæ©Ÿèƒ½ã‚’ä½¿ç”¨ã—ã¾ã™")
    CONFIG_AVAILABLE = False

# ğŸ”§ BasicEvaluatorï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”¨ãƒ»å®Œå…¨ç‰ˆï¼‰
if not EVALUATOR_AVAILABLE:
    print("ğŸ”§ åŸºæœ¬è©•ä¾¡æ©Ÿèƒ½ã‚’ä½¿ç”¨ã—ã¾ã™")
    
    class BasicEvaluator:
        def __init__(self, config=None):
            self.config = config or {}
            self.results = {}
            self.logger = logging.getLogger(__name__)
        
        def evaluate_comprehensive(self, video_path, detection_results, video_name):
            """åŸºæœ¬çš„ãªè©•ä¾¡ï¼ˆå®Œå…¨ç‰ˆï¼‰"""
            try:
                self.logger.info(f"ğŸ” åŸºæœ¬è©•ä¾¡é–‹å§‹: {video_name}")
                
                # ãƒ‡ãƒ¼ã‚¿æŠ½å‡ºã®æ”¹å–„
                if isinstance(detection_results, dict):
                    if detection_results.get("success", False):
                        data = detection_results.get("data", {})
                    else:
                        self.logger.warning("detection_results ãŒå¤±æ•—çŠ¶æ…‹ã§ã™")
                        data = {}
                else:
                    data = {}
                
                csv_path = data.get("csv_path") or data.get("enhanced_csv_path")
                
                basic_metrics = {
                    "video_name": video_name,
                    "video_path": str(video_path),
                    "detection_count": data.get("detection_count", 0),
                    "frame_count": data.get("frame_count", 0),
                    "processing_time": data.get("processing_time", 0),
                    "timestamp": datetime.now().isoformat(),
                    "evaluator_type": "BasicEvaluator",
                    "depth_enabled": data.get("depth_enabled", False),
                    "processing_stats": data.get("processing_stats", {})
                }
                
                # CSVãƒ•ã‚¡ã‚¤ãƒ«åˆ†æã®æ”¹å–„
                if csv_path and Path(csv_path).exists():
                    try:
                        df = pd.read_csv(csv_path)
                        self.logger.info(f"ğŸ“Š CSVåˆ†æ: {len(df)}è¡Œã®ãƒ‡ãƒ¼ã‚¿")
                        
                        csv_metrics = {
                            "total_detections": len(df),
                            "detection_success": True,
                            "csv_path": str(csv_path)
                        }
                        
                        # ã‚«ãƒ©ãƒ ãƒ™ãƒ¼ã‚¹ã®è©³ç´°åˆ†æ
                        available_columns = df.columns.tolist()
                        csv_metrics["available_columns"] = available_columns
                        
                        if 'track_id' in df.columns:
                            csv_metrics["unique_track_ids"] = df['track_id'].nunique()
                        
                        if 'confidence' in df.columns:
                            csv_metrics["confidence_mean"] = float(df['confidence'].mean())
                            csv_metrics["confidence_std"] = float(df['confidence'].std())
                            csv_metrics["confidence_min"] = float(df['confidence'].min())
                            csv_metrics["confidence_max"] = float(df['confidence'].max())
                        
                        # æ·±åº¦é–¢é€£ã‚«ãƒ©ãƒ ã®è©³ç´°ç¢ºèª
                        depth_columns = [col for col in df.columns if 'depth' in col.lower()]
                        if depth_columns:
                            csv_metrics["depth_columns"] = depth_columns
                            csv_metrics["depth_analysis_available"] = True
                            # æ·±åº¦ãƒ‡ãƒ¼ã‚¿ã®çµ±è¨ˆ
                            for depth_col in depth_columns:
                                if df[depth_col].dtype in ['float64', 'int64']:
                                    csv_metrics[f"{depth_col}_mean"] = float(df[depth_col].mean())
                        
                        basic_metrics.update(csv_metrics)
                        
                    except Exception as e:
                        self.logger.warning(f"CSVåˆ†æã‚¨ãƒ©ãƒ¼: {e}")
                        basic_metrics.update({
                            "detection_success": False,
                            "csv_error": str(e),
                            "csv_path": str(csv_path) if csv_path else None
                        })
                else:
                    self.logger.warning(f"CSV ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {csv_path}")
                    basic_metrics["csv_available"] = False
                
                self.logger.info(f"âœ… åŸºæœ¬è©•ä¾¡å®Œäº†: {video_name}")
                return ResponseBuilder.success(data=basic_metrics)
                
            except Exception as e:
                self.logger.error(f"âŒ åŸºæœ¬è©•ä¾¡ã‚¨ãƒ©ãƒ¼: {e}")
                return ResponseBuilder.error(e, suggestions=[
                    "è©•ä¾¡ãƒ‡ãƒ¼ã‚¿ã®å½¢å¼ã‚’ç¢ºèªã—ã¦ãã ã•ã„",
                    "CSVãƒ•ã‚¡ã‚¤ãƒ«ãŒæ­£ã—ãç”Ÿæˆã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„",
                    "å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ã®å‹ã‚’ç¢ºèªã—ã¦ãã ã•ã„"
                ])
        
        def evaluate_with_depth(self, video_path, detection_results, video_name):
            """æ·±åº¦å¯¾å¿œè©•ä¾¡ï¼ˆBasicEvaluatorç‰ˆï¼‰"""
            self.logger.info(f"ğŸ” æ·±åº¦å¯¾å¿œåŸºæœ¬è©•ä¾¡: {video_name}")
            result = self.evaluate_comprehensive(video_path, detection_results, video_name)
            
            if result.get("success", False):
                result["data"]["depth_evaluator_type"] = "BasicEvaluator"
                result["data"]["depth_support"] = "limited"
            
            return result

# ğŸ”§ æ¡ä»¶ä»˜ãã‚¤ãƒ³ãƒãƒ¼ãƒˆ - ãƒ—ãƒ­ã‚»ãƒƒã‚µãƒ¼ï¼ˆå®Œå…¨çµ±åˆç‰ˆï¼‰
VIDEO_PROCESSOR_AVAILABLE = False
VideoProcessor = None

try:
    from processors.video_processor import VideoProcessor
    VIDEO_PROCESSOR_AVAILABLE = True
    print("âœ… VideoProcessor ãŒåˆ©ç”¨å¯èƒ½ã§ã™")
except ImportError as e:
    print(f"âš ï¸ VideoProcessor ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {e}")
    print("ğŸ”§ åŸºæœ¬å‹•ç”»å‡¦ç†ã‚’ä½¿ç”¨ã—ã¾ã™")
    VIDEO_PROCESSOR_AVAILABLE = False

# ğŸ”§ BasicVideoProcessorï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”¨ãƒ»å®Œå…¨ç‰ˆï¼‰
if not VIDEO_PROCESSOR_AVAILABLE:
    class BasicVideoProcessor:
        def __init__(self, config):
            """åŸºæœ¬å‹•ç”»ãƒ—ãƒ­ã‚»ãƒƒã‚µãƒ¼åˆæœŸåŒ–ï¼ˆå®Œå…¨ç‰ˆï¼‰"""
            self.config = config
            self.logger = logging.getLogger(__name__)
            self.processing_stats = {}  # ğŸ”§ çµ±è¨ˆæƒ…å ±è¾æ›¸ã‚’åˆæœŸåŒ–
    
            if hasattr(config, 'get'):
                self.output_dir = Path(config.get('output_dir', 'outputs'))
                self.max_frames = config.get('processing.max_frames', 100)
            else:
                self.output_dir = Path('outputs')
                self.max_frames = 100
    
            self.output_dir.mkdir(exist_ok=True)
            self.logger.info(f"ğŸ¬ åŸºæœ¬å‹•ç”»ãƒ—ãƒ­ã‚»ãƒƒã‚µãƒ¼åˆæœŸåŒ–å®Œäº†")
        
        def load_models(self):
            """ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰ï¼ˆãƒ‘ã‚¹é‡è¤‡ä¿®æ­£ç‰ˆï¼‰"""
            try:
                if hasattr(self.config, 'get'):
                    models_config = self.config.get('models', {})
                elif isinstance(self.config, dict):
                    models_config = self.config.get('models', {})
                else:
                    models_config = {}
                
                # âš¡ ãƒ‘ã‚¹é‡è¤‡ã‚’é˜²ãä¿®æ­£
                detection_path = models_config.get('detection', 'models/yolo11x.pt')
                pose_path = models_config.get('pose', 'models/yolo11x-pose.pt')
                
                # ãƒ‘ã‚¹é‡è¤‡ãƒã‚§ãƒƒã‚¯
                if detection_path.startswith('models/models/'):
                    detection_path = detection_path.replace('models/models/', 'models/')
                if pose_path.startswith('models/models/'):
                    pose_path = pose_path.replace('models/models/', 'models/')
                
                self.logger.info(f"ğŸ” ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰é–‹å§‹")
                self.logger.info(f"ğŸ“Š æ¤œå‡ºãƒ¢ãƒ‡ãƒ«ãƒ‘ã‚¹: {detection_path}")
                self.logger.info(f"ğŸ“Š ãƒãƒ¼ã‚ºãƒ¢ãƒ‡ãƒ«ãƒ‘ã‚¹: {pose_path}")
                
                # æ¤œå‡ºãƒ¢ãƒ‡ãƒ«
                if Path(detection_path).exists():
                    self.detection_model = YOLO(detection_path)
                    self.logger.info(f"âœ… æ¤œå‡ºãƒ¢ãƒ‡ãƒ«: {detection_path}")
                else:
                    self.logger.warning(f"âš ï¸ æ¤œå‡ºãƒ¢ãƒ‡ãƒ«æœªç™ºè¦‹: {detection_path}")
                    # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: è‡ªå‹•ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
                    self.detection_model = YOLO('yolo11x.pt')
                    self.logger.info("âœ… æ¤œå‡ºãƒ¢ãƒ‡ãƒ«: è‡ªå‹•ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰")

                # ãƒãƒ¼ã‚ºãƒ¢ãƒ‡ãƒ«
                if Path(pose_path).exists():
                    self.pose_model = YOLO(pose_path)
                    self.logger.info(f"âœ… ãƒãƒ¼ã‚ºãƒ¢ãƒ‡ãƒ«: {pose_path}")
                else:
                    self.logger.warning(f"âš ï¸ ãƒãƒ¼ã‚ºãƒ¢ãƒ‡ãƒ«æœªç™ºè¦‹: {pose_path}")
                    # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: è‡ªå‹•ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
                    self.pose_model = YOLO('yolo11x-pose.pt')
                    self.logger.info("âœ… ãƒãƒ¼ã‚ºãƒ¢ãƒ‡ãƒ«: è‡ªå‹•ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰")
                
                self.logger.info("âœ… å…¨ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰å®Œäº†")
                
            except Exception as e:
                self.logger.error(f"âŒ ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼: {e}")
                raise
        
        # BasicVideoProcessor ã® extract_frames ãƒ¡ã‚½ãƒƒãƒ‰ã‚’ä¿®æ­£:

        def extract_frames(self, video_path, frame_dir, max_frames=1000):
            """ãƒ•ãƒ¬ãƒ¼ãƒ æŠ½å‡ºï¼ˆçµ±è¨ˆä¿®æ­£ç‰ˆï¼‰"""
            try:
                # ğŸ”§ processing_statsã®ç¢ºå®ŸãªåˆæœŸåŒ–
                if not hasattr(self, 'processing_stats'):
                    self.processing_stats = {}
            
                self.logger.info(f"ğŸ“¸ ãƒ•ãƒ¬ãƒ¼ãƒ æŠ½å‡ºé–‹å§‹: {video_path}")
                frame_dir = Path(frame_dir)
                frame_dir.mkdir(parents=True, exist_ok=True)

                # å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã®å­˜åœ¨ç¢ºèª
                if not Path(video_path).exists():
                    self.logger.error(f"âŒ å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ã¾ã›ã‚“: {video_path}")
                    return {"success": False, "error": f"å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ã¾ã›ã‚“: {video_path}"}

                # ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºãƒã‚§ãƒƒã‚¯
                file_size = Path(video_path).stat().st_size
                if file_size == 0:
                    self.logger.error(f"âŒ å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ãŒç©ºã§ã™: {video_path}")
                    return {"success": False, "error": f"å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ãŒç©ºã§ã™: {video_path}"}

                self.logger.info(f"ğŸ“¹ å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: {file_size / (1024*1024):.1f}MB")

                # ğŸ”§ OpenCVã§ãƒ•ãƒ¬ãƒ¼ãƒ æŠ½å‡º
                cap = cv2.VideoCapture(str(video_path))
                if not cap.isOpened():
                    self.logger.error(f"âŒ å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é–‹ã‘ã¾ã›ã‚“: {video_path}")
                    return {"success": False, "error": f"å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é–‹ã‘ã¾ã›ã‚“: {video_path}"}

                # å‹•ç”»æƒ…å ±å–å¾—
                frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
                fps = cap.get(cv2.CAP_PROP_FPS)
                width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
                height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
                duration = frame_count / fps if fps > 0 else 0

                self.logger.info(f"ğŸ“¹ å‹•ç”»æƒ…å ±: {width}x{height}, {frame_count}ãƒ•ãƒ¬ãƒ¼ãƒ , {fps:.1f}FPS, {duration:.1f}ç§’")

                # ãƒ•ãƒ¬ãƒ¼ãƒ æ•°ãŒ0ã®å ´åˆã®ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°
                if frame_count <= 0:
                    cap.release()
                    self.logger.error(f"âŒ æœ‰åŠ¹ãªãƒ•ãƒ¬ãƒ¼ãƒ ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {video_path}")
                    return {"success": False, "error": "æœ‰åŠ¹ãªãƒ•ãƒ¬ãƒ¼ãƒ ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“"}

                # æŠ½å‡ºé–“éš”è¨ˆç®—
                interval = max(1, frame_count // max_frames)
                self.logger.info(f"ğŸ”¢ æŠ½å‡ºé–“éš”: {interval} (æœ€å¤§{max_frames}ãƒ•ãƒ¬ãƒ¼ãƒ )")

                # ãƒ•ãƒ¬ãƒ¼ãƒ æŠ½å‡ºãƒ«ãƒ¼ãƒ—
                extracted = 0
                frame_number = 0

                while True:
                    ret, frame = cap.read()
                    if not ret:
                        break

                    if frame_number % interval == 0:
                        frame_path = frame_dir / f"frame_{frame_number:06d}.jpg"
                        success = cv2.imwrite(str(frame_path), frame)

                        if success:
                            extracted += 1
                            if extracted >= max_frames:
                                break
                        else:
                            self.logger.warning(f"âš ï¸ ãƒ•ãƒ¬ãƒ¼ãƒ ä¿å­˜å¤±æ•—: {frame_path}")
            
                    frame_number += 1

                cap.release()

                # ğŸ”§ å®Ÿéš›ã«ä¿å­˜ã•ã‚ŒãŸãƒ•ãƒ¬ãƒ¼ãƒ æ•°ã‚’å†ç¢ºèªï¼ˆé‡è¦ï¼ï¼‰
                saved_frames = len(list(frame_dir.glob("frame_*.jpg")))
                self.logger.info(f"ğŸ“Š OpenCVã§æŠ½å‡º: {extracted}å€‹")
                self.logger.info(f"ğŸ“Š å®Ÿéš›ã«ä¿å­˜: {saved_frames}å€‹")

                # ğŸ”§ æœ€å¤§å€¤ã‚’æ¡ç”¨ï¼ˆç¢ºå®Ÿã«ãƒ•ãƒ¬ãƒ¼ãƒ æ•°ã‚’å–å¾—ï¼‰
                final_extracted = max(extracted, saved_frames)

                # çµ±è¨ˆæƒ…å ±ã®æ›´æ–°
                self.processing_stats["frame_extraction"] = {
                    "total_frames": frame_count,
                    "extracted_frames": final_extracted,  # â† ç¢ºå®Ÿãªå€¤
                    "video_fps": fps,
                    "video_duration": duration,
                    "resolution": [width, height],
                    "extraction_interval": interval
                }

                self.logger.info(f"âœ… ãƒ•ãƒ¬ãƒ¼ãƒ æŠ½å‡ºå®Œäº†: {final_extracted}ãƒ•ãƒ¬ãƒ¼ãƒ ")

                if final_extracted == 0:
                    self.logger.error("âŒ ãƒ•ãƒ¬ãƒ¼ãƒ æŠ½å‡ºã«å¤±æ•—ã—ã¾ã—ãŸ")
                    return {"success": False, "error": "ãƒ•ãƒ¬ãƒ¼ãƒ æŠ½å‡ºã«å¤±æ•—ã—ã¾ã—ãŸ"}

                # ğŸ”§ ç¢ºå®Ÿã«extracted_framesã‚’è¿”ã™
                return {
                    "success": True, 
                    "extracted_frames": final_extracted,  # â† é‡è¦ï¼šã“ã®å€¤ãŒ0ã«ãªã£ã¦ã¯ã„ã‘ãªã„
                    "video_info": self.processing_stats["frame_extraction"]
                }

            except Exception as e:
                self.logger.error(f"âŒ ãƒ•ãƒ¬ãƒ¼ãƒ æŠ½å‡ºã‚¨ãƒ©ãƒ¼: {e}")
                return {"success": False, "error": str(e)}
        
        def run_detection_tracking(self, frame_dir, video_name):
            """åŸºæœ¬æ¤œå‡ºãƒ»è¿½è·¡å‡¦ç†ï¼ˆå®‰å®šåŒ–ç‰ˆï¼‰"""
            try:
                self.logger.info(f"ğŸ‘ï¸ åŸºæœ¬æ¤œå‡ºãƒ»è¿½è·¡å‡¦ç†é–‹å§‹: {video_name}")
                frame_files = sorted(list(Path(frame_dir).glob("*.jpg")))
        
                if not frame_files:
                    raise VideoProcessingError(f"ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {frame_dir}")
        
                self.logger.info(f"ğŸ“¸ å‡¦ç†å¯¾è±¡ãƒ•ãƒ¬ãƒ¼ãƒ : {len(frame_files)}å€‹")
        
                # ãƒ¢ãƒ‡ãƒ«ã®äº‹å‰ãƒ­ãƒ¼ãƒ‰ç¢ºèª
                if not hasattr(self, 'detection_model') and not hasattr(self, 'pose_model'):
                    self.load_models()
        
                detection_count = 0
                frame_stats = []
        
                # ä¿¡é ¼åº¦ã—ãã„å€¤ï¼ˆã‚ˆã‚Šä½ãè¨­å®šã—ã¦æ¤œå‡ºç‡å‘ä¸Šï¼‰
                conf_threshold = 0.25
        
                # ğŸ”§ ç°¡ç•¥åŒ–ã•ã‚ŒãŸå‡¦ç†ãƒ«ãƒ¼ãƒ—
                for i, frame_file in enumerate(frame_files):
                    try:
                        # ãƒ•ãƒ¬ãƒ¼ãƒ èª­ã¿è¾¼ã¿
                        frame = cv2.imread(str(frame_file))
                        if frame is None:
                            self.logger.warning(f"âš ï¸ ãƒ•ãƒ¬ãƒ¼ãƒ èª­ã¿è¾¼ã¿å¤±æ•—: {frame_file}")
                            continue
                
                        frame_detections = 0
                
                        # ğŸ”§ ãƒãƒ¼ã‚ºãƒ¢ãƒ‡ãƒ«å„ªå…ˆï¼ˆã‚ˆã‚Šç¢ºå®Ÿï¼‰
                        if hasattr(self, 'pose_model') and self.pose_model:
                            try:
                                results = self.pose_model(frame, verbose=False, conf=conf_threshold)
                                if results and len(results[0].boxes) > 0:
                                    frame_detections = len(results[0].boxes)
                                    detection_count += frame_detections
                            except Exception as e:
                                self.logger.debug(f"ãƒ•ãƒ¬ãƒ¼ãƒ {i}ãƒãƒ¼ã‚ºæ¤œå‡ºã‚¨ãƒ©ãƒ¼: {e}")
                
                        # ãƒ•ãƒ¬ãƒ¼ãƒ çµ±è¨ˆè¨˜éŒ²ï¼ˆç°¡ç•¥åŒ–ï¼‰
                        frame_stats.append({
                            "frame_id": i,
                            "frame_file": frame_file.name,
                            "detections": frame_detections,
                            "conf": conf_threshold,  # å›ºå®šå€¤
                            "track_id": i,  # ç°¡æ˜“ID
                            "timestamp": datetime.now().isoformat()
                        })
                
                    except Exception as e:
                        self.logger.warning(f"ãƒ•ãƒ¬ãƒ¼ãƒ {i}å‡¦ç†ã‚¨ãƒ©ãƒ¼ï¼ˆç¶šè¡Œï¼‰: {e}")
                        continue
        
                # çµæœCSVä½œæˆ
                output_dir = Path("outputs/temp") / video_name
                output_dir.mkdir(parents=True, exist_ok=True)
                csv_path = output_dir / f"{video_name}_results.csv"
        
                if frame_stats:
                    df = pd.DataFrame(frame_stats)
                    df.to_csv(csv_path, index=False)
                    self.logger.info(f"ğŸ“Š çµæœCSVä¿å­˜: {csv_path}")
                else:
                    # ğŸ”§ ç©ºã®å ´åˆã§ã‚‚CSVã‚’ä½œæˆ
                    empty_df = pd.DataFrame(columns=["frame_id", "frame_file", "detections", "conf", "track_id", "timestamp"])
                    empty_df.to_csv(csv_path, index=False)
                    self.logger.warning("âš ï¸ æ¤œå‡ºçµæœãªã— - ç©ºã®CSVã‚’ä½œæˆ")
        
                # çµ±è¨ˆæƒ…å ±
                self.processing_stats = {
                    "detection_tracking": {
                        "total_frames": len(frame_files),
                        "processed_frames": len(frame_stats),
                        "total_detections": detection_count,
                        "success_rate": len(frame_stats) / len(frame_files) if frame_files else 0
                    }
                }
        
                self.logger.info(f"âœ… åŸºæœ¬æ¤œå‡ºãƒ»è¿½è·¡å®Œäº†: {detection_count}å€‹æ¤œå‡º / {len(frame_stats)}ãƒ•ãƒ¬ãƒ¼ãƒ å‡¦ç†")
        
                return {
                    "success": True,
                    "data": {
                        "csv_path": str(csv_path),
                        "detection_count": detection_count,
                        "frame_count": len(frame_files),
                        "processed_frames": len(frame_stats),
                        "processing_stats": self.processing_stats["detection_tracking"]
                    }
                }
        
            except Exception as e:
                self.logger.error(f"âŒ åŸºæœ¬æ¤œå‡ºãƒ»è¿½è·¡ã‚¨ãƒ©ãƒ¼: {e}")
                return {"success": False, "error": str(e)}
        
        def run_detection_tracking_with_depth(self, frame_dir, video_name):
            """æ·±åº¦çµ±åˆæ¤œå‡ºãƒ»è¿½è·¡å‡¦ç†ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç‰ˆï¼‰"""
            self.logger.warning("ğŸ”§ æ·±åº¦çµ±åˆå‡¦ç†ã¯åˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚é€šå¸¸å‡¦ç†ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã—ã¾ã™")
            result = self.run_detection_tracking(frame_dir, video_name)
            
            if result.get("success", False):
                result["data"]["depth_enabled"] = False
                result["data"]["depth_fallback"] = True
                result["data"]["enhanced_csv_path"] = result["data"]["csv_path"]
                self.logger.info("âœ… ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç†å®Œäº†ï¼ˆæ·±åº¦æ©Ÿèƒ½ç„¡åŠ¹ï¼‰")
            
            return result

# ğŸ”§ æ¡ä»¶ä»˜ãã‚¤ãƒ³ãƒãƒ¼ãƒˆ - ã‚¢ãƒŠãƒ©ã‚¤ã‚¶ãƒ¼ï¼ˆå®Œå…¨çµ±åˆç‰ˆï¼‰
METRICS_ANALYZER_AVAILABLE = False
MetricsAnalyzer = None

try:
    from analyzers.metrics_analyzer import MetricsAnalyzer
    METRICS_ANALYZER_AVAILABLE = True
    print("âœ… MetricsAnalyzer ãŒåˆ©ç”¨å¯èƒ½ã§ã™")
except ImportError as e:
    print(f"âš ï¸ MetricsAnalyzer ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {e}")
    print("ğŸ”§ åŸºæœ¬åˆ†ææ©Ÿèƒ½ã‚’ä½¿ç”¨ã—ã¾ã™")
    METRICS_ANALYZER_AVAILABLE = False

# ğŸ”§ BasicMetricsAnalyzerï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”¨ãƒ»å®Œå…¨ç‰ˆï¼‰
if not METRICS_ANALYZER_AVAILABLE:
    class BasicMetricsAnalyzer:
        def __init__(self, config):
            self.config = config
            self.logger = logging.getLogger(__name__)
        
        def analyze_improvements(self, comparison_results):
            """åŸºæœ¬æ”¹å–„åˆ†æï¼ˆå®Œå…¨ç‰ˆï¼‰"""
            self.logger.info("ğŸ“Š åŸºæœ¬æ”¹å–„åˆ†æé–‹å§‹")
            
            try:
                baseline = comparison_results.get("baseline", {})
                experiment = comparison_results.get("experiment", {})
                
                analysis = {
                    "analyzer_type": "BasicMetricsAnalyzer",
                    "comparison_available": bool(baseline and experiment),
                    "timestamp": datetime.now().isoformat()
                }
                
                if baseline and experiment:
                    # å‡¦ç†æ™‚é–“æ¯”è¼ƒ
                    baseline_time = baseline.get("processing_time", 0)
                    experiment_time = experiment.get("processing_time", 0)
                    
                    if baseline_time > 0:
                        time_improvement = ((baseline_time - experiment_time) / baseline_time) * 100
                        analysis["time_improvement_percent"] = time_improvement
                        analysis["time_comparison"] = {
                            "baseline_time": baseline_time,
                            "experiment_time": experiment_time,
                            "improvement": time_improvement
                        }
                    
                    # æ¤œå‡ºæ•°æ¯”è¼ƒ
                    baseline_detections = baseline.get("detection_count", 0)
                    experiment_detections = experiment.get("detection_count", 0)
                    
                    analysis["detection_comparison"] = {
                        "baseline": baseline_detections,
                        "experiment": experiment_detections,
                        "difference": experiment_detections - baseline_detections,
                        "improvement_rate": ((experiment_detections - baseline_detections) / baseline_detections * 100) if baseline_detections > 0 else 0
                    }
                    
                    # å“è³ªæ¯”è¼ƒ
                    analysis["quality_comparison"] = {
                        "baseline_success": baseline.get("success", False),
                        "experiment_success": experiment.get("success", False)
                    }
                
                self.logger.info("âœ… åŸºæœ¬æ”¹å–„åˆ†æå®Œäº†")
                return analysis
                
            except Exception as e:
                self.logger.error(f"âŒ æ”¹å–„åˆ†æã‚¨ãƒ©ãƒ¼: {e}")
                return {"basic_analysis": f"ã‚¨ãƒ©ãƒ¼: {e}", "error": True}
        
        # Line 845ä»˜è¿‘ã® create_visualizations ãƒ¡ã‚½ãƒƒãƒ‰ã‚’å®Œå…¨ç½®æ›:

        # Line 874ä»˜è¿‘ã®create_visualizationsãƒ¡ã‚½ãƒƒãƒ‰ã‚’ä»¥ä¸‹ã§å®Œå…¨ç½®æ›:

        def create_visualizations(self, detection_results, vis_dir):
            """åŸºæœ¬å¯è¦–åŒ–ï¼ˆæ—¥æ™‚ä»˜ããƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå¯¾å¿œç‰ˆï¼‰"""
            self.logger.info(f"ğŸ“ˆ åŸºæœ¬å¯è¦–åŒ–ç”Ÿæˆ: {vis_dir}")

            # ğŸ”§ å¿…ãšæˆ»ã‚Šå€¤ã‚’è¿”ã™ã‚ˆã†ã«ã™ã‚‹ï¼ˆåˆæœŸåŒ–ï¼‰
            result = {
                "success": False,
                "error": "åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼",
                "basic_stats_file": None,
                "graphs_generated": 0,
                "total_files": 0
            }

            try:
                from pathlib import Path
                import json
                from datetime import datetime

                # ğŸ”§ ä¿®æ­£: vis_dir ãŒã™ã§ã«ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ä»˜ãã®å ´åˆã¯ãã®ã¾ã¾ä½¿ç”¨
                vis_path = Path(str(vis_dir))
        
                # ğŸ”§ è¿½åŠ : ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ãŒå«ã¾ã‚Œã¦ã„ãªã„å ´åˆã®ã¿è¿½åŠ 
                if not any(char.isdigit() for char in vis_path.name[-15:]):  # æœ«å°¾15æ–‡å­—ã«æ•°å­—ãŒå«ã¾ã‚Œã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
                    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                    vis_path = vis_path.parent / f"{vis_path.name}_{timestamp}"
        
                vis_path.mkdir(parents=True, exist_ok=True)
                self.logger.info(f"ğŸ“ æ—¥æ™‚ä»˜ãå¯è¦–åŒ–ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ: {vis_path}")

                # detection_results ã®è©³ç´°ãƒ­ã‚°
                self.logger.info(f"ğŸ”§ detection_results type: {type(detection_results)}")
                self.logger.info(f"ğŸ”§ detection_results content: {detection_results}")

                # CSVãƒ‘ã‚¹æŠ½å‡º
                csv_path = None
                data = {}

                if isinstance(detection_results, dict):
                    if detection_results.get("success", False):
                        data = detection_results.get("data", {})
                        csv_path = data.get("csv_path")

                        # ãƒã‚¹ãƒˆæ§‹é€ å¯¾å¿œ
                        if not csv_path and "detection_result" in data:
                            nested_data = data["detection_result"].get("data", {})
                            csv_path = nested_data.get("csv_path")
        
                self.logger.info(f"ğŸ”§ æ¤œå‡ºã•ã‚ŒãŸCSVãƒ‘ã‚¹: {csv_path}")

                # åŸºæœ¬çµ±è¨ˆãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆï¼ˆå¿…ãšä½œæˆï¼‰
                stats_file = vis_path / "basic_stats.json"
                basic_stats = {
                    "visualization_type": "BasicVisualization",
                    "detection_count": data.get("detection_count", 0),
                    "frame_count": data.get("frame_count", 0),
                    "processing_time": data.get("processing_time", 0),
                    "processing_stats": data.get("processing_stats", {}),
                    "timestamp": datetime.now().isoformat(),
                    "csv_path": str(csv_path) if csv_path else None,
                    "success": detection_results.get("success", False) if isinstance(detection_results, dict) else False
                }

                with open(stats_file, 'w', encoding='utf-8') as f:
                    json.dump(basic_stats, f, indent=2, ensure_ascii=False)
                self.logger.info(f"âœ… åŸºæœ¬çµ±è¨ˆä¿å­˜: {stats_file}")

                # æˆ»ã‚Šå€¤æ›´æ–°ï¼ˆé‡è¦ï¼ï¼‰
                result.update({
                    "success": True,
                    "error": None,
                    "basic_stats_file": str(stats_file),
                    "total_files": 1,
                    "graphs_generated": 0
                })

                # çµ±è¨ˆã‚°ãƒ©ãƒ•ç”Ÿæˆï¼ˆæ—¢å­˜ã®ã‚³ãƒ¼ãƒ‰ï¼‰
                graphs_generated = 0

                try:
                    # matplotlib/pandas ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
                    import matplotlib
                    matplotlib.use('Agg')
                    import matplotlib.pyplot as plt
                    import pandas as pd
    
                    # ç°¡æ˜“ãƒ•ã‚©ãƒ³ãƒˆè¨­å®š
                    try:
                        plt.rcParams['font.family'] = ['Hiragino Sans', 'DejaVu Sans']
                    except:
                        plt.rcParams['font.family'] = 'DejaVu Sans'
    
                    # CSV ãƒ•ã‚¡ã‚¤ãƒ«ã®å‡¦ç†
                    if csv_path and Path(csv_path).exists():
                        self.logger.info(f"ğŸ“Š CSVãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿: {csv_path}")
                        df = pd.read_csv(csv_path)
                        self.logger.info(f"ğŸ“Š ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿: {len(df)}è¡Œ, ã‚«ãƒ©ãƒ : {list(df.columns)}")
        
                        if not df.empty:
                            # 1. ãƒ•ãƒ¬ãƒ¼ãƒ åˆ¥æ¤œå‡ºæ•°ã‚°ãƒ©ãƒ•
                            if 'frame' in df.columns or 'frame_id' in df.columns:
                                try:
                                    frame_col = 'frame' if 'frame' in df.columns else 'frame_id'
                                    plt.figure(figsize=(12, 6))
                                    frame_counts = df[frame_col].value_counts().sort_index()
                                    plt.plot(frame_counts.index, frame_counts.values, 
                                    marker='o', linewidth=2, markersize=4, color='blue')
                                    plt.title('Detection Count by Frame', fontsize=16, pad=20)
                                    plt.xlabel('Frame Number', fontsize=12)
                                    plt.ylabel('Detection Count', fontsize=12)
                                    plt.grid(True, alpha=0.3)
                                    plt.tight_layout()
                    
                                    timeline_path = vis_path / "detection_timeline.png"
                                    plt.savefig(timeline_path, dpi=300, bbox_inches='tight')
                                    plt.close()
                                    graphs_generated += 1
                                    self.logger.info(f"âœ… æ™‚ç³»åˆ—ã‚°ãƒ©ãƒ•ç”Ÿæˆ: {timeline_path}")
                                except Exception as e:
                                    self.logger.error(f"âŒ æ™‚ç³»åˆ—ã‚°ãƒ©ãƒ•ã‚¨ãƒ©ãƒ¼: {e}")
            
                            # 2. ä¿¡é ¼åº¦åˆ†å¸ƒã‚°ãƒ©ãƒ•
                            if 'conf' in df.columns or 'confidence' in df.columns:
                                try:
                                    conf_col = 'conf' if 'conf' in df.columns else 'confidence'
                                    plt.figure(figsize=(10, 6))
                                    conf_data = df[conf_col].dropna()
                                    plt.hist(conf_data, bins=30, alpha=0.7, color='green', edgecolor='black')
                                    plt.axvline(conf_data.mean(), color='red', linestyle='--', 
                                        label=f'Average: {conf_data.mean():.3f}')
                                    plt.title('Confidence Distribution', fontsize=16, pad=20)
                                    plt.xlabel('Confidence', fontsize=12)
                                    plt.ylabel('Frequency', fontsize=12)
                                    plt.legend()
                                    plt.grid(True, alpha=0.3)
                                    plt.tight_layout()
                    
                                    conf_path = vis_path / "confidence_distribution.png"
                                    plt.savefig(conf_path, dpi=300, bbox_inches='tight')
                                    plt.close()
                                    graphs_generated += 1
                                    self.logger.info(f"âœ… ä¿¡é ¼åº¦åˆ†å¸ƒã‚°ãƒ©ãƒ•ç”Ÿæˆ: {conf_path}")
                                except Exception as e:
                                    self.logger.error(f"âŒ ä¿¡é ¼åº¦åˆ†å¸ƒã‚°ãƒ©ãƒ•ã‚¨ãƒ©ãƒ¼: {e}")
            
                            # 3. ã‚¯ãƒ©ã‚¹åˆ†å¸ƒã‚°ãƒ©ãƒ•
                            if 'class_name' in df.columns:
                                try:
                                    plt.figure(figsize=(12, 8))
                                    class_counts = df['class_name'].value_counts()
                                    class_counts.plot(kind='bar', color='skyblue', edgecolor='black')
                                    plt.title('Class Distribution', fontsize=16, pad=20)
                                    plt.xlabel('Class Name', fontsize=12)
                                    plt.ylabel('Detection Count', fontsize=12)
                                    plt.xticks(rotation=45)
                                    plt.tight_layout()
                    
                                    class_path = vis_path / "class_distribution.png"
                                    plt.savefig(class_path, dpi=300, bbox_inches='tight')
                                    plt.close()
                                    graphs_generated += 1
                                    self.logger.info(f"âœ… ã‚¯ãƒ©ã‚¹åˆ†å¸ƒã‚°ãƒ©ãƒ•ç”Ÿæˆ: {class_path}")
                                except Exception as e:
                                    self.logger.error(f"âŒ ã‚¯ãƒ©ã‚¹åˆ†å¸ƒã‚°ãƒ©ãƒ•ã‚¨ãƒ©ãƒ¼: {e}")
        
                        else:
                            self.logger.warning("âš ï¸ CSVãƒ‡ãƒ¼ã‚¿ãŒç©ºã§ã™")
                    else:
                        self.logger.warning(f"âš ï¸ CSVãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚‰ãªã„: {csv_path}")
        
                except ImportError as e:
                    self.logger.warning(f"âš ï¸ matplotlib/pandasã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
                except Exception as plot_error:
                    self.logger.error(f"âŒ ã‚°ãƒ©ãƒ•ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {plot_error}", exc_info=True)

                # æœ€çµ‚çµæœæ›´æ–°
                total_files = 1 + graphs_generated
                result.update({
                    "success": True,
                    "error": None,
                    "graphs_generated": graphs_generated,
                    "total_files": total_files
                })

                self.logger.info(f"ğŸ¨ å¯è¦–åŒ–ç”Ÿæˆå®Œäº†: åŸºæœ¬çµ±è¨ˆ1å€‹ + ã‚°ãƒ©ãƒ•{graphs_generated}å€‹ = åˆè¨ˆ{total_files}å€‹")

                # ğŸ”§ å¿…ãšè¾æ›¸ã‚’è¿”ã™ï¼ˆç¢ºå®Ÿæ€§ã®ãŸã‚ï¼‰
                return result

            except Exception as e:
                self.logger.error(f"âŒ å¯è¦–åŒ–ç”Ÿæˆå…¨ä½“ã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
                # ğŸ”§ ã‚¨ãƒ©ãƒ¼æ™‚ã‚‚è¾æ›¸ã‚’è¿”ã™
                result.update({
                    "success": False,
                    "error": str(e),
                    "graphs_generated": 0,
                    "total_files": 0
                })
                return result
                
        def _create_detection_charts(self, data, vis_path):
            """æ¤œå‡ºçµæœã®ãƒãƒ£ãƒ¼ãƒˆç”Ÿæˆ"""
            try:
                import matplotlib.pyplot as plt
                import pandas as pd
                import seaborn as sns
                
                # çµ±è¨ˆãƒ‡ãƒ¼ã‚¿ã®ç¢ºèª
                processing_stats = data.get("processing_stats", {})
                detection_count = data.get("detection_count", 0)
                
                # 1. åŸºæœ¬çµ±è¨ˆã‚°ãƒ©ãƒ•
                fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 12))
                
                # æ¤œå‡ºæ•°ã‚°ãƒ©ãƒ•
                ax1.bar(['æ¤œå‡ºæ•°'], [detection_count], color='skyblue')
                ax1.set_title('ç·æ¤œå‡ºæ•°')
                ax1.set_ylabel('ä»¶æ•°')
                
                # å‡¦ç†çµ±è¨ˆ
                if processing_stats:
                    stats_keys = list(processing_stats.keys())[:5]  # æœ€å¤§5é …ç›®
                    stats_values = [processing_stats[k] for k in stats_keys]
                    ax2.barh(stats_keys, stats_values, color='lightcoral')
                    ax2.set_title('å‡¦ç†çµ±è¨ˆ')
                    ax2.set_xlabel('å€¤')
                
                # ãƒ•ãƒ¬ãƒ¼ãƒ æ•°
                frame_count = data.get("frame_count", 0)
                ax3.pie([frame_count, max(1, 120 - frame_count)], 
                        labels=['å‡¦ç†æ¸ˆã¿', 'æœªå‡¦ç†'], autopct='%1.1f%%',
                        colors=['lightgreen', 'lightgray'])
                ax3.set_title('ãƒ•ãƒ¬ãƒ¼ãƒ å‡¦ç†çŠ¶æ³')
                
                # å‡¦ç†æ™‚é–“
                processing_time = data.get("processing_time", 0)
                ax4.bar(['å‡¦ç†æ™‚é–“'], [processing_time], color='gold')
                ax4.set_title('å‡¦ç†æ™‚é–“ (ç§’)')
                ax4.set_ylabel('ç§’')
                
                plt.tight_layout()
                plt.savefig(vis_path / "detection_summary.png", dpi=300, bbox_inches='tight')
                plt.close()
                
                self.logger.info(f"âœ… ã‚µãƒãƒªãƒ¼ãƒãƒ£ãƒ¼ãƒˆç”Ÿæˆ: detection_summary.png")
                
            except ImportError:
                self.logger.warning("âš ï¸ matplotlibæœªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ« - åŸºæœ¬çµ±è¨ˆã®ã¿ä¿å­˜")
            except Exception as e:
                self.logger.error(f"âŒ ãƒãƒ£ãƒ¼ãƒˆç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")

# ğŸ”§ BasicConfigï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”¨ãƒ»å®Œå…¨ç‰ˆï¼‰
if not CONFIG_AVAILABLE:
    class BasicConfig:
        def __init__(self, config_path=None):
            self.config_path = config_path
            self.data = self.load_config()
            self.logger = logging.getLogger(__name__)
        
        def load_config(self):
            """è¨­å®šãƒ­ãƒ¼ãƒ‰ï¼ˆå®Œå…¨ç‰ˆï¼‰"""
            logger = logging.getLogger(__name__)
            logger.info(f"âš™ï¸ è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿: {self.config_path}")
            
            if self.config_path and Path(self.config_path).exists():
                try:
                    with open(self.config_path, 'r', encoding='utf-8') as f:
                        if self.config_path.endswith(('.yaml', '.yml')):
                            config_data = yaml.safe_load(f)
                            logger.info("âœ… YAMLè¨­å®šãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿æˆåŠŸ")
                        else:
                            config_data = json.load(f)
                            logger.info("âœ… JSONè¨­å®šãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿æˆåŠŸ")
                    
                    return config_data
                    
                except Exception as e:
                    logger.warning(f"âš ï¸ è¨­å®šèª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
                    logger.info("ğŸ”§ ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šã‚’ä½¿ç”¨ã—ã¾ã™")
            else:
                logger.warning(f"âš ï¸ è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {self.config_path}")
                logger.info("ğŸ”§ ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šã‚’ä½¿ç”¨ã—ã¾ã™")
            
            # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šï¼ˆå®Œå…¨ç‰ˆï¼‰
            default_config = {
                "models": {
                    "detection": "models/yolo/yolo11x.pt",
                    "pose": "models/yolo/yolo11x-pose.pt"
                },
                "processing": {
                    "detection": {
                        "confidence_threshold": 0.3, 
                        "iou_threshold": 0.45,
                        "max_detections": 1000
                    },
                    "depth_estimation": {
                        "enabled": False,
                        "model": "midas_v21_small_256",
                        "model_path": "models/depth/midas_v21_small_256.pt"
                    },
                    "tile_inference": {
                        "enabled": False,
                        "tile_size": [640, 640],
                        "overlap": 0.1
                    }
                },
                "video_dir": "videos",
                "output_dir": "outputs",
                "logging": {
                    "level": "INFO",
                    "file": "logs/analysis.log"
                },
                "experiments": {
                    "comparison": {"type": "comparison", "description": "åŸºæœ¬æ¯”è¼ƒå®Ÿé¨“"},
                    "model_test": {"type": "model_test", "description": "ãƒ¢ãƒ‡ãƒ«æ€§èƒ½ãƒ†ã‚¹ãƒˆ"},
                    "tile_inference": {"type": "tile_inference", "description": "ã‚¿ã‚¤ãƒ«æ¨è«–ãƒ†ã‚¹ãƒˆ"}
                }
            }
            
            logger.info("âœ… ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šã‚’é©ç”¨ã—ã¾ã—ãŸ")
            return default_config
        
        def get(self, key, default=None):
            """è¨­å®šå€¤å–å¾—ï¼ˆãƒ‰ãƒƒãƒˆè¨˜æ³•å¯¾å¿œãƒ»å®Œå…¨ç‰ˆï¼‰"""
            keys = key.split('.')
            value = self.data
            for k in keys:
                if isinstance(value, dict) and k in value:
                    value = value[k]
                else:
                    return default
            return value
        
        def get_experiment_config(self, experiment_type):
            """å®Ÿé¨“è¨­å®šå–å¾—ï¼ˆå®Œå…¨ç‰ˆï¼‰"""
            experiment_configs = self.get("experiments", {})
            if experiment_type in experiment_configs:
                return experiment_configs[experiment_type]
            
            # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå®Ÿé¨“è¨­å®š
            return {
                "type": experiment_type,
                "basic_mode": True,
                "description": f"åŸºæœ¬å®Ÿé¨“: {experiment_type}",
                "enabled": True
            }
        
        @property
        def video_dir(self):
            return self.get("video_dir", "videos")

LOGGER_AVAILABLE = False
setup_logger = None

try:
    from utils.logger import setup_logger
    LOGGER_AVAILABLE = True
    print("âœ… setup_logger ãŒåˆ©ç”¨å¯èƒ½ã§ã™")
except ImportError as e:
    print(f"âš ï¸ setup_logger ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {e}")
    print("ğŸ”§ åŸºæœ¬ãƒ­ã‚°æ©Ÿèƒ½ã‚’ä½¿ç”¨ã—ã¾ã™")
    LOGGER_AVAILABLE = False

# ğŸ”§ åŸºæœ¬ãƒ­ã‚°è¨­å®šï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”¨ãƒ»å®Œå…¨ç‰ˆï¼‰
if not LOGGER_AVAILABLE:
    def setup_logger():
        """åŸºæœ¬ãƒ­ã‚°è¨­å®šï¼ˆå®Œå…¨ç‰ˆï¼‰"""
        # ãƒ­ã‚°ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
        log_dir = Path("logs")
        log_dir.mkdir(exist_ok=True)
        
        # ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«å
        log_file = log_dir / f"analysis_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log"
        
        # æ—¢å­˜ã®ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ã‚’ã‚¯ãƒªã‚¢
        logger = logging.getLogger()
        for handler in logger.handlers[:]:
            logger.removeHandler(handler)
        
        # ãƒ­ã‚°è¨­å®š
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler(log_file, encoding='utf-8'),
                logging.StreamHandler(sys.stdout)
            ]
        )
        
        logger = logging.getLogger(__name__)
        logger.info(f"ğŸ”§ åŸºæœ¬ãƒ­ã‚°æ©Ÿèƒ½ã‚’åˆæœŸåŒ–ã—ã¾ã—ãŸ: {log_file}")
        return logger

# âœ… ã“ã“ã§ã‚¯ãƒ©ã‚¹å®šç¾©é–‹å§‹ï¼ˆifæ–‡ã®å¤–ã€ã‚¤ãƒ³ãƒ‡ãƒ³ãƒˆ0ï¼‰
class ImprovedYOLOAnalyzer:
    """
    YOLO11 åºƒè§’ã‚«ãƒ¡ãƒ©åˆ†æã‚·ã‚¹ãƒ†ãƒ ï¼ˆå®Œå…¨çµ±åˆç‰ˆï¼‰
    - æ·±åº¦æ¨å®šçµ±åˆå¯¾å¿œ
    - ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ä¸è¶³å®Œå…¨å¯¾å¿œ
    - Stage 5/6ä¿®æ­£å®Œäº†
    - ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æ©Ÿèƒ½å®Œå…¨çµ±åˆ
    """

    # Line 834-854ã‚’ä¿®æ­£:

    # Line 1272-1310ã®__init__ãƒ¡ã‚½ãƒƒãƒ‰ã‚’ä»¥ä¸‹ã§ç½®ãæ›ãˆ:

    def __init__(self, config_path: str = "configs/default.yaml"):
        """
        åˆæœŸåŒ–ï¼ˆå®Œå…¨çµ±åˆç‰ˆï¼‰

        Args:
            config_path: è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
        """
        # ğŸ”§ ãƒ­ã‚¬ãƒ¼ã‚’æœ€åˆã«åˆæœŸåŒ–
        self.logger = setup_logger()

        # ã‚¨ãƒ©ãƒ¼ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆè¨­å®š
        if ERROR_HANDLER_AVAILABLE:
            context_manager = ErrorContext("ImprovedYOLOAnalyzeråˆæœŸåŒ–", logger=self.logger)
        else:
            context_manager = self._basic_context("ImprovedYOLOAnalyzeråˆæœŸåŒ–")

        with context_manager as ctx:
            # è¨­å®šåˆæœŸåŒ–
            self.config = self._initialize_config(config_path)

            # æ·±åº¦æ¨å®šæœ‰åŠ¹æ€§ã®ç¢ºèª
            self.depth_enabled = self.config.get('processing.depth_estimation.enabled', False)
            self.logger.info(f"ğŸ” æ·±åº¦æ¨å®š: {'æœ‰åŠ¹' if self.depth_enabled else 'ç„¡åŠ¹'}")

            # ğŸ”§ å³å¯†ãƒ¢ãƒ‡ãƒ«ä½¿ç”¨ãƒ•ãƒ©ã‚°è¿½åŠ 
            self.force_exact_model = True
            self.model_verification_results = {}

            # è©•ä¾¡å™¨ã®é¸æŠã¨åˆæœŸåŒ–
            self._initialize_evaluator(ctx)

            # ãƒ—ãƒ­ã‚»ãƒƒã‚µãƒ¼ã¨ã‚¢ãƒŠãƒ©ã‚¤ã‚¶ãƒ¼åˆæœŸåŒ–
            self._initialize_processor_analyzer(ctx)

            # ğŸ”§ analyzer ã®æ˜ç¤ºçš„åˆæœŸåŒ–ã‚’è¿½åŠ 
            self._initialize_analyzer(ctx)

            # ã‚¨ãƒ©ãƒ¼åé›†ç”¨
            self.error_collector = []

            # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
            self._setup_directories()

            # åˆæœŸåŒ–å®Œäº†å ±å‘Š
            self._report_initialization(ctx)

    def _basic_context(self, name):
        """åŸºæœ¬ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼"""
        class BasicContext:
            def __init__(self, name):
                self.name = name
                self.logger = logging.getLogger(__name__)
            def __enter__(self):
                self.logger.debug(f"ğŸ” å‡¦ç†é–‹å§‹: {self.name}")
                return self
            def __exit__(self, exc_type, exc_val, exc_tb):
                if exc_type:
                    self.logger.error(f"âŒ ã‚¨ãƒ©ãƒ¼ in {self.name}: {exc_val}")
                else:
                    self.logger.debug(f"âœ… å‡¦ç†å®Œäº†: {self.name}")
                return False
            def add_info(self, key, value):
                self.logger.debug(f"ğŸ“ {self.name} - {key}: {value}")
        return BasicContext(name)

    # Line 857ã®_initialize_configãƒ¡ã‚½ãƒƒãƒ‰ã‚’ä¿®æ­£:

    def _initialize_config(self, config_path: str):
        """è¨­å®šåˆæœŸåŒ–ï¼ˆå®Œå…¨ç‰ˆï¼‰"""
        depth_config_path = "configs/depth_config.yaml"
    
        # âš ï¸ ã“ã“ã§ self.logger ã‚’ä½¿ã†å‰ã«ã€ãƒ­ã‚¬ãƒ¼ã‚’åˆæœŸåŒ–ã™ã‚‹å¿…è¦ãŒã‚ã‚‹
        logger = logging.getLogger(__name__)  # ğŸ”§ ä¸€æ™‚çš„ãªãƒ­ã‚¬ãƒ¼ä½¿ç”¨
        logger.info(f"âš™ï¸ è¨­å®šåˆæœŸåŒ–é–‹å§‹: {config_path}")
    
        # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®å„ªå…ˆé †ä½æ±ºå®š
        if Path(config_path).exists():
            primary_config = config_path
            logger.info(f"ğŸ“„ æŒ‡å®šè¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ä½¿ç”¨: {config_path}")
        elif Path(depth_config_path).exists():
            primary_config = depth_config_path
            logger.info(f"ğŸ” æ·±åº¦è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«è‡ªå‹•æ¤œå‡º: {depth_config_path}")
        else:
            primary_config = config_path
            logger.warning(f"âš ï¸ è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {config_path}")

        # è¨­å®šã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆåˆæœŸåŒ–
        if CONFIG_AVAILABLE and Config:
            return Config(primary_config)
        else:
            return BasicConfig(primary_config)

    def _initialize_evaluator(self, ctx):
        """è©•ä¾¡å™¨åˆæœŸåŒ–ï¼ˆå®Œå…¨ç‰ˆï¼‰"""
        if self.depth_enabled and DEPTH_EVALUATOR_AVAILABLE and DepthEnhancedEvaluator:
            try:
                self.evaluator = DepthEnhancedEvaluator(self.config)
                self.logger.info("ğŸ” æ·±åº¦çµ±åˆè©•ä¾¡å™¨ã‚’åˆæœŸåŒ–")
                if hasattr(ctx, 'add_info'):
                    ctx.add_info("evaluator_type", "DepthEnhancedEvaluator")
            except Exception as e:
                self.logger.warning(f"DepthEnhancedEvaluator åˆæœŸåŒ–å¤±æ•—: {e}")
                self._fallback_to_basic_evaluator(ctx)
        elif COMPREHENSIVE_EVALUATOR_AVAILABLE and ComprehensiveEvaluator:
            try:
                self.evaluator = ComprehensiveEvaluator(self.config)
                self.logger.info("ğŸ“Š æ¨™æº–è©•ä¾¡å™¨ã‚’åˆæœŸåŒ–")
                if hasattr(ctx, 'add_info'):
                    ctx.add_info("evaluator_type", "ComprehensiveEvaluator")
            except Exception as e:
                self.logger.warning(f"ComprehensiveEvaluator åˆæœŸåŒ–å¤±æ•—: {e}")
                self._fallback_to_basic_evaluator(ctx)
        else:
            self._fallback_to_basic_evaluator(ctx)

    def _fallback_to_basic_evaluator(self, ctx):
        """åŸºæœ¬è©•ä¾¡å™¨ã¸ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯"""
        self.evaluator = BasicEvaluator(self.config)
        self.logger.info("ğŸ”§ åŸºæœ¬è©•ä¾¡å™¨ã‚’åˆæœŸåŒ–")
        if hasattr(ctx, 'add_info'):
            ctx.add_info("evaluator_type", "BasicEvaluator")

    def _initialize_processor_analyzer(self, ctx):
        """ãƒ—ãƒ­ã‚»ãƒƒã‚µãƒ¼ãƒ»ã‚¢ãƒŠãƒ©ã‚¤ã‚¶ãƒ¼åˆæœŸåŒ–ï¼ˆå®Œå…¨ç‰ˆï¼‰"""
        try:
            # Video Processor åˆæœŸåŒ–
            if VIDEO_PROCESSOR_AVAILABLE:
                self.logger.info("ğŸ¥ é«˜åº¦å‹•ç”»ãƒ—ãƒ­ã‚»ãƒƒã‚µãƒ¼ã‚’åˆæœŸåŒ–")
                self.processor = VideoProcessor(self.config)
            else:
                self.logger.info("ğŸ”„ BasicVideoProcessor ã‚’åˆæœŸåŒ–")
                self.processor = BasicVideoProcessor(self.config)

            # ğŸ”§ analyzer ã®åˆæœŸåŒ–ã¯åˆ¥ãƒ¡ã‚½ãƒƒãƒ‰ã§è¡Œã†ï¼ˆé‡è¤‡ã‚’é¿ã‘ã‚‹ãŸã‚ï¼‰
            # self._initialize_analyzer(ctx) ã¯ __init__ ã§å‘¼ã³å‡ºã—æ¸ˆã¿
        
            ctx.add_info("processor_type", type(self.processor).__name__)
        
        except Exception as e:
            self.logger.error(f"âŒ ãƒ—ãƒ­ã‚»ãƒƒã‚µãƒ¼ãƒ»ã‚¢ãƒŠãƒ©ã‚¤ã‚¶ãƒ¼åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
            self._fallback_processor_analyzer(ctx)

    def _fallback_processor_analyzer(self, ctx):
        """ãƒ—ãƒ­ã‚»ãƒƒã‚µãƒ¼ãƒ»ã‚¢ãƒŠãƒ©ã‚¤ã‚¶ãƒ¼ç”¨ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯"""
        try:
            self.logger.warning("ğŸ”„ åŸºæœ¬ãƒ—ãƒ­ã‚»ãƒƒã‚µãƒ¼ãƒ»ã‚¢ãƒŠãƒ©ã‚¤ã‚¶ãƒ¼ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯")
            self.processor = BasicVideoProcessor(self.config)
        
            # analyzer ãŒæœªåˆæœŸåŒ–ã®å ´åˆã¯åˆæœŸåŒ–
            if not hasattr(self, 'analyzer') or self.analyzer is None:
                self._create_fallback_analyzer(ctx)
            
            ctx.add_info("fallback_applied", True)
        
        except Exception as e:
            self.logger.error(f"âŒ ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å¤±æ•—: {e}", exc_info=True)
            raise

    def _initialize_analyzer(self, ctx):
        """ãƒ¡ãƒˆãƒªã‚¯ã‚¹åˆ†æå™¨åˆæœŸåŒ–ï¼ˆå®Œå…¨ç‰ˆï¼‰"""
        try:
            self.logger.info("ğŸ“Š é«˜åº¦ãƒ¡ãƒˆãƒªã‚¯ã‚¹åˆ†æå™¨ã‚’åˆæœŸåŒ–")
        
            # ğŸ”§ METRICS_ANALYZER_AVAILABLE ã®ç¢ºèª
            if METRICS_ANALYZER_AVAILABLE:
                try:
                    # é«˜åº¦åˆ†æå™¨ã®åˆæœŸåŒ–ã‚’è©¦è¡Œ
                    self.analyzer = MetricsAnalyzer(self.config)
                    self.logger.info("âœ… MetricsAnalyzeråˆæœŸåŒ–æˆåŠŸ")
                    ctx.add_info("analyzer_type", "MetricsAnalyzer")
                    return
                except Exception as e:
                    self.logger.warning(f"MetricsAnalyzeråˆæœŸåŒ–å¤±æ•—: {e}")
        
            # ğŸ”§ ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: BasicMetricsAnalyzer
            self.logger.info("ğŸ”„ BasicMetricsAnalyzerã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯")
            self.analyzer = BasicMetricsAnalyzer(self.config)
            self.logger.info("âœ… BasicMetricsAnalyzeråˆæœŸåŒ–æˆåŠŸ")
            ctx.add_info("analyzer_type", "BasicMetricsAnalyzer")
        
            # ğŸ”§ create_visualizations ãƒ¡ã‚½ãƒƒãƒ‰ã®å­˜åœ¨ç¢ºèª
            if hasattr(self.analyzer, 'create_visualizations'):
                self.logger.info("âœ… create_visualizations ãƒ¡ã‚½ãƒƒãƒ‰ç¢ºèª")
            else:
                self.logger.error("âŒ create_visualizations ãƒ¡ã‚½ãƒƒãƒ‰ãŒå­˜åœ¨ã—ã¾ã›ã‚“")
                # ğŸ”§ ãƒ¡ã‚½ãƒƒãƒ‰ã‚’å‹•çš„ã«è¿½åŠ 
                self._add_fallback_visualization_method()
            
        except Exception as e:
            self.logger.error(f"âŒ åˆ†æå™¨åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
            # ğŸ”§ æœ€çµ‚ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
            self._create_fallback_analyzer(ctx)

    def _add_fallback_visualization_method(self):
        """ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å¯è¦–åŒ–ãƒ¡ã‚½ãƒƒãƒ‰ã®å‹•çš„è¿½åŠ """
        def fallback_create_visualizations(detection_results, vis_dir):
            """ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å¯è¦–åŒ–ç”Ÿæˆ"""
            try:
                self.logger.info(f"ğŸ”§ ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å¯è¦–åŒ–ç”Ÿæˆ: {vis_dir}")
            
                from pathlib import Path
                import json
                from datetime import datetime
            
                # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
                vis_path = Path(str(vis_dir))
                vis_path.mkdir(parents=True, exist_ok=True)
            
                # åŸºæœ¬çµ±è¨ˆãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ
                stats_file = vis_path / "basic_stats.json"
                basic_stats = {
                    "visualization_type": "FallbackVisualization",
                    "timestamp": datetime.now().isoformat(),
                    "detection_results_type": str(type(detection_results)),
                    "success": True
                }
            
                with open(stats_file, 'w', encoding='utf-8') as f:
                    json.dump(basic_stats, f, indent=2, ensure_ascii=False)
            
                self.logger.info(f"âœ… ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å¯è¦–åŒ–å®Œäº†: {stats_file}")
            
                return {
                    "success": True,
                    "basic_stats_file": str(stats_file),
                    "total_files": 1,
                    "graphs_generated": 0,
                    "fallback": True
                }
            
            except Exception as e:
                self.logger.error(f"âŒ ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å¯è¦–åŒ–ã‚¨ãƒ©ãƒ¼: {e}")
                return {
                    "success": False,
                    "error": str(e),
                    "total_files": 0,
                    "graphs_generated": 0,
                    "fallback": True
                }
    
        # ğŸ”§ ãƒ¡ã‚½ãƒƒãƒ‰ã‚’å‹•çš„ã«ãƒã‚¤ãƒ³ãƒ‰
        import types
        self.analyzer.create_visualizations = types.MethodType(fallback_create_visualizations, self.analyzer)
        self.logger.info("ğŸ”§ ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å¯è¦–åŒ–ãƒ¡ã‚½ãƒƒãƒ‰è¿½åŠ å®Œäº†")

    def _create_fallback_analyzer(self, ctx):
        """æœ€çµ‚ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯åˆ†æå™¨ã®ä½œæˆ"""
        class FallbackAnalyzer:
            def __init__(self, config):
                self.config = config
                self.logger = logging.getLogger(__name__)
        
            def create_visualizations(self, detection_results, vis_dir):
                """æœ€çµ‚ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å¯è¦–åŒ–"""
                try:
                    from pathlib import Path
                    import json
                    from datetime import datetime
                
                    vis_path = Path(str(vis_dir))
                    vis_path.mkdir(parents=True, exist_ok=True)
                
                    fallback_file = vis_path / "fallback_analysis.json"
                    fallback_data = {
                        "analyzer_type": "FallbackAnalyzer",
                        "timestamp": datetime.now().isoformat(),
                        "note": "åˆ†æå™¨åˆæœŸåŒ–å¤±æ•—ã®ãŸã‚æœ€çµ‚ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚’ä½¿ç”¨",
                        "detection_results_available": detection_results is not None
                    }
                
                    with open(fallback_file, 'w', encoding='utf-8') as f:
                        json.dump(fallback_data, f, indent=2, ensure_ascii=False)
                
                    return {
                        "success": True,
                        "total_files": 1,
                        "graphs_generated": 0,
                        "fallback": True,
                        "analyzer_type": "FallbackAnalyzer"
                    }
                
                except Exception as e:
                    return {
                        "success": False,
                        "error": str(e),
                        "total_files": 0,
                        "graphs_generated": 0,
                        "fallback": True
                    }
    
        self.analyzer = FallbackAnalyzer(self.config)
        self.logger.warning("âš ï¸ æœ€çµ‚ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯åˆ†æå™¨ã‚’ä½œæˆ")
        ctx.add_info("analyzer_type", "FallbackAnalyzer")

    def _setup_directories(self):
        """ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ï¼ˆå®Œå…¨ç‰ˆï¼‰"""
        directories = [
            "outputs/baseline",
            "outputs/experiments",
            "outputs/visualizations",
            "outputs/temp",
            "logs",
            "models/yolo",
            "models/depth"
        ]
        
        self.logger.info("ğŸ“ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—é–‹å§‹")
        
        for directory in directories:
            dir_path = Path(directory)
            dir_path.mkdir(parents=True, exist_ok=True)
            self.logger.debug(f"ğŸ“ ä½œæˆ/ç¢ºèª: {directory}")
        
        self.logger.info("âœ… ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—å®Œäº†")

    def _report_initialization(self, ctx):
        """åˆæœŸåŒ–å®Œäº†å ±å‘Šï¼ˆå®Œå…¨ç‰ˆï¼‰"""
        features = []
        if self.depth_enabled:
            features.append("æ·±åº¦æ¨å®š")
        if self.config.get('processing.tile_inference.enabled', False):
            features.append("ã‚¿ã‚¤ãƒ«æ¨è«–")
        
        # ä½¿ç”¨ä¸­ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æ©Ÿèƒ½ã®è¡¨ç¤º
        fallbacks = []
        if not COMPREHENSIVE_EVALUATOR_AVAILABLE:
            fallbacks.append("åŸºæœ¬è©•ä¾¡å™¨")
        if not VIDEO_PROCESSOR_AVAILABLE:
            fallbacks.append("åŸºæœ¬å‹•ç”»å‡¦ç†")
        if not METRICS_ANALYZER_AVAILABLE:
            fallbacks.append("åŸºæœ¬åˆ†æ")
        if not CONFIG_AVAILABLE:
            fallbacks.append("åŸºæœ¬è¨­å®š")
        if not LOGGER_AVAILABLE:
            fallbacks.append("åŸºæœ¬ãƒ­ã‚°")

        if features:
            self.logger.info(f"ğŸš€ ImprovedYOLOAnalyzeråˆæœŸåŒ–å®Œäº† (æ©Ÿèƒ½: {', '.join(features)})")
        else:
            self.logger.info("ğŸ“‹ ImprovedYOLOAnalyzeråˆæœŸåŒ–å®Œäº† (æ¨™æº–ãƒ¢ãƒ¼ãƒ‰)")
            
        if fallbacks:
            self.logger.info(f"ğŸ”§ ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æ©Ÿèƒ½ä½¿ç”¨ä¸­: {', '.join(fallbacks)}")

        if hasattr(ctx, 'add_info'):
            ctx.add_info("depth_enabled", self.depth_enabled)
            ctx.add_info("fallback_count", len(fallbacks))


    def run_baseline_analysis(self, video_path: str) -> Dict[str, Any]:
        """
        ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³åˆ†æå®Ÿè¡Œï¼ˆä¾‹å¤–æ™‚ã‚‚å¿…ãšè¾æ›¸å‹ã§è¿”ã™å®Œå…¨ä¿®æ­£ç‰ˆï¼‰

        Args:
            video_path: åˆ†æå¯¾è±¡å‹•ç”»ã®ãƒ‘ã‚¹

        Returns:
            åˆ†æçµæœè¾æ›¸ï¼ˆå¿…ãšdictå‹ã€"success": True/False ã‚’å«ã‚€ï¼‰
        """
        try:
            if ERROR_HANDLER_AVAILABLE:
                context_manager = ErrorContext(f"ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³åˆ†æ: {Path(video_path).name}",
                                          logger=self.logger, raise_on_error=False)
            else:
                context_manager = self._basic_context(f"ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³åˆ†æ: {Path(video_path).name}")

            with context_manager as ctx:
                video_path = Path(video_path)
                video_name = video_path.stem
    
                self.logger.info(f"ğŸ¯ ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³åˆ†æé–‹å§‹: {video_name}")

                if hasattr(ctx, 'add_info'):
                    ctx.add_info("video_path", str(video_path))
                    ctx.add_info("video_name", video_name)
                    ctx.add_info("depth_enabled", self.depth_enabled)

                # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæº–å‚™
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                output_dir = Path("outputs/baseline") / f"{video_name}_{timestamp}"
                frame_dir = output_dir / "frames"
                output_dir.mkdir(parents=True, exist_ok=True)
                frame_dir.mkdir(parents=True, exist_ok=True)
                self.logger.info(f"ğŸ“ æ—¥æ™‚ä»˜ãå‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {output_dir}")

                try:
                    start_time = time.time()
                    detection_result = None
                    evaluation_result = None
                    vis_result = None
                    final_frame_count = 0

                    # Step 1: ãƒ•ãƒ¬ãƒ¼ãƒ æŠ½å‡º
                    self.logger.info("ğŸ“¸ Step 1: ãƒ•ãƒ¬ãƒ¼ãƒ æŠ½å‡ºé–‹å§‹")
                    frame_result = self.processor.extract_frames(video_path, frame_dir)
                    if not frame_result.get("success", False):
                        error_msg = f"ãƒ•ãƒ¬ãƒ¼ãƒ æŠ½å‡ºå¤±æ•—: {frame_result.get('error', 'ä¸æ˜ãªã‚¨ãƒ©ãƒ¼')}"
                        self.error_collector.append(error_msg)
                        self.logger.error(f"âŒ {error_msg}")
                        raise VideoProcessingError(error_msg)

                    api_extracted_frames = frame_result.get("extracted_frames", 0)
                    frame_files_jpg = list(frame_dir.glob("frame_*.jpg"))
                    frame_files_jpeg = list(frame_dir.glob("frame_*.jpeg"))
                    frame_files_png = list(frame_dir.glob("frame_*.png"))
                    all_frame_files = [f for f in frame_dir.glob("frame_*") if f.suffix.lower() in [".jpg", ".jpeg", ".png"]]
                    actual_frame_count = len(all_frame_files)
                    self.logger.info(f"æ¤œå‡ºã•ã‚ŒãŸãƒ•ãƒ¬ãƒ¼ãƒ ãƒ•ã‚¡ã‚¤ãƒ«: {[f.name for f in all_frame_files]}")
                    stats_frames = 0
                    if hasattr(self.processor, 'processing_stats') and self.processor.processing_stats:
                        frame_extraction_stats = self.processor.processing_stats.get("frame_extraction", {})
                        stats_frames = frame_extraction_stats.get("extracted_frames", 0)
                    frame_counts = [api_extracted_frames,                     actual_frame_count, stats_frames]
                    valid_counts = [count for count in frame_counts if count > 0]
                    if valid_counts:
                        final_frame_count = max(valid_counts)
                        self.logger.info(f"ğŸ“Š ãƒ•ãƒ¬ãƒ¼ãƒ æ•°ç¢ºå®š: {final_frame_count}å€‹ï¼ˆå€™è£œ: {frame_counts}ï¼‰")
                    else:
                        self.logger.error("âŒ å…¨ã¦ã®æ–¹æ³•ã§ãƒ•ãƒ¬ãƒ¼ãƒ æ•°ãŒ0ã§ã™")
                        raise VideoProcessingError("ãƒ•ãƒ¬ãƒ¼ãƒ æŠ½å‡ºã«å¤±æ•—ã—ã¾ã—ãŸ")
                    self.logger.info(f"âœ… Step 1å®Œäº†: {final_frame_count}ãƒ•ãƒ¬ãƒ¼ãƒ æŠ½å‡º")

                    # Step 2: æ¤œå‡ºãƒ»è¿½è·¡å‡¦ç†
                    self.logger.info("ğŸ¯ Step 2: YOLOãƒãƒ¼ã‚ºãƒ¢ãƒ‡ãƒ«ç¢ºå®Ÿä½¿ç”¨å‡¦ç†é–‹å§‹")
                    models_config = self.config.get('models', {}) if hasattr(self.config, 'get') else {}
                    pose_model_path = models_config.get('pose', 'models/yolo/yolo11x-pose.pt')
                    if not Path(pose_model_path).exists():
                        self.logger.error(f"ğŸš¨ ãƒãƒ¼ã‚ºãƒ¢ãƒ‡ãƒ«ãŒå­˜åœ¨ã—ã¾ã›ã‚“: {pose_model_path}")
                        alternative_paths = [
                            "models/yolo/yolo11x-pose.pt",
                            "models/yolo11x-pose.pt", 
                            "yolo11x-pose.pt",
                            "models/yolo/yolo11l-pose.pt",
                            "models/yolo11l-pose.pt",
                            "models/yolo/yolo11m-pose.pt",
                            "models/yolo11m-pose.pt"
                        ]
                        found_model = None
                        for alt_path in alternative_paths:
                            if Path(alt_path).exists():
                                found_model = alt_path
                                self.logger.info(f"ğŸ”§ ä»£æ›¿ãƒãƒ¼ã‚ºãƒ¢ãƒ‡ãƒ«ç™ºè¦‹: {alt_path}")
                                break
                        if found_model:
                            pose_model_path = found_model
                            self.logger.info(f"âœ… ãƒãƒ¼ã‚ºãƒ¢ãƒ‡ãƒ«ãƒ‘ã‚¹æ›´æ–°: {pose_model_path}")
                        else:
                            self.logger.error("ğŸš¨ åˆ©ç”¨å¯èƒ½ãªãƒãƒ¼ã‚ºãƒ¢ãƒ‡ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                            raise VideoProcessingError("ãƒãƒ¼ã‚ºãƒ¢ãƒ‡ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                    try:
                        if YOLOPOSE_ANALYZER_AVAILABLE:
                            enhanced_config = {
                                "models": {"pose": pose_model_path},
                                "processing": {
                                    "confidence_threshold": 0.3,
                                    "save_keypoints": True,
                                    "keypoint_format": "coco",
                                    "force_keypoint_detection": True
                                },
                                "tracking": {"tracker_type": "bytetrack"},
                                "output": {"save_csv": True, "csv_include_keypoints": True},
                                "inference": {"task": "pose"}
                            }
                            self.logger.info("ğŸš€ ç¢ºå®Ÿã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆæ¤œå‡ºã‚’å®Ÿè¡Œ")
                            detection_result = analyze_frames_with_tracking_enhanced(
                                frame_dir=str(frame_dir),
                                result_dir=str(output_dir),
                                model_path=pose_model_path,
                                config=enhanced_config,
                                force_exact_model=True
                            )
                            processing_type = "ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆçµ±åˆ"
                        else:
                            raise ImportError("yolopose_analyzer ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“")
                    except ImportError as e:
                        self.logger.error(f"âŒ yolopose_analyzer ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
                        self.logger.warning("ğŸ”„ BasicVideoProcessor ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯")
                        if self.depth_enabled and hasattr(self.processor, 'run_detection_tracking_with_depth'):
                            detection_result = self.processor.run_detection_tracking_with_depth(frame_dir, video_name)
                        else:
                            detection_result = self.processor.run_detection_tracking(frame_dir, video_name)
                        processing_type = "åŸºæœ¬æ¤œå‡ºï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰"
                    if not detection_result.get("success", False):
                        error_msg = detection_result.get("error", "ä¸æ˜ãªã‚¨ãƒ©ãƒ¼")
                        self.logger.error(f"âŒ {processing_type}å‡¦ç†ã‚¨ãƒ©ãƒ¼: {error_msg}")
                        self.error_collector.append(f"{processing_type}å‡¦ç†å¤±æ•—: {error_msg}")
                        raise VideoProcessingError(error_msg)
                    self.logger.info(f"âœ… Step 2å®Œäº†: {processing_type}å‡¦ç†")

                    # Step 2.5: 4ç‚¹ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆå‡¦ç†
                    try:
                        original_csv = detection_result["data"]["csv_path"]
                        four_point_result = self.filter_4point_keypoints(original_csv, output_dir)
                        if four_point_result.get("success", False):
                            self.logger.info(f"âœ… 4ç‚¹ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°æˆåŠŸ: {four_point_result['valid_detections']}/{four_point_result['total_detections']}")
                            metrics_csv = four_point_result.get("metrics_csv_path")
                            if metrics_csv and Path(metrics_csv).exists():
                                self.logger.info(f"ğŸ“ ãƒ¡ãƒˆãƒªã‚¯ã‚¹CSVç¢ºèª: {metrics_csv}")
                                try:
                                    six_point_vis_result = self.create_6point_visualization(metrics_csv, output_dir)
                                    if six_point_vis_result.get("success", False):
                                        saved_frames = six_point_vis_result.get('frames_saved', 0)
                                        total_det = six_point_vis_result.get('total_detections', 0)
                                        success_rate = six_point_vis_result.get('frame_success_rate', 0)
                                        self.logger.info(f"âœ… 6ç‚¹å¯è¦–åŒ–å®Œäº†:")
                                        self.logger.info(f"  - ä¿å­˜ãƒ•ãƒ¬ãƒ¼ãƒ : {saved_frames}")
                                        self.logger.info(f"  - ç·æ¤œå‡ºæ•°: {total_det}")
                                        self.logger.info(f"  - æˆåŠŸç‡: {success_rate:.1%}")
                                        four_point_result["six_point_visualization"] = six_point_vis_result
                                        vis_output_dir = six_point_vis_result.get('output_dir')
                                        if vis_output_dir:
                                            self.logger.info(f"ğŸ“ 6ç‚¹å¯è¦–åŒ–ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {vis_output_dir}")
                                    else:
                                        error_msg = six_point_vis_result.get('error', 'ä¸æ˜ãªã‚¨ãƒ©ãƒ¼')
                                        self.logger.warning(f"âš ï¸ 6ç‚¹å¯è¦–åŒ–å¤±æ•—: {error_msg}")
                                        four_point_result["six_point_visualization"] = six_point_vis_result
                                except Exception as vis_error:
                                    self.logger.error(f"âŒ 6ç‚¹å¯è¦–åŒ–å‘¼ã³å‡ºã—ã‚¨ãƒ©ãƒ¼: {vis_error}")
                                    import traceback
                                    self.logger.error(f"ğŸ”§ è©³ç´°: {traceback.format_exc()}")
                                    four_point_result["six_point_visualization"] = {
                                        "success": False,
                                        "error": str(vis_error),
                                        "call_error": True
                                    }
                                try:
                                    four_point_vis_result = self.create_4point_visualization(metrics_csv, None, output_dir)
                                    if four_point_vis_result.get("success", False):
                                        saved_4pt = four_point_vis_result.get('frames_saved', 0)
                                        self.logger.info(f"âœ… 4ç‚¹å¯è¦–åŒ–ã‚‚å®Œäº†: {saved_4pt}ãƒ•ãƒ¬ãƒ¼ãƒ ")
                                        four_point_result["four_point_visualization"] = four_point_vis_result
                                    else:
                                        self.logger.warning(f"âš ï¸ 4ç‚¹å¯è¦–åŒ–å¤±æ•—: {four_point_vis_result.get('error', 'ä¸æ˜')}")
                                except Exception as vis4_error:
                                    self.logger.warning(f"âš ï¸ 4ç‚¹å¯è¦–åŒ–ã‚¨ãƒ©ãƒ¼: {vis4_error}")
                            else:
                                self.logger.error(f"âŒ ãƒ¡ãƒˆãƒªã‚¯ã‚¹CSVãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {metrics_csv}")
                                self.logger.error(f"ğŸ”§ 4ç‚¹çµæœã®å†…å®¹: {four_point_result}")
                                self.logger.debug("ğŸ”§ 4ç‚¹çµæœã®ã‚­ãƒ¼:")
                            for key, value in four_point_result.items():
                                    self.logger.debug(f"  {key}: {value}")
                            detection_result["data"]["four_point_analysis"] = four_point_result
                            self.logger.info("âœ… Step 2.5å®Œäº†: 4ç‚¹ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆå‡¦ç†æˆåŠŸ")
                        else:
                            error_msg = four_point_result.get("error", "ä¸æ˜ãªã‚¨ãƒ©ãƒ¼")
                            self.logger.error(f"âŒ 4ç‚¹ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°å¤±æ•—: {error_msg}")
                            detection_result["data"]["four_point_analysis"] = four_point_result
                            self.error_collector.append(f"4ç‚¹ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆå‡¦ç†å¤±æ•—: {error_msg}")
                    except Exception as e:
                        self.logger.error(f"âŒ Step 2.5ã‚¨ãƒ©ãƒ¼: 4ç‚¹ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆå‡¦ç†å¤±æ•—: {e}")
                        four_point_result = {"success": False, "error": str(e)}
                        detection_result["data"]["four_point_analysis"] = four_point_result
                        self.error_collector.append(f"4ç‚¹ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆå‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")

                    # Step 3: åŒ…æ‹¬çš„è©•ä¾¡
                    self.logger.info("ğŸ“Š Step 3: åŒ…æ‹¬çš„è©•ä¾¡é–‹å§‹")
                    if hasattr(self.evaluator, 'evaluate_with_depth') and self.depth_enabled:
                        evaluation_result = self.evaluator.evaluate_with_depth(
                            video_path, detection_result, video_name
                        )
                    else:
                        evaluation_result = self.evaluator.evaluate_comprehensive(
                            video_path, detection_result, video_name
                        )
                    if not evaluation_result.get("success", False):
                        error_msg = f"è©•ä¾¡å‡¦ç†å¤±æ•—: {evaluation_result.get('error', {}).get('message', 'ä¸æ˜ãªã‚¨ãƒ©ãƒ¼')}"
                        self.error_collector.append(error_msg)
                        self.logger.warning(f"âš ï¸ {error_msg}")
                        evaluation_result = ResponseBuilder.success(data={
                            "basic_evaluation": True, 
                            "fallback": True,
                            "evaluator_type": type(self.evaluator).__name__
                        })
                    self.logger.info("âœ… Step 3å®Œäº†: åŒ…æ‹¬çš„è©•ä¾¡")

                    # Step 4: åŸºæœ¬å¯è¦–åŒ–ï¼ˆã‚¹ã‚­ãƒƒãƒ—ï¼‰
                    self.logger.info("ğŸ“ˆ Step 4: åŸºæœ¬å¯è¦–åŒ–ã‚¹ã‚­ãƒƒãƒ—ï¼ˆ6ç‚¹å¯è¦–åŒ–ã®ã¿ä½¿ç”¨ï¼‰")
                    vis_result = {
                        "success": True, 
                        "message": "åŸºæœ¬å¯è¦–åŒ–ã¯ã‚¹ã‚­ãƒƒãƒ—ã•ã‚Œã¾ã—ãŸï¼ˆ6ç‚¹å¯è¦–åŒ–ã‚’ä½¿ç”¨ï¼‰",
                        "total_files": 0,
                        "graphs_generated": 0,
                        "skipped": True,
                        "reason": "6ç‚¹å¯è¦–åŒ–ãŒå„ªå…ˆã•ã‚Œã‚‹ãŸã‚åŸºæœ¬å¯è¦–åŒ–ã‚’ç„¡åŠ¹åŒ–"
                    }
                    self.logger.info("âœ… Step 4å®Œäº†: åŸºæœ¬å¯è¦–åŒ–ã‚¹ã‚­ãƒƒãƒ—ï¼ˆ6ç‚¹å¯è¦–åŒ–ã®ã¿ä½¿ç”¨ï¼‰")

                    # æœ€çµ‚çµæœã®æ§‹ç¯‰
                    final_result = {
                        "video_name": video_name,
                        "processing_time": time.time() - start_time,
                        "detection_result": detection_result,
                        "evaluation_result": evaluation_result,
                        "visualization_result": vis_result,
                        "output_directory": str(output_dir),
                        "timestamp": timestamp,
                        "depth_enabled": self.depth_enabled,
                        "error_count": len(self.error_collector),
                        "errors": self.error_collector.copy()
                    }
                    return ResponseBuilder.success(data=final_result)

                except VideoProcessingError as step_error:
                    self.logger.error(f"âŒ Stepå‡¦ç†ä¸­ã‚¨ãƒ©ãƒ¼: {step_error}")
                    self.error_collector.append(f"Stepå‡¦ç†ã‚¨ãƒ©ãƒ¼: {step_error}")
                    raise step_error

                except Exception as step_error:
                    self.logger.error(f"âŒ äºˆæœŸã—ãªã„Stepå†…ã‚¨ãƒ©ãƒ¼: {step_error}")
                    import traceback
                    self.logger.error(f"ğŸ”§ è©³ç´°ã‚¨ãƒ©ãƒ¼: {traceback.format_exc()}")
                    self.error_collector.append(f"äºˆæœŸã—ãªã„Stepå†…ã‚¨ãƒ©ãƒ¼: {step_error}")
                    raise VideoProcessingError(f"å‡¦ç†ã‚¹ãƒ†ãƒƒãƒ—ã§ã‚¨ãƒ©ãƒ¼: {step_error}")

        except VideoProcessingError as e:
            self.logger.error(f"âŒ å‹•ç”»å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
            self.error_collector.append(f"å‹•ç”»å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
            return ResponseBuilder.error(e, suggestions=[
                "å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã®å½¢å¼ã‚’ç¢ºèªã—ã¦ãã ã•ã„",
                "å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã®ç ´æã‚’ç¢ºèªã—ã¦ãã ã•ã„",
                "ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãŒæ­£ã—ããƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„"
            ])

        except Exception as e:
            self.logger.error(f"âŒ äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼: {e}")
            import traceback
            self.logger.error(f"ğŸ”§ è©³ç´°ã‚¨ãƒ©ãƒ¼: {traceback.format_exc()}")
            self.error_collector.append(f"äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼: {e}")
            return {
                "success": False,
                "error": str(e)
            }

    # å®Œå…¨ç½®æ›: Line 2184-2296
    def filter_4point_keypoints(self, csv_path, output_dir):
        """
        ğŸ¯ 4ç‚¹ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ï¼ˆå®Œå…¨ä¿®æ­£ç‰ˆï¼‰
    
        Args:
            csv_path: å…¥åŠ›CSVãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
            output_dir: å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        
        Returns:
            dict: çµ±ä¸€ã•ã‚ŒãŸæˆ»ã‚Šå€¤å½¢å¼
        """
        try:
            self.logger.info("ğŸ¯ 4ç‚¹ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°é–‹å§‹")
            self.logger.info(f"ğŸ“‚ å…¥åŠ›CSV: {csv_path}")
            self.logger.info(f"ğŸ“ å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {output_dir}")
        
            # ğŸ”§ å…¥åŠ›æ¤œè¨¼
            csv_path = Path(csv_path)
            if not csv_path.exists():
                raise FileNotFoundError(f"CSVãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {csv_path}")
        
            # ğŸ”§ å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªç¢ºèª
            output_dir = Path(output_dir)
            output_dir.mkdir(parents=True, exist_ok=True)
        
            # CSVãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
            df = pd.read_csv(csv_path)
            original_rows = len(df)
            self.logger.info(f"ğŸ“Š å…ƒãƒ‡ãƒ¼ã‚¿: {original_rows}è¡Œ, {len(df.columns)}åˆ—")
            self.logger.debug(f"ğŸ“‹ åˆ—å: {list(df.columns)}")
        
            # ğŸ¯ 4ç‚¹ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆã®ç¢ºèª
            target_keypoints = {
                'left_ear': 3,      # COCO: 3ç•ª
                'right_ear': 4,     # COCO: 4ç•ª  
                'left_shoulder': 5, # COCO: 5ç•ª
                'right_shoulder': 6 # COCO: 6ç•ª
            }
        
            available_keypoints = {}
            missing_keypoints = []
        
            for kpt_name, coco_idx in target_keypoints.items():
                x_col = f"{kpt_name}_x"
                y_col = f"{kpt_name}_y"
                conf_col = f"{kpt_name}_conf"
            
                if all(col in df.columns for col in [x_col, y_col, conf_col]):
                    available_keypoints[kpt_name] = {
                        'x': x_col, 'y': y_col, 'conf': conf_col, 'coco_idx': coco_idx
                    }
                    self.logger.debug(f"âœ… ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆåˆ©ç”¨å¯èƒ½: {kpt_name}")
                else:
                    missing_keypoints.append(kpt_name)
                    missing_cols = [col for col in [x_col, y_col, conf_col] if col not in df.columns]
                    self.logger.warning(f"âš ï¸ ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆä¸è¶³: {kpt_name} - æ¬ æåˆ—: {missing_cols}")
            
            # ğŸ”§ æœ€å°è¦ä»¶ãƒã‚§ãƒƒã‚¯
            if len(available_keypoints) < 2:
                raise ValueError(f"4ç‚¹ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã«å¿…è¦ãªã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆãŒä¸è¶³: åˆ©ç”¨å¯èƒ½{len(available_keypoints)}/4ç‚¹")
        
            self.logger.info(f"ğŸ¯ ä½¿ç”¨ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆ: {list(available_keypoints.keys())} ({len(available_keypoints)}/4ç‚¹)")
        
            # ğŸ¯ ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°å‡¦ç†
            confidence_threshold = 0.3
            if hasattr(self, 'config') and self.config:
                confidence_threshold = self.config.get('processing', {}).get('keypoint_confidence_threshold', 0.3)
        
            self.logger.info(f"ğŸ¯ ä¿¡é ¼åº¦é–¾å€¤: {confidence_threshold}")
        
            filtered_data = []
            valid_detections = 0
        
            for idx, row in df.iterrows():
                # åŸºæœ¬æƒ…å ±ã®ä¿æŒ
                filtered_row = {}
            
                # åŸºæœ¬åˆ—ã®ã‚³ãƒ”ãƒ¼
                basic_columns = ['frame', 'person_id', 'x1', 'y1', 'x2', 'y2', 'conf', 'class_name']
                for col in basic_columns:
                    if col in df.columns:
                        filtered_row[col] = row[col]
            
                # 4ç‚¹ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆæƒ…å ±ã®è¿½åŠ 
                valid_keypoints_count = 0
            
                for kpt_name, kpt_info in available_keypoints.items():
                    x_val = row[kpt_info['x']]
                    y_val = row[kpt_info['y']]
                    conf_val = row[kpt_info['conf']]
                
                    # ãƒ‡ãƒ¼ã‚¿ä¿å­˜
                    filtered_row[f"{kpt_name}_x"] = x_val
                    filtered_row[f"{kpt_name}_y"] = y_val
                    filtered_row[f"{kpt_name}_conf"] = conf_val
                
                    # æœ‰åŠ¹æ€§ãƒã‚§ãƒƒã‚¯
                    if conf_val >= confidence_threshold and x_val > 0 and y_val > 0:
                        valid_keypoints_count += 1
            
                # ä¸è¶³ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆã¯ã‚¼ãƒ­åŸ‹ã‚
                for missing_kpt in missing_keypoints:
                    filtered_row[f"{missing_kpt}_x"] = 0.0
                    filtered_row[f"{missing_kpt}_y"] = 0.0
                    filtered_row[f"{missing_kpt}_conf"] = 0.0
            
                # æœ€ä½è¦ä»¶ã‚’æº€ãŸã™å ´åˆã®ã¿ä¿æŒ
                min_valid_keypoints = max(1, len(available_keypoints) // 2)
                if valid_keypoints_count >= min_valid_keypoints:
                    filtered_data.append(filtered_row)
                    valid_detections += 1
        
            # çµæœæ¤œè¨¼
            if not filtered_data:
                raise ValueError(f"ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°å¾Œã®ãƒ‡ãƒ¼ã‚¿ãŒç©ºã§ã™ã€‚é–¾å€¤ {confidence_threshold} ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        
            self.logger.info(f"ğŸ“Š ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°çµæœ: {valid_detections}/{original_rows} ({valid_detections/original_rows*100:.1f}%)")
        
            # ğŸ¯ ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ä½œæˆ
            filtered_df = pd.DataFrame(filtered_data)
        
            # ğŸ¯ ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨ˆç®—
            self.logger.info("ğŸ“Š 4ç‚¹ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨ˆç®—é–‹å§‹")
            metrics_df = self.calculate_4point_metrics(filtered_df.copy())
        
            # ğŸ”§ ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜ï¼ˆçµ±ä¸€ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«åï¼‰
            filtered_csv_path = output_dir / "four_point_keypoints.csv"
            metrics_csv_path = output_dir / "four_point_keypoints_with_metrics.csv"
        
            # CSVãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
            filtered_df.to_csv(filtered_csv_path, index=False)
            metrics_df.to_csv(metrics_csv_path, index=False)
        
            self.logger.info(f"âœ… 4ç‚¹ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°å®Œäº†")
            self.logger.info(f"ğŸ“ ãƒ•ã‚£ãƒ«ã‚¿CSV: {filtered_csv_path}")
            self.logger.info(f"ğŸ“ ãƒ¡ãƒˆãƒªã‚¯ã‚¹CSV: {metrics_csv_path}")
        
            # ğŸ”§ ä¿®æ­£: çµ±ä¸€ã•ã‚ŒãŸæˆ»ã‚Šå€¤ï¼ˆå‘¼ã³å‡ºã—å´ã®æœŸå¾…ã«åˆã‚ã›ã‚‹ï¼‰
            return {
                "success": True,
                "filtered_csv_path": str(filtered_csv_path),      # â† çµ±ä¸€
                "metrics_csv_path": str(metrics_csv_path),        # â† é‡è¦ï¼ã“ã®åå‰
                "original_rows": original_rows,
                "filtered_rows": valid_detections,
                "valid_detections": valid_detections,
                "total_detections": original_rows,
                "filter_rate": valid_detections / original_rows,
                "available_keypoints": list(available_keypoints.keys()),
                "missing_keypoints": missing_keypoints,
                "confidence_threshold": confidence_threshold,
            
                # è¿½åŠ çµ±è¨ˆæƒ…å ±
                "statistics": {
                    "filter_success_rate": valid_detections / original_rows,
                    "keypoints_coverage": len(available_keypoints) / 4.0,
                    "avg_valid_keypoints": sum(
                        sum(1 for kpt in available_keypoints.keys() 
                            if row.get(f"{kpt}_conf", 0) >= confidence_threshold)
                        for row in filtered_data
                    ) / len(filtered_data) if filtered_data else 0
                }
            }
        
        except Exception as e:
            self.logger.error(f"âŒ 4ç‚¹ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã‚¨ãƒ©ãƒ¼: {e}")
            import traceback
            self.logger.error(f"ğŸ”§ è©³ç´°ã‚¨ãƒ©ãƒ¼: {traceback.format_exc()}")
        
            # ğŸ”§ ã‚¨ãƒ©ãƒ¼æ™‚ã‚‚çµ±ä¸€ã•ã‚ŒãŸæˆ»ã‚Šå€¤
            return {
                "success": False,
                "error": str(e),
                "filtered_csv_path": None,
                "metrics_csv_path": None,       # â† é‡è¦ï¼
                "original_rows": 0,
                "filtered_rows": 0,
                "valid_detections": 0,
                "total_detections": 0,
                "filter_rate": 0.0,
                "available_keypoints": [],
                "missing_keypoints": [],
                "confidence_threshold": 0.3
            }

    def calculate_4point_metrics(self, df):
        """
        4ç‚¹å°‚ç”¨ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨ˆç®—ï¼ˆä¸­ç‚¹åº§æ¨™ä¿å­˜ç¢ºå®Ÿç‰ˆï¼‰
        """
        import numpy as np
        import pandas as pd
    
        self.logger.info("ğŸ“Š 4ç‚¹ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨ˆç®—é–‹å§‹")
    
        # çµæœä¿å­˜ç”¨ã®åˆ—ã‚’äº‹å‰ã«åˆæœŸåŒ–
        metrics_columns = [
            'shoulder_width', 'head_center_x', 'head_center_y', 
            'shoulder_center_x', 'shoulder_center_y', 'pose_angle',
            'pose_completeness', 'pose_confidence', 'head_shoulder_distance'
        ]
    
        for col in metrics_columns:
            if col not in df.columns:
                df[col] = np.nan
    
        # çµ±è¨ˆã‚«ã‚¦ãƒ³ã‚¿ãƒ¼
        stats = {
            'total_rows': len(df),
            'shoulder_width_calculated': 0,
            'head_center_calculated': 0,
            'shoulder_center_calculated': 0,
            'pose_angle_calculated': 0
        }
    
        # å„è¡Œã®ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨ˆç®—
        for idx, row in df.iterrows():
            try:
                # ğŸ¯ ä¸­ç‚¹è¨ˆç®—ï¼ˆå¿…ãšå®Ÿè¡Œï¼‰
                # é ­ä¸­ç‚¹ï¼ˆè€³ã®ä¸­ç‚¹ï¼‰
                left_ear_x = row.get('left_ear_x')
                left_ear_y = row.get('left_ear_y')
                right_ear_x = row.get('right_ear_x')
                right_ear_y = row.get('right_ear_y')
                left_ear_conf = row.get('left_ear_conf', 0)
                right_ear_conf = row.get('right_ear_conf', 0)
            
                if (pd.notna(left_ear_x) and pd.notna(left_ear_y) and 
                    pd.notna(right_ear_x) and pd.notna(right_ear_y) and
                    left_ear_conf > 0.3 and right_ear_conf > 0.3):
                
                    head_center_x = (left_ear_x + right_ear_x) / 2
                    head_center_y = (left_ear_y + right_ear_y) / 2
                    df.at[idx, 'head_center_x'] = head_center_x
                    df.at[idx, 'head_center_y'] = head_center_y
                    stats['head_center_calculated'] += 1
            
                # è‚©ä¸­ç‚¹
                left_shoulder_x = row.get('left_shoulder_x')
                left_shoulder_y = row.get('left_shoulder_y')
                right_shoulder_x = row.get('right_shoulder_x')
                right_shoulder_y = row.get('right_shoulder_y')
                left_shoulder_conf = row.get('left_shoulder_conf', 0)
                right_shoulder_conf = row.get('right_shoulder_conf', 0)
            
                if (pd.notna(left_shoulder_x) and pd.notna(left_shoulder_y) and 
                    pd.notna(right_shoulder_x) and pd.notna(right_shoulder_y) and
                    left_shoulder_conf > 0.3 and right_shoulder_conf > 0.3):
                
                    shoulder_center_x = (left_shoulder_x + right_shoulder_x) / 2
                    shoulder_center_y = (left_shoulder_y + right_shoulder_y) / 2
                    df.at[idx, 'shoulder_center_x'] = shoulder_center_x
                    df.at[idx, 'shoulder_center_y'] = shoulder_center_y
                    stats['shoulder_center_calculated'] += 1
                
                    # è‚©å¹…è¨ˆç®—
                    shoulder_width = np.sqrt((right_shoulder_x - left_shoulder_x)**2 + 
                                        (right_shoulder_y - left_shoulder_y)**2)
                    df.at[idx, 'shoulder_width'] = shoulder_width
                    stats['shoulder_width_calculated'] += 1
                
                    # å§¿å‹¢è§’åº¦è¨ˆç®—
                    angle = np.arctan2(right_shoulder_y - left_shoulder_y, 
                                    right_shoulder_x - left_shoulder_x)
                    angle_degrees = np.degrees(angle)
                    df.at[idx, 'pose_angle'] = angle_degrees
                    stats['pose_angle_calculated'] += 1
            
                # é ­-è‚©ã®è·é›¢
                if (pd.notna(df.at[idx, 'head_center_x']) and 
                    pd.notna(df.at[idx, 'shoulder_center_x'])):
                    head_shoulder_dist = np.sqrt(
                        (df.at[idx, 'head_center_x'] - df.at[idx, 'shoulder_center_x'])**2 +
                        (df.at[idx, 'head_center_y'] - df.at[idx, 'shoulder_center_y'])**2
                    )
                    df.at[idx, 'head_shoulder_distance'] = head_shoulder_dist
            
                # å®Œå…¨æ€§ã‚¹ã‚³ã‚¢è¨ˆç®—
                valid_keypoints = sum([
                    1 for point in ['left_ear', 'right_ear', 'left_shoulder', 'right_shoulder']
                    if row.get(f'{point}_conf', 0) > 0.3
                ])
                df.at[idx, 'pose_completeness'] = valid_keypoints / 4.0
            
                # ãƒãƒ¼ã‚ºä¿¡é ¼åº¦ï¼ˆå¹³å‡ï¼‰
                confidences = [row.get(f'{point}_conf', 0) 
                            for point in ['left_ear', 'right_ear', 'left_shoulder', 'right_shoulder']
                            if pd.notna(row.get(f'{point}_conf'))]
                if confidences:
                    df.at[idx, 'pose_confidence'] = np.mean(confidences)
            
            except Exception as e:
                self.logger.warning(f"âš ï¸ è¡Œ {idx} ã§ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨ˆç®—ã‚¨ãƒ©ãƒ¼: {e}")
                continue
    
        # çµ±è¨ˆå‡ºåŠ›
        self.logger.info("ğŸ“Š ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨ˆç®—å®Œäº†:")
        for key, value in stats.items():
            self.logger.info(f"  {key}: {value}")
    
        # ğŸ”§ ä¸­ç‚¹åº§æ¨™ã®å­˜åœ¨ç¢ºèª
        head_center_count = df['head_center_x'].notna().sum()
        shoulder_center_count = df['shoulder_center_x'].notna().sum()
    
        self.logger.info(f"âœ… ä¸­ç‚¹åº§æ¨™ç¢ºèª:")
        self.logger.info(f"  é ­ä¸­ç‚¹åº§æ¨™æ•°: {head_center_count}")
        self.logger.info(f"  è‚©ä¸­ç‚¹åº§æ¨™æ•°: {shoulder_center_count}")
    
        # çµ±è¨ˆã‚µãƒãƒªãƒ¼
        if stats['shoulder_width_calculated'] > 0:
            valid_widths = df['shoulder_width'].dropna()
            avg_width = valid_widths.mean()
            self.logger.info(f"ğŸ“Š ãƒ¡ãƒˆãƒªã‚¯ã‚¹çµ±è¨ˆ:")
            self.logger.info(f"  å¹³å‡è‚©å¹…: {avg_width:.1f}px")
        
            if stats['pose_completeness'] > 0:
                avg_completeness = df['pose_completeness'].mean()
                avg_confidence = df['pose_confidence'].mean()
                self.logger.info(f"  å¹³å‡å®Œå…¨æ€§: {avg_completeness:.2f}")
                self.logger.info(f"  å¹³å‡ãƒãƒ¼ã‚ºä¿¡é ¼åº¦: {avg_confidence:.2f}")
    
        return df

    def create_4point_visualization(self, csv_path, video_path, output_dir):
        """4ç‚¹ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆå°‚ç”¨å¯è¦–åŒ–ç”Ÿæˆï¼ˆæ—¥æ™‚ä»˜ããƒ•ã‚©ãƒ«ãƒ€å¯¾å¿œç‰ˆï¼‰"""
        try:
            import cv2
            import pandas as pd
            from pathlib import Path
            from datetime import datetime

            self.logger.info("ğŸ¨ 4ç‚¹å¯è¦–åŒ–ç”Ÿæˆé–‹å§‹ï¼ˆæ—¥æ™‚ä»˜ããƒ•ã‚©ãƒ«ãƒ€å¯¾å¿œï¼‰")

            # ğŸ”§ æ—¥æ™‚ä»˜ãå¯è¦–åŒ–ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            vis_dir = Path(output_dir) / f"visualized_frames_4points_{timestamp}"
            vis_dir.mkdir(exist_ok=True)

            self.logger.info(f"ğŸ“ 4ç‚¹å¯è¦–åŒ–ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {vis_dir}")

            # CSVèª­ã¿è¾¼ã¿
            df = pd.read_csv(csv_path)

            if df.empty:
                self.logger.warning("âš ï¸ 4ç‚¹CSVãƒ‡ãƒ¼ã‚¿ãŒç©ºã§ã™")
                return {"success": False, "error": "Empty CSV data"}

            self.logger.info(f"ğŸ“‹ CSVåˆ—å: {df.columns.tolist()}")
            self.logger.info(f"ğŸ“‹ CSVãƒ‡ãƒ¼ã‚¿å½¢çŠ¶: {df.shape}")

            # ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ç¢ºèª
            frames_dir = Path(output_dir) / "frames"
            if not frames_dir.exists():
                self.logger.error(f"âŒ ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒå­˜åœ¨ã—ã¾ã›ã‚“: {frames_dir}")
                return {"success": False, "error": "Frames directory not found"}

            frame_files = sorted(frames_dir.glob("*.jpg"))
            if not frame_files:
                self.logger.error("âŒ ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                return {"success": False, "error": "No frame files found"}

            self.logger.info(f"ğŸ“ ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {len(frame_files)}")
            self.logger.info(f"ğŸ“ ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ•ã‚¡ã‚¤ãƒ«ä¾‹: {[f.name for f in frame_files[:3]]}")

            # ãƒ•ãƒ¬ãƒ¼ãƒ ç•ªå·ã®å¯¾å¿œãƒ†ãƒ¼ãƒ–ãƒ«ä½œæˆ
            frame_mapping = {}
            for i, frame_file in enumerate(frame_files):
                frame_num_from_file = i
                frame_identifier = frame_file.name
                frame_mapping[frame_identifier] = frame_num_from_file
                frame_mapping[frame_num_from_file] = frame_identifier

            self.logger.info(f"ğŸ“‹ ãƒ•ãƒ¬ãƒ¼ãƒ å¯¾å¿œä¾‹: {list(frame_mapping.items())[:5]}")

            # ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆåˆ—ã®ç¢ºèª
            keypoint_columns = {
                'left_ear': {'x': 'left_ear_x', 'y': 'left_ear_y', 'conf': 'left_ear_conf'},
                'right_ear': {'x': 'right_ear_x', 'y': 'right_ear_y', 'conf': 'right_ear_conf'},
                'left_shoulder': {'x': 'left_shoulder_x', 'y': 'left_shoulder_y', 'conf': 'left_shoulder_conf'},
                'right_shoulder': {'x': 'right_shoulder_x', 'y': 'right_shoulder_y', 'conf': 'right_shoulder_conf'}
            }

            # åˆ—ã®å­˜åœ¨ç¢ºèª
            missing_columns = []
            for kpt_name, cols in keypoint_columns.items():
                for col_type, col_name in cols.items():
                    if col_name not in df.columns:
                        missing_columns.append(col_name)

            if missing_columns:
                self.logger.warning(f"âš ï¸ ä¸è¶³åˆ—: {missing_columns}")

            saved_count = 0
            total_detections = 0
            processed_frames = 0
            debug_info = []

            # å„ãƒ•ãƒ¬ãƒ¼ãƒ ã«å¯¾ã™ã‚‹å‡¦ç†
            for frame_file in frame_files:
                processed_frames += 1
                frame_identifier = frame_file.name
    
                # è¤‡æ•°ã®æ–¹æ³•ã§CSVãƒ‡ãƒ¼ã‚¿ã‚’æ¤œç´¢
                frame_data = None
    
                # æ–¹æ³•1: å®Œå…¨ãªãƒ•ã‚¡ã‚¤ãƒ«åã§ãƒãƒƒãƒ
                frame_data = df[df['frame'] == frame_identifier]
    
                # æ–¹æ³•2: ãƒ•ãƒ¬ãƒ¼ãƒ ç•ªå·ã§ãƒãƒƒãƒï¼ˆ0ã‹ã‚‰å§‹ã¾ã‚‹é€£ç•ªï¼‰
                if frame_data.empty:
                    frame_index = processed_frames - 1
                    numeric_frame_data = df[df['frame'] == frame_index]
                    if not numeric_frame_data.empty:
                        frame_data = numeric_frame_data
    
                # æ–¹æ³•3: ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹é †åºã§ãƒãƒƒãƒ
                if frame_data.empty and processed_frames <= len(df):
                    frame_data = df.iloc[[processed_frames - 1]]
    
                if not frame_data.empty:
                    # ãƒ•ãƒ¬ãƒ¼ãƒ ç”»åƒèª­ã¿è¾¼ã¿
                    frame = cv2.imread(str(frame_file))
                    if frame is None:
                        self.logger.warning(f"âš ï¸ ãƒ•ãƒ¬ãƒ¼ãƒ èª­ã¿è¾¼ã¿å¤±æ•—: {frame_file}")
                        continue
        
                    frame_height, frame_width = frame.shape[:2]
                    temp_frame = frame.copy()
                    frame_detections = 0
        
                    for idx, row in frame_data.iterrows():
                        # ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆãƒ‡ãƒ¼ã‚¿ã®æŠ½å‡ºã¨æ¤œè¨¼
                        keypoints = {}
                        valid_keypoint_count = 0
            
                        for kpt_name, cols in keypoint_columns.items():
                            try:
                                x = float(row.get(cols['x'], 0))
                                y = float(row.get(cols['y'], 0))
                                conf = float(row.get(cols['conf'], 1.0))
                    
                                # åº§æ¨™ã®æœ‰åŠ¹æ€§ãƒã‚§ãƒƒã‚¯ï¼ˆç·©ã„æ¡ä»¶ï¼‰
                                if (0 <= x <= frame_width and 
                                   0 <= y <= frame_height and 
                                    conf > 0.1):  # ä¿¡é ¼åº¦é–¾å€¤ã‚’0.3ã‹ã‚‰0.1ã«ç·©å’Œ
                                    keypoints[kpt_name] = (int(x), int(y), conf)
                                    valid_keypoint_count += 1
                            except (ValueError, TypeError) as e:
                                continue
            
                        # ãƒ‡ãƒãƒƒã‚°æƒ…å ±è¨˜éŒ²
                        if processed_frames <= 3:  # æœ€åˆã®3ãƒ•ãƒ¬ãƒ¼ãƒ ã®ãƒ‡ãƒãƒƒã‚°
                            debug_info.append({
                                'frame': frame_identifier,
                                'valid_keypoints': valid_keypoint_count,
                                'keypoints': keypoints,
                                'row_data': {k: row.get(k) for k in ['left_ear_x', 'left_ear_y', 'left_ear_conf']}
                            })
            
                        # 1ç‚¹ã§ã‚‚æœ‰åŠ¹ãªã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆãŒã‚ã‚Œã°æç”»
                        if valid_keypoint_count >= 1:  # 4ã‹ã‚‰1ã«æ¡ä»¶ç·©å’Œ
                            temp_frame = self.draw_4point_keypoints_robust(temp_frame, keypoints, row)
                            frame_detections += 1
        
                    # 1ã¤ã§ã‚‚æ¤œå‡ºãŒã‚ã‚Œã°ä¿å­˜
                    if frame_detections > 0:
                        output_filename = f"4pt_{frame_file.name}"
                        output_path = vis_dir / output_filename
                        success = cv2.imwrite(str(output_path), temp_frame)
            
                        if success:
                            saved_count += 1
                            total_detections += frame_detections
                
                            # æœ€åˆã®5æšã®ä¿å­˜æˆåŠŸã‚’ãƒ­ã‚°
                            if saved_count <= 5:
                                self.logger.info(f"âœ… 4ç‚¹ç”»åƒä¿å­˜æˆåŠŸ: {output_filename} (æ¤œå‡º: {frame_detections})")
                        else:
                            self.logger.warning(f"âŒ ç”»åƒä¿å­˜å¤±æ•—: {output_path}")
    
                # é€²æ—è¡¨ç¤ºï¼ˆé »åº¦ã‚’ä¸‹ã’ã‚‹ï¼‰
                if processed_frames % 100 == 0:
                    self.logger.info(f"ğŸ¨ 4ç‚¹å¯è¦–åŒ–é€²æ—: {processed_frames}ãƒ•ãƒ¬ãƒ¼ãƒ  (ä¿å­˜æ¸ˆã¿: {saved_count})")

            # ãƒ‡ãƒãƒƒã‚°æƒ…å ±å‡ºåŠ›
            if debug_info:
                self.logger.info("ğŸ”§ ãƒ‡ãƒãƒƒã‚°æƒ…å ±ï¼ˆæœ€åˆã®3ãƒ•ãƒ¬ãƒ¼ãƒ ï¼‰:")
                for info in debug_info:
                    self.logger.info(f"  ãƒ•ãƒ¬ãƒ¼ãƒ : {info['frame']}, æœ‰åŠ¹ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆ: {info['valid_keypoints']}")
                    self.logger.info(f"  ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿: {info['row_data']}")

            self.logger.info(f"âœ… 4ç‚¹å¯è¦–åŒ–å®Œäº†: {saved_count}ãƒ•ãƒ¬ãƒ¼ãƒ ä¿å­˜ (æ¤œå‡ºæ•°: {total_detections})")
            self.logger.info(f"ğŸ“Š å‡¦ç†çµ±è¨ˆ: {processed_frames}ãƒ•ãƒ¬ãƒ¼ãƒ å‡¦ç†, æˆåŠŸç‡: {(saved_count/processed_frames)*100:.1f}%")
    
            return {
                "success": True, 
                "frames_saved": saved_count, 
                "total_detections": total_detections,
                "processed_frames": processed_frames,
                "output_dir": str(vis_dir),
                "timestamp": timestamp,  # ğŸ”§ è¿½åŠ : ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—
                "debug_info": debug_info
                }
    
        except Exception as e:
            self.logger.error(f"âŒ 4ç‚¹å¯è¦–åŒ–ã‚¨ãƒ©ãƒ¼: {e}")
            import traceback
            self.logger.error(f"ğŸ”§ è©³ç´°ã‚¨ãƒ©ãƒ¼: {traceback.format_exc()}")
            return {"success": False, "error": str(e)}

    def create_6point_visualization(self, csv_path, output_dir):
        """
        6ç‚¹ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆå°‚ç”¨å¯è¦–åŒ–ç”Ÿæˆï¼ˆå¼•æ•°ä¿®æ­£ãƒ»ãƒ•ãƒ¬ãƒ¼ãƒ æ¤œç´¢å¼·åŒ–ç‰ˆï¼‰
    
        Args:
            csv_path: ãƒ¡ãƒˆãƒªã‚¯ã‚¹ä»˜ãCSVãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
            output_dir: å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ãƒ‘ã‚¹
        
        Returns:
            dict: å¯è¦–åŒ–çµæœ
        """
        try:
            import cv2
            import pandas as pd
            from pathlib import Path
            from datetime import datetime

            self.logger.info("ğŸ¨ 6ç‚¹å¯è¦–åŒ–ç”Ÿæˆé–‹å§‹ï¼ˆå¼•æ•°ä¿®æ­£ç‰ˆï¼‰")
        
            # ğŸ”§ å…¥åŠ›æ¤œè¨¼ã®å¼·åŒ–
            csv_path = Path(csv_path)
            output_dir = Path(output_dir)
        
            if not csv_path.exists():
                raise FileNotFoundError(f"ãƒ¡ãƒˆãƒªã‚¯ã‚¹CSVãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {csv_path}")
            
            self.logger.info(f"ğŸ“‚ å…¥åŠ›CSV: {csv_path}")
            self.logger.info(f"ğŸ“ å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {output_dir}")

            # æ—¥æ™‚ä»˜ãå¯è¦–åŒ–ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            vis_dir = output_dir / "6point_visualizations"
            vis_dir.mkdir(parents=True, exist_ok=True)
            
            self.logger.info(f"ğŸ“ 6ç‚¹å¯è¦–åŒ–ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {vis_dir}")

            # CSVèª­ã¿è¾¼ã¿ï¼ˆãƒ¡ãƒˆãƒªã‚¯ã‚¹ä»˜ããƒ‡ãƒ¼ã‚¿ï¼‰
            df = pd.read_csv(csv_path)
        
            if df.empty:
                self.logger.warning("âš ï¸ ãƒ¡ãƒˆãƒªã‚¯ã‚¹CSVãƒ‡ãƒ¼ã‚¿ãŒç©ºã§ã™")
                return {"success": False, "error": "Empty metrics CSV data"}

            # ğŸ”§ ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®è¤‡æ•°å€™è£œæ¤œç´¢
            frame_search_dirs = [
                output_dir / "frames",           # æ¨™æº–ãƒ‘ã‚¹
                output_dir.parent / "frames",    # è¦ªãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
                Path(output_dir).resolve() / "frames",  # çµ¶å¯¾ãƒ‘ã‚¹
                Path(csv_path).parent / "frames", # CSVã¨åŒéšå±¤
            ]
        
            frame_dir = None
            frame_files = []
        
            for search_dir in frame_search_dirs:
                if search_dir.exists():
                    potential_frames = sorted(search_dir.glob("*.jpg"))
                    if potential_frames:
                        frame_dir = search_dir
                        frame_files = potential_frames
                        self.logger.info(f"âœ… ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªç™ºè¦‹: {frame_dir}")
                        break
                    else:
                        self.logger.debug(f"ğŸ” ãƒ•ãƒ¬ãƒ¼ãƒ ãªã—: {search_dir}")
                else:
                    self.logger.debug(f"ğŸ” ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãªã—: {search_dir}")

            if not frame_dir or not frame_files:
                error_msg = f"ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚æ¤œç´¢ãƒ‘ã‚¹: {[str(d) for d in frame_search_dirs]}"
                self.logger.error(f"âŒ {error_msg}")
                return {"success": False, "error": error_msg}

            self.logger.info(f"ğŸ“ ä½¿ç”¨ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {frame_dir}")
            self.logger.info(f"ğŸ“ ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {len(frame_files)}")

            # ğŸ”§ å¿…è¦ãªåˆ—ã®ç¢ºèªï¼ˆã‚ˆã‚ŠæŸ”è»Ÿï¼‰
            required_basic_cols = [
                'left_ear_x', 'left_ear_y', 'left_ear_conf',
                'right_ear_x', 'right_ear_y', 'right_ear_conf',
                'left_shoulder_x', 'left_shoulder_y', 'left_shoulder_conf',
                'right_shoulder_x', 'right_shoulder_y', 'right_shoulder_conf'
            ]
        
            center_cols = ['head_center_x', 'head_center_y', 'shoulder_center_x', 'shoulder_center_y']
        
            missing_basic = [col for col in required_basic_cols if col not in df.columns]
            missing_centers = [col for col in center_cols if col not in df.columns]
        
            if missing_basic:
                self.logger.error(f"âŒ åŸºæœ¬ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆåˆ—ãŒä¸è¶³: {missing_basic}")
                return {"success": False, "error": f"Missing basic columns: {missing_basic}"}
            
            if missing_centers:
                self.logger.warning(f"âš ï¸ ä¸­ç‚¹åˆ—ãŒä¸è¶³ï¼ˆå‹•çš„è¨ˆç®—ã—ã¾ã™ï¼‰: {missing_centers}")

            self.logger.info(f"ğŸ“‹ CSVãƒ‡ãƒ¼ã‚¿å½¢çŠ¶: {df.shape}")
            self.logger.info(f"ğŸ“‹ åˆ©ç”¨å¯èƒ½ãªåŸºæœ¬åˆ—: {len(required_basic_cols) - len(missing_basic)}/12")
            self.logger.info(f"ğŸ“‹ åˆ©ç”¨å¯èƒ½ãªä¸­ç‚¹åˆ—: {len(center_cols) - len(missing_centers)}/4")

            # ğŸ”§ ãƒ•ãƒ¬ãƒ¼ãƒ ãƒãƒƒãƒ”ãƒ³ã‚°ã®æ”¹å–„
            frame_mapping = {}
        
            # æ–¹æ³•1: ãƒ•ã‚¡ã‚¤ãƒ«åãƒ™ãƒ¼ã‚¹
            for i, frame_file in enumerate(frame_files):
                frame_name = frame_file.name
                frame_mapping[frame_name] = i
                frame_mapping[i] = frame_name
            
                # æ‹¡å¼µå­ãªã—ã®åå‰ã‚‚è¿½åŠ 
                frame_stem = frame_file.stem
                frame_mapping[frame_stem] = i

            self.logger.debug(f"ğŸ”§ ãƒ•ãƒ¬ãƒ¼ãƒ ãƒãƒƒãƒ”ãƒ³ã‚°ä¾‹: {list(frame_mapping.items())[:10]}")

            # å‡¦ç†çµ±è¨ˆ
            processed_frames = 0
            saved_count = 0
            total_detections = 0
            skipped_no_data = 0
            debug_info = []

            # ğŸ”§ ãƒ•ãƒ¬ãƒ¼ãƒ åˆ¥å‡¦ç†ï¼ˆæ”¹è‰¯ç‰ˆï¼‰
            for frame_file in frame_files:
                processed_frames += 1
                frame_identifier = frame_file.name
                frame_stem = frame_file.stem

                # ğŸ”§ è¤‡æ•°ã®æ–¹æ³•ã§CSVãƒ‡ãƒ¼ã‚¿ã‚’æ¤œç´¢
                frame_data = pd.DataFrame()
            
                # æ–¹æ³•1: å®Œå…¨ãªãƒ•ã‚¡ã‚¤ãƒ«åã§ãƒãƒƒãƒ
                if 'frame' in df.columns:
                    frame_data = df[df['frame'] == frame_identifier]
                    if frame_data.empty:
                        frame_data = df[df['frame'] == frame_stem]
            
                # æ–¹æ³•2: ãƒ•ãƒ¬ãƒ¼ãƒ ç•ªå·ã§ãƒãƒƒãƒï¼ˆ0ã‹ã‚‰å§‹ã¾ã‚‹é€£ç•ªï¼‰
                if frame_data.empty:
                    frame_index = processed_frames - 1
                    if 'frame' in df.columns:
                        frame_data = df[df['frame'] == frame_index]
                    
                    # ãƒ•ãƒ¬ãƒ¼ãƒ ç•ªå·ï¼ˆ1ã‹ã‚‰å§‹ã¾ã‚‹ï¼‰ã‚‚è©¦è¡Œ
                    if frame_data.empty:
                        frame_data = df[df['frame'] == processed_frames]
            
                # æ–¹æ³•3: ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹é †åºã§ãƒãƒƒãƒï¼ˆæœ€å¾Œã®æ‰‹æ®µï¼‰
                if frame_data.empty and processed_frames <= len(df):
                    try:
                        frame_data = df.iloc[[processed_frames - 1]]
                    except IndexError:
                        pass

                if frame_data.empty:
                    skipped_no_data += 1
                    continue

                # ãƒ•ãƒ¬ãƒ¼ãƒ èª­ã¿è¾¼ã¿
                temp_frame = cv2.imread(str(frame_file))
                if temp_frame is None:
                    self.logger.warning(f"âš ï¸ ãƒ•ãƒ¬ãƒ¼ãƒ èª­ã¿è¾¼ã¿å¤±æ•—: {frame_file}")
                    continue

                frame_detections = 0
            
                # ğŸ”§ å„äººç‰©ã®6ç‚¹æç”»
                for idx, row in frame_data.iterrows():
                    # ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆæŠ½å‡º
                    keypoints = {}
                    for point in ['left_ear', 'right_ear', 'left_shoulder', 'right_shoulder']:
                        for coord in ['x', 'y', 'conf']:
                            col_name = f"{point}_{coord}"
                            if col_name in df.columns and col_name in row.index:
                                keypoints[col_name] = row[col_name]

                    # æœ‰åŠ¹ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆæ•°ãƒã‚§ãƒƒã‚¯
                    valid_count = sum(1 for point in ['left_ear', 'right_ear', 'left_shoulder', 'right_shoulder']
                                    if keypoints.get(f"{point}_conf", 0) > 0.3)

                    if valid_count >= 2:  # æœ€ä½2ç‚¹ã‚ã‚Œã°æç”»
                        # ğŸ¯ 6ç‚¹æç”»ï¼ˆ4ç‚¹ + 2ä¸­ç‚¹ï¼‰
                        temp_frame = self.draw_6point_keypoints_with_centers(temp_frame, keypoints, row)
                        frame_detections += 1

                    # ãƒ‡ãƒãƒƒã‚°æƒ…å ±ï¼ˆæœ€åˆã®3ãƒ•ãƒ¬ãƒ¼ãƒ ï¼‰
                    if processed_frames <= 3:
                        debug_info.append({
                            'frame_file': frame_identifier,
                            'frame_index': processed_frames - 1,
                            'csv_frame_value': row.get('frame', 'N/A'),
                            'person_id': row.get('person_id', 'unknown'),
                            'valid_keypoints': valid_count,
                            'has_head_center': 'head_center_x' in row and pd.notna(row.get('head_center_x')),
                            'has_shoulder_center': 'shoulder_center_x' in row and pd.notna(row.get('shoulder_center_x')),
                            'matching_method': 'successful'
                        })

                # ãƒ•ãƒ¬ãƒ¼ãƒ ä¿å­˜
                if frame_detections > 0:
                    output_filename = f"6point_frame_{processed_frames:06d}.jpg"
                    output_path = vis_dir / output_filename
                    success = cv2.imwrite(str(output_path), temp_frame)

                    if success:
                        saved_count += 1
                        total_detections += frame_detections
                    
                        # æœ€åˆã®5æšã®ä¿å­˜æˆåŠŸã‚’ãƒ­ã‚°
                        if saved_count <= 5:
                            self.logger.info(f"âœ… 6ç‚¹ç”»åƒä¿å­˜æˆåŠŸ: {output_filename} (æ¤œå‡º: {frame_detections})")
                    else:
                        self.logger.warning(f"âŒ ç”»åƒä¿å­˜å¤±æ•—: {output_path}")

                # é€²æ—è¡¨ç¤ºï¼ˆ100ãƒ•ãƒ¬ãƒ¼ãƒ ã”ã¨ï¼‰
                if processed_frames % 100 == 0:
                    self.logger.info(f"ğŸ¨ 6ç‚¹å¯è¦–åŒ–é€²æ—: {processed_frames}/{len(frame_files)} (ä¿å­˜æ¸ˆã¿: {saved_count})")

            # ãƒ‡ãƒãƒƒã‚°æƒ…å ±å‡ºåŠ›
            if debug_info:
                self.logger.info("ğŸ”§ ãƒ•ãƒ¬ãƒ¼ãƒ ãƒãƒƒãƒãƒ³ã‚°ãƒ‡ãƒãƒƒã‚°æƒ…å ±ï¼ˆæœ€åˆã®3ãƒ•ãƒ¬ãƒ¼ãƒ ï¼‰:")
                for info in debug_info[:9]:  # æœ€å¤§9å€‹
                    self.logger.info(f"  ãƒ•ãƒ¬ãƒ¼ãƒ : {info['frame_file']} -> CSV: {info['csv_frame_value']}")
                    self.logger.info(f"  äººç‰©ID: {info['person_id']}, æœ‰åŠ¹ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆ: {info['valid_keypoints']}")
                    self.logger.info(f"  é ­ä¸­ç‚¹: {info['has_head_center']}, è‚©ä¸­ç‚¹: {info['has_shoulder_center']}")

            self.logger.info(f"âœ… 6ç‚¹å¯è¦–åŒ–å®Œäº†: {saved_count}ãƒ•ãƒ¬ãƒ¼ãƒ ä¿å­˜ (æ¤œå‡ºæ•°: {total_detections})")
            self.logger.info(f"ğŸ“Š å‡¦ç†çµ±è¨ˆ:")
            self.logger.info(f"  - ç·ãƒ•ãƒ¬ãƒ¼ãƒ å‡¦ç†: {processed_frames}")
            self.logger.info(f"  - ç”»åƒä¿å­˜æˆåŠŸ: {saved_count}")
            self.logger.info(f"  - ãƒ‡ãƒ¼ã‚¿ãªã—ã‚¹ã‚­ãƒƒãƒ—: {skipped_no_data}")
            self.logger.info(f"  - æˆåŠŸç‡: {(saved_count/processed_frames)*100:.1f}%")

            return {
                "success": True,
                "frames_saved": saved_count,
                "total_detections": total_detections,
                "processed_frames": processed_frames,
                "skipped_frames": skipped_no_data,
                "output_dir": str(vis_dir),
                "timestamp": timestamp,
                "debug_info": debug_info,
                "frame_success_rate": saved_count / processed_frames if processed_frames > 0 else 0
            }

        except Exception as e:
            self.logger.error(f"âŒ 6ç‚¹å¯è¦–åŒ–ã‚¨ãƒ©ãƒ¼: {e}")
            import traceback
            self.logger.error(f"ğŸ”§ è©³ç´°ã‚¨ãƒ©ãƒ¼: {traceback.format_exc()}")
            return {
                "success": False, 
                "error": str(e),
                "frames_saved": 0,
                "total_detections": 0,
                "processed_frames": 0
            }

    def draw_4point_keypoints_robust(self, frame, keypoints, row):
        """4ç‚¹ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆæç”»ï¼ˆæ¤œå‡ºæ ï¼‹IDè¡¨ç¤ºä»˜ãã€æ–‡å­—ãƒ©ãƒ™ãƒ«ãªã—ï¼‰"""
        try:
            import cv2

            # ğŸ¨ ã‚·ãƒ³ãƒ—ãƒ«2è‰²è¨­å®š
            ear_color = (100, 180, 100)         # è½ã¡ç€ã„ãŸã‚°ãƒªãƒ¼ãƒ³ï¼ˆè€³ï¼‰
            shoulder_color = (100, 100, 180)    # è½ã¡ç€ã„ãŸãƒ¬ãƒƒãƒ‰ï¼ˆè‚©ï¼‰
            center_color = (255, 200, 0)        # ã‚´ãƒ¼ãƒ«ãƒ‰ï¼ˆä¸­ç‚¹ï¼‰
            line_color = (0, 255, 255)          # ã‚·ã‚¢ãƒ³ï¼ˆæ¥ç¶šç·šï¼‰
        
            # æç”»è¨­å®š
            point_radius = 5         # ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆã®ã‚µã‚¤ã‚º
            center_radius = 8        # ä¸­ç‚¹ã®ã‚µã‚¤ã‚ºï¼ˆå°‘ã—å¤§ããï¼‰
            outer_radius = 7         # ç™½ã„å¤–æ 
            line_thickness = 2       # æ¥ç¶šç·šã®å¤ªã•
        
            drawn_points = 0

            # ğŸ”² æ¤œå‡ºæ ã®æç”»
            try:
                if hasattr(row, 'get'):
                    x1 = int(row.get('x1', 0))
                    y1 = int(row.get('y1', 0))
                    x2 = int(row.get('x2', 0))
                    y2 = int(row.get('y2', 0))
                    person_id = row.get('person_id', '?')
                    conf = float(row.get('conf', 0))
                
                    if x1 > 0 and y1 > 0 and x2 > x1 and y2 > y1:
                        # æ¤œå‡ºæ ã®æç”»ï¼ˆç·‘è‰²ï¼‰
                        cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)
                    
                        # ğŸ·ï¸ IDï¼‹ä¿¡é ¼åº¦è¡¨ç¤ºï¼ˆèƒŒæ™¯ä»˜ãï¼‰
                        id_text = f"ID:{person_id} ({conf:.2f})"
                        text_size = 0.6
                        text_thickness = 1
                    
                        # ãƒ†ã‚­ã‚¹ãƒˆã‚µã‚¤ã‚ºè¨ˆç®—
                        (text_w, text_h), baseline = cv2.getTextSize(id_text, cv2.FONT_HERSHEY_SIMPLEX, text_size, text_thickness)
                    
                        # èƒŒæ™¯çŸ©å½¢
                        bg_x1 = x1
                        bg_y1 = y1 - text_h - 10
                        bg_x2 = x1 + text_w + 10
                        bg_y2 = y1
                    
                        # èƒŒæ™¯æç”»ï¼ˆåŠé€æ˜é»’ï¼‰
                        overlay = frame.copy()
                        cv2.rectangle(overlay, (bg_x1, bg_y1), (bg_x2, bg_y2), (0, 0, 0), -1)
                        cv2.addWeighted(overlay, 0.6, frame, 0.4, 0, frame)
                    
                        # ãƒ†ã‚­ã‚¹ãƒˆæç”»ï¼ˆç™½ï¼‰
                        cv2.putText(frame, id_text, (x1 + 5, y1 - 5), 
                                cv2.FONT_HERSHEY_SIMPLEX, text_size, (255, 255, 255), text_thickness)
            except Exception as e:
                self.logger.debug(f"æ¤œå‡ºæ æç”»ã‚¨ãƒ©ãƒ¼: {e}")

            # ğŸ¯ å„ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆã®æç”»
            ear_points = []
            shoulder_points = []

            for kpt_name, (x, y, conf) in keypoints.items():
                # è‚©ã¨è€³ã§è‰²åˆ†ã‘
                if 'ear' in kpt_name:
                    color = ear_color
                elif 'shoulder' in kpt_name:
                    color = shoulder_color
                else:
                    color = (128, 128, 128)  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚°ãƒ¬ãƒ¼
            
                try:
                    # ãƒ¡ã‚¤ãƒ³ã®ç‚¹
                    cv2.circle(frame, (x, y), point_radius, color, -1)
                
                    # ç™½ã„å¤–æ ï¼ˆè¦‹ã‚„ã™ã•ã®ãŸã‚ï¼‰
                    cv2.circle(frame, (x, y), outer_radius, (255, 255, 255), 1)
                
                    drawn_points += 1
                
                except Exception as e:
                    self.logger.debug(f"ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆæç”»ã‚¹ã‚­ãƒƒãƒ—: {kpt_name} - {e}")
                    continue

            # ğŸ”— æ¥ç¶šç·šã®æç”»
            try:
                # è‚©ã®ãƒ©ã‚¤ãƒ³ï¼ˆè‚©ã®è‰²ã§ï¼‰
                if len(shoulder_points) == 2:
                    cv2.line(frame, shoulder_points[0], shoulder_points[1], 
                            shoulder_color, line_thickness)
            
                # è€³ã®ãƒ©ã‚¤ãƒ³ï¼ˆè€³ã®è‰²ã§ã€ç´°ã‚ï¼‰
                if len(ear_points) == 2:
                    cv2.line(frame, ear_points[0], ear_points[1], 
                            ear_color, 1)  # ã‚ˆã‚Šç´°ã„ç·š
            except:
                pass

            # ğŸ”§ ä¸­ç‚¹ã®è¨ˆç®—ã¨æç”»ï¼ˆhead_centerçµ±ä¸€ç‰ˆï¼‰
            try:
                # ğŸ¯ head_centerï¼ˆä¸¡è€³ä¸­ç‚¹ï¼‰ã®æç”»
                if len(ear_points) == 2:
                    head_center_x = (ear_points[0][0] + ear_points[1][0]) // 2
                    head_center_y = (ear_points[0][1] + ear_points[1][1]) // 2
                
                    # ä¸­ç‚¹æç”»ï¼ˆã‚´ãƒ¼ãƒ«ãƒ‰è‰²ã€ã‚„ã‚„å¤§ãã‚ï¼‰
                    cv2.circle(frame, (head_center_x, head_center_y), center_radius, center_color, -1)
                    cv2.circle(frame, (head_center_x, head_center_y), center_radius + 2, (255, 255, 255), 1)
                
                    # ğŸ”§ ãƒ©ãƒ™ãƒ«ä¿®æ­£: H-Cï¼ˆHead Centerï¼‰
                    cv2.putText(frame, "H-C", (head_center_x + 10, head_center_y - 10),
                            cv2.FONT_HERSHEY_SIMPLEX, 0.4, center_color, 1)
            
                # ğŸ¯ è‚©ä¸­ç‚¹ã®æç”»
                if len(shoulder_points) == 2:
                    shoulder_center_x = (shoulder_points[0][0] + shoulder_points[1][0]) // 2
                    shoulder_center_y = (shoulder_points[0][1] + shoulder_points[1][1]) // 2
                
                    # ä¸­ç‚¹æç”»ï¼ˆã‚´ãƒ¼ãƒ«ãƒ‰è‰²ã€ã‚„ã‚„å¤§ãã‚ï¼‰
                    cv2.circle(frame, (shoulder_center_x, shoulder_center_y), center_radius, center_color, -1)
                    cv2.circle(frame, (shoulder_center_x, shoulder_center_y), center_radius + 2, (255, 255, 255), 1)
                
                    # ãƒ©ãƒ™ãƒ«æç”»
                    cv2.putText(frame, "S-C", (shoulder_center_x + 10, shoulder_center_y - 10),
                            cv2.FONT_HERSHEY_SIMPLEX, 0.4, center_color, 1)
                
                # ğŸ”§ head_centerã¨è‚©ä¸­ç‚¹ã‚’çµã¶ç·šï¼ˆä½“è»¸ã®å¯è¦–åŒ–ï¼‰
                if len(ear_points) == 2 and len(shoulder_points) == 2:
                    head_center = ((ear_points[0][0] + ear_points[1][0]) // 2, 
                                  (ear_points[0][1] + ear_points[1][1]) // 2)
                    shoulder_center = ((shoulder_points[0][0] + shoulder_points[1][0]) // 2,
                                     (shoulder_points[0][1] + shoulder_points[1][1]) // 2)
                
                    # ä½“è»¸ç·šã®æç”»ï¼ˆç ´ç·šé¢¨ï¼‰
                    cv2.line(frame, head_center, shoulder_center, line_color, 2)
                
            except Exception as e:
                self.logger.debug(f"ä¸­ç‚¹æç”»ã‚¨ãƒ©ãƒ¼: {e}")

            return frame

        except Exception as e:
            self.logger.error(f"âŒ ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆæç”»ã‚¨ãƒ©ãƒ¼: {e}")
            return frame
        
    def draw_6point_keypoints_with_centers(self, frame, keypoints, row_data):
        """
        6ç‚¹ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆæç”»ï¼ˆ4ç‚¹ + 2ã¤ã®ä¸­ç‚¹ï¼‰- å®‰å…¨æ€§å¼·åŒ–ç‰ˆ
        """
        try:
            import cv2
            import numpy as np
            import pandas as pd
    
            # ğŸ¨ è‰²å®šç¾©ï¼ˆã‚ˆã‚Šè¦‹ã‚„ã™ãï¼‰
            colors = {
                'left_ear': (0, 255, 0),          # ç·‘è‰² - å·¦è€³
                'right_ear': (0, 200, 0),         # æ¿ƒã„ç·‘ - å³è€³
                'left_shoulder': (0, 0, 255),     # èµ¤è‰² - å·¦è‚©
                'right_shoulder': (0, 0, 200),    # æ¿ƒã„èµ¤ - å³è‚©
                'head_center': (255, 0, 255),     # ãƒã‚¼ãƒ³ã‚¿ - é ­ä¸­ç‚¹
                'shoulder_center': (0, 255, 255), # ã‚·ã‚¢ãƒ³ - è‚©ä¸­ç‚¹
                'connection': (255, 255, 255),    # ç™½è‰² - æ¥ç¶šç·š
                'axis': (255, 255, 0)             # é»„è‰² - ä½“è»¸ç·š
            }
    
            # ğŸ”§ ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆåº§æ¨™æŠ½å‡ºï¼ˆå®‰å…¨æ€§å¼·åŒ–ï¼‰
            valid_points = {}
            center_points = {}
    
            # 4ã¤ã®åŸºæœ¬ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆ
            points_config = [
                ('left_ear', 'left_ear'),
                ('right_ear', 'right_ear'), 
                ('left_shoulder', 'left_shoulder'),
                ('right_shoulder', 'right_shoulder')
            ]
    
            for point_name, color_key in points_config:
                try:
                    x = keypoints.get(f"{point_name}_x")
                    y = keypoints.get(f"{point_name}_y") 
                    conf = keypoints.get(f"{point_name}_conf", 0)
            
                    # ğŸ”§ å®‰å…¨ãªå‹å¤‰æ›
                    if x is not None and y is not None:
                        x_val = float(x) if not pd.isna(x) else None
                        y_val = float(y) if not pd.isna(y) else None
                        conf_val = float(conf) if not pd.isna(conf) else 0.0
                
                        if x_val is not None and y_val is not None and conf_val > 0.3:
                            # ãƒ•ãƒ¬ãƒ¼ãƒ ç¯„å›²ãƒã‚§ãƒƒã‚¯
                            frame_h, frame_w = frame.shape[:2]
                            if 0 <= x_val <= frame_w and 0 <= y_val <= frame_h:
                                valid_points[point_name] = {
                                    'pos': (int(x_val), int(y_val)),
                                    'conf': conf_val,
                                    'color': colors[color_key]
                                }
                except (ValueError, TypeError) as e:
                    self.logger.debug(f"ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆ{point_name}å¤‰æ›ã‚¨ãƒ©ãƒ¼: {e}")
                    continue
    
            # ğŸ”§ ä¸­ç‚¹è¨ˆç®—ï¼ˆrow_dataã‹ã‚‰å–å¾—ã¾ãŸã¯è¨ˆç®—ï¼‰
            # é ­ä¸­ç‚¹ï¼ˆè€³ã®ä¸­ç‚¹ï¼‰
            try:
                if hasattr(row_data, 'get'):
                    head_center_x = row_data.get('head_center_x')
                    head_center_y = row_data.get('head_center_y')
                else:
                    head_center_x = getattr(row_data, 'head_center_x', None)
                    head_center_y = getattr(row_data, 'head_center_y', None)
                
                if (head_center_x is not None and head_center_y is not None and 
                    not pd.isna(head_center_x) and not pd.isna(head_center_y)):
                    center_points['head_center'] = (int(float(head_center_x)), int(float(head_center_y)))
                elif 'left_ear' in valid_points and 'right_ear' in valid_points:
                    # å‹•çš„è¨ˆç®—
                    left_ear = valid_points['left_ear']['pos']
                    right_ear = valid_points['right_ear']['pos']
                    center_points['head_center'] = (
                        int((left_ear[0] + right_ear[0]) / 2),
                        int((left_ear[1] + right_ear[1]) / 2)
                    )
            except Exception as e:
                self.logger.debug(f"é ­ä¸­ç‚¹è¨ˆç®—ã‚¨ãƒ©ãƒ¼: {e}")
    
            # è‚©ä¸­ç‚¹
            try:
                if hasattr(row_data, 'get'):
                    shoulder_center_x = row_data.get('shoulder_center_x')
                    shoulder_center_y = row_data.get('shoulder_center_y')
                else:
                    shoulder_center_x = getattr(row_data, 'shoulder_center_x', None)
                    shoulder_center_y = getattr(row_data, 'shoulder_center_y', None)
                
                if (shoulder_center_x is not None and shoulder_center_y is not None and 
                    not pd.isna(shoulder_center_x) and not pd.isna(shoulder_center_y)):
                    center_points['shoulder_center'] = (int(float(shoulder_center_x)), int(float(shoulder_center_y)))
                elif 'left_shoulder' in valid_points and 'right_shoulder' in valid_points:
                    # å‹•çš„è¨ˆç®—
                    left_shoulder = valid_points['left_shoulder']['pos']
                    right_shoulder = valid_points['right_shoulder']['pos']
                    center_points['shoulder_center'] = (
                        int((left_shoulder[0] + right_shoulder[0]) / 2),
                        int((left_shoulder[1] + right_shoulder[1]) / 2)
                    )
            except Exception as e:
                self.logger.debug(f"è‚©ä¸­ç‚¹è¨ˆç®—ã‚¨ãƒ©ãƒ¼: {e}")
    
            # ğŸ¨ 4ã¤ã®åŸºæœ¬ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆæç”»
            for point_name, point_data in valid_points.items():
                try:
                    pos = point_data['pos']
                    color = point_data['color']
                    conf = point_data['conf']
            
                    # ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆã®å††æç”»
                    cv2.circle(frame, pos, 6, color, -1)
                    cv2.circle(frame, pos, 8, (255, 255, 255), 2)  # ç™½ã„å¤–æ 
            
                    # ãƒ©ãƒ™ãƒ«æç”»
                    label = point_name.replace('_', ' ').title()
                    label_pos = (pos[0] + 10, pos[1] - 10)
                    cv2.putText(frame, label, label_pos, cv2.FONT_HERSHEY_SIMPLEX, 
                            0.4, color, 1)
                except Exception as e:
                    self.logger.debug(f"ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆ{point_name}æç”»ã‚¨ãƒ©ãƒ¼: {e}")
    
            # ğŸ¯ ä¸­ç‚¹æç”»ï¼ˆç‰¹åˆ¥ãªãƒãƒ¼ã‚¯ï¼‰
            for center_name, center_pos in center_points.items():
                try:
                    color = colors[center_name]
                
                    # ä¸­ç‚¹ã®ç‰¹åˆ¥ãªæç”»ï¼ˆå¤§ãã‚ã®å†† + ã‚¯ãƒ­ã‚¹ãƒãƒ¼ã‚¯ï¼‰
                    cv2.circle(frame, center_pos, 8, color, -1)
                    cv2.circle(frame, center_pos, 10, (0, 0, 0), 2)  # é»’ã„å¤–æ 
            
                    # ã‚¯ãƒ­ã‚¹ãƒãƒ¼ã‚¯æç”»
                    cross_size = 6
                    cv2.line(frame, 
                            (center_pos[0] - cross_size, center_pos[1] - cross_size),
                            (center_pos[0] + cross_size, center_pos[1] + cross_size),
                            (0, 0, 0), 2)
                    cv2.line(frame, 
                            (center_pos[0] - cross_size, center_pos[1] + cross_size),
                            (center_pos[0] + cross_size, center_pos[1] - cross_size),
                            (0, 0, 0), 2)
            
                    # ä¸­ç‚¹ãƒ©ãƒ™ãƒ«
                    if center_name == 'head_center':
                        label = "HEAD"
                    elif center_name == 'shoulder_center':
                        label = "SHOULDER"
                    else:
                        label = center_name.upper()
            
                    label_pos = (center_pos[0] + 15, center_pos[1] + 5)
                    cv2.putText(frame, label, label_pos, cv2.FONT_HERSHEY_SIMPLEX, 
                            0.5, color, 2)
                except Exception as e:
                    self.logger.debug(f"ä¸­ç‚¹{center_name}æç”»ã‚¨ãƒ©ãƒ¼: {e}")
    
            # ğŸ“ æ¥ç¶šç·šæç”»
            try:
                # è€³é–“ã®ç·š
                if 'left_ear' in valid_points and 'right_ear' in valid_points:
                    cv2.line(frame, 
                            valid_points['left_ear']['pos'], 
                            valid_points['right_ear']['pos'],
                            colors['connection'], 2)
        
                # è‚©é–“ã®ç·š  
                if 'left_shoulder' in valid_points and 'right_shoulder' in valid_points:
                    cv2.line(frame, 
                            valid_points['left_shoulder']['pos'], 
                            valid_points['right_shoulder']['pos'],
                            colors['connection'], 3)
        
                # ä½“è»¸ç·šï¼ˆé ­ä¸­ç‚¹-è‚©ä¸­ç‚¹ï¼‰
                if 'head_center' in center_points and 'shoulder_center' in center_points:
                    cv2.line(frame, 
                            center_points['head_center'], 
                            center_points['shoulder_center'],
                            colors['axis'], 3)
            except Exception as e:
                self.logger.debug(f"æ¥ç¶šç·šæç”»ã‚¨ãƒ©ãƒ¼: {e}")
    
            # ğŸ“Š çµ±è¨ˆæƒ…å ±ã‚’ãƒ•ãƒ¬ãƒ¼ãƒ ã«æç”»
            try:
                info_y = 30
                font = cv2.FONT_HERSHEY_SIMPLEX
        
                # 6ç‚¹æƒ…å ±è¡¨ç¤º
                info_text = f"6-Point: {len(valid_points)} keypoints + {len(center_points)} centers"
                cv2.putText(frame, info_text, (10, info_y), font, 0.6, (255, 255, 255), 2)
        
                # å€‹åˆ¥ç‚¹ã®ä¿¡é ¼åº¦
                info_y += 20
                for i, (point_name, point_data) in enumerate(valid_points.items()):
                    if i >= 2:  # æœ€å¤§2å€‹ã¾ã§è¡¨ç¤º
                        break
                    conf = point_data['conf']
                    info_text = f"{point_name}: {conf:.3f}"
                    cv2.putText(frame, info_text, (10, info_y), font, 0.4, (200, 200, 200), 1)
                    info_y += 15
            except Exception as e:
                self.logger.debug(f"çµ±è¨ˆæƒ…å ±æç”»ã‚¨ãƒ©ãƒ¼: {e}")
    
            return frame
    
        except Exception as e:
            self.logger.error(f"âŒ 6ç‚¹æç”»ã‚¨ãƒ©ãƒ¼: {e}")
            return frame

    def draw_4point_keypoints_dynamic(self, frame, keypoint_data, row):
        """å‹•çš„4ç‚¹ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆæç”»"""
        try:
            import cv2
            import numpy as np
        
            # âš¡ ã‚ˆã‚Šç›®ç«‹ã¤è‰²ã¨ã‚µã‚¤ã‚º
            ear_color = (0, 255, 0)       # ç·‘ï¼ˆè€³ï¼‰
            shoulder_color = (0, 100, 255) # ã‚ªãƒ¬ãƒ³ã‚¸ï¼ˆè‚©ï¼‰
            line_color = (0, 255, 255)     # é»„ï¼ˆç·šï¼‰
            text_color = (255, 255, 255)   # ç™½ï¼ˆãƒ†ã‚­ã‚¹ãƒˆï¼‰
        
            # âš¡ ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆæç”»
            ear_points = []
            shoulder_points = []
        
            for name, (x, y, conf) in keypoint_data.items():
                color = ear_color if 'ear' in name else shoulder_color
            
                # âš¡ å¤§ããªå††ã§æç”»
                cv2.circle(frame, (x, y), 8, color, -1)  
                cv2.circle(frame, (x, y), 12, text_color, 2)
            
                # âš¡ ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆåã¨ä¿¡é ¼åº¦
                cv2.putText(frame, f"{name.split('_')[0]}:{conf:.2f}", 
                        (x + 10, y - 10),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)
            
                # ç‚¹ã‚’åˆ†é¡
                if 'ear' in name:
                    ear_points.append((x, y))
                elif 'shoulder' in name:
                    shoulder_points.append((x, y))
        
            # âš¡ è‚©ãƒ©ã‚¤ãƒ³
            if len(shoulder_points) == 2:
                cv2.line(frame, shoulder_points[0], shoulder_points[1], line_color, 4)
        
            # âš¡ é ­éƒ¨ä¸­å¿ƒ
            if len(ear_points) == 2:
                head_x = (ear_points[0][0] + ear_points[1][0]) // 2
                head_y = (ear_points[0][1] + ear_points[1][1]) // 2
                cv2.circle(frame, (head_x, head_y), 6, line_color, -1)
        
            # äººç‰©IDè¡¨ç¤º
            person_id = row.get('person_id', -1)
            if person_id != -1 and keypoint_data:
                all_points = list(keypoint_data.values())
                center_x = int(np.mean([p[0] for p in all_points]))
                center_y = int(np.mean([p[1] for p in all_points])) - 30
            
                cv2.putText(frame, f"ID:{person_id}", (center_x, center_y),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, text_color, 2)
        
            return frame
        
        except Exception as e:
            self.logger.warning(f"å‹•çš„æç”»ã‚¨ãƒ©ãƒ¼: {e}")
            return frame

    def run_experiment(self, video_path: str, experiment_type: str) -> Dict[str, Any]:
        """
        å®Ÿé¨“åˆ†æå®Ÿè¡Œï¼ˆå®Œå…¨çµ±åˆç‰ˆãƒ»ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°å†…è”µï¼‰

        Args:
            video_path: åˆ†æå¯¾è±¡å‹•ç”»ã®ãƒ‘ã‚¹
            experiment_type: å®Ÿé¨“ã‚¿ã‚¤ãƒ—

        Returns:
            å®Ÿé¨“çµæœè¾æ›¸
        """
        # ğŸ”§ å†…è”µã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°
        try:
            if ERROR_HANDLER_AVAILABLE:
                context_manager = ErrorContext(f"å®Ÿé¨“åˆ†æ: {experiment_type}", 
                                            logger=self.logger, raise_on_error=False)
            else:
                context_manager = self._basic_context(f"å®Ÿé¨“åˆ†æ: {experiment_type}")

            with context_manager as ctx:
                self.logger.info(f"ğŸ§ª å®Ÿé¨“åˆ†æé–‹å§‹: {experiment_type}")
            
                if hasattr(ctx, 'add_info'):
                    ctx.add_info("experiment_type", experiment_type)
                    ctx.add_info("video_path", str(video_path))

                # å®Ÿé¨“ã‚¿ã‚¤ãƒ—åˆ¥å‡¦ç†
                if experiment_type == "4point_keypoints":
                    # 4ç‚¹ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆå®Ÿé¨“
                    experiment_result = self._run_4point_experiment(video_path)
                elif experiment_type == "depth_analysis":
                    # æ·±åº¦åˆ†æå®Ÿé¨“
                    experiment_result = self._run_depth_experiment(video_path)
                elif experiment_type == "comparative_analysis":
                    # æ¯”è¼ƒåˆ†æå®Ÿé¨“
                    experiment_result = self._run_comparative_experiment(video_path)
                else:
                    # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³åˆ†æã‚’å®Ÿè¡Œ
                    self.logger.warning(f"âš ï¸ ä¸æ˜ãªå®Ÿé¨“ã‚¿ã‚¤ãƒ—: {experiment_type}, ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³åˆ†æã‚’å®Ÿè¡Œ")
                    experiment_result = self.run_baseline_analysis(video_path)
            
                return experiment_result

        except Exception as e:
            self.logger.error(f"âŒ å®Ÿé¨“åˆ†æã‚¨ãƒ©ãƒ¼: {e}")
            import traceback
            self.logger.error(f"ğŸ”§ è©³ç´°ã‚¨ãƒ©ãƒ¼: {traceback.format_exc()}")
        
            # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæƒ…å ±ã®è¿½åŠ ï¼ˆå®‰å…¨ã«ï¼‰
            try:
                if 'ctx' in locals() and hasattr(ctx, 'add_info'):
                    ctx.add_info("error_type", type(e).__name__)
                    ctx.add_info("error_message", str(e))
            except:
                pass  # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆè¿½åŠ ã«å¤±æ•—ã—ã¦ã‚‚å‡¦ç†ã‚’ç¶šè¡Œ
            
            return ResponseBuilder.error(e, suggestions=[
                f"å®Ÿé¨“ã‚¿ã‚¤ãƒ— '{experiment_type}' ã®è¨­å®šã‚’ç¢ºèªã—ã¦ãã ã•ã„",
                "ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³åˆ†æãŒæ­£å¸¸ã«å‹•ä½œã™ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„",
                "å¿…è¦ãªãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãŒãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„",
                "ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã§è©³ç´°ã‚¨ãƒ©ãƒ¼ã‚’ç¢ºèªã—ã¦ãã ã•ã„"
            ])

    def generate_error_report(self) -> Dict[str, Any]:
        """ã‚¨ãƒ©ãƒ¼ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆï¼ˆå®Œå…¨ç‰ˆï¼‰"""
        try:
            self.logger.info("ğŸ“‹ ã‚¨ãƒ©ãƒ¼ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆé–‹å§‹")
            
            error_report = {
                "timestamp": datetime.now().isoformat(),
                "total_errors": len(self.error_collector),
                "errors": self.error_collector.copy(),
                "system_info": {
                    "depth_enabled": self.depth_enabled,
                    "evaluator_type": type(self.evaluator).__name__,
                    "processor_type": type(self.processor).__name__,
                    "analyzer_type": type(self.analyzer).__name__,
                    "config_type": type(self.config).__name__
                },
                "module_availability": {
                    "error_handler": ERROR_HANDLER_AVAILABLE,
                    "evaluator": EVALUATOR_AVAILABLE,
                    "comprehensive_evaluator": COMPREHENSIVE_EVALUATOR_AVAILABLE,
                    "depth_evaluator": DEPTH_EVALUATOR_AVAILABLE,
                    "video_processor": VIDEO_PROCESSOR_AVAILABLE,
                    "metrics_analyzer": METRICS_ANALYZER_AVAILABLE,
                    "config": CONFIG_AVAILABLE,
                    "logger": LOGGER_AVAILABLE
                },
                "performance_info": {
                    "processing_stats": getattr(self.processor, 'processing_stats', {}),
                    "error_count_by_type": self._categorize_errors()
                }
            }
            
            # ã‚¨ãƒ©ãƒ¼ãƒ¬ãƒãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
            report_file = Path("logs") / f"error_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
            report_file.parent.mkdir(exist_ok=True)
            
            with open(report_file, 'w', encoding='utf-8') as f:
                json.dump(error_report, f, indent=2, ensure_ascii=False)
                
            self.logger.info(f"âœ… ã‚¨ãƒ©ãƒ¼ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆå®Œäº†: {report_file}")
            return error_report
            
        except Exception as e:
            self.logger.error(f"âŒ ã‚¨ãƒ©ãƒ¼ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆå¤±æ•—: {e}")
            return {"error": str(e)}

    def _categorize_errors(self) -> Dict[str, int]:
        """ã‚¨ãƒ©ãƒ¼ã®åˆ†é¡ï¼ˆå®Œå…¨ç‰ˆï¼‰"""
        categories = {
            "video_processing": 0,
            "model_loading": 0,
            "evaluation": 0,
            "configuration": 0,
            "depth_processing": 0,
            "io_operations": 0,
            "other": 0
        }
        
        for error in self.error_collector:
            error_lower = error.lower()
            if any(keyword in error_lower for keyword in ["video", "frame", "opencv", "mp4", "avi"]):
                categories["video_processing"] += 1
            elif any(keyword in error_lower for keyword in ["model", "yolo", "loading", "pt", "weights"]):
                categories["model_loading"] += 1
            elif any(keyword in error_lower for keyword in ["evaluation", "csv", "analysis", "metrics"]):
                categories["evaluation"] += 1
            elif any(keyword in error_lower for keyword in ["config", "setting", "yaml", "json"]):
                categories["configuration"] += 1
            elif any(keyword in error_lower for keyword in ["depth", "midas", "disparity"]):
                categories["depth_processing"] += 1
            elif any(keyword in error_lower for keyword in ["file", "directory", "path", "permission"]):
                categories["io_operations"] += 1
            else:
                categories["other"] += 1
        
        return categories

    def get_video_files(self) -> List[Path]:
        """å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«å–å¾—ï¼ˆä¿®æ­£ç‰ˆãƒ»åŸºæœ¬æ¨è«–å„ªå…ˆï¼‰"""
        try:
            # ğŸ”§ --video ã‚ªãƒ—ã‚·ãƒ§ãƒ³ãŒæŒ‡å®šã•ã‚ŒãŸå ´åˆã¯ã€ãã®ãƒ•ã‚¡ã‚¤ãƒ«ã®ã¿å‡¦ç†
            if hasattr(sys, 'argv') and '--video' in ' '.join(sys.argv):
                # ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°ã‹ã‚‰å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç›´æ¥å–å¾—ã™ã‚‹å ´åˆã¯
                # ãƒ¡ã‚¤ãƒ³é–¢æ•°ã§å‡¦ç†ã•ã‚Œã‚‹ã®ã§ã€ã“ã“ã§ã¯ç©ºãƒªã‚¹ãƒˆã‚’è¿”ã™
                return []
        
            # é€šå¸¸ã®å‹•ç”»ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ¤œç´¢
            if hasattr(self.config, 'video_dir'):
                video_dir = Path(self.config.video_dir)
            else:
                video_dir = Path(self.config.get("video_dir", "videos"))
            
            self.logger.info(f"ğŸ¥ å‹•ç”»ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ¤œç´¢: {video_dir}")
            
            if not video_dir.exists():
                self.logger.warning(f"âš ï¸ å‹•ç”»ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒå­˜åœ¨ã—ã¾ã›ã‚“: {video_dir}")
                return []
            
            # ã‚µãƒãƒ¼ãƒˆã™ã‚‹å‹•ç”»å½¢å¼
            video_extensions = ['.mp4', '.avi', '.mov', '.mkv', '.wmv', '.flv', '.webm']
            video_files = []
        
            for ext in video_extensions:
                found_files = list(video_dir.glob(f"*{ext}"))
                found_files.extend(video_dir.glob(f"*{ext.upper()}"))
                video_files.extend(found_files)
            
            video_files = sorted(set(video_files))
        
            if not video_files:
                self.logger.warning(f"âš ï¸ å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {video_dir}")
                return []
        
            self.logger.info(f"âœ… å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ç™ºè¦‹: {len(video_files)}å€‹")
            for video_file in video_files:
                file_size_mb = video_file.stat().st_size / 1024 / 1024
                self.logger.debug(f"  ğŸ“¹ {video_file.name} ({file_size_mb:.1f}MB)")
            
            return video_files
        
        except Exception as e:
            self.logger.error(f"âŒ å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            return []

def main():
    """
    ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°ï¼ˆ4ç‚¹ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆå¯¾å¿œå®Œå…¨ä¿®æ­£ç‰ˆï¼‰
    """
    # ã‚¢ã‚¹ã‚­ãƒ¼ã‚¢ãƒ¼ãƒˆã¨ãƒãƒ¼ã‚¸ãƒ§ãƒ³æƒ…å ±
    print("""
    â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
    â•‘                     ğŸ¯ YOLO11 å§¿å‹¢åˆ†æã‚·ã‚¹ãƒ†ãƒ  v2.1                    â•‘
    â•‘                        ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆæ¤œå‡ºãƒ»è¿½è·¡ãƒ»è§£æ                        â•‘
    â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """)

    # ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°ãƒ‘ãƒ¼ã‚µãƒ¼ã®è¨­å®š
    parser = argparse.ArgumentParser(
        description="ğŸ¯ YOLO11å§¿å‹¢åˆ†æã‚·ã‚¹ãƒ†ãƒ  - å‹•ç”»ã‹ã‚‰äººç‰©ã®å§¿å‹¢ã‚’åˆ†æã—ã¾ã™",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ä¾‹:
    # åŸºæœ¬çš„ãªå§¿å‹¢åˆ†æ
    python improved_main.py input.mp4

    # 4ç‚¹ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆåˆ†æï¼ˆé«˜ç²¾åº¦ï¼‰
    python improved_main.py input.mp4 --use-4points --keypoint-threshold 0.5

    # æ·±åº¦æ¨å®šä»˜ãåˆ†æ
    python improved_main.py input.mp4 --enable-depth --depth-model dpt_hybrid

    # ã‚«ã‚¹ã‚¿ãƒ è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ä½¿ç”¨
    python improved_main.py input.mp4 --config custom_config.yaml

    # é«˜è§£åƒåº¦å‡¦ç†
    python improved_main.py input.mp4 --resolution 1920x1080 --quality high
        """
    )

    # å¿…é ˆå¼•æ•°
    parser.add_argument(
        'video_path',
        type=str,
        help='ğŸ¬ åˆ†æå¯¾è±¡ã®å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹'
    )

    # ã‚ªãƒ—ã‚·ãƒ§ãƒ³å¼•æ•°
    parser.add_argument(
        '--config',
        type=str,
        default=None,
        help='âš™ï¸ è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ï¼ˆYAML/JSONå½¢å¼ï¼‰'
    )

    parser.add_argument(
        '--output-dir',
        type=str,
        default=None,
        help='ğŸ“ å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: results/å‹•ç”»å_YYYYMMDD_HHMMSSï¼‰'
    )

    # ğŸ¯ 4ç‚¹ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆé–¢é€£ã‚ªãƒ—ã‚·ãƒ§ãƒ³
    parser.add_argument(
        '--use-4points',
        action='store_true',
        help='ğŸ¦´ 4ç‚¹ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆãƒ¢ãƒ¼ãƒ‰ã‚’æœ‰åŠ¹åŒ–ï¼ˆè€³2ç‚¹ + è‚©2ç‚¹ï¼‰'
    )

    parser.add_argument(
        '--keypoint-threshold',
        type=float,
        default=0.3,
        help='ğŸ¯ ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆä¿¡é ¼åº¦é–¾å€¤ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 0.3ï¼‰'
    )

    parser.add_argument(
        '--disable-shoulder-metrics',
        action='store_true',
        help='ğŸš« è‚©å¹…ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’ç„¡åŠ¹åŒ–'
    )

    parser.add_argument(
        '--disable-head-tracking',
        action='store_true',
        help='ğŸš« é ­éƒ¨è¿½è·¡æ©Ÿèƒ½ã‚’ç„¡åŠ¹åŒ–'
    )

    # æ·±åº¦æ¨å®šã‚ªãƒ—ã‚·ãƒ§ãƒ³
    parser.add_argument(
        '--enable-depth',
        action='store_true',
        help='ğŸŒŠ æ·±åº¦æ¨å®šæ©Ÿèƒ½ã‚’æœ‰åŠ¹åŒ–'
    )

    parser.add_argument(
        '--depth-model',
        type=str,
        default='dpt_hybrid',
        choices=['dpt_hybrid', 'midas', 'dpt_large'],
        help='ğŸ§  æ·±åº¦æ¨å®šãƒ¢ãƒ‡ãƒ«ã®é¸æŠ'
    )

    # å‡¦ç†ã‚ªãƒ—ã‚·ãƒ§ãƒ³
    parser.add_argument(
        '--resolution',
        type=str,
        default=None,
        help='ğŸ“ å‡¦ç†è§£åƒåº¦ï¼ˆä¾‹: 1920x1080, 1280x720ï¼‰'
    )

    parser.add_argument(
        '--fps',
        type=int,
        default=None,
        help='ğŸ¬ å‡¦ç†FPSï¼ˆãƒ•ãƒ¬ãƒ¼ãƒ é–“å¼•ãç”¨ï¼‰'
    )

    parser.add_argument(
        '--quality',
        type=str,
        default='medium',
        choices=['low', 'medium', 'high', 'ultra'],
        help='ğŸ¨ å‡¦ç†å“è³ªãƒ¬ãƒ™ãƒ«'
    )

    parser.add_argument(
        '--skip-frames',
        type=int,
        default=0,
        help='â­ï¸ ã‚¹ã‚­ãƒƒãƒ—ãƒ•ãƒ¬ãƒ¼ãƒ æ•°ï¼ˆå‡¦ç†é«˜é€ŸåŒ–ç”¨ï¼‰'
    )

    # ãƒ‡ãƒãƒƒã‚°ã‚ªãƒ—ã‚·ãƒ§ãƒ³
    parser.add_argument(
        '--debug',
        action='store_true',
        help='ğŸ› ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰ã‚’æœ‰åŠ¹åŒ–'
    )

    parser.add_argument(
        '--log-level',
        type=str,
        default='INFO',
        choices=['DEBUG', 'INFO', 'WARNING', 'ERROR'],
        help='ğŸ“ ãƒ­ã‚°ãƒ¬ãƒ™ãƒ«'
    )

    parser.add_argument(
        '--save-intermediate',
        action='store_true',
        help='ğŸ’¾ ä¸­é–“ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜'
    )

    # ãƒ¢ãƒ‡ãƒ«ã‚ªãƒ—ã‚·ãƒ§ãƒ³
    parser.add_argument(
        '--model-size',
        type=str,
        default='x',
        choices=['n', 's', 'm', 'l', 'x'],
        help='ğŸ¯ YOLOãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºï¼ˆn=nano, s=small, m=medium, l=large, x=xlargeï¼‰'
    )

    parser.add_argument(
        '--confidence-threshold',
        type=float,
        default=0.3,
        help='ğŸ¯ æ¤œå‡ºä¿¡é ¼åº¦é–¾å€¤'
    )

    parser.add_argument(
        '--iou-threshold',
        type=float,
        default=0.45,
        help='ğŸ“ IoUé–¾å€¤ï¼ˆé‡è¤‡æ¤œå‡ºé™¤å»ç”¨ï¼‰'
    )

    # å‡ºåŠ›ã‚ªãƒ—ã‚·ãƒ§ãƒ³
    parser.add_argument(
        '--disable-visualization',
        action='store_true',
        help='ğŸš« å¯è¦–åŒ–å‡ºåŠ›ã‚’ç„¡åŠ¹åŒ–'
    )

    parser.add_argument(
        '--output-format',
        type=str,
        default='csv',
        choices=['csv', 'json', 'both'],
        help='ğŸ“Š å‡ºåŠ›ãƒ‡ãƒ¼ã‚¿å½¢å¼'
    )

    # å¼•æ•°è§£æ
    args = parser.parse_args()

    # ğŸ”§ ãƒ­ã‚°ãƒ¬ãƒ™ãƒ«è¨­å®š
    log_level = getattr(logging, args.log_level.upper())
    logging.basicConfig(
        level=log_level,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        handlers=[
            logging.StreamHandler(),
            logging.FileHandler('yolo_pose_analysis.log', encoding='utf-8')
        ]
    )
    logger = logging.getLogger(__name__)

    # ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰è¨­å®š
    if args.debug:
        logger.setLevel(logging.DEBUG)
        logger.info("ğŸ› ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰ãŒæœ‰åŠ¹åŒ–ã•ã‚Œã¾ã—ãŸ")

    try:
        # ğŸ”§ å…¥åŠ›æ¤œè¨¼
        if not Path(args.video_path).exists():
            logger.error(f"âŒ å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {args.video_path}")
            return 1

        video_path = Path(args.video_path)
        logger.info(f"ğŸ¬ å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«: {video_path}")

        # ğŸ”§ å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªè¨­å®š
        if args.output_dir:
            output_dir = Path(args.output_dir)
        else:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            video_name = video_path.stem
            output_dir = Path("results") / f"{video_name}_{timestamp}"

        output_dir.mkdir(parents=True, exist_ok=True)
        logger.info(f"ğŸ“ å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {output_dir}")

        # ğŸ¯ ã‚¢ãƒŠãƒ©ã‚¤ã‚¶ãƒ¼åˆæœŸåŒ–
        try:
            # ğŸ”§ ä¿®æ­£: æ­£ã—ã„ã‚¯ãƒ©ã‚¹åã¨åˆæœŸåŒ–ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
            analyzer = ImprovedYOLOAnalyzer(
                config_path=args.config or "configs/default.yaml"
            )
            # ğŸ”§ æ·±åº¦æ¨å®šè¨­å®šã®é©ç”¨
            if args.enable_depth:
                analyzer.depth_enabled = True
                logger.info("ğŸ” æ·±åº¦æ¨å®šæ©Ÿèƒ½ã‚’æœ‰åŠ¹åŒ–")
            
            logger.info("âœ… ã‚¢ãƒŠãƒ©ã‚¤ã‚¶ãƒ¼åˆæœŸåŒ–å®Œäº†")
        except Exception as e:
            logger.error(f"âŒ ã‚¢ãƒŠãƒ©ã‚¤ã‚¶ãƒ¼åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
            import traceback
            logger.error(f"ğŸ”§ è©³ç´°ã‚¨ãƒ©ãƒ¼: {traceback.format_exc()}")
            return 1

        # ğŸ¯ ä¿®æ­£: 4ç‚¹ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆè¨­å®šã®ç¢ºå®Ÿãªé©ç”¨
        if args.use_4points:
            try:
                # ğŸ”§ ä¿®æ­£: è¨­å®šã‚ªãƒ¼ãƒãƒ¼ãƒ©ã‚¤ãƒ‰ã‚’å¼·åŒ–
                if hasattr(analyzer, 'config') and hasattr(analyzer.config, 'data') and isinstance(analyzer.config.data, dict):
                    analyzer.config.data.setdefault('processing', {})
                    
                    # ğŸ”§ ä¿®æ­£: ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆå‡¦ç†è¨­å®šã‚’ç¢ºå®Ÿã«é©ç”¨
                    analyzer.config.data['processing']['use_4point_keypoints'] = True
                    analyzer.config.data['processing']['keypoint_confidence_threshold'] = args.keypoint_threshold
                    analyzer.config.data['processing']['force_pose_model'] = True  # ğŸ”§ è¿½åŠ 
                    analyzer.config.data['processing']['verify_keypoint_columns'] = True  # ğŸ”§ è¿½åŠ 
                    
                    # ğŸ”§ ä¿®æ­£: trackerè¨­å®šã‚‚ç¢ºå®Ÿã«è¨­å®š
                    analyzer.config.data['processing'].setdefault('tracking', {})
                    analyzer.config.data['processing']['tracking']['config'] = 'bytetrack.yaml'
                    
                    # ğŸ”§ ä¿®æ­£: è‚©ãƒ»é ­éƒ¨è¨­å®šã®é©ç”¨
                    if args.disable_shoulder_metrics:
                        analyzer.config.data['processing']['enable_shoulder_metrics'] = False
                        logger.info("ğŸ”§ è‚©ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’ç„¡åŠ¹åŒ–")
                    else:
                        analyzer.config.data['processing']['enable_shoulder_metrics'] = True
                        
                    if args.disable_head_tracking:
                        analyzer.config.data['processing']['enable_head_tracking'] = False
                        logger.info("ğŸ”§ é ­éƒ¨è¿½è·¡ã‚’ç„¡åŠ¹åŒ–")
                    else:
                        analyzer.config.data['processing']['enable_head_tracking'] = True
                        
                    logger.info("ğŸ”§ è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’4ç‚¹ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆãƒ¢ãƒ¼ãƒ‰ç”¨ã«ç¢ºå®Ÿã«æ›´æ–°")
                    logger.info(f"   ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆä¿¡é ¼åº¦é–¾å€¤: {args.keypoint_threshold}")
                    logger.info(f"   è‚©ãƒ¡ãƒˆãƒªã‚¯ã‚¹: {'ç„¡åŠ¹' if args.disable_shoulder_metrics else 'æœ‰åŠ¹'}")
                    logger.info(f"   é ­éƒ¨è¿½è·¡: {'ç„¡åŠ¹' if args.disable_head_tracking else 'æœ‰åŠ¹'}")
                    
                else:
                    # ğŸ”§ ä¿®æ­£: è¨­å®šãŒãªã„å ´åˆã®å‡¦ç†ã‚’å¼·åŒ–
                    logger.error("âŒ è¨­å®šã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆãŒä¸æ­£ã§ã™")
                    logger.error("ğŸ”§ ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ4ç‚¹è¨­å®šã‚’ç›´æ¥é©ç”¨ã—ã¾ã™")
                    
                    # ç›´æ¥è¨­å®šã‚’ä½œæˆ
                    fallback_config = {
                        'processing': {
                            'use_4point_keypoints': True,
                            'keypoint_confidence_threshold': args.keypoint_threshold,
                            'force_pose_model': True,
                            'verify_keypoint_columns': True,
                            'tracking': {'config': 'bytetrack.yaml'},
                            'enable_shoulder_metrics': not args.disable_shoulder_metrics,
                            'enable_head_tracking': not args.disable_head_tracking
                        }
                    }
                    
                    if hasattr(analyzer, 'config'):
                        analyzer.config.data = fallback_config
                        logger.info("âœ… ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯è¨­å®šã‚’é©ç”¨")
                    else:
                        logger.error("ğŸš¨ è¨­å®šã®é©ç”¨ã«å®Œå…¨ã«å¤±æ•—ã—ã¾ã—ãŸ")
                        logger.error("ğŸš¨ 4ç‚¹ãƒ¢ãƒ¼ãƒ‰ã§ã®å‡¦ç†ãŒæ­£å¸¸ã«å‹•ä½œã—ãªã„å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™")
                        
            except Exception as config_error:
                logger.error(f"âŒ 4ç‚¹ãƒ¢ãƒ¼ãƒ‰è¨­å®šã‚¨ãƒ©ãƒ¼: {config_error}")
                logger.warning("âš ï¸ ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šã§å‡¦ç†ã‚’ç¶šè¡Œã—ã¾ã™")

        # ğŸ”§ å“è³ªè¨­å®šã®é©ç”¨
        quality_configs = {
            'low': {'resolution': '640x480', 'skip_frames': 2},
            'medium': {'resolution': '1280x720', 'skip_frames': 1},
            'high': {'resolution': '1920x1080', 'skip_frames': 0},
            'ultra': {'resolution': '1920x1080', 'skip_frames': 0}
        }

        if args.quality in quality_configs:
            quality_config = quality_configs[args.quality]
            if not args.resolution:
                args.resolution = quality_config['resolution']
            if args.skip_frames == 0:
                args.skip_frames = quality_config['skip_frames']

        # ğŸ”§ è§£åƒåº¦è¨­å®š
        if args.resolution:
            try:
                width, height = map(int, args.resolution.split('x'))
                if hasattr(analyzer.config, 'data'):
                    analyzer.config.data.setdefault('processing', {})
                    analyzer.config.data['processing']['target_width'] = width
                    analyzer.config.data['processing']['target_height'] = height
                logger.info(f"ğŸ“ è§£åƒåº¦è¨­å®š: {width}x{height}")
            except ValueError:
                logger.warning(f"âš ï¸ ä¸æ­£ãªè§£åƒåº¦å½¢å¼: {args.resolution}")

        # ğŸ”§ ãã®ä»–ã®å‡¦ç†è¨­å®š
        if hasattr(analyzer.config, 'data') and analyzer.config.data:
            processing_config = analyzer.config.data.setdefault('processing', {})
            
            # ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°ã‹ã‚‰è¨­å®šã‚’æ›´æ–°
            processing_config['confidence_threshold'] = args.confidence_threshold
            processing_config['iou_threshold'] = args.iou_threshold
            
            if args.fps:
                processing_config['target_fps'] = args.fps
                
            processing_config['skip_frames'] = args.skip_frames
            processing_config['save_intermediate'] = args.save_intermediate
            processing_config['enable_visualization'] = not args.disable_visualization
            
            # ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºè¨­å®š
            model_size_map = {
                'n': 'nano', 's': 'small', 'm': 'medium', 
                'l': 'large', 'x': 'xlarge'
            }
            processing_config['model_size'] = model_size_map.get(args.model_size, 'xlarge')

        # ğŸ¯ ãƒ¡ã‚¤ãƒ³åˆ†æå‡¦ç†å®Ÿè¡Œ
        logger.info("ğŸš€ ========== å§¿å‹¢åˆ†æå‡¦ç†é–‹å§‹ ==========")
        
        start_time = time.time()
        
        try:
            # ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³åˆ†æå®Ÿè¡Œ
            result = analyzer.run_baseline_analysis(str(video_path))
            
            if result is None:
                logger.error("âŒ åˆ†æå‡¦ç†ãŒç•°å¸¸çµ‚äº†ã—ã¾ã—ãŸï¼ˆæˆ»ã‚Šå€¤ãŒNoneï¼‰")
                return 1

            if not isinstance(result, dict):
                logger.error(f"âŒ åˆ†æå‡¦ç†ã®æˆ»ã‚Šå€¤ãŒæƒ³å®šå¤–ã®å‹ã§ã™: {type(result)}")
                return 1

            if not result.get("success", False):
                error_msg = result.get("error", "ä¸æ˜ãªã‚¨ãƒ©ãƒ¼")
                # errorãŒdictå‹ã®å ´åˆã‚‚è€ƒæ…®
                if isinstance(error_msg, dict):
                    error_msg = error_msg.get("message", str(error_msg))
                logger.error(f"âŒ åˆ†æå‡¦ç†å¤±æ•—: {error_msg}")
                return 1

            processing_time = time.time() - start_time
            logger.info(f"â±ï¸ ç·å‡¦ç†æ™‚é–“: {processing_time:.2f}ç§’")
            
            # ğŸ¯ çµæœã®ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
            data = result.get("data", {})

            # detection_resultã®ä¸­ã‚’å‚ç…§
            detection_result = data.get("detection_result", {})
            detection_data = detection_result.get("data", {}) if isinstance(detection_result, dict) else {}

            # CSVãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹å–å¾—
            csv_path = detection_data.get("csv_path") or data.get("csv_path")
            if csv_path and Path(csv_path).exists():
                import pandas as pd
                df = pd.read_csv(csv_path)
                total_detections = len(df)
                total_frames = len(df['frame'].unique()) if 'frame' in df.columns else 0
                unique_ids = len(df['person_id'].unique()) if 'person_id' in df.columns else 0
            else:
                # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: åŸºæœ¬çµ±è¨ˆã‹ã‚‰å–å¾—
                total_detections = detection_data.get("total_detections", 0) or data.get("total_detections", 0)
                total_frames = detection_data.get("total_frames", 0) or data.get("total_frames", 0)
                unique_ids = detection_data.get("unique_ids", 0) or data.get("unique_ids", 0)
        
            logger.info("ğŸ“Š ========== å‡¦ç†çµæœã‚µãƒãƒªãƒ¼ ==========")
            logger.info(f"ğŸ¬ ç·ãƒ•ãƒ¬ãƒ¼ãƒ æ•°: {total_frames}")
            logger.info(f"ğŸ¯ ç·æ¤œå‡ºæ•°: {total_detections}")
            logger.info(f"ğŸ‘¥ ãƒ¦ãƒ‹ãƒ¼ã‚¯äººç‰©ID: {unique_ids}")
        
            if total_frames > 0:
                detection_rate = total_detections / total_frames
                logger.info(f"ğŸ“ˆ ãƒ•ãƒ¬ãƒ¼ãƒ å½“ãŸã‚Šæ¤œå‡ºæ•°: {detection_rate:.2f}")
        
            # ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆçµ±è¨ˆï¼ˆ4ç‚¹ãƒ¢ãƒ¼ãƒ‰ã®å ´åˆï¼‰
            if args.use_4points:
                keypoint_stats = detection_data.get("keypoint_stats", {}) or data.get("keypoint_stats", {})
                if keypoint_stats:
                    keypoint_frames = keypoint_stats.get("frames_with_keypoints", 0)
                    keypoint_rate = keypoint_frames / total_frames if total_frames > 0 else 0
                
                    logger.info("ğŸ¦´ ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆçµ±è¨ˆ:")
                    logger.info(f"  ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆæ¤œå‡ºãƒ•ãƒ¬ãƒ¼ãƒ : {keypoint_frames} ({keypoint_rate:.1%})")
                    logger.info(f"  ç·ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆæ•°: {keypoint_stats.get('total_keypoints', 0)}")
                
                    avg_keypoints = keypoint_stats.get('avg_keypoints_per_person', 0)
                    if avg_keypoints > 0:
                        logger.info(f"  å¹³å‡ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆ/äºº: {avg_keypoints:.1f}")
        
            # å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§
            output_files = detection_data.get("output_files", []) or data.get("output_files", [])
            if output_files:
                logger.info("ğŸ“ ç”Ÿæˆãƒ•ã‚¡ã‚¤ãƒ«:")
                for file_path in output_files:
                    if Path(file_path).exists():
                        size_mb = Path(file_path).stat().st_size / (1024 * 1024)
                        logger.info(f"  âœ… {file_path} ({size_mb:.2f}MB)")
                    else:
                        logger.warning(f"  âš ï¸ {file_path} (ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“)")
        
            # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹çµ±è¨ˆ
            fps = total_frames / processing_time if processing_time > 0 else 0
            logger.info(f"âš¡ å‡¦ç†æ€§èƒ½: {fps:.2f} FPS")
            
            # ã‚¨ãƒ©ãƒ¼å ±å‘Š
            if hasattr(analyzer, 'error_collector') and analyzer.error_collector:
                logger.warning(f"âš ï¸ å‡¦ç†ä¸­ã®ã‚¨ãƒ©ãƒ¼: {len(analyzer.error_collector)}ä»¶")
                for i, error in enumerate(analyzer.error_collector[:5], 1):
                    logger.warning(f"  {i}. {error}")
                if len(analyzer.error_collector) > 5:
                    logger.warning(f"  ... ä»– {len(analyzer.error_collector) - 5}ä»¶")
            
            logger.info("ğŸ¯ ========== å‡¦ç†å®Œäº† ==========")
            
            # æˆåŠŸæ™‚ã®è¿½åŠ æƒ…å ±
            if args.use_4points:
                logger.info("ğŸ’¡ 4ç‚¹ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’ç¢ºèªã—ã¦ãã ã•ã„:")
                logger.info("   - 4point_keypoints.csv: ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿")
                logger.info("   - 4point_metrics.csv: å§¿å‹¢ãƒ¡ãƒˆãƒªã‚¯ã‚¹ä»˜ããƒ‡ãƒ¼ã‚¿")
            
            if args.enable_depth:
                logger.info("ğŸ’¡ æ·±åº¦æ¨å®šãƒ‡ãƒ¼ã‚¿ã‚’ç¢ºèªã—ã¦ãã ã•ã„:")
                logger.info("   - depth_analysis/ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…ã®æ·±åº¦ãƒãƒƒãƒ—")
                
            return 0
            
        except Exception as e:
            logger.error(f"âŒ åˆ†æå‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ: {e}")
            import traceback
            logger.error(f"ğŸ”§ ãƒˆãƒ¬ãƒ¼ã‚¹ãƒãƒƒã‚¯:\n{traceback.format_exc()}")
            return 1

    except KeyboardInterrupt:
        logger.warning("â¸ï¸ ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ã‚ˆã‚‹å‡¦ç†ä¸­æ–­")
        return 130
        
    except Exception as e:
        logger.error(f"âŒ äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        logger.error(f"ğŸ”§ ãƒˆãƒ¬ãƒ¼ã‚¹ãƒãƒƒã‚¯:\n{traceback.format_exc()}")
        return 1


if __name__ == "__main__":
    # ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±å‡ºåŠ›
    print(f"ğŸ Python: {sys.version}")
    print(f"ğŸ’» Platform: {platform.platform()}")
    print(f"ğŸ§  CPU Count: {os.cpu_count()}")
    
    # GPUæƒ…å ±ç¢ºèª
    try:
        import torch
        if torch.cuda.is_available():
            print(f"ğŸš€ CUDA: {torch.version.cuda}")
            print(f"ğŸ® GPU: {torch.cuda.get_device_name(0)}")
        else:
            print("ğŸ’» GPU: CUDAåˆ©ç”¨ä¸å¯ï¼ˆCPUå‡¦ç†ï¼‰")
    except ImportError:
        print("âš ï¸ PyTorchæœªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«")
    
    print()
    
    # ãƒ¡ã‚¤ãƒ³å‡¦ç†å®Ÿè¡Œ
    sys.exit(main())