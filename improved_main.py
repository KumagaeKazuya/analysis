"""
YOLO11 åºƒè§’ã‚«ãƒ¡ãƒ©åˆ†æã‚·ã‚¹ãƒ†ãƒ  - æ”¹è‰¯ç‰ˆï¼ˆçµ±ä¸€ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚° + æ·±åº¦æ¨å®šçµ±åˆå¯¾å¿œç‰ˆï¼‰

ğŸ”§ ä¸»ãªæ”¹å–„ç‚¹:
1. çµ±ä¸€ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°å¯¾å¿œ
2. æ·±åº¦æ¨å®šï¼ˆMiDaSï¼‰çµ±åˆæ©Ÿèƒ½
3. æ·±åº¦å¯¾å¿œè©•ä¾¡å™¨ã®è‡ªå‹•é¸æŠ
4. è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®è‡ªå‹•åˆ‡ã‚Šæ›¿ãˆ
5. ã‚¨ãƒ©ãƒ¼åé›†ã¨ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
6. ğŸ”§ ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ä¸è¶³å¯¾å¿œã¨ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æ©Ÿèƒ½
7. ğŸ”§ ErrorCategory.EVALUATION å¯¾å¿œï¼ˆStage 5ä¿®æ­£ï¼‰
8. ğŸ”§ æ¡ä»¶ä»˜ãã‚¤ãƒ³ãƒãƒ¼ãƒˆã®å¼·åŒ–ï¼ˆStage 6ä¿®æ­£ï¼‰
9. ğŸ”§ ç›´æ¥ã‚¤ãƒ³ãƒãƒ¼ãƒˆå‰Šé™¤ã¨ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å®Œå…¨çµ±åˆ
"""
import argparse
import os
import sys
import json
import logging
from datetime import datetime
from pathlib import Path
import argparse
from typing import Dict, Any, Optional, List
import time
from datetime import datetime  # ğŸ”§ è¿½åŠ 
import traceback
import platform

# ğŸ”§ æ¡ä»¶ä»˜ãã‚¤ãƒ³ãƒãƒ¼ãƒˆ - å¿…é ˆãƒ©ã‚¤ãƒ–ãƒ©ãƒª
try:
    import cv2
    import numpy as np
    import pandas as pd
    from ultralytics import YOLO
    import torch
    import matplotlib.pyplot as plt
    from tqdm import tqdm
    import yaml
    print("âœ… å¿…é ˆãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆæˆåŠŸ")
except ImportError as e:
    print(f"âŒ å¿…é ˆãƒ©ã‚¤ãƒ–ãƒ©ãƒªä¸è¶³: {e}")
    print("ğŸ“¦ ä»¥ä¸‹ã§ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¦ãã ã•ã„:")
    print("pip install ultralytics opencv-python numpy pandas matplotlib tqdm pyyaml torch")
    sys.exit(1)

# ğŸ”§ æ¡ä»¶ä»˜ãã‚¤ãƒ³ãƒãƒ¼ãƒˆ - çµ±ä¸€ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ï¼ˆå®Œå…¨çµ±åˆç‰ˆï¼‰
ERROR_HANDLER_AVAILABLE = False
try:
    from utils.error_handler import (
        BaseYOLOError,
        ConfigurationError,
        VideoProcessingError,
        ResponseBuilder,
        handle_errors,
        ErrorContext,
        ErrorCategory,
        ErrorReporter,
        ErrorSeverity
    )
    ERROR_HANDLER_AVAILABLE = True
    print("âœ… çµ±ä¸€ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ãŒåˆ©ç”¨å¯èƒ½ã§ã™")
except ImportError as e:
    print(f"âš ï¸ çµ±ä¸€ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {e}")
    print("ğŸ”§ åŸºæœ¬ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã‚’ä½¿ç”¨ã—ã¾ã™")
    ERROR_HANDLER_AVAILABLE = False

# ğŸ”§ æ¡ä»¶ä»˜ãã‚¤ãƒ³ãƒãƒ¼ãƒˆ - yolopose_analyzerï¼ˆXLargeãƒ¢ãƒ‡ãƒ«ç¢ºå®Ÿä½¿ç”¨ç‰ˆï¼‰
YOLOPOSE_ANALYZER_AVAILABLE = False

try:
    from yolopose_analyzer import analyze_frames_with_tracking_enhanced
    YOLOPOSE_ANALYZER_AVAILABLE = True
    print("âœ… yolopose_analyzer ãŒåˆ©ç”¨å¯èƒ½ã§ã™")
except ImportError as e:
    print(f"âš ï¸ yolopose_analyzer ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {e}")
    YOLOPOSE_ANALYZER_AVAILABLE = False
    
    # ğŸ”§ åŸºæœ¬ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã‚¯ãƒ©ã‚¹ï¼ˆå®Œå…¨ç‰ˆï¼‰
    class BaseYOLOError(Exception):
        def __init__(self, message, details=None):
            super().__init__(message)
            self.message = message
            self.details = details or {}
    
    class ConfigurationError(BaseYOLOError):
        pass
    
    class VideoProcessingError(BaseYOLOError):
        pass
    
    # ğŸ”§ ErrorCategory ã®å®Œå…¨å®Ÿè£…
    class ErrorCategory:
        INITIALIZATION = "initialization"
        VIDEO_PROCESSING = "video_processing"
        EVALUATION = "evaluation"  # ğŸ”§ Stage 5ã‚¨ãƒ©ãƒ¼è§£æ±ºç”¨
        EXPERIMENT = "experiment"
        CONFIGURATION = "configuration"
        MODEL_LOADING = "model_loading"
        MODEL = "model"  # ğŸ”§ è¿½åŠ 
        DEPTH_PROCESSING = "depth_processing"
        PROCESSING = "processing"
        IO_OPERATIONS = "io_operations"
    
    # ğŸ”§ ErrorSeverity ã®å®Œå…¨å®Ÿè£…
    class ErrorSeverity:
        LOW = "low"
        MEDIUM = "medium"
        HIGH = "high"
        CRITICAL = "critical"
    
    # Line 89-250ä»˜è¿‘ã®ResponseBuilderã‚¯ãƒ©ã‚¹ã‚’ä»¥ä¸‹ã§å®Œå…¨ç½®æ›:

    class ResponseBuilder:
        """çµ±ä¸€ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãƒ“ãƒ«ãƒ€ãƒ¼ï¼ˆå®Œå…¨å¾Œæ–¹äº’æ›ç‰ˆï¼‰"""

        @staticmethod
        def success(data=None, message=""):
            """æˆåŠŸãƒ¬ã‚¹ãƒãƒ³ã‚¹"""
            return {"success": True, "data": data, "message": message}

        @staticmethod
        def error(
            error=None,
            include_traceback: bool = True,
            suggestions=None,
            message=None,                         # ğŸ”§ yolopose_analyzerç”¨
            details=None,                         # ğŸ”§ yolopose_analyzerç”¨
            exception=None,                       # ğŸ”§ å¾Œæ–¹äº’æ›æ€§
            **kwargs                              # ğŸ”§ å®Œå…¨äº’æ›ã®ãŸã‚
        ):
            """ã‚¨ãƒ©ãƒ¼ãƒ¬ã‚¹ãƒãƒ³ã‚¹ï¼ˆå®Œå…¨äº’æ›APIï¼‰"""
    
            # å¼•æ•°ã®æ­£è¦åŒ–ï¼ˆè¤‡æ•°ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã«å¯¾å¿œï¼‰
            target_error = error or exception
    
            if message:
                # messageãŒç›´æ¥æŒ‡å®šã•ã‚ŒãŸå ´åˆï¼ˆyolopose_analyzerç”¨ï¼‰
                response = {
                    "success": False,
                    "error": {
                        "error_type": "CustomError",
                        "message": message,
                        "category": "unknown",
                        "severity": "error",
                        "timestamp": datetime.now().isoformat()
                    }
                }
            elif hasattr(target_error, 'to_dict') and callable(getattr(target_error, 'to_dict')):
                # BaseYOLOErrorã®å ´åˆ
                response = {
                    "success": False,
                    "error": target_error.to_dict()
                }
            elif isinstance(target_error, Exception):
                # æ¨™æº–Exceptionã®å ´åˆ
                response = {
                    "success": False,
                    "error": {
                        "error_type": type(target_error).__name__,
                        "message": str(target_error),
                        "category": "unknown",
                        "severity": "error",
                        "timestamp": datetime.now().isoformat()
                    }
                }
        
                if include_traceback:
                    import traceback
                    response["error"]["traceback"] = traceback.format_exc()
            elif isinstance(target_error, str):
                # æ–‡å­—åˆ—ã‚¨ãƒ©ãƒ¼ã®å ´åˆ
                response = {
                    "success": False,
                    "error": {
                        "error_type": "StringError",
                        "message": target_error,
                        "category": "unknown", 
                        "severity": "error",
                        "timestamp": datetime.now().isoformat()
                    }
                }
            else:
                # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
                response = {
                    "success": False,
                    "error": {
                        "error_type": "UnknownError",
                        "message": "ä¸æ˜ãªã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ",
                        "category": "unknown",
                        "severity": "error",
                        "timestamp": datetime.now().isoformat()
                    }
                }
    
            # suggestionsè¿½åŠ 
            if suggestions:
                response["suggestions"] = suggestions
        
            # detailsè¿½åŠ ï¼ˆé‡è¦ï¼ï¼‰
            if details:
                response["details"] = details
        
            # ãã®ä»–ã®kwargså¯¾å¿œ
            for key, value in kwargs.items():
                if key not in response:
                    response[key] = value
        
            return response

        @staticmethod
        def validation_error(field=None, message=None, details=None, **kwargs):
            """ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã‚¨ãƒ©ãƒ¼ï¼ˆå®Œå…¨å¾Œæ–¹äº’æ›ï¼‰"""
            if message:
                error_message = message
            elif field:
                error_message = f"ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã‚¨ãƒ©ãƒ¼: {field}"
            else:
                error_message = "ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã‚¨ãƒ©ãƒ¼"
            
            response = {
                "success": False,
                "error": {
                    "error_type": "ValidationError",
                    "message": error_message,
                    "field": field,
                    "category": "validation",
                    "severity": "error",
                    "timestamp": datetime.now().isoformat()
                }
            }
        
            # detailså¼•æ•°ã®ã‚µãƒãƒ¼ãƒˆï¼ˆé‡è¦ï¼ï¼‰
            if details:
                response["details"] = details
            
            # ãã®ä»–ã®kwargså¯¾å¿œ
            for key, value in kwargs.items():
                if key not in response:
                    response[key] = value
            
            return response

        @staticmethod
        def processing_error(step=None, message=None, details=None, **kwargs):
            """å‡¦ç†ã‚¨ãƒ©ãƒ¼ï¼ˆå®Œå…¨äº’æ›ï¼‰"""
            error_message = message or f"å‡¦ç†ã‚¨ãƒ©ãƒ¼: {step}"
            result = {
                "success": False,
                "error": {
                    "error_type": "ProcessingError", 
                    "message": error_message,
                    "step": step,
                    "category": "processing",
                    "severity": "error",
                    "timestamp": datetime.now().isoformat()
               }
            }
        
            if details:
                result["details"] = details
            
            # ãã®ä»–ã®kwargså¯¾å¿œ
            for key, value in kwargs.items():
                if key not in result:
                    result[key] = value
            
            return result

        @staticmethod
        def configuration_error(config_key=None, message=None, details=None, **kwargs):
            """è¨­å®šã‚¨ãƒ©ãƒ¼ï¼ˆå®Œå…¨äº’æ›ï¼‰"""
            error_message = message or f"è¨­å®šã‚¨ãƒ©ãƒ¼: {config_key}"
            result = {
                "success": False,
                "error": {
                    "error_type": "ConfigurationError",
                    "message": error_message,
                    "config_key": config_key,
                    "category": "configuration",
                    "severity": "error",
                    "timestamp": datetime.now().isoformat()
                }
            }
        
            if details:
                result["details"] = details
            
            # ãã®ä»–ã®kwargså¯¾å¿œ
            for key, value in kwargs.items():
                if key not in result:
                    result[key] = value
            
            return result

        @staticmethod
        def model_error(model_path=None, message=None, details=None, **kwargs):
            """ãƒ¢ãƒ‡ãƒ«ã‚¨ãƒ©ãƒ¼ï¼ˆå®Œå…¨äº’æ›ï¼‰"""
            error_message = message or f"ãƒ¢ãƒ‡ãƒ«ã‚¨ãƒ©ãƒ¼: {model_path}"
            result = {
                "success": False,
                "error": {
                    "error_type": "ModelError",
                    "message": error_message,
                    "model_path": model_path,
                    "category": "model",
                    "severity": "error",
                    "timestamp": datetime.now().isoformat()
                }
            }
        
            if details:
                result["details"] = details
            
            # ãã®ä»–ã®kwargså¯¾å¿œ
            for key, value in kwargs.items():
                if key not in result:
                    result[key] = value
            
            return result
    
    class ErrorContext:
        def __init__(self, name, logger=None, raise_on_error=False):
            self.name = name
            self.logger = logger or logging.getLogger(__name__)
            self.raise_on_error = raise_on_error
            
        def __enter__(self):
            self.logger.debug(f"ğŸ” ã‚¨ãƒ©ãƒ¼ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆé–‹å§‹: {self.name}")
            return self
            
        def __exit__(self, exc_type, exc_val, exc_tb):
            if exc_type and self.logger:
                self.logger.error(f"âŒ ã‚¨ãƒ©ãƒ¼ in {self.name}: {exc_val}")
            elif self.logger:
                self.logger.debug(f"âœ… ã‚¨ãƒ©ãƒ¼ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæ­£å¸¸çµ‚äº†: {self.name}")
            return not self.raise_on_error
        
        def add_info(self, key, value):
            self.logger.debug(f"ğŸ“ {self.name} - {key}: {value}")

    class ErrorReporter:
        def __init__(self):
            self.errors = []
        
        def add_error(self, error, context=None):
            self.errors.append({"error": str(error), "context": context, "timestamp": datetime.now().isoformat()})

# ğŸ”§ æ¡ä»¶ä»˜ãã‚¤ãƒ³ãƒãƒ¼ãƒˆ - è©•ä¾¡å™¨ï¼ˆå®Œå…¨çµ±åˆç‰ˆï¼‰
EVALUATOR_AVAILABLE = False
DEPTH_EVALUATOR_AVAILABLE = False
COMPREHENSIVE_EVALUATOR_AVAILABLE = False
ComprehensiveEvaluator = None
DepthEnhancedEvaluator = None

try:
    # evaluatorsãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®æ®µéšçš„ãƒã‚§ãƒƒã‚¯
    import evaluators
    print("âœ… evaluators ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸ")
    
    try:
        from evaluators.comprehensive_evaluator import ComprehensiveEvaluator
        COMPREHENSIVE_EVALUATOR_AVAILABLE = True
        EVALUATOR_AVAILABLE = True
        print("âœ… ComprehensiveEvaluator ãŒåˆ©ç”¨å¯èƒ½ã§ã™")
        
        try:
            from evaluators.comprehensive_evaluator import DepthEnhancedEvaluator
            DEPTH_EVALUATOR_AVAILABLE = True
            print("âœ… DepthEnhancedEvaluator ãŒåˆ©ç”¨å¯èƒ½ã§ã™")
        except (ImportError, AttributeError) as e:
            print(f"âš ï¸ DepthEnhancedEvaluator ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“: {e}")
            DEPTH_EVALUATOR_AVAILABLE = False
            
    except ImportError as e:
        print(f"âš ï¸ ComprehensiveEvaluator ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆã«å¤±æ•—: {e}")
        COMPREHENSIVE_EVALUATOR_AVAILABLE = False
        EVALUATOR_AVAILABLE = False
        
except ImportError as e:
    print(f"âš ï¸ evaluators ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {e}")
    EVALUATOR_AVAILABLE = False
    COMPREHENSIVE_EVALUATOR_AVAILABLE = False
    DEPTH_EVALUATOR_AVAILABLE = False

# ğŸ”§ æ¡ä»¶ä»˜ãã‚¤ãƒ³ãƒãƒ¼ãƒˆ - è¨­å®šç®¡ç†ï¼ˆå®Œå…¨çµ±åˆç‰ˆï¼‰
CONFIG_AVAILABLE = False
Config = None

try:
    from utils.config import Config
    CONFIG_AVAILABLE = True
    print("âœ… Config ãŒåˆ©ç”¨å¯èƒ½ã§ã™")
except ImportError as e:
    print(f"âš ï¸ Config ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {e}")
    print("ğŸ”§ åŸºæœ¬è¨­å®šæ©Ÿèƒ½ã‚’ä½¿ç”¨ã—ã¾ã™")
    CONFIG_AVAILABLE = False

# ğŸ”§ BasicEvaluatorï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”¨ãƒ»å®Œå…¨ç‰ˆï¼‰
if not EVALUATOR_AVAILABLE:
    print("ğŸ”§ åŸºæœ¬è©•ä¾¡æ©Ÿèƒ½ã‚’ä½¿ç”¨ã—ã¾ã™")
    
    class BasicEvaluator:
        def __init__(self, config=None):
            self.config = config or {}
            self.results = {}
            self.logger = logging.getLogger(__name__)
        
        def evaluate_comprehensive(self, video_path, detection_results, video_name):
            """åŸºæœ¬çš„ãªè©•ä¾¡ï¼ˆå®Œå…¨ç‰ˆï¼‰"""
            try:
                self.logger.info(f"ğŸ” åŸºæœ¬è©•ä¾¡é–‹å§‹: {video_name}")
                
                # ãƒ‡ãƒ¼ã‚¿æŠ½å‡ºã®æ”¹å–„
                if isinstance(detection_results, dict):
                    if detection_results.get("success", False):
                        data = detection_results.get("data", {})
                    else:
                        self.logger.warning("detection_results ãŒå¤±æ•—çŠ¶æ…‹ã§ã™")
                        data = {}
                else:
                    data = {}
                
                csv_path = data.get("csv_path") or data.get("enhanced_csv_path")
                
                basic_metrics = {
                    "video_name": video_name,
                    "video_path": str(video_path),
                    "detection_count": data.get("detection_count", 0),
                    "frame_count": data.get("frame_count", 0),
                    "processing_time": data.get("processing_time", 0),
                    "timestamp": datetime.now().isoformat(),
                    "evaluator_type": "BasicEvaluator",
                    "depth_enabled": data.get("depth_enabled", False),
                    "processing_stats": data.get("processing_stats", {})
                }
                
                # CSVãƒ•ã‚¡ã‚¤ãƒ«åˆ†æã®æ”¹å–„
                if csv_path and Path(csv_path).exists():
                    try:
                        df = pd.read_csv(csv_path)
                        self.logger.info(f"ğŸ“Š CSVåˆ†æ: {len(df)}è¡Œã®ãƒ‡ãƒ¼ã‚¿")
                        
                        csv_metrics = {
                            "total_detections": len(df),
                            "detection_success": True,
                            "csv_path": str(csv_path)
                        }
                        
                        # ã‚«ãƒ©ãƒ ãƒ™ãƒ¼ã‚¹ã®è©³ç´°åˆ†æ
                        available_columns = df.columns.tolist()
                        csv_metrics["available_columns"] = available_columns
                        
                        if 'track_id' in df.columns:
                            csv_metrics["unique_track_ids"] = df['track_id'].nunique()
                        
                        if 'confidence' in df.columns:
                            csv_metrics["confidence_mean"] = float(df['confidence'].mean())
                            csv_metrics["confidence_std"] = float(df['confidence'].std())
                            csv_metrics["confidence_min"] = float(df['confidence'].min())
                            csv_metrics["confidence_max"] = float(df['confidence'].max())
                        
                        # æ·±åº¦é–¢é€£ã‚«ãƒ©ãƒ ã®è©³ç´°ç¢ºèª
                        depth_columns = [col for col in df.columns if 'depth' in col.lower()]
                        if depth_columns:
                            csv_metrics["depth_columns"] = depth_columns
                            csv_metrics["depth_analysis_available"] = True
                            # æ·±åº¦ãƒ‡ãƒ¼ã‚¿ã®çµ±è¨ˆ
                            for depth_col in depth_columns:
                                if df[depth_col].dtype in ['float64', 'int64']:
                                    csv_metrics[f"{depth_col}_mean"] = float(df[depth_col].mean())
                        
                        basic_metrics.update(csv_metrics)
                        
                    except Exception as e:
                        self.logger.warning(f"CSVåˆ†æã‚¨ãƒ©ãƒ¼: {e}")
                        basic_metrics.update({
                            "detection_success": False,
                            "csv_error": str(e),
                            "csv_path": str(csv_path) if csv_path else None
                        })
                else:
                    self.logger.warning(f"CSV ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {csv_path}")
                    basic_metrics["csv_available"] = False
                
                self.logger.info(f"âœ… åŸºæœ¬è©•ä¾¡å®Œäº†: {video_name}")
                return ResponseBuilder.success(data=basic_metrics)
                
            except Exception as e:
                self.logger.error(f"âŒ åŸºæœ¬è©•ä¾¡ã‚¨ãƒ©ãƒ¼: {e}")
                return ResponseBuilder.error(e, suggestions=[
                    "è©•ä¾¡ãƒ‡ãƒ¼ã‚¿ã®å½¢å¼ã‚’ç¢ºèªã—ã¦ãã ã•ã„",
                    "CSVãƒ•ã‚¡ã‚¤ãƒ«ãŒæ­£ã—ãç”Ÿæˆã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„",
                    "å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ã®å‹ã‚’ç¢ºèªã—ã¦ãã ã•ã„"
                ])
        
        def evaluate_with_depth(self, video_path, detection_results, video_name):
            """æ·±åº¦å¯¾å¿œè©•ä¾¡ï¼ˆBasicEvaluatorç‰ˆï¼‰"""
            self.logger.info(f"ğŸ” æ·±åº¦å¯¾å¿œåŸºæœ¬è©•ä¾¡: {video_name}")
            result = self.evaluate_comprehensive(video_path, detection_results, video_name)
            
            if result.get("success", False):
                result["data"]["depth_evaluator_type"] = "BasicEvaluator"
                result["data"]["depth_support"] = "limited"
            
            return result

# ğŸ”§ æ¡ä»¶ä»˜ãã‚¤ãƒ³ãƒãƒ¼ãƒˆ - ãƒ—ãƒ­ã‚»ãƒƒã‚µãƒ¼ï¼ˆå®Œå…¨çµ±åˆç‰ˆï¼‰
VIDEO_PROCESSOR_AVAILABLE = False
VideoProcessor = None

try:
    from processors.video_processor import VideoProcessor
    VIDEO_PROCESSOR_AVAILABLE = True
    print("âœ… VideoProcessor ãŒåˆ©ç”¨å¯èƒ½ã§ã™")
except ImportError as e:
    print(f"âš ï¸ VideoProcessor ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {e}")
    print("ğŸ”§ åŸºæœ¬å‹•ç”»å‡¦ç†ã‚’ä½¿ç”¨ã—ã¾ã™")
    VIDEO_PROCESSOR_AVAILABLE = False

# ğŸ”§ BasicVideoProcessorï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”¨ãƒ»å®Œå…¨ç‰ˆï¼‰
if not VIDEO_PROCESSOR_AVAILABLE:
    class BasicVideoProcessor:
        def __init__(self, config):
            """åŸºæœ¬å‹•ç”»ãƒ—ãƒ­ã‚»ãƒƒã‚µãƒ¼åˆæœŸåŒ–ï¼ˆå®Œå…¨ç‰ˆï¼‰"""
            self.config = config
            self.logger = logging.getLogger(__name__)
            self.processing_stats = {}  # ğŸ”§ çµ±è¨ˆæƒ…å ±è¾æ›¸ã‚’åˆæœŸåŒ–
    
            if hasattr(config, 'get'):
                self.output_dir = Path(config.get('output_dir', 'outputs'))
                self.max_frames = config.get('processing.max_frames', 100)
            else:
                self.output_dir = Path('outputs')
                self.max_frames = 100
    
            self.output_dir.mkdir(exist_ok=True)
            self.logger.info(f"ğŸ¬ åŸºæœ¬å‹•ç”»ãƒ—ãƒ­ã‚»ãƒƒã‚µãƒ¼åˆæœŸåŒ–å®Œäº†")
        
        def load_models(self):
            """ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰ï¼ˆãƒ‘ã‚¹é‡è¤‡ä¿®æ­£ç‰ˆï¼‰"""
            try:
                if hasattr(self.config, 'get'):
                    models_config = self.config.get('models', {})
                elif isinstance(self.config, dict):
                    models_config = self.config.get('models', {})
                else:
                    models_config = {}
                
                # âš¡ ãƒ‘ã‚¹é‡è¤‡ã‚’é˜²ãä¿®æ­£
                detection_path = models_config.get('detection', 'models/yolo11x.pt')
                pose_path = models_config.get('pose', 'models/yolo11x-pose.pt')
                
                # ãƒ‘ã‚¹é‡è¤‡ãƒã‚§ãƒƒã‚¯
                if detection_path.startswith('models/models/'):
                    detection_path = detection_path.replace('models/models/', 'models/')
                if pose_path.startswith('models/models/'):
                    pose_path = pose_path.replace('models/models/', 'models/')
                
                self.logger.info(f"ğŸ” ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰é–‹å§‹")
                self.logger.info(f"ğŸ“Š æ¤œå‡ºãƒ¢ãƒ‡ãƒ«ãƒ‘ã‚¹: {detection_path}")
                self.logger.info(f"ğŸ“Š ãƒãƒ¼ã‚ºãƒ¢ãƒ‡ãƒ«ãƒ‘ã‚¹: {pose_path}")
                
                # æ¤œå‡ºãƒ¢ãƒ‡ãƒ«
                if Path(detection_path).exists():
                    self.detection_model = YOLO(detection_path)
                    self.logger.info(f"âœ… æ¤œå‡ºãƒ¢ãƒ‡ãƒ«: {detection_path}")
                else:
                    self.logger.warning(f"âš ï¸ æ¤œå‡ºãƒ¢ãƒ‡ãƒ«æœªç™ºè¦‹: {detection_path}")
                    # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: è‡ªå‹•ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
                    self.detection_model = YOLO('yolo11x.pt')
                    self.logger.info("âœ… æ¤œå‡ºãƒ¢ãƒ‡ãƒ«: è‡ªå‹•ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰")

                # ãƒãƒ¼ã‚ºãƒ¢ãƒ‡ãƒ«
                if Path(pose_path).exists():
                    self.pose_model = YOLO(pose_path)
                    self.logger.info(f"âœ… ãƒãƒ¼ã‚ºãƒ¢ãƒ‡ãƒ«: {pose_path}")
                else:
                    self.logger.warning(f"âš ï¸ ãƒãƒ¼ã‚ºãƒ¢ãƒ‡ãƒ«æœªç™ºè¦‹: {pose_path}")
                    # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: è‡ªå‹•ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
                    self.pose_model = YOLO('yolo11x-pose.pt')
                    self.logger.info("âœ… ãƒãƒ¼ã‚ºãƒ¢ãƒ‡ãƒ«: è‡ªå‹•ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰")
                
                self.logger.info("âœ… å…¨ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰å®Œäº†")
                
            except Exception as e:
                self.logger.error(f"âŒ ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼: {e}")
                raise
        
        # BasicVideoProcessor ã® extract_frames ãƒ¡ã‚½ãƒƒãƒ‰ã‚’ä¿®æ­£:

        def extract_frames(self, video_path, frame_dir, max_frames=1000):
            """ãƒ•ãƒ¬ãƒ¼ãƒ æŠ½å‡ºï¼ˆçµ±è¨ˆä¿®æ­£ç‰ˆï¼‰"""
            try:
                # ğŸ”§ processing_statsã®ç¢ºå®ŸãªåˆæœŸåŒ–
                if not hasattr(self, 'processing_stats'):
                    self.processing_stats = {}
            
                self.logger.info(f"ğŸ“¸ ãƒ•ãƒ¬ãƒ¼ãƒ æŠ½å‡ºé–‹å§‹: {video_path}")
                frame_dir = Path(frame_dir)
                frame_dir.mkdir(parents=True, exist_ok=True)

                # å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã®å­˜åœ¨ç¢ºèª
                if not Path(video_path).exists():
                    self.logger.error(f"âŒ å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ã¾ã›ã‚“: {video_path}")
                    return {"success": False, "error": f"å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ã¾ã›ã‚“: {video_path}"}

                # ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºãƒã‚§ãƒƒã‚¯
                file_size = Path(video_path).stat().st_size
                if file_size == 0:
                    self.logger.error(f"âŒ å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ãŒç©ºã§ã™: {video_path}")
                    return {"success": False, "error": f"å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ãŒç©ºã§ã™: {video_path}"}

                self.logger.info(f"ğŸ“¹ å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: {file_size / (1024*1024):.1f}MB")

                # ğŸ”§ OpenCVã§ãƒ•ãƒ¬ãƒ¼ãƒ æŠ½å‡º
                cap = cv2.VideoCapture(str(video_path))
                if not cap.isOpened():
                    self.logger.error(f"âŒ å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é–‹ã‘ã¾ã›ã‚“: {video_path}")
                    return {"success": False, "error": f"å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é–‹ã‘ã¾ã›ã‚“: {video_path}"}

                # å‹•ç”»æƒ…å ±å–å¾—
                frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
                fps = cap.get(cv2.CAP_PROP_FPS)
                width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
                height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
                duration = frame_count / fps if fps > 0 else 0

                self.logger.info(f"ğŸ“¹ å‹•ç”»æƒ…å ±: {width}x{height}, {frame_count}ãƒ•ãƒ¬ãƒ¼ãƒ , {fps:.1f}FPS, {duration:.1f}ç§’")

                # ãƒ•ãƒ¬ãƒ¼ãƒ æ•°ãŒ0ã®å ´åˆã®ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°
                if frame_count <= 0:
                    cap.release()
                    self.logger.error(f"âŒ æœ‰åŠ¹ãªãƒ•ãƒ¬ãƒ¼ãƒ ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {video_path}")
                    return {"success": False, "error": "æœ‰åŠ¹ãªãƒ•ãƒ¬ãƒ¼ãƒ ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“"}

                # æŠ½å‡ºé–“éš”è¨ˆç®—
                interval = max(1, frame_count // max_frames)
                self.logger.info(f"ğŸ”¢ æŠ½å‡ºé–“éš”: {interval} (æœ€å¤§{max_frames}ãƒ•ãƒ¬ãƒ¼ãƒ )")

                # ãƒ•ãƒ¬ãƒ¼ãƒ æŠ½å‡ºãƒ«ãƒ¼ãƒ—
                extracted = 0
                frame_number = 0

                while True:
                    ret, frame = cap.read()
                    if not ret:
                        break

                    if frame_number % interval == 0:
                        frame_path = frame_dir / f"frame_{frame_number:06d}.jpg"
                        success = cv2.imwrite(str(frame_path), frame)

                        if success:
                            extracted += 1
                            if extracted >= max_frames:
                                break
                        else:
                            self.logger.warning(f"âš ï¸ ãƒ•ãƒ¬ãƒ¼ãƒ ä¿å­˜å¤±æ•—: {frame_path}")
            
                    frame_number += 1

                cap.release()

                # ğŸ”§ å®Ÿéš›ã«ä¿å­˜ã•ã‚ŒãŸãƒ•ãƒ¬ãƒ¼ãƒ æ•°ã‚’å†ç¢ºèªï¼ˆé‡è¦ï¼ï¼‰
                saved_frames = len(list(frame_dir.glob("frame_*.jpg")))
                self.logger.info(f"ğŸ“Š OpenCVã§æŠ½å‡º: {extracted}å€‹")
                self.logger.info(f"ğŸ“Š å®Ÿéš›ã«ä¿å­˜: {saved_frames}å€‹")

                # ğŸ”§ æœ€å¤§å€¤ã‚’æ¡ç”¨ï¼ˆç¢ºå®Ÿã«ãƒ•ãƒ¬ãƒ¼ãƒ æ•°ã‚’å–å¾—ï¼‰
                final_extracted = max(extracted, saved_frames)

                # çµ±è¨ˆæƒ…å ±ã®æ›´æ–°
                self.processing_stats["frame_extraction"] = {
                    "total_frames": frame_count,
                    "extracted_frames": final_extracted,  # â† ç¢ºå®Ÿãªå€¤
                    "video_fps": fps,
                    "video_duration": duration,
                    "resolution": [width, height],
                    "extraction_interval": interval
                }

                self.logger.info(f"âœ… ãƒ•ãƒ¬ãƒ¼ãƒ æŠ½å‡ºå®Œäº†: {final_extracted}ãƒ•ãƒ¬ãƒ¼ãƒ ")

                if final_extracted == 0:
                    self.logger.error("âŒ ãƒ•ãƒ¬ãƒ¼ãƒ æŠ½å‡ºã«å¤±æ•—ã—ã¾ã—ãŸ")
                    return {"success": False, "error": "ãƒ•ãƒ¬ãƒ¼ãƒ æŠ½å‡ºã«å¤±æ•—ã—ã¾ã—ãŸ"}

                # ğŸ”§ ç¢ºå®Ÿã«extracted_framesã‚’è¿”ã™
                return {
                    "success": True, 
                    "extracted_frames": final_extracted,  # â† é‡è¦ï¼šã“ã®å€¤ãŒ0ã«ãªã£ã¦ã¯ã„ã‘ãªã„
                    "video_info": self.processing_stats["frame_extraction"]
                }

            except Exception as e:
                self.logger.error(f"âŒ ãƒ•ãƒ¬ãƒ¼ãƒ æŠ½å‡ºã‚¨ãƒ©ãƒ¼: {e}")
                return {"success": False, "error": str(e)}
        
        def run_detection_tracking(self, frame_dir, video_name):
            """åŸºæœ¬æ¤œå‡ºãƒ»è¿½è·¡å‡¦ç†ï¼ˆå®‰å®šåŒ–ç‰ˆï¼‰"""
            try:
                self.logger.info(f"ğŸ‘ï¸ åŸºæœ¬æ¤œå‡ºãƒ»è¿½è·¡å‡¦ç†é–‹å§‹: {video_name}")
                frame_files = sorted(list(Path(frame_dir).glob("*.jpg")))
        
                if not frame_files:
                    raise VideoProcessingError(f"ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {frame_dir}")
        
                self.logger.info(f"ğŸ“¸ å‡¦ç†å¯¾è±¡ãƒ•ãƒ¬ãƒ¼ãƒ : {len(frame_files)}å€‹")
        
                # ãƒ¢ãƒ‡ãƒ«ã®äº‹å‰ãƒ­ãƒ¼ãƒ‰ç¢ºèª
                if not hasattr(self, 'detection_model') and not hasattr(self, 'pose_model'):
                    self.load_models()
        
                detection_count = 0
                frame_stats = []
        
                # ä¿¡é ¼åº¦ã—ãã„å€¤ï¼ˆã‚ˆã‚Šä½ãè¨­å®šã—ã¦æ¤œå‡ºç‡å‘ä¸Šï¼‰
                conf_threshold = 0.25
        
                # ğŸ”§ ç°¡ç•¥åŒ–ã•ã‚ŒãŸå‡¦ç†ãƒ«ãƒ¼ãƒ—
                for i, frame_file in enumerate(frame_files):
                    try:
                        # ãƒ•ãƒ¬ãƒ¼ãƒ èª­ã¿è¾¼ã¿
                        frame = cv2.imread(str(frame_file))
                        if frame is None:
                            self.logger.warning(f"âš ï¸ ãƒ•ãƒ¬ãƒ¼ãƒ èª­ã¿è¾¼ã¿å¤±æ•—: {frame_file}")
                            continue
                
                        frame_detections = 0
                
                        # ğŸ”§ ãƒãƒ¼ã‚ºãƒ¢ãƒ‡ãƒ«å„ªå…ˆï¼ˆã‚ˆã‚Šç¢ºå®Ÿï¼‰
                        if hasattr(self, 'pose_model') and self.pose_model:
                            try:
                                results = self.pose_model(frame, verbose=False, conf=conf_threshold)
                                if results and len(results[0].boxes) > 0:
                                    frame_detections = len(results[0].boxes)
                                    detection_count += frame_detections
                            except Exception as e:
                                self.logger.debug(f"ãƒ•ãƒ¬ãƒ¼ãƒ {i}ãƒãƒ¼ã‚ºæ¤œå‡ºã‚¨ãƒ©ãƒ¼: {e}")
                
                        # ãƒ•ãƒ¬ãƒ¼ãƒ çµ±è¨ˆè¨˜éŒ²ï¼ˆç°¡ç•¥åŒ–ï¼‰
                        frame_stats.append({
                            "frame_id": i,
                            "frame_file": frame_file.name,
                            "detections": frame_detections,
                            "conf": conf_threshold,  # å›ºå®šå€¤
                            "track_id": i,  # ç°¡æ˜“ID
                            "timestamp": datetime.now().isoformat()
                        })
                
                    except Exception as e:
                        self.logger.warning(f"ãƒ•ãƒ¬ãƒ¼ãƒ {i}å‡¦ç†ã‚¨ãƒ©ãƒ¼ï¼ˆç¶šè¡Œï¼‰: {e}")
                        continue
        
                # çµæœCSVä½œæˆ
                output_dir = Path("outputs/temp") / video_name
                output_dir.mkdir(parents=True, exist_ok=True)
                csv_path = output_dir / f"{video_name}_results.csv"
        
                if frame_stats:
                    df = pd.DataFrame(frame_stats)
                    df.to_csv(csv_path, index=False)
                    self.logger.info(f"ğŸ“Š çµæœCSVä¿å­˜: {csv_path}")
                else:
                    # ğŸ”§ ç©ºã®å ´åˆã§ã‚‚CSVã‚’ä½œæˆ
                    empty_df = pd.DataFrame(columns=["frame_id", "frame_file", "detections", "conf", "track_id", "timestamp"])
                    empty_df.to_csv(csv_path, index=False)
                    self.logger.warning("âš ï¸ æ¤œå‡ºçµæœãªã— - ç©ºã®CSVã‚’ä½œæˆ")
        
                # çµ±è¨ˆæƒ…å ±
                self.processing_stats = {
                    "detection_tracking": {
                        "total_frames": len(frame_files),
                        "processed_frames": len(frame_stats),
                        "total_detections": detection_count,
                        "success_rate": len(frame_stats) / len(frame_files) if frame_files else 0
                    }
                }
        
                self.logger.info(f"âœ… åŸºæœ¬æ¤œå‡ºãƒ»è¿½è·¡å®Œäº†: {detection_count}å€‹æ¤œå‡º / {len(frame_stats)}ãƒ•ãƒ¬ãƒ¼ãƒ å‡¦ç†")
        
                return {
                    "success": True,
                    "data": {
                        "csv_path": str(csv_path),
                        "detection_count": detection_count,
                        "frame_count": len(frame_files),
                        "processed_frames": len(frame_stats),
                        "processing_stats": self.processing_stats["detection_tracking"]
                    }
                }
        
            except Exception as e:
                self.logger.error(f"âŒ åŸºæœ¬æ¤œå‡ºãƒ»è¿½è·¡ã‚¨ãƒ©ãƒ¼: {e}")
                return {"success": False, "error": str(e)}
        
        def run_detection_tracking_with_depth(self, frame_dir, video_name):
            """æ·±åº¦çµ±åˆæ¤œå‡ºãƒ»è¿½è·¡å‡¦ç†ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç‰ˆï¼‰"""
            self.logger.warning("ğŸ”§ æ·±åº¦çµ±åˆå‡¦ç†ã¯åˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚é€šå¸¸å‡¦ç†ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã—ã¾ã™")
            result = self.run_detection_tracking(frame_dir, video_name)
            
            if result.get("success", False):
                result["data"]["depth_enabled"] = False
                result["data"]["depth_fallback"] = True
                result["data"]["enhanced_csv_path"] = result["data"]["csv_path"]
                self.logger.info("âœ… ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç†å®Œäº†ï¼ˆæ·±åº¦æ©Ÿèƒ½ç„¡åŠ¹ï¼‰")
            
            return result

# ğŸ”§ æ¡ä»¶ä»˜ãã‚¤ãƒ³ãƒãƒ¼ãƒˆ - ã‚¢ãƒŠãƒ©ã‚¤ã‚¶ãƒ¼ï¼ˆå®Œå…¨çµ±åˆç‰ˆï¼‰
METRICS_ANALYZER_AVAILABLE = False
MetricsAnalyzer = None

try:
    from analyzers.metrics_analyzer import MetricsAnalyzer
    METRICS_ANALYZER_AVAILABLE = True
    print("âœ… MetricsAnalyzer ãŒåˆ©ç”¨å¯èƒ½ã§ã™")
except ImportError as e:
    print(f"âš ï¸ MetricsAnalyzer ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {e}")
    print("ğŸ”§ åŸºæœ¬åˆ†ææ©Ÿèƒ½ã‚’ä½¿ç”¨ã—ã¾ã™")
    METRICS_ANALYZER_AVAILABLE = False

# ğŸ”§ BasicMetricsAnalyzerï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”¨ãƒ»å®Œå…¨ç‰ˆï¼‰
if not METRICS_ANALYZER_AVAILABLE:
    class BasicMetricsAnalyzer:
        def __init__(self, config):
            self.config = config
            self.logger = logging.getLogger(__name__)
        
        def analyze_improvements(self, comparison_results):
            """åŸºæœ¬æ”¹å–„åˆ†æï¼ˆå®Œå…¨ç‰ˆï¼‰"""
            self.logger.info("ğŸ“Š åŸºæœ¬æ”¹å–„åˆ†æé–‹å§‹")
            
            try:
                baseline = comparison_results.get("baseline", {})
                experiment = comparison_results.get("experiment", {})
                
                analysis = {
                    "analyzer_type": "BasicMetricsAnalyzer",
                    "comparison_available": bool(baseline and experiment),
                    "timestamp": datetime.now().isoformat()
                }
                
                if baseline and experiment:
                    # å‡¦ç†æ™‚é–“æ¯”è¼ƒ
                    baseline_time = baseline.get("processing_time", 0)
                    experiment_time = experiment.get("processing_time", 0)
                    
                    if baseline_time > 0:
                        time_improvement = ((baseline_time - experiment_time) / baseline_time) * 100
                        analysis["time_improvement_percent"] = time_improvement
                        analysis["time_comparison"] = {
                            "baseline_time": baseline_time,
                            "experiment_time": experiment_time,
                            "improvement": time_improvement
                        }
                    
                    # æ¤œå‡ºæ•°æ¯”è¼ƒ
                    baseline_detections = baseline.get("detection_count", 0)
                    experiment_detections = experiment.get("detection_count", 0)
                    
                    analysis["detection_comparison"] = {
                        "baseline": baseline_detections,
                        "experiment": experiment_detections,
                        "difference": experiment_detections - baseline_detections,
                        "improvement_rate": ((experiment_detections - baseline_detections) / baseline_detections * 100) if baseline_detections > 0 else 0
                    }
                    
                    # å“è³ªæ¯”è¼ƒ
                    analysis["quality_comparison"] = {
                        "baseline_success": baseline.get("success", False),
                        "experiment_success": experiment.get("success", False)
                    }
                
                self.logger.info("âœ… åŸºæœ¬æ”¹å–„åˆ†æå®Œäº†")
                return analysis
                
            except Exception as e:
                self.logger.error(f"âŒ æ”¹å–„åˆ†æã‚¨ãƒ©ãƒ¼: {e}")
                return {"basic_analysis": f"ã‚¨ãƒ©ãƒ¼: {e}", "error": True}
        
        # Line 845ä»˜è¿‘ã® create_visualizations ãƒ¡ã‚½ãƒƒãƒ‰ã‚’å®Œå…¨ç½®æ›:

        # Line 874ä»˜è¿‘ã®create_visualizationsãƒ¡ã‚½ãƒƒãƒ‰ã‚’ä»¥ä¸‹ã§å®Œå…¨ç½®æ›:

        def create_visualizations(self, detection_results, vis_dir):
            """åŸºæœ¬å¯è¦–åŒ–ï¼ˆæ—¥æ™‚ä»˜ããƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå¯¾å¿œç‰ˆï¼‰"""
            self.logger.info(f"ğŸ“ˆ åŸºæœ¬å¯è¦–åŒ–ç”Ÿæˆ: {vis_dir}")

            # ğŸ”§ å¿…ãšæˆ»ã‚Šå€¤ã‚’è¿”ã™ã‚ˆã†ã«ã™ã‚‹ï¼ˆåˆæœŸåŒ–ï¼‰
            result = {
                "success": False,
                "error": "åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼",
                "basic_stats_file": None,
                "graphs_generated": 0,
                "total_files": 0
            }

            try:
                from pathlib import Path
                import json
                from datetime import datetime

                # ğŸ”§ ä¿®æ­£: vis_dir ãŒã™ã§ã«ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ä»˜ãã®å ´åˆã¯ãã®ã¾ã¾ä½¿ç”¨
                vis_path = Path(str(vis_dir))
        
                # ğŸ”§ è¿½åŠ : ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ãŒå«ã¾ã‚Œã¦ã„ãªã„å ´åˆã®ã¿è¿½åŠ 
                if not any(char.isdigit() for char in vis_path.name[-15:]):  # æœ«å°¾15æ–‡å­—ã«æ•°å­—ãŒå«ã¾ã‚Œã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
                    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                    vis_path = vis_path.parent / f"{vis_path.name}_{timestamp}"
        
                vis_path.mkdir(parents=True, exist_ok=True)
                self.logger.info(f"ğŸ“ æ—¥æ™‚ä»˜ãå¯è¦–åŒ–ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ: {vis_path}")

                # detection_results ã®è©³ç´°ãƒ­ã‚°
                self.logger.info(f"ğŸ”§ detection_results type: {type(detection_results)}")
                self.logger.info(f"ğŸ”§ detection_results content: {detection_results}")

                # CSVãƒ‘ã‚¹æŠ½å‡º
                csv_path = None
                data = {}

                if isinstance(detection_results, dict):
                    if detection_results.get("success", False):
                        data = detection_results.get("data", {})
                        csv_path = data.get("csv_path")

                        # ãƒã‚¹ãƒˆæ§‹é€ å¯¾å¿œ
                        if not csv_path and "detection_result" in data:
                            nested_data = data["detection_result"].get("data", {})
                            csv_path = nested_data.get("csv_path")
        
                self.logger.info(f"ğŸ”§ æ¤œå‡ºã•ã‚ŒãŸCSVãƒ‘ã‚¹: {csv_path}")

                # åŸºæœ¬çµ±è¨ˆãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆï¼ˆå¿…ãšä½œæˆï¼‰
                stats_file = vis_path / "basic_stats.json"
                basic_stats = {
                    "visualization_type": "BasicVisualization",
                    "detection_count": data.get("detection_count", 0),
                    "frame_count": data.get("frame_count", 0),
                    "processing_time": data.get("processing_time", 0),
                    "processing_stats": data.get("processing_stats", {}),
                    "timestamp": datetime.now().isoformat(),
                    "csv_path": str(csv_path) if csv_path else None,
                    "success": detection_results.get("success", False) if isinstance(detection_results, dict) else False
                }

                with open(stats_file, 'w', encoding='utf-8') as f:
                    json.dump(basic_stats, f, indent=2, ensure_ascii=False)
                self.logger.info(f"âœ… åŸºæœ¬çµ±è¨ˆä¿å­˜: {stats_file}")

                # æˆ»ã‚Šå€¤æ›´æ–°ï¼ˆé‡è¦ï¼ï¼‰
                result.update({
                    "success": True,
                    "error": None,
                    "basic_stats_file": str(stats_file),
                    "total_files": 1,
                    "graphs_generated": 0
                })

                # çµ±è¨ˆã‚°ãƒ©ãƒ•ç”Ÿæˆï¼ˆæ—¢å­˜ã®ã‚³ãƒ¼ãƒ‰ï¼‰
                graphs_generated = 0

                try:
                    # matplotlib/pandas ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
                    import matplotlib
                    matplotlib.use('Agg')
                    import matplotlib.pyplot as plt
                    import pandas as pd
    
                    # ç°¡æ˜“ãƒ•ã‚©ãƒ³ãƒˆè¨­å®š
                    try:
                        plt.rcParams['font.family'] = ['Hiragino Sans', 'DejaVu Sans']
                    except:
                        plt.rcParams['font.family'] = 'DejaVu Sans'
    
                    # CSV ãƒ•ã‚¡ã‚¤ãƒ«ã®å‡¦ç†
                    if csv_path and Path(csv_path).exists():
                        self.logger.info(f"ğŸ“Š CSVãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿: {csv_path}")
                        df = pd.read_csv(csv_path)
                        self.logger.info(f"ğŸ“Š ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿: {len(df)}è¡Œ, ã‚«ãƒ©ãƒ : {list(df.columns)}")
        
                        if not df.empty:
                            # 1. ãƒ•ãƒ¬ãƒ¼ãƒ åˆ¥æ¤œå‡ºæ•°ã‚°ãƒ©ãƒ•
                            if 'frame' in df.columns or 'frame_id' in df.columns:
                                try:
                                    frame_col = 'frame' if 'frame' in df.columns else 'frame_id'
                                    plt.figure(figsize=(12, 6))
                                    frame_counts = df[frame_col].value_counts().sort_index()
                                    plt.plot(frame_counts.index, frame_counts.values, 
                                    marker='o', linewidth=2, markersize=4, color='blue')
                                    plt.title('Detection Count by Frame', fontsize=16, pad=20)
                                    plt.xlabel('Frame Number', fontsize=12)
                                    plt.ylabel('Detection Count', fontsize=12)
                                    plt.grid(True, alpha=0.3)
                                    plt.tight_layout()
                    
                                    timeline_path = vis_path / "detection_timeline.png"
                                    plt.savefig(timeline_path, dpi=300, bbox_inches='tight')
                                    plt.close()
                                    graphs_generated += 1
                                    self.logger.info(f"âœ… æ™‚ç³»åˆ—ã‚°ãƒ©ãƒ•ç”Ÿæˆ: {timeline_path}")
                                except Exception as e:
                                    self.logger.error(f"âŒ æ™‚ç³»åˆ—ã‚°ãƒ©ãƒ•ã‚¨ãƒ©ãƒ¼: {e}")
            
                            # 2. ä¿¡é ¼åº¦åˆ†å¸ƒã‚°ãƒ©ãƒ•
                            if 'conf' in df.columns or 'confidence' in df.columns:
                                try:
                                    conf_col = 'conf' if 'conf' in df.columns else 'confidence'
                                    plt.figure(figsize=(10, 6))
                                    conf_data = df[conf_col].dropna()
                                    plt.hist(conf_data, bins=30, alpha=0.7, color='green', edgecolor='black')
                                    plt.axvline(conf_data.mean(), color='red', linestyle='--', 
                                        label=f'Average: {conf_data.mean():.3f}')
                                    plt.title('Confidence Distribution', fontsize=16, pad=20)
                                    plt.xlabel('Confidence', fontsize=12)
                                    plt.ylabel('Frequency', fontsize=12)
                                    plt.legend()
                                    plt.grid(True, alpha=0.3)
                                    plt.tight_layout()
                    
                                    conf_path = vis_path / "confidence_distribution.png"
                                    plt.savefig(conf_path, dpi=300, bbox_inches='tight')
                                    plt.close()
                                    graphs_generated += 1
                                    self.logger.info(f"âœ… ä¿¡é ¼åº¦åˆ†å¸ƒã‚°ãƒ©ãƒ•ç”Ÿæˆ: {conf_path}")
                                except Exception as e:
                                    self.logger.error(f"âŒ ä¿¡é ¼åº¦åˆ†å¸ƒã‚°ãƒ©ãƒ•ã‚¨ãƒ©ãƒ¼: {e}")
            
                            # 3. ã‚¯ãƒ©ã‚¹åˆ†å¸ƒã‚°ãƒ©ãƒ•
                            if 'class_name' in df.columns:
                                try:
                                    plt.figure(figsize=(12, 8))
                                    class_counts = df['class_name'].value_counts()
                                    class_counts.plot(kind='bar', color='skyblue', edgecolor='black')
                                    plt.title('Class Distribution', fontsize=16, pad=20)
                                    plt.xlabel('Class Name', fontsize=12)
                                    plt.ylabel('Detection Count', fontsize=12)
                                    plt.xticks(rotation=45)
                                    plt.tight_layout()
                    
                                    class_path = vis_path / "class_distribution.png"
                                    plt.savefig(class_path, dpi=300, bbox_inches='tight')
                                    plt.close()
                                    graphs_generated += 1
                                    self.logger.info(f"âœ… ã‚¯ãƒ©ã‚¹åˆ†å¸ƒã‚°ãƒ©ãƒ•ç”Ÿæˆ: {class_path}")
                                except Exception as e:
                                    self.logger.error(f"âŒ ã‚¯ãƒ©ã‚¹åˆ†å¸ƒã‚°ãƒ©ãƒ•ã‚¨ãƒ©ãƒ¼: {e}")
        
                        else:
                            self.logger.warning("âš ï¸ CSVãƒ‡ãƒ¼ã‚¿ãŒç©ºã§ã™")
                    else:
                        self.logger.warning(f"âš ï¸ CSVãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚‰ãªã„: {csv_path}")
        
                except ImportError as e:
                    self.logger.warning(f"âš ï¸ matplotlib/pandasã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
                except Exception as plot_error:
                    self.logger.error(f"âŒ ã‚°ãƒ©ãƒ•ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {plot_error}", exc_info=True)

                # æœ€çµ‚çµæœæ›´æ–°
                total_files = 1 + graphs_generated
                result.update({
                    "success": True,
                    "error": None,
                    "graphs_generated": graphs_generated,
                    "total_files": total_files
                })

                self.logger.info(f"ğŸ¨ å¯è¦–åŒ–ç”Ÿæˆå®Œäº†: åŸºæœ¬çµ±è¨ˆ1å€‹ + ã‚°ãƒ©ãƒ•{graphs_generated}å€‹ = åˆè¨ˆ{total_files}å€‹")

                # ğŸ”§ å¿…ãšè¾æ›¸ã‚’è¿”ã™ï¼ˆç¢ºå®Ÿæ€§ã®ãŸã‚ï¼‰
                return result

            except Exception as e:
                self.logger.error(f"âŒ å¯è¦–åŒ–ç”Ÿæˆå…¨ä½“ã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
                # ğŸ”§ ã‚¨ãƒ©ãƒ¼æ™‚ã‚‚è¾æ›¸ã‚’è¿”ã™
                result.update({
                    "success": False,
                    "error": str(e),
                    "graphs_generated": 0,
                    "total_files": 0
                })
                return result
                
        def _create_detection_charts(self, data, vis_path):
            """æ¤œå‡ºçµæœã®ãƒãƒ£ãƒ¼ãƒˆç”Ÿæˆ"""
            try:
                import matplotlib.pyplot as plt
                import pandas as pd
                import seaborn as sns
                
                # çµ±è¨ˆãƒ‡ãƒ¼ã‚¿ã®ç¢ºèª
                processing_stats = data.get("processing_stats", {})
                detection_count = data.get("detection_count", 0)
                
                # 1. åŸºæœ¬çµ±è¨ˆã‚°ãƒ©ãƒ•
                fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 12))
                
                # æ¤œå‡ºæ•°ã‚°ãƒ©ãƒ•
                ax1.bar(['æ¤œå‡ºæ•°'], [detection_count], color='skyblue')
                ax1.set_title('ç·æ¤œå‡ºæ•°')
                ax1.set_ylabel('ä»¶æ•°')
                
                # å‡¦ç†çµ±è¨ˆ
                if processing_stats:
                    stats_keys = list(processing_stats.keys())[:5]  # æœ€å¤§5é …ç›®
                    stats_values = [processing_stats[k] for k in stats_keys]
                    ax2.barh(stats_keys, stats_values, color='lightcoral')
                    ax2.set_title('å‡¦ç†çµ±è¨ˆ')
                    ax2.set_xlabel('å€¤')
                
                # ãƒ•ãƒ¬ãƒ¼ãƒ æ•°
                frame_count = data.get("frame_count", 0)
                ax3.pie([frame_count, max(1, 120 - frame_count)], 
                        labels=['å‡¦ç†æ¸ˆã¿', 'æœªå‡¦ç†'], autopct='%1.1f%%',
                        colors=['lightgreen', 'lightgray'])
                ax3.set_title('ãƒ•ãƒ¬ãƒ¼ãƒ å‡¦ç†çŠ¶æ³')
                
                # å‡¦ç†æ™‚é–“
                processing_time = data.get("processing_time", 0)
                ax4.bar(['å‡¦ç†æ™‚é–“'], [processing_time], color='gold')
                ax4.set_title('å‡¦ç†æ™‚é–“ (ç§’)')
                ax4.set_ylabel('ç§’')
                
                plt.tight_layout()
                plt.savefig(vis_path / "detection_summary.png", dpi=300, bbox_inches='tight')
                plt.close()
                
                self.logger.info(f"âœ… ã‚µãƒãƒªãƒ¼ãƒãƒ£ãƒ¼ãƒˆç”Ÿæˆ: detection_summary.png")
                
            except ImportError:
                self.logger.warning("âš ï¸ matplotlibæœªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ« - åŸºæœ¬çµ±è¨ˆã®ã¿ä¿å­˜")
            except Exception as e:
                self.logger.error(f"âŒ ãƒãƒ£ãƒ¼ãƒˆç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")

# ğŸ”§ BasicConfigï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”¨ãƒ»å®Œå…¨ç‰ˆï¼‰
if not CONFIG_AVAILABLE:
    class BasicConfig:
        def __init__(self, config_path=None):
            self.config_path = config_path
            self.data = self.load_config()
            self.logger = logging.getLogger(__name__)
        
        def load_config(self):
            """è¨­å®šãƒ­ãƒ¼ãƒ‰ï¼ˆå®Œå…¨ç‰ˆï¼‰"""
            logger = logging.getLogger(__name__)
            logger.info(f"âš™ï¸ è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿: {self.config_path}")
            
            if self.config_path and Path(self.config_path).exists():
                try:
                    with open(self.config_path, 'r', encoding='utf-8') as f:
                        if self.config_path.endswith(('.yaml', '.yml')):
                            config_data = yaml.safe_load(f)
                            logger.info("âœ… YAMLè¨­å®šãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿æˆåŠŸ")
                        else:
                            config_data = json.load(f)
                            logger.info("âœ… JSONè¨­å®šãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿æˆåŠŸ")
                    
                    return config_data
                    
                except Exception as e:
                    logger.warning(f"âš ï¸ è¨­å®šèª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
                    logger.info("ğŸ”§ ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šã‚’ä½¿ç”¨ã—ã¾ã™")
            else:
                logger.warning(f"âš ï¸ è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {self.config_path}")
                logger.info("ğŸ”§ ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šã‚’ä½¿ç”¨ã—ã¾ã™")
            
            # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šï¼ˆå®Œå…¨ç‰ˆï¼‰
            default_config = {
                "models": {
                    "detection": "models/yolo/yolo11x.pt",
                    "pose": "models/yolo/yolo11x-pose.pt"
                },
                "processing": {
                    "detection": {
                        "confidence_threshold": 0.3, 
                        "iou_threshold": 0.45,
                        "max_detections": 1000
                    },
                    "depth_estimation": {
                        "enabled": False,
                        "model": "midas_v21_small_256",
                        "model_path": "models/depth/midas_v21_small_256.pt"
                    },
                    "tile_inference": {
                        "enabled": False,
                        "tile_size": [640, 640],
                        "overlap": 0.1
                    }
                },
                "video_dir": "videos",
                "output_dir": "outputs",
                "logging": {
                    "level": "INFO",
                    "file": "logs/analysis.log"
                },
                "experiments": {
                    "comparison": {"type": "comparison", "description": "åŸºæœ¬æ¯”è¼ƒå®Ÿé¨“"},
                    "model_test": {"type": "model_test", "description": "ãƒ¢ãƒ‡ãƒ«æ€§èƒ½ãƒ†ã‚¹ãƒˆ"},
                    "tile_inference": {"type": "tile_inference", "description": "ã‚¿ã‚¤ãƒ«æ¨è«–ãƒ†ã‚¹ãƒˆ"}
                }
            }
            
            logger.info("âœ… ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šã‚’é©ç”¨ã—ã¾ã—ãŸ")
            return default_config
        
        def get(self, key, default=None):
            """è¨­å®šå€¤å–å¾—ï¼ˆãƒ‰ãƒƒãƒˆè¨˜æ³•å¯¾å¿œãƒ»å®Œå…¨ç‰ˆï¼‰"""
            keys = key.split('.')
            value = self.data
            for k in keys:
                if isinstance(value, dict) and k in value:
                    value = value[k]
                else:
                    return default
            return value
        
        def get_experiment_config(self, experiment_type):
            """å®Ÿé¨“è¨­å®šå–å¾—ï¼ˆå®Œå…¨ç‰ˆï¼‰"""
            experiment_configs = self.get("experiments", {})
            if experiment_type in experiment_configs:
                return experiment_configs[experiment_type]
            
            # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå®Ÿé¨“è¨­å®š
            return {
                "type": experiment_type,
                "basic_mode": True,
                "description": f"åŸºæœ¬å®Ÿé¨“: {experiment_type}",
                "enabled": True
            }
        
        @property
        def video_dir(self):
            return self.get("video_dir", "videos")

LOGGER_AVAILABLE = False
setup_logger = None

try:
    from utils.logger import setup_logger
    LOGGER_AVAILABLE = True
    print("âœ… setup_logger ãŒåˆ©ç”¨å¯èƒ½ã§ã™")
except ImportError as e:
    print(f"âš ï¸ setup_logger ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {e}")
    print("ğŸ”§ åŸºæœ¬ãƒ­ã‚°æ©Ÿèƒ½ã‚’ä½¿ç”¨ã—ã¾ã™")
    LOGGER_AVAILABLE = False

# ğŸ”§ åŸºæœ¬ãƒ­ã‚°è¨­å®šï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”¨ãƒ»å®Œå…¨ç‰ˆï¼‰
if not LOGGER_AVAILABLE:
    def setup_logger():
        """åŸºæœ¬ãƒ­ã‚°è¨­å®šï¼ˆå®Œå…¨ç‰ˆï¼‰"""
        # ãƒ­ã‚°ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
        log_dir = Path("logs")
        log_dir.mkdir(exist_ok=True)
        
        # ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«å
        log_file = log_dir / f"analysis_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log"
        
        # æ—¢å­˜ã®ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ã‚’ã‚¯ãƒªã‚¢
        logger = logging.getLogger()
        for handler in logger.handlers[:]:
            logger.removeHandler(handler)
        
        # ãƒ­ã‚°è¨­å®š
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler(log_file, encoding='utf-8'),
                logging.StreamHandler(sys.stdout)
            ]
        )
        
        logger = logging.getLogger(__name__)
        logger.info(f"ğŸ”§ åŸºæœ¬ãƒ­ã‚°æ©Ÿèƒ½ã‚’åˆæœŸåŒ–ã—ã¾ã—ãŸ: {log_file}")
        return logger

# âœ… ã“ã“ã§ã‚¯ãƒ©ã‚¹å®šç¾©é–‹å§‹ï¼ˆifæ–‡ã®å¤–ã€ã‚¤ãƒ³ãƒ‡ãƒ³ãƒˆ0ï¼‰
class ImprovedYOLOAnalyzer:
    """
    YOLO11 åºƒè§’ã‚«ãƒ¡ãƒ©åˆ†æã‚·ã‚¹ãƒ†ãƒ ï¼ˆå®Œå…¨çµ±åˆç‰ˆï¼‰
    - æ·±åº¦æ¨å®šçµ±åˆå¯¾å¿œ
    - ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ä¸è¶³å®Œå…¨å¯¾å¿œ
    - Stage 5/6ä¿®æ­£å®Œäº†
    - ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æ©Ÿèƒ½å®Œå…¨çµ±åˆ
    """

    # Line 834-854ã‚’ä¿®æ­£:

    # Line 1272-1310ã®__init__ãƒ¡ã‚½ãƒƒãƒ‰ã‚’ä»¥ä¸‹ã§ç½®ãæ›ãˆ:

    def __init__(self, config_path: str = "configs/default.yaml"):
        """
        åˆæœŸåŒ–ï¼ˆå®Œå…¨çµ±åˆç‰ˆï¼‰

        Args:
            config_path: è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
        """
        # ğŸ”§ ãƒ­ã‚¬ãƒ¼ã‚’æœ€åˆã«åˆæœŸåŒ–
        self.logger = setup_logger()

        # ã‚¨ãƒ©ãƒ¼ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆè¨­å®š
        if ERROR_HANDLER_AVAILABLE:
            context_manager = ErrorContext("ImprovedYOLOAnalyzeråˆæœŸåŒ–", logger=self.logger)
        else:
            context_manager = self._basic_context("ImprovedYOLOAnalyzeråˆæœŸåŒ–")

        with context_manager as ctx:
            # è¨­å®šåˆæœŸåŒ–
            self.config = self._initialize_config(config_path)

            # æ·±åº¦æ¨å®šæœ‰åŠ¹æ€§ã®ç¢ºèª
            self.depth_enabled = self.config.get('processing.depth_estimation.enabled', False)
            self.logger.info(f"ğŸ” æ·±åº¦æ¨å®š: {'æœ‰åŠ¹' if self.depth_enabled else 'ç„¡åŠ¹'}")

            # ğŸ”§ å³å¯†ãƒ¢ãƒ‡ãƒ«ä½¿ç”¨ãƒ•ãƒ©ã‚°è¿½åŠ 
            self.force_exact_model = True
            self.model_verification_results = {}

            # è©•ä¾¡å™¨ã®é¸æŠã¨åˆæœŸåŒ–
            self._initialize_evaluator(ctx)

            # ãƒ—ãƒ­ã‚»ãƒƒã‚µãƒ¼ã¨ã‚¢ãƒŠãƒ©ã‚¤ã‚¶ãƒ¼åˆæœŸåŒ–
            self._initialize_processor_analyzer(ctx)

            # ğŸ”§ analyzer ã®æ˜ç¤ºçš„åˆæœŸåŒ–ã‚’è¿½åŠ 
            self._initialize_analyzer(ctx)

            # ã‚¨ãƒ©ãƒ¼åé›†ç”¨
            self.error_collector = []

            # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
            self._setup_directories()

            # åˆæœŸåŒ–å®Œäº†å ±å‘Š
            self._report_initialization(ctx)

    def _basic_context(self, name):
        """åŸºæœ¬ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼"""
        class BasicContext:
            def __init__(self, name):
                self.name = name
                self.logger = logging.getLogger(__name__)
            def __enter__(self):
                self.logger.debug(f"ğŸ” å‡¦ç†é–‹å§‹: {self.name}")
                return self
            def __exit__(self, exc_type, exc_val, exc_tb):
                if exc_type:
                    self.logger.error(f"âŒ ã‚¨ãƒ©ãƒ¼ in {self.name}: {exc_val}")
                else:
                    self.logger.debug(f"âœ… å‡¦ç†å®Œäº†: {self.name}")
                return False
            def add_info(self, key, value):
                self.logger.debug(f"ğŸ“ {self.name} - {key}: {value}")
        return BasicContext(name)

    # Line 857ã®_initialize_configãƒ¡ã‚½ãƒƒãƒ‰ã‚’ä¿®æ­£:

    def _initialize_config(self, config_path: str):
        """è¨­å®šåˆæœŸåŒ–ï¼ˆå®Œå…¨ç‰ˆï¼‰"""
        depth_config_path = "configs/depth_config.yaml"
    
        # âš ï¸ ã“ã“ã§ self.logger ã‚’ä½¿ã†å‰ã«ã€ãƒ­ã‚¬ãƒ¼ã‚’åˆæœŸåŒ–ã™ã‚‹å¿…è¦ãŒã‚ã‚‹
        logger = logging.getLogger(__name__)  # ğŸ”§ ä¸€æ™‚çš„ãªãƒ­ã‚¬ãƒ¼ä½¿ç”¨
        logger.info(f"âš™ï¸ è¨­å®šåˆæœŸåŒ–é–‹å§‹: {config_path}")
    
        # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®å„ªå…ˆé †ä½æ±ºå®š
        if Path(config_path).exists():
            primary_config = config_path
            logger.info(f"ğŸ“„ æŒ‡å®šè¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ä½¿ç”¨: {config_path}")
        elif Path(depth_config_path).exists():
            primary_config = depth_config_path
            logger.info(f"ğŸ” æ·±åº¦è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«è‡ªå‹•æ¤œå‡º: {depth_config_path}")
        else:
            primary_config = config_path
            logger.warning(f"âš ï¸ è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {config_path}")

        # è¨­å®šã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆåˆæœŸåŒ–
        if CONFIG_AVAILABLE and Config:
            return Config(primary_config)
        else:
            return BasicConfig(primary_config)

    def _initialize_evaluator(self, ctx):
        """è©•ä¾¡å™¨åˆæœŸåŒ–ï¼ˆå®Œå…¨ç‰ˆï¼‰"""
        if self.depth_enabled and DEPTH_EVALUATOR_AVAILABLE and DepthEnhancedEvaluator:
            try:
                self.evaluator = DepthEnhancedEvaluator(self.config)
                self.logger.info("ğŸ” æ·±åº¦çµ±åˆè©•ä¾¡å™¨ã‚’åˆæœŸåŒ–")
                if hasattr(ctx, 'add_info'):
                    ctx.add_info("evaluator_type", "DepthEnhancedEvaluator")
            except Exception as e:
                self.logger.warning(f"DepthEnhancedEvaluator åˆæœŸåŒ–å¤±æ•—: {e}")
                self._fallback_to_basic_evaluator(ctx)
        elif COMPREHENSIVE_EVALUATOR_AVAILABLE and ComprehensiveEvaluator:
            try:
                self.evaluator = ComprehensiveEvaluator(self.config)
                self.logger.info("ğŸ“Š æ¨™æº–è©•ä¾¡å™¨ã‚’åˆæœŸåŒ–")
                if hasattr(ctx, 'add_info'):
                    ctx.add_info("evaluator_type", "ComprehensiveEvaluator")
            except Exception as e:
                self.logger.warning(f"ComprehensiveEvaluator åˆæœŸåŒ–å¤±æ•—: {e}")
                self._fallback_to_basic_evaluator(ctx)
        else:
            self._fallback_to_basic_evaluator(ctx)

    def _fallback_to_basic_evaluator(self, ctx):
        """åŸºæœ¬è©•ä¾¡å™¨ã¸ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯"""
        self.evaluator = BasicEvaluator(self.config)
        self.logger.info("ğŸ”§ åŸºæœ¬è©•ä¾¡å™¨ã‚’åˆæœŸåŒ–")
        if hasattr(ctx, 'add_info'):
            ctx.add_info("evaluator_type", "BasicEvaluator")

    def _initialize_processor_analyzer(self, ctx):
        """ãƒ—ãƒ­ã‚»ãƒƒã‚µãƒ¼ãƒ»ã‚¢ãƒŠãƒ©ã‚¤ã‚¶ãƒ¼åˆæœŸåŒ–ï¼ˆå®Œå…¨ç‰ˆï¼‰"""
        try:
            # Video Processor åˆæœŸåŒ–
            if VIDEO_PROCESSOR_AVAILABLE:
                self.logger.info("ğŸ¥ é«˜åº¦å‹•ç”»ãƒ—ãƒ­ã‚»ãƒƒã‚µãƒ¼ã‚’åˆæœŸåŒ–")
                self.processor = VideoProcessor(self.config)
            else:
                self.logger.info("ğŸ”„ BasicVideoProcessor ã‚’åˆæœŸåŒ–")
                self.processor = BasicVideoProcessor(self.config)

            # ğŸ”§ analyzer ã®åˆæœŸåŒ–ã¯åˆ¥ãƒ¡ã‚½ãƒƒãƒ‰ã§è¡Œã†ï¼ˆé‡è¤‡ã‚’é¿ã‘ã‚‹ãŸã‚ï¼‰
            # self._initialize_analyzer(ctx) ã¯ __init__ ã§å‘¼ã³å‡ºã—æ¸ˆã¿
        
            ctx.add_info("processor_type", type(self.processor).__name__)
        
        except Exception as e:
            self.logger.error(f"âŒ ãƒ—ãƒ­ã‚»ãƒƒã‚µãƒ¼ãƒ»ã‚¢ãƒŠãƒ©ã‚¤ã‚¶ãƒ¼åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
            self._fallback_processor_analyzer(ctx)

    def _fallback_processor_analyzer(self, ctx):
        """ãƒ—ãƒ­ã‚»ãƒƒã‚µãƒ¼ãƒ»ã‚¢ãƒŠãƒ©ã‚¤ã‚¶ãƒ¼ç”¨ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯"""
        try:
            self.logger.warning("ğŸ”„ åŸºæœ¬ãƒ—ãƒ­ã‚»ãƒƒã‚µãƒ¼ãƒ»ã‚¢ãƒŠãƒ©ã‚¤ã‚¶ãƒ¼ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯")
            self.processor = BasicVideoProcessor(self.config)
        
            # analyzer ãŒæœªåˆæœŸåŒ–ã®å ´åˆã¯åˆæœŸåŒ–
            if not hasattr(self, 'analyzer') or self.analyzer is None:
                self._create_fallback_analyzer(ctx)
            
            ctx.add_info("fallback_applied", True)
        
        except Exception as e:
            self.logger.error(f"âŒ ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å¤±æ•—: {e}", exc_info=True)
            raise

    def _initialize_analyzer(self, ctx):
        """ãƒ¡ãƒˆãƒªã‚¯ã‚¹åˆ†æå™¨åˆæœŸåŒ–ï¼ˆå®Œå…¨ç‰ˆï¼‰"""
        try:
            self.logger.info("ğŸ“Š é«˜åº¦ãƒ¡ãƒˆãƒªã‚¯ã‚¹åˆ†æå™¨ã‚’åˆæœŸåŒ–")
        
            # ğŸ”§ METRICS_ANALYZER_AVAILABLE ã®ç¢ºèª
            if METRICS_ANALYZER_AVAILABLE:
                try:
                    # é«˜åº¦åˆ†æå™¨ã®åˆæœŸåŒ–ã‚’è©¦è¡Œ
                    self.analyzer = MetricsAnalyzer(self.config)
                    self.logger.info("âœ… MetricsAnalyzeråˆæœŸåŒ–æˆåŠŸ")
                    ctx.add_info("analyzer_type", "MetricsAnalyzer")
                    return
                except Exception as e:
                    self.logger.warning(f"MetricsAnalyzeråˆæœŸåŒ–å¤±æ•—: {e}")
        
            # ğŸ”§ ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: BasicMetricsAnalyzer
            self.logger.info("ğŸ”„ BasicMetricsAnalyzerã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯")
            self.analyzer = BasicMetricsAnalyzer(self.config)
            self.logger.info("âœ… BasicMetricsAnalyzeråˆæœŸåŒ–æˆåŠŸ")
            ctx.add_info("analyzer_type", "BasicMetricsAnalyzer")
        
            # ğŸ”§ create_visualizations ãƒ¡ã‚½ãƒƒãƒ‰ã®å­˜åœ¨ç¢ºèª
            if hasattr(self.analyzer, 'create_visualizations'):
                self.logger.info("âœ… create_visualizations ãƒ¡ã‚½ãƒƒãƒ‰ç¢ºèª")
            else:
                self.logger.error("âŒ create_visualizations ãƒ¡ã‚½ãƒƒãƒ‰ãŒå­˜åœ¨ã—ã¾ã›ã‚“")
                # ğŸ”§ ãƒ¡ã‚½ãƒƒãƒ‰ã‚’å‹•çš„ã«è¿½åŠ 
                self._add_fallback_visualization_method()
            
        except Exception as e:
            self.logger.error(f"âŒ åˆ†æå™¨åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
            # ğŸ”§ æœ€çµ‚ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
            self._create_fallback_analyzer(ctx)

    def _add_fallback_visualization_method(self):
        """ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å¯è¦–åŒ–ãƒ¡ã‚½ãƒƒãƒ‰ã®å‹•çš„è¿½åŠ """
        def fallback_create_visualizations(detection_results, vis_dir):
            """ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å¯è¦–åŒ–ç”Ÿæˆ"""
            try:
                self.logger.info(f"ğŸ”§ ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å¯è¦–åŒ–ç”Ÿæˆ: {vis_dir}")
            
                from pathlib import Path
                import json
                from datetime import datetime
            
                # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
                vis_path = Path(str(vis_dir))
                vis_path.mkdir(parents=True, exist_ok=True)
            
                # åŸºæœ¬çµ±è¨ˆãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ
                stats_file = vis_path / "basic_stats.json"
                basic_stats = {
                    "visualization_type": "FallbackVisualization",
                    "timestamp": datetime.now().isoformat(),
                    "detection_results_type": str(type(detection_results)),
                    "success": True
                }
            
                with open(stats_file, 'w', encoding='utf-8') as f:
                    json.dump(basic_stats, f, indent=2, ensure_ascii=False)
            
                self.logger.info(f"âœ… ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å¯è¦–åŒ–å®Œäº†: {stats_file}")
            
                return {
                    "success": True,
                    "basic_stats_file": str(stats_file),
                    "total_files": 1,
                    "graphs_generated": 0,
                    "fallback": True
                }
            
            except Exception as e:
                self.logger.error(f"âŒ ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å¯è¦–åŒ–ã‚¨ãƒ©ãƒ¼: {e}")
                return {
                    "success": False,
                    "error": str(e),
                    "total_files": 0,
                    "graphs_generated": 0,
                    "fallback": True
                }
    
        # ğŸ”§ ãƒ¡ã‚½ãƒƒãƒ‰ã‚’å‹•çš„ã«ãƒã‚¤ãƒ³ãƒ‰
        import types
        self.analyzer.create_visualizations = types.MethodType(fallback_create_visualizations, self.analyzer)
        self.logger.info("ğŸ”§ ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å¯è¦–åŒ–ãƒ¡ã‚½ãƒƒãƒ‰è¿½åŠ å®Œäº†")

    def _create_fallback_analyzer(self, ctx):
        """æœ€çµ‚ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯åˆ†æå™¨ã®ä½œæˆ"""
        class FallbackAnalyzer:
            def __init__(self, config):
                self.config = config
                self.logger = logging.getLogger(__name__)
        
            def create_visualizations(self, detection_results, vis_dir):
                """æœ€çµ‚ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å¯è¦–åŒ–"""
                try:
                    from pathlib import Path
                    import json
                    from datetime import datetime
                
                    vis_path = Path(str(vis_dir))
                    vis_path.mkdir(parents=True, exist_ok=True)
                
                    fallback_file = vis_path / "fallback_analysis.json"
                    fallback_data = {
                        "analyzer_type": "FallbackAnalyzer",
                        "timestamp": datetime.now().isoformat(),
                        "note": "åˆ†æå™¨åˆæœŸåŒ–å¤±æ•—ã®ãŸã‚æœ€çµ‚ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚’ä½¿ç”¨",
                        "detection_results_available": detection_results is not None
                    }
                
                    with open(fallback_file, 'w', encoding='utf-8') as f:
                        json.dump(fallback_data, f, indent=2, ensure_ascii=False)
                
                    return {
                        "success": True,
                        "total_files": 1,
                        "graphs_generated": 0,
                        "fallback": True,
                        "analyzer_type": "FallbackAnalyzer"
                    }
                
                except Exception as e:
                    return {
                        "success": False,
                        "error": str(e),
                        "total_files": 0,
                        "graphs_generated": 0,
                        "fallback": True
                    }
    
        self.analyzer = FallbackAnalyzer(self.config)
        self.logger.warning("âš ï¸ æœ€çµ‚ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯åˆ†æå™¨ã‚’ä½œæˆ")
        ctx.add_info("analyzer_type", "FallbackAnalyzer")

    def _setup_directories(self):
        """ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ï¼ˆå®Œå…¨ç‰ˆï¼‰"""
        directories = [
            "outputs/baseline",
            "outputs/experiments",
            "outputs/visualizations",
            "outputs/temp",
            "logs",
            "models/yolo",
            "models/depth"
        ]
        
        self.logger.info("ğŸ“ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—é–‹å§‹")
        
        for directory in directories:
            dir_path = Path(directory)
            dir_path.mkdir(parents=True, exist_ok=True)
            self.logger.debug(f"ğŸ“ ä½œæˆ/ç¢ºèª: {directory}")
        
        self.logger.info("âœ… ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—å®Œäº†")

    def _report_initialization(self, ctx):
        """åˆæœŸåŒ–å®Œäº†å ±å‘Šï¼ˆå®Œå…¨ç‰ˆï¼‰"""
        features = []
        if self.depth_enabled:
            features.append("æ·±åº¦æ¨å®š")
        if self.config.get('processing.tile_inference.enabled', False):
            features.append("ã‚¿ã‚¤ãƒ«æ¨è«–")
        
        # ä½¿ç”¨ä¸­ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æ©Ÿèƒ½ã®è¡¨ç¤º
        fallbacks = []
        if not COMPREHENSIVE_EVALUATOR_AVAILABLE:
            fallbacks.append("åŸºæœ¬è©•ä¾¡å™¨")
        if not VIDEO_PROCESSOR_AVAILABLE:
            fallbacks.append("åŸºæœ¬å‹•ç”»å‡¦ç†")
        if not METRICS_ANALYZER_AVAILABLE:
            fallbacks.append("åŸºæœ¬åˆ†æ")
        if not CONFIG_AVAILABLE:
            fallbacks.append("åŸºæœ¬è¨­å®š")
        if not LOGGER_AVAILABLE:
            fallbacks.append("åŸºæœ¬ãƒ­ã‚°")

        if features:
            self.logger.info(f"ğŸš€ ImprovedYOLOAnalyzeråˆæœŸåŒ–å®Œäº† (æ©Ÿèƒ½: {', '.join(features)})")
        else:
            self.logger.info("ğŸ“‹ ImprovedYOLOAnalyzeråˆæœŸåŒ–å®Œäº† (æ¨™æº–ãƒ¢ãƒ¼ãƒ‰)")
            
        if fallbacks:
            self.logger.info(f"ğŸ”§ ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æ©Ÿèƒ½ä½¿ç”¨ä¸­: {', '.join(fallbacks)}")

        if hasattr(ctx, 'add_info'):
            ctx.add_info("depth_enabled", self.depth_enabled)
            ctx.add_info("fallback_count", len(fallbacks))

    @handle_errors(error_category=ErrorCategory.VIDEO_PROCESSING)
    def run_baseline_analysis(self, video_path: str) -> Dict[str, Any]:
        """
        ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³åˆ†æå®Ÿè¡Œï¼ˆå®Œå…¨çµ±åˆç‰ˆï¼‰

        Args:
            video_path: åˆ†æå¯¾è±¡å‹•ç”»ã®ãƒ‘ã‚¹

        Returns:
            åˆ†æçµæœè¾æ›¸
        """
        if ERROR_HANDLER_AVAILABLE:
            context_manager = ErrorContext(f"ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³åˆ†æ: {Path(video_path).name}",
                                        logger=self.logger, raise_on_error=False)
        else:
            context_manager = self._basic_context(f"ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³åˆ†æ: {Path(video_path).name}")

        with context_manager as ctx:
            video_path = Path(video_path)
            video_name = video_path.stem

            self.logger.info(f"ğŸ¯ ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³åˆ†æé–‹å§‹: {video_name}")

            if hasattr(ctx, 'add_info'):
                ctx.add_info("video_path", str(video_path))
                ctx.add_info("video_name", video_name)
                ctx.add_info("depth_enabled", self.depth_enabled)

            # ğŸ”§ ä¿®æ­£: æ—¥æ™‚ãƒ™ãƒ¼ã‚¹ã®å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæº–å‚™
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")  # ä¾‹: 20241117_143025
            output_dir = Path("outputs/baseline") / f"{video_name}_{timestamp}"
            frame_dir = output_dir / "frames"
        
            output_dir.mkdir(parents=True, exist_ok=True)
            frame_dir.mkdir(parents=True, exist_ok=True)

            self.logger.info(f"ğŸ“ æ—¥æ™‚ä»˜ãå‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {output_dir}")

            # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæº–å‚™
            output_dir = Path("outputs/baseline") / video_name
            frame_dir = output_dir / "frames"
            
            output_dir.mkdir(parents=True, exist_ok=True)
            frame_dir.mkdir(parents=True, exist_ok=True)

            self.logger.info(f"ğŸ“ å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {output_dir}")

            try:
                # Step 1: ãƒ•ãƒ¬ãƒ¼ãƒ æŠ½å‡º
                self.logger.info("ğŸ“¸ Step 1: ãƒ•ãƒ¬ãƒ¼ãƒ æŠ½å‡ºé–‹å§‹")
                
                # ãƒ•ãƒ¬ãƒ¼ãƒ æŠ½å‡ºå®Ÿè¡Œ
                frame_result = self.processor.extract_frames(video_path, frame_dir)
                
                # ğŸ”§ åŸºæœ¬çš„ãªæˆåŠŸ/å¤±æ•—ãƒã‚§ãƒƒã‚¯
                if not frame_result.get("success", False):
                    error_msg = f"ãƒ•ãƒ¬ãƒ¼ãƒ æŠ½å‡ºå¤±æ•—: {frame_result.get('error', 'ä¸æ˜ãªã‚¨ãƒ©ãƒ¼')}"
                    self.error_collector.append(error_msg)
                    self.logger.error(f"âŒ {error_msg}")
                    raise VideoProcessingError(error_msg)

                # ğŸ”§ ãƒ•ãƒ¬ãƒ¼ãƒ æ•°ã®å¤šé‡ç¢ºèªã‚·ã‚¹ãƒ†ãƒ 
                
                # æ–¹æ³•1: APIã‹ã‚‰è¿”å´ã•ã‚ŒãŸå€¤
                api_extracted_frames = frame_result.get("extracted_frames", 0)
                self.logger.debug(f"ğŸ“Š APIè¿”å´ãƒ•ãƒ¬ãƒ¼ãƒ æ•°: {api_extracted_frames}")
                
                # æ–¹æ³•2: ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ç›´æ¥ç¢ºèª
                frame_files_jpg = list(frame_dir.glob("frame_*.jpg"))
                frame_files_jpeg = list(frame_dir.glob("frame_*.jpeg"))
                frame_files_png = list(frame_dir.glob("frame_*.png"))
                
                # ã™ã¹ã¦ã®ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã‚’çµ±åˆ
                all_frame_files = frame_files_jpg + frame_files_jpeg + frame_files_png
                actual_frame_count = len(all_frame_files)
                
                self.logger.debug(f"ğŸ“Š ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…ãƒ•ã‚¡ã‚¤ãƒ«æ•°:")
                self.logger.debug(f"  - JPGãƒ•ã‚¡ã‚¤ãƒ«: {len(frame_files_jpg)}å€‹")
                self.logger.debug(f"  - JPEGãƒ•ã‚¡ã‚¤ãƒ«: {len(frame_files_jpeg)}å€‹") 
                self.logger.debug(f"  - PNGãƒ•ã‚¡ã‚¤ãƒ«: {len(frame_files_png)}å€‹")
                self.logger.debug(f"  - åˆè¨ˆ: {actual_frame_count}å€‹")
                
                # æ–¹æ³•3: processing_statsã‹ã‚‰ã®å–å¾—
                stats_frames = 0
                if hasattr(self.processor, 'processing_stats') and self.processor.processing_stats:
                    frame_extraction_stats = self.processor.processing_stats.get("frame_extraction", {})
                    stats_frames = frame_extraction_stats.get("extracted_frames", 0)
                
                self.logger.debug(f"ğŸ“Š çµ±è¨ˆæƒ…å ±ãƒ•ãƒ¬ãƒ¼ãƒ æ•°: {stats_frames}")
                
                # ğŸ”§ æœ€ã‚‚ä¿¡é ¼ã§ãã‚‹å€¤ã‚’æ¡ç”¨
                frame_counts = [api_extracted_frames, actual_frame_count, stats_frames]
                valid_counts = [count for count in frame_counts if count > 0]
                
                if valid_counts:
                    # æœ‰åŠ¹ãªå€¤ãŒã‚ã‚‹å ´åˆã¯æœ€å¤§å€¤ã‚’æ¡ç”¨
                    final_frame_count = max(valid_counts)
                    self.logger.info(f"ğŸ“Š ãƒ•ãƒ¬ãƒ¼ãƒ æ•°ç¢ºå®š: {final_frame_count}å€‹ï¼ˆå€™è£œ: {frame_counts}ï¼‰")
                else:
                    # ã™ã¹ã¦0ã®å ´åˆã¯è©³ç´°èª¿æŸ»
                    self.logger.warning("âš ï¸ å…¨ã¦ã®æ–¹æ³•ã§ãƒ•ãƒ¬ãƒ¼ãƒ æ•°ãŒ0ã§ã™ã€‚è©³ç´°èª¿æŸ»ã‚’å®Ÿè¡Œ...")
                    
                    # æ–¹æ³•4: ã‚ˆã‚Šåºƒç¯„å›²ãªãƒ•ã‚¡ã‚¤ãƒ«ç¢ºèª
                    all_files = list(frame_dir.glob("*"))
                    image_extensions = ['.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.webp']
                    image_files = []
                    
                    for file_path in all_files:
                        if file_path.suffix.lower() in image_extensions:
                            image_files.append(file_path)
                    
                    final_frame_count = len(image_files)
                    
                    if final_frame_count > 0:
                        self.logger.info(f"ğŸ” åºƒç¯„å›²ç¢ºèªã§ç™ºè¦‹: {final_frame_count}å€‹ã®ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«")
                        # ãƒ•ã‚¡ã‚¤ãƒ«åã®ä¾‹ã‚’è¡¨ç¤º
                        sample_files = [f.name for f in image_files[:3]]
                        self.logger.debug(f"  ã‚µãƒ³ãƒ—ãƒ«: {sample_files}")
                    else:
                        # æ–¹æ³•5: æœ€å¾Œã®æ‰‹æ®µ - ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…å®¹ã®å®Œå…¨ãƒã‚§ãƒƒã‚¯
                        self.logger.error("ğŸ” æœ€çµ‚ç¢ºèª - ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…å®¹:")
                        self.logger.error(f"  - ãƒ‘ã‚¹: {frame_dir}")
                        self.logger.error(f"  - å­˜åœ¨ç¢ºèª: {frame_dir.exists()}")
                        self.logger.error(f"  - ã‚¢ã‚¯ã‚»ã‚¹æ¨©é™: {frame_dir.is_dir() if frame_dir.exists() else 'N/A'}")
                        
                        if frame_dir.exists():
                            all_content = list(frame_dir.glob("*"))
                            self.logger.error(f"  - å…¨ãƒ•ã‚¡ã‚¤ãƒ«({len(all_content)}å€‹): {[f.name for f in all_content[:10]]}")
                            
                            # ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºç¢ºèª
                            for file_path in all_content[:5]:
                                if file_path.is_file():
                                    size_mb = file_path.stat().st_size / (1024 * 1024)
                                    self.logger.error(f"    {file_path.name}: {size_mb:.2f}MB")
                
                # ğŸ”§ çµæœã®è©³ç´°ãƒ­ã‚°å‡ºåŠ›
                self.logger.info(f"âœ… Step 1å®Œäº†: {final_frame_count}ãƒ•ãƒ¬ãƒ¼ãƒ æŠ½å‡º")
                
                if final_frame_count > 0:
                    # æˆåŠŸæ™‚ã®çµ±è¨ˆæƒ…å ±
                    if actual_frame_count > 0 and len(all_frame_files) > 0:
                        # ãƒ•ã‚¡ã‚¤ãƒ«ã‚µãƒ³ãƒ—ãƒ«ã®è¡¨ç¤º
                        sample_count = min(3, len(all_frame_files))
                        sample_files = [f.name for f in all_frame_files[:sample_count]]
                        self.logger.info(f"ğŸ“ ä¿å­˜ãƒ•ã‚¡ã‚¤ãƒ«ä¾‹: {sample_files}")
                        
                        # ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºçµ±è¨ˆ
                        total_size = sum(f.stat().st_size for f in all_frame_files[:10])  # æœ€åˆã®10ãƒ•ã‚¡ã‚¤ãƒ«
                        avg_size_kb = (total_size / min(10, len(all_frame_files))) / 1024 if all_frame_files else 0
                        self.logger.debug(f"ğŸ“Š å¹³å‡ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: {avg_size_kb:.1f}KB")
                    
                    # ãƒ•ãƒ¬ãƒ¼ãƒ æŠ½å‡ºç‡ã®è¨ˆç®—
                    if hasattr(self.processor, 'processing_stats') and self.processor.processing_stats:
                        extraction_stats = self.processor.processing_stats.get("frame_extraction", {})
                        total_frames = extraction_stats.get("total_frames", 0)
                        if total_frames > 0:
                            extraction_rate = (final_frame_count / total_frames) * 100
                            self.logger.info(f"ğŸ“Š æŠ½å‡ºç‡: {extraction_rate:.1f}% ({final_frame_count}/{total_frames})")
                
                # ğŸ”§ ã‚¼ãƒ­ãƒ•ãƒ¬ãƒ¼ãƒ ã®å ´åˆã®ã‚¨ãƒ©ãƒ¼å‡¦ç†
                if final_frame_count == 0:
                    error_msg = "ãƒ•ãƒ¬ãƒ¼ãƒ æŠ½å‡ºæ•°ãŒ0ã§ã™ã€‚å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã¨å‡¦ç†ã‚’ç¢ºèªã—ã¦ãã ã•ã„"
                    self.error_collector.append(error_msg)
                    self.logger.error(f"âŒ {error_msg}")
                    
                    # ğŸ”§ è©³ç´°ãªãƒ‡ãƒãƒƒã‚°æƒ…å ±ã‚’å‡ºåŠ›
                    self.logger.error(f"ğŸ” ãƒ‡ãƒãƒƒã‚°æƒ…å ±è©³ç´°:")
                    self.logger.error(f"  å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«:")
                    self.logger.error(f"    - ãƒ‘ã‚¹: {video_path}")
                    self.logger.error(f"    - å­˜åœ¨: {Path(video_path).exists()}")
                    if Path(video_path).exists():
                        video_size = Path(video_path).stat().st_size / (1024 * 1024)
                        self.logger.error(f"    - ã‚µã‚¤ã‚º: {video_size:.1f}MB")
                    
                    self.logger.error(f"  å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª:")
                    self.logger.error(f"    - ãƒ‘ã‚¹: {frame_dir}")
                    self.logger.error(f"    - å­˜åœ¨: {frame_dir.exists()}")
                    self.logger.error(f"    - æ¨©é™: {oct(frame_dir.stat().st_mode)[-3:] if frame_dir.exists() else 'N/A'}")
                    
                    self.logger.error(f"  ãƒ—ãƒ­ã‚»ãƒƒã‚µæƒ…å ±:")
                    self.logger.error(f"    - ã‚¿ã‚¤ãƒ—: {type(self.processor).__name__}")
                    self.logger.error(f"    - è¨­å®š: {getattr(self.processor, 'config', 'N/A')}")
                    
                    # frame_resultã®è©³ç´°
                    self.logger.error(f"  APIå¿œç­”:")
                    self.logger.error(f"    - frame_result: {frame_result}")
                    
                    raise VideoProcessingError(error_msg)
                
                # âœ… å‡¦ç†ç¶™ç¶šã®ãŸã‚ã®ãƒ•ãƒ¬ãƒ¼ãƒ æ•°è¨˜éŒ²
                # å¾Œç¶šå‡¦ç†ã§ä½¿ç”¨ã™ã‚‹ãŸã‚ã€ç¢ºå®šã—ãŸãƒ•ãƒ¬ãƒ¼ãƒ æ•°ã‚’ä¿å­˜
                if not hasattr(self, 'current_analysis_stats'):
                    self.current_analysis_stats = {}
                self.current_analysis_stats['extracted_frame_count'] = final_frame_count
                self.current_analysis_stats['frame_directory'] = str(frame_dir)
                
                self.logger.debug(f"ğŸ“ ç¾åœ¨ã®è§£æçµ±è¨ˆã‚’æ›´æ–°: {self.current_analysis_stats}")

                # Step 2: æ¤œå‡ºãƒ»è¿½è·¡å‡¦ç†ï¼ˆã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆç¢ºå®Ÿå–å¾—ç‰ˆï¼‰
                self.logger.info("ğŸ¯ Step 2: YOLOãƒãƒ¼ã‚ºãƒ¢ãƒ‡ãƒ«ç¢ºå®Ÿä½¿ç”¨å‡¦ç†é–‹å§‹")

                # ğŸ”§ ãƒãƒ¼ã‚ºãƒ¢ãƒ‡ãƒ«ãƒ‘ã‚¹ã®ç¢ºå®Ÿãªå–å¾—
                models_config = self.config.get('models', {}) if hasattr(self.config, 'get') else {}
                pose_model_path = models_config.get('pose', 'models/yolo/yolo11x-pose.pt')

                # ğŸ”§ ä¿®æ­£: ãƒãƒ¼ã‚ºãƒ¢ãƒ‡ãƒ«ã®ç¢ºå®Ÿãªç¢ºèª
                if not Path(pose_model_path).exists():
                    self.logger.error(f"ğŸš¨ ãƒãƒ¼ã‚ºãƒ¢ãƒ‡ãƒ«ãŒå­˜åœ¨ã—ã¾ã›ã‚“: {pose_model_path}")
    
                    # ä»£æ›¿ãƒãƒ¼ã‚ºãƒ¢ãƒ‡ãƒ«ã‚’æ¢ç´¢
                    alternative_paths = [
                        "models/yolo/yolo11x-pose.pt",
                        "models/yolo11x-pose.pt", 
                        "yolo11x-pose.pt",
                        "models/yolo/yolo11l-pose.pt",
                        "models/yolo11l-pose.pt",
                        "models/yolo/yolo11m-pose.pt",
                        "models/yolo11m-pose.pt"
                    ]
    
                    found_model = None
                    for alt_path in alternative_paths:
                        if Path(alt_path).exists():
                            found_model = alt_path
                            self.logger.info(f"ğŸ”§ ä»£æ›¿ãƒãƒ¼ã‚ºãƒ¢ãƒ‡ãƒ«ç™ºè¦‹: {alt_path}")
                            break
    
                    if found_model:
                        pose_model_path = found_model
                        self.logger.info(f"âœ… ãƒãƒ¼ã‚ºãƒ¢ãƒ‡ãƒ«ãƒ‘ã‚¹æ›´æ–°: {pose_model_path}")
                    else:
                        self.logger.error("ğŸš¨ åˆ©ç”¨å¯èƒ½ãªãƒãƒ¼ã‚ºãƒ¢ãƒ‡ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                        self.logger.error("ğŸ”§ ä»¥ä¸‹ã®ãƒ‘ã‚¹ã‚’ç¢ºèªã—ã¦ãã ã•ã„:")
                        for path in [pose_model_path] + alternative_paths:
                            self.logger.error(f"  - {path}")
                        return ResponseBuilder.error(
                            message="ãƒãƒ¼ã‚ºãƒ¢ãƒ‡ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“",
                            details={
                                "original_path": pose_model_path,
                                "searched_paths": alternative_paths,
                                "suggestion": "setup.py ã‚’å®Ÿè¡Œã—ã¦ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„"
                            }
                        )

                # ğŸ”§ ä¿®æ­£: ãƒãƒ¼ã‚ºãƒ¢ãƒ‡ãƒ«ç¢ºå®Ÿä½¿ç”¨ã®è¨­å®š
                detection_config = {
                    "confidence_threshold": 0.3,
                    "tracking_config": "bytetrack.yaml",  # ğŸ”§ ç¢ºå®Ÿã«è¨­å®š
                    "save_visualizations": True,
                    "save_detection_frames": True,
                    "force_pose_task": True,  # ğŸ”§ ãƒãƒ¼ã‚ºã‚¿ã‚¹ã‚¯å¼·åˆ¶
                    "model_verification_required": True,  # ğŸ”§ ãƒ¢ãƒ‡ãƒ«æ¤œè¨¼å¿…é ˆ
                    "keypoint_processing_enabled": True  # ğŸ”§ ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆå‡¦ç†ç¢ºå®Ÿæœ‰åŠ¹
                }

                self.logger.info(f"ğŸ¯ æ¤œå‡ºè¨­å®š:")
                self.logger.info(f"  ãƒãƒ¼ã‚ºãƒ¢ãƒ‡ãƒ«: {pose_model_path}")
                self.logger.info(f"  tracker: {detection_config['tracking_config']}")
                self.logger.info(f"  ãƒãƒ¼ã‚ºã‚¿ã‚¹ã‚¯å¼·åˆ¶: {detection_config['force_pose_task']}")

                # ğŸš€ yolopose_analyzer ã§ã®ç¢ºå®Ÿãªã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆæ¤œå‡ºå®Ÿè¡Œ
                try:
                    if not YOLOPOSE_ANALYZER_AVAILABLE:
                        raise ImportError("yolopose_analyzer ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“")
    
                    # ğŸ”§ ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆæ¤œå‡ºã‚’ç¢ºå®Ÿã«ã™ã‚‹è¨­å®š
                    enhanced_config = {
                        "models": {
                            "pose": pose_model_path
                        },
                        "processing": {
                            "confidence_threshold": 0.3,
                            "save_keypoints": True,
                            "keypoint_format": "coco",
                            "force_keypoint_detection": True,
                            "model_policy": {
                                "verify_pose_model": True,
                                "require_keypoints": True,
                                "use_pose_model": True
                            }
                        },
                        "tracking": {
                            "tracker_type": "bytetrack",
                            "track_thresh": 0.6,
                            "track_buffer": 60,
                            "match_thresh": 0.8
                        },
                        "output": {
                            "save_visualizations": True,
                            "save_csv": True,
                            "csv_include_keypoints": True
                        },
                        "inference": {
                            "batch_size": 16,
                            "device": "auto",
                            "task": "pose"  # ğŸ”§ configã®ä¸­ã§ã‚¿ã‚¹ã‚¯æŒ‡å®š
                        }
                    }
    
                    # æ—¢å­˜è¨­å®šã¨ãƒãƒ¼ã‚¸
                    base_config = {}
                    if hasattr(self.config, '__dict__'):
                        base_config = self.config.__dict__
                    elif hasattr(self.config, 'data'):
                        base_config = self.config.data
    
                    for key, value in base_config.items():
                        if key not in enhanced_config:
                            enhanced_config[key] = value
    
                    self.logger.info("ğŸš€ ç¢ºå®Ÿã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆæ¤œå‡ºã‚’å®Ÿè¡Œ")
    
                    # yolopose_analyzerå®Ÿè¡Œï¼ˆã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆé‡è¦–è¨­å®šï¼‰
                    detection_result = analyze_frames_with_tracking_enhanced(
                        frame_dir=str(frame_dir),
                        result_dir=str(output_dir),
                        model_path=pose_model_path,
                        config=enhanced_config,
                        force_exact_model=True  # ğŸ”§ ç¢ºå®Ÿãªãƒ¢ãƒ‡ãƒ«ä½¿ç”¨ãƒ•ãƒ©ã‚°
                    )
    
                    processing_type = "ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆçµ±åˆ"
    
                    # ğŸ” ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆæ¤œå‡ºçµæœã®è©³ç´°æ¤œè¨¼
                    if detection_result.get("success", False):
                        data = detection_result.get("data", {})
                        csv_path = data.get("csv_path")
        
                        if csv_path and Path(csv_path).exists():
                            # CSVå†…å®¹ã®è©³ç´°ç¢ºèª
                            import pandas as pd
                            df = pd.read_csv(csv_path)
            
                            self.logger.info("ğŸ” ========== ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆæ¤œå‡ºçµæœæ¤œè¨¼ ==========")
                            self.logger.info(f"ğŸ“Š æ¤œå‡ºãƒ‡ãƒ¼ã‚¿å½¢çŠ¶: {df.shape}")
                            self.logger.info(f"ğŸ“‹ å…¨åˆ—å: {df.columns.tolist()}")
            
                            # ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆåˆ—ã®ç¢ºèª
                            keypoint_cols = [col for col in df.columns if 'keypoint' in col.lower() or 'kpt' in col.lower()]
                            self.logger.info(f"ğŸ¦´ ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆé–¢é€£åˆ—: {len(keypoint_cols)}å€‹")
            
                            if keypoint_cols:
                                self.logger.info(f"âœ… ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆæ¤œå‡ºæˆåŠŸ: {keypoint_cols[:10]}...")
                
                                # 4ç‚¹ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆï¼ˆCOCOå½¢å¼ï¼‰ã®ç‰¹åˆ¥ç¢ºèª
                                target_keypoints = [3, 4, 5, 6]  # left_ear, right_ear, left_shoulder, right_shoulder
                                found_targets = []
                
                                for kpt_idx in target_keypoints:
                                    x_cols = [col for col in df.columns if f'keypoint_{kpt_idx}_x' in col or f'kpt_{kpt_idx}_x' in col]
                                    y_cols = [col for col in df.columns if f'keypoint_{kpt_idx}_y' in col or f'kpt_{kpt_idx}_y' in col]
                    
                                    if x_cols and y_cols:
                                        found_targets.append(f"COCO#{kpt_idx}")
                                        self.logger.info(f"âœ… COCO#{kpt_idx}ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆç™ºè¦‹: {x_cols[0]}, {y_cols[0]}")
                
                                if len(found_targets) >= 3:
                                    self.logger.info(f"ğŸ¯ 4ç‚¹ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆæ¤œå‡ºçŠ¶æ³: {len(found_targets)}/4ç‚¹ç™ºè¦‹")
                                    self.logger.info(f"  ç™ºè¦‹: {found_targets}")
                                else:
                                    self.logger.warning(f"âš ï¸ 4ç‚¹ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆä¸å®Œå…¨: {len(found_targets)}/4ç‚¹ã®ã¿")
                                    self.logger.warning(f"  ç™ºè¦‹æ¸ˆã¿: {found_targets}")
                            else:
                                self.logger.error("âŒ ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆåˆ—ãŒä¸€åˆ‡æ¤œå‡ºã•ã‚Œã¦ã„ã¾ã›ã‚“ï¼")
                                self.logger.error("ğŸ”§ åŸå› : ãƒãƒ¼ã‚ºãƒ¢ãƒ‡ãƒ«ãŒæ­£ã—ãå‹•ä½œã—ã¦ã„ãªã„å¯èƒ½æ€§")
                
                                # ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã®è¡¨ç¤º
                                if not df.empty:
                                    self.logger.error("ğŸ“‹ æ¤œå‡ºã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã‚µãƒ³ãƒ—ãƒ«:")
                                    for col in df.columns[:10]:
                                        sample_value = df.iloc[0][col] if len(df) > 0 else "N/A"
                                        self.logger.error(f"  {col}: {sample_value}")
                        else:
                            self.logger.error(f"âŒ æ¤œå‡ºçµæœCSVãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {csv_path}")
                    else:
                        error_msg = detection_result.get("error", "ä¸æ˜ãªã‚¨ãƒ©ãƒ¼")
                        self.logger.error(f"âŒ ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆæ¤œå‡ºå¤±æ•—: {error_msg}")
                        self.error_collector.append(f"ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆæ¤œå‡ºå¤±æ•—: {error_msg}")
                        raise VideoProcessingError(error_msg)

                except ImportError as e:
                    self.logger.error(f"âŒ yolopose_analyzer ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
                    self.logger.warning("ğŸ”„ BasicVideoProcessor ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼ˆã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆæ©Ÿèƒ½åˆ¶é™ï¼‰")
    
                    # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç†
                    if self.depth_enabled and hasattr(self.processor, 'run_detection_tracking_with_depth'):
                        detection_result = self.processor.run_detection_tracking_with_depth(frame_dir, video_name)
                    else:
                        detection_result = self.processor.run_detection_tracking(frame_dir, video_name)
    
                    processing_type = "åŸºæœ¬æ¤œå‡ºï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰"
    
                    # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æ™‚ã®è­¦å‘Š
                    self.logger.warning("âš ï¸ yolopose_analyzerãŒåˆ©ç”¨ã§ããªã„ãŸã‚ã€ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆæ©Ÿèƒ½ãŒåˆ¶é™ã•ã‚Œã¾ã™")
                    self.logger.warning("ğŸ’¡ è§£æ±ºç­–: pip install yolopose-analyzer ã§ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¦ãã ã•ã„")

                except Exception as e:
                    self.logger.error(f"âŒ ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆæ¤œå‡ºå‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
                    import traceback
                    self.logger.error(f"ğŸ”§ è©³ç´°ãƒˆãƒ¬ãƒ¼ã‚¹ãƒãƒƒã‚¯: {traceback.format_exc()}")
                    self.error_collector.append(f"ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆæ¤œå‡ºã‚¨ãƒ©ãƒ¼: {e}")
                    raise VideoProcessingError(f"ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆæ¤œå‡ºã«å¤±æ•—: {e}")

                # ğŸ”§ Step 2çµæœã®æœ€çµ‚ç¢ºèª
                if not detection_result.get("success", False):
                    error_msg = detection_result.get("error", "ä¸æ˜ãªã‚¨ãƒ©ãƒ¼")
                    self.logger.error(f"âŒ {processing_type}å‡¦ç†ã‚¨ãƒ©ãƒ¼: {error_msg}")
                    self.error_collector.append(f"{processing_type}å‡¦ç†å¤±æ•—: {error_msg}")
                    raise VideoProcessingError(error_msg)

                self.logger.info(f"âœ… Step 2å®Œäº†: {processing_type}å‡¦ç†")

                # ğŸ”§ æ¤œå‡ºçµ±è¨ˆã®è¡¨ç¤º
                if detection_result.get("success", False):
                    data = detection_result.get("data", {})
                    detection_count = data.get("detection_count", 0)
                    frame_count = data.get("frame_count", 0)
    
                    self.logger.info(f"ğŸ“Š æ¤œå‡ºçµ±è¨ˆ:")
                    self.logger.info(f"  - ç·æ¤œå‡ºæ•°: {detection_count}")
                    self.logger.info(f"  - å‡¦ç†ãƒ•ãƒ¬ãƒ¼ãƒ æ•°: {frame_count}")
    
                    if frame_count > 0:
                        detection_rate = (detection_count / frame_count)
                        self.logger.info(f"  - ãƒ•ãƒ¬ãƒ¼ãƒ å½“ãŸã‚Šæ¤œå‡ºæ•°: {detection_rate:.2f}")

                # ğŸ¯ Step 2.5: 4ç‚¹ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆå‡¦ç†ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
                try:
                    original_csv = detection_result["data"]["csv_path"]
                    filtered_result = self.filter_keypoints_to_4points(original_csv, output_dir)
                    
                    # ğŸ”§ ä¿®æ­£: è¾æ›¸ã‹ã‚‰å®Ÿéš›ã®CSVãƒ‘ã‚¹ã‚’å–å¾—
                    if isinstance(filtered_result, dict) and filtered_result.get("success"):
                        filtered_csv = filtered_result.get("fourpoint_csv")
                        metrics_csv = filtered_result.get("metrics_csv")
                        
                        # çµæœã«4ç‚¹æƒ…å ±è¿½åŠ 
                        detection_result["data"]["filtered_csv_path"] = filtered_csv
                        detection_result["data"]["metrics_csv_path"] = metrics_csv
                        detection_result["data"]["keypoint_mode"] = "4_points"
                        
                        # ğŸ”§ ä¿®æ­£: CSVãƒ‘ã‚¹ï¼ˆæ–‡å­—åˆ—ï¼‰ã‚’æ¸¡ã™
                        if filtered_csv and Path(filtered_csv).exists():
                            self.logger.info(f"ğŸ¨ 4ç‚¹å¯è¦–åŒ–ç”Ÿæˆ: {filtered_csv}")
                            vis_result = self.create_4point_visualization(filtered_csv, video_path, output_dir)
                        #                                                ^^^^^^^^^^ 
                        #                                                æ–‡å­—åˆ—ãƒ‘ã‚¹ã‚’æ¸¡ã™
                        else:
                            self.logger.error(f"âŒ 4ç‚¹CSVãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {filtered_csv}")
                            vis_result = {"success": False, "error": "4ç‚¹CSVãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“"}
                    else:
                        self.logger.error(f"âŒ 4ç‚¹ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°å¤±æ•—: {filtered_result}")
                        vis_result = {"success": False, "error": "4ç‚¹ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°å¤±æ•—"}
                
                except Exception as e:
                    self.logger.error(f"âŒ 4ç‚¹å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
                    vis_result = {"success": False, "error": str(e)}

                # Step 3: åŒ…æ‹¬çš„è©•ä¾¡
                self.logger.info("ğŸ“Š Step 3: åŒ…æ‹¬çš„è©•ä¾¡é–‹å§‹")
                
                # è©•ä¾¡ãƒ¡ã‚½ãƒƒãƒ‰ã®é¸æŠ
                if hasattr(self.evaluator, 'evaluate_with_depth') and self.depth_enabled:
                    evaluation_result = self.evaluator.evaluate_with_depth(
                        video_path, detection_result, video_name
                    )
                else:
                    evaluation_result = self.evaluator.evaluate_comprehensive(
                        video_path, detection_result, video_name
                    )

                if not evaluation_result.get("success", False):
                    error_msg = f"è©•ä¾¡å‡¦ç†å¤±æ•—: {evaluation_result.get('error', {}).get('message', 'ä¸æ˜ãªã‚¨ãƒ©ãƒ¼')}"
                    self.error_collector.append(error_msg)
                    self.logger.warning(f"âš ï¸ {error_msg}")
                    # è©•ä¾¡å¤±æ•—ã¯è­¦å‘Šã«ç•™ã‚ã‚‹
                    evaluation_result = ResponseBuilder.success(data={
                        "basic_evaluation": True, 
                        "fallback": True,
                        "evaluator_type": type(self.evaluator).__name__
                    })

                self.logger.info("âœ… Step 3å®Œäº†: åŒ…æ‹¬çš„è©•ä¾¡")

                # Step 4: å¯è¦–åŒ–ç”Ÿæˆï¼ˆæ—¥æ™‚å¯¾å¿œä¿®æ­£ï¼‰
                self.logger.info("ğŸ“ˆ Step 4: å¯è¦–åŒ–ç”Ÿæˆé–‹å§‹")
            
                # ğŸ”§ ä¿®æ­£: æ—¥æ™‚ä»˜ãå¯è¦–åŒ–ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
                vis_timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                vis_dir = output_dir / f"visualizations_{vis_timestamp}"
                vis_dir.mkdir(exist_ok=True)

                try:
                    # ğŸ”§ æˆ»ã‚Šå€¤ã‚’å—ã‘å–ã£ã¦è©³ç´°ãƒ­ã‚°å‡ºåŠ›
                    vis_result = self.analyzer.create_visualizations(detection_result, vis_dir)
    
                    # ğŸ”§ None ãƒã‚§ãƒƒã‚¯ã‚’è¿½åŠ 
                    if vis_result is None:
                        self.logger.warning("âš ï¸ Step 4è­¦å‘Š: å¯è¦–åŒ–ãƒ¡ã‚½ãƒƒãƒ‰ãŒNoneã‚’è¿”ã—ã¾ã—ãŸ")
                        vis_result = {"success": False, "error": "å¯è¦–åŒ–ãƒ¡ã‚½ãƒƒãƒ‰ãŒNoneã‚’è¿”ã—ã¾ã—ãŸ"}
                    elif not isinstance(vis_result, dict):
                        self.logger.warning(f"âš ï¸ Step 4è­¦å‘Š: äºˆæœŸã—ãªã„æˆ»ã‚Šå€¤å‹: {type(vis_result)}")
                        vis_result = {"success": False, "error": f"äºˆæœŸã—ãªã„æˆ»ã‚Šå€¤å‹: {type(vis_result)}"}
    
                    # ğŸ”§ å®‰å…¨ãªæˆåŠŸåˆ¤å®š
                    if vis_result.get("success", False):
                        total_files = vis_result.get("total_files", 0)
                        graphs_count = vis_result.get("graphs_generated", 0)
                        self.logger.info(f"âœ… Step 4å®Œäº†: å¯è¦–åŒ–ç”Ÿæˆ ({total_files}å€‹ã®ãƒ•ã‚¡ã‚¤ãƒ«, {graphs_count}å€‹ã®ã‚°ãƒ©ãƒ•)")
                    else:
                        error_msg = vis_result.get("error", "ä¸æ˜ãªã‚¨ãƒ©ãƒ¼")
                        self.logger.warning(f"âš ï¸ Step 4è­¦å‘Š: å¯è¦–åŒ–ç”Ÿæˆã‚¨ãƒ©ãƒ¼ï¼ˆå‡¦ç†ç¶™ç¶šï¼‰: {error_msg}")
                        self.error_collector.append(f"å¯è¦–åŒ–ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {error_msg}")
        
                except Exception as e:
                    self.logger.warning(f"âš ï¸ Step 4è­¦å‘Š: å¯è¦–åŒ–ç”Ÿæˆã‚¨ãƒ©ãƒ¼ï¼ˆå‡¦ç†ç¶™ç¶šï¼‰: {e}")
                    self.logger.error(f"ğŸ”§ Step 4è©³ç´°ã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
                    self.error_collector.append(f"å¯è¦–åŒ–ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
                    # ğŸ”§ ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”¨ã®ãƒ€ãƒŸãƒ¼çµæœ
                    vis_result = {"success": False, "error": str(e)}

                # çµ±åˆçµæœã®æ§‹ç¯‰ï¼ˆæ—¥æ™‚æƒ…å ±è¿½åŠ ï¼‰
                integrated_result = {
                    "success": True,
                    "video_name": video_name,
                    "video_path": str(video_path),
                    "processing_type": processing_type,
                    "depth_enabled": self.depth_enabled,
                    "output_directory": str(output_dir),
                    "visualization_path": str(vis_dir),
                    "processing_timestamp": datetime.now().isoformat(),
                    "folder_timestamp": timestamp,  # ğŸ”§ è¿½åŠ : ãƒ•ã‚©ãƒ«ãƒ€ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—
                    "visualization_timestamp": vis_timestamp,  # ğŸ”§ è¿½åŠ : å¯è¦–åŒ–ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—
                    "frame_extraction": frame_result,
                    "detection_tracking": detection_result,
                    "evaluation": evaluation_result,
                    "errors": self.error_collector.copy() if self.error_collector else [],
                    "system_info": {
                        "evaluator_type": type(self.evaluator).__name__,
                        "processor_type": type(self.processor).__name__,
                        "analyzer_type": type(self.analyzer).__name__,
                        "config_type": type(self.config).__name__,
                        "module_availability": {
                            "error_handler": ERROR_HANDLER_AVAILABLE,
                            "comprehensive_evaluator": COMPREHENSIVE_EVALUATOR_AVAILABLE,
                            "depth_evaluator": DEPTH_EVALUATOR_AVAILABLE,
                            "video_processor": VIDEO_PROCESSOR_AVAILABLE,
                            "metrics_analyzer": METRICS_ANALYZER_AVAILABLE,
                            "config": CONFIG_AVAILABLE,
                            "logger": LOGGER_AVAILABLE
                        }
                    }
                }

                # çµæœãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
                result_file = output_dir / f"{video_name}_baseline_result.json"
                with open(result_file, 'w', encoding='utf-8') as f:
                    json.dump(integrated_result, f, indent=2, ensure_ascii=False)

                if hasattr(ctx, 'add_info'):
                    ctx.add_info("result_file", str(result_file))
                    ctx.add_info("processing_success", True)

                self.logger.info(f"ğŸ‰ ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³åˆ†æå®Œäº†: {video_name}")
                self.logger.info(f"ğŸ“ çµæœä¿å­˜å…ˆ: {output_dir}")
                self.logger.info(f"ğŸ“„ çµæœãƒ•ã‚¡ã‚¤ãƒ«: {result_file}")

                return ResponseBuilder.success(data=integrated_result)

            except VideoProcessingError as e:
                self.logger.error(f"âŒ å‹•ç”»å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
                if hasattr(ctx, 'add_info'):
                    ctx.add_info("error_type", "VideoProcessingError")
                    ctx.add_info("error_message", str(e))
                return ResponseBuilder.error(e, suggestions=[
                    "å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã®å½¢å¼ã‚’ç¢ºèªã—ã¦ãã ã•ã„",
                    "å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ãŒç ´æã—ã¦ã„ãªã„ã‹ç¢ºèªã—ã¦ãã ã•ã„",
                    f"å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª {output_dir} ã¸ã®æ›¸ãè¾¼ã¿æ¨©é™ã‚’ç¢ºèªã—ã¦ãã ã•ã„"
                ])
            
            except Exception as e:
                self.logger.error(f"âŒ äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼: {e}")
                if hasattr(ctx, 'add_info'):
                    ctx.add_info("error_type", "UnexpectedError")
                    ctx.add_info("error_message", str(e))
                return ResponseBuilder.error(e, suggestions=[
                    "ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã§è©³ç´°ãªã‚¨ãƒ©ãƒ¼æƒ…å ±ã‚’ç¢ºèªã—ã¦ãã ã•ã„",
                    "è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãŒæ­£ã—ãè¨­å®šã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„",
                    "å¿…è¦ãªãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã™ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„"
                ])
    
    # Line 1100ä»˜è¿‘ï¼ˆrun_baseline_analysisãƒ¡ã‚½ãƒƒãƒ‰ã®ç›´å¾Œï¼‰ã«è¿½åŠ :

    # å®Œå…¨ç½®æ›: Line 2184-2296
    def filter_keypoints_to_4points(self, csv_path, output_dir):
        """
        ğŸ¯ 4ç‚¹ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ï¼ˆå®Œå…¨ä¿®æ­£ç‰ˆï¼‰
    
        ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆæ¤œå‡ºå¤±æ•—æ™‚ã¯ç–‘ä¼¼ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆã§ã¯ãªãã€
        æ ¹æœ¬åŸå› ã®ç‰¹å®šã¨è§£æ±ºã‚’ä¿ƒé€²ã™ã‚‹ã€‚
        """
        try:
            self.logger.info("ğŸ¯ 4ç‚¹ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°é–‹å§‹")
            self.logger.info(f"ğŸ“‚ å…¥åŠ›CSV: {csv_path}")
        
            # CSVãƒ•ã‚¡ã‚¤ãƒ«å­˜åœ¨ç¢ºèª
            if not Path(csv_path).exists():
                self.logger.error(f"âŒ CSVãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ã¾ã›ã‚“: {csv_path}")
                raise FileNotFoundError(f"CSVãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {csv_path}")
        
            # CSVãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
            try:
                df = pd.read_csv(csv_path)
                self.logger.info(f"ğŸ“Š CSVèª­ã¿è¾¼ã¿å®Œäº†: {len(df)}è¡Œ, {len(df.columns)}åˆ—")
            except Exception as csv_error:
                self.logger.error(f"âŒ CSVèª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {csv_error}")
                raise
        
            # ğŸ”§ ä¿®æ­£: ã‚ˆã‚Šè©³ç´°ãªåˆ—è¨ºæ–­ã¨ã‚¨ãƒ©ãƒ¼å‡¦ç†
            df = pd.read_csv(csv_path)
            self.logger.info(f"ğŸ“‹ æ¤œå‡ºã•ã‚ŒãŸå…¨åˆ—: {list(df.columns)}")
        
            # ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆåˆ—ã®å­˜åœ¨ç¢ºèªï¼ˆè©³ç´°è¨ºæ–­ï¼‰
            keypoint_columns = [col for col in df.columns if col.endswith(('_x', '_y', '_conf'))]
        
            if not keypoint_columns:
                # ğŸš¨ ä¿®æ­£: ç–‘ä¼¼ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆã‚’å®Œå…¨ã«ç¦æ­¢ã—ã€æ ¹æœ¬åŸå› ã‚’ç‰¹å®š
                self.logger.error("ğŸš¨ è‡´å‘½çš„: ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆåˆ—ãŒä¸€åˆ‡æ¤œå‡ºã•ã‚Œã¦ã„ã¾ã›ã‚“")
                self.logger.error(f"ğŸ“Š æ¤œå‡ºã•ã‚ŒãŸåˆ—: {list(df.columns)}")
                self.logger.error("ğŸ” æ ¹æœ¬åŸå› è¨ºæ–­:")
                self.logger.error("ğŸ’¡ è§£æ±ºç­–1: YOLOãƒãƒ¼ã‚ºãƒ¢ãƒ‡ãƒ«(-pose.pt)ãŒä½¿ç”¨ã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèª")
                self.logger.error("ğŸ’¡ è§£æ±ºç­–2: core.pyã®ãƒãƒ¼ã‚ºã‚¿ã‚¹ã‚¯æŒ‡å®šãŒæ­£ã—ã„ã‹ç¢ºèª")
                self.logger.error("ğŸ’¡ è§£æ±ºç­–3: trackerè¨­å®šãŒæ­£ã—ãè¨­å®šã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèª")
            
                # ğŸš¨ ä¿®æ­£: ç–‘ä¼¼ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆã¯çµ¶å¯¾ã«è¡Œã‚ãªã„
                raise ValueError(
                    "ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆæ¤œå‡ºãŒå®Œå…¨ã«å¤±æ•—ã—ã¦ã„ã¾ã™ã€‚"
                    "YOLOãƒãƒ¼ã‚ºãƒ¢ãƒ‡ãƒ«(-pose.pt)ã®è¨­å®šã¨core.pyã®ãƒãƒ¼ã‚ºã‚¿ã‚¹ã‚¯æŒ‡å®šã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚"
                )
            
                # ğŸ”§ ä¿®æ­£: æ ¹æœ¬åŸå› ã®è¨ºæ–­æƒ…å ±ã‚’æä¾›
                self.logger.error("ğŸ” æ ¹æœ¬åŸå› è¨ºæ–­:")
                self.logger.error("ğŸ’¡ è§£æ±ºç­–1: YOLOãƒãƒ¼ã‚ºãƒ¢ãƒ‡ãƒ«(-pose.pt)ãŒä½¿ç”¨ã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèª")
                self.logger.error("ğŸ’¡ è§£æ±ºç­–2: core.pyã®ãƒãƒ¼ã‚ºã‚¿ã‚¹ã‚¯æŒ‡å®šãŒæ­£ã—ã„ã‹ç¢ºèª")
                self.logger.error("ğŸ’¡ è§£æ±ºç­–3: trackerè¨­å®šãŒæ­£ã—ãè¨­å®šã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèª")
            
                # CSVã®åŸºæœ¬æƒ…å ±ã‚’ãƒ­ã‚°å‡ºåŠ›
                if 'frame' in df.columns and 'person_id' in df.columns:
                    self.logger.error(f"ğŸ“Š åŸºæœ¬æ¤œå‡ºãƒ‡ãƒ¼ã‚¿ã¯å­˜åœ¨: ãƒ•ãƒ¬ãƒ¼ãƒ æ•° {df['frame'].nunique()}, äººç‰©æ¤œå‡º {len(df)}")
                    self.logger.error("ğŸš¨ ã—ã‹ã—ã€ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆæ¤œå‡ºãŒå®Œå…¨ã«å¤±æ•—ã—ã¦ã„ã¾ã™")
                else:
                    self.logger.error("ğŸš¨ åŸºæœ¬æ¤œå‡ºãƒ‡ãƒ¼ã‚¿ã‚‚ç•°å¸¸ã§ã™")
            
                # ğŸš¨ ä¿®æ­£: ç–‘ä¼¼ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆã¯çµ¶å¯¾ã«è¡Œã‚ãªã„
                raise ValueError(
                    "ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆæ¤œå‡ºãŒå®Œå…¨ã«å¤±æ•—ã—ã¦ã„ã¾ã™ã€‚"
                    "YOLOãƒãƒ¼ã‚ºãƒ¢ãƒ‡ãƒ«(-pose.pt)ã®è¨­å®šã¨core.pyã®ãƒãƒ¼ã‚ºã‚¿ã‚¹ã‚¯æŒ‡å®šã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚"
                    "ç–‘ä¼¼ãƒ‡ãƒ¼ã‚¿ã§ã®å‡¦ç†ã¯è¡Œã„ã¾ã›ã‚“ã€‚"
                )
        
            self.logger.info(f"âœ… ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆåˆ—æ¤œå‡º: {len(keypoint_columns)}å€‹")
        
            # ğŸ¯ ä¿®æ­£: 4ç‚¹ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆï¼ˆCOCOãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆï¼‰ã®ç¢ºå®ŸãªæŠ½å‡º
            target_keypoints = {
                "left_ear": 3,      # COCO: 3ç•ª
                "right_ear": 4,     # COCO: 4ç•ª  
                "left_shoulder": 5, # COCO: 5ç•ª
                "right_shoulder": 6 # COCO: 6ç•ª
            }
        
            # ğŸ”§ ä¿®æ­£: ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆåˆ—ã®å­˜åœ¨ç¢ºèªã‚’å¼·åŒ–
            missing_keypoints = []
            available_keypoints = {}
        
            for kpt_name, kpt_idx in target_keypoints.items():
                x_col = f"{kpt_name}_x"
                y_col = f"{kpt_name}_y"
                conf_col = f"{kpt_name}_conf"
            
                if all(col in df.columns for col in [x_col, y_col, conf_col]):
                    available_keypoints[kpt_name] = {
                        'x': x_col, 'y': y_col, 'conf': conf_col,
                        'coco_idx': kpt_idx
                    }
                    self.logger.debug(f"âœ… ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆåˆ©ç”¨å¯èƒ½: {kpt_name}")
                else:
                    missing_keypoints.append(kpt_name)
                    self.logger.error(f"âŒ æ¬ æã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆ: {kpt_name}")
                
                    # ã©ã®åˆ—ãŒä¸è¶³ã—ã¦ã„ã‚‹ã‹ã‚’è©³ç´°ã«å ±å‘Š
                    missing_cols = [col for col in [x_col, y_col, conf_col] if col not in df.columns]
                    self.logger.error(f"   ä¸è¶³åˆ—: {missing_cols}")
        
            if missing_keypoints:
                self.logger.error(f"ğŸš¨ å¿…è¦ãª4ç‚¹ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆãŒä¸è¶³: {missing_keypoints}")
                self.logger.error(f"âœ… åˆ©ç”¨å¯èƒ½ãªã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆ: {list(available_keypoints.keys())}")
            
                # éƒ¨åˆ†çš„ãªå‡¦ç†ã‚’ææ¡ˆ
                if len(available_keypoints) >= 2:
                    self.logger.warning(f"âš ï¸ éƒ¨åˆ†çš„ãªå‡¦ç†ãŒå¯èƒ½: {len(available_keypoints)}/4ç‚¹")
                    self.logger.warning("ğŸ”§ åˆ©ç”¨å¯èƒ½ãªã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆã®ã¿ã§å‡¦ç†ã‚’ç¶šè¡Œã—ã¾ã™")
                else:
                    raise ValueError(
                        f"4ç‚¹ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã«å¿…è¦ãªã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆãŒä¸è¶³ã—ã¦ã„ã¾ã™: {missing_keypoints}\n"
                        f"åˆ©ç”¨å¯èƒ½: {list(available_keypoints.keys())}\n"
                        "æœ€ä½2ç‚¹ã®ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆãŒå¿…è¦ã§ã™ã€‚"
                    )
        
            self.logger.info(f"ğŸ¯ ä½¿ç”¨ã™ã‚‹ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆ: {list(available_keypoints.keys())}")
        
            # ğŸ¯ 4ç‚¹ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°å‡¦ç†ã®å®Ÿè¡Œ
            filtered_data = []
            confidence_threshold = 0.3  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆä¿¡é ¼åº¦é–¾å€¤
        
            if hasattr(self, 'config') and self.config:
                confidence_threshold = self.config.get('processing', {}).get('keypoint_confidence_threshold', 0.3)
        
            self.logger.info(f"ğŸ¯ ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆä¿¡é ¼åº¦é–¾å€¤: {confidence_threshold}")
        
            total_detections = len(df)
            valid_detections = 0
        
            for idx, row in df.iterrows():
                # åŸºæœ¬æ¤œå‡ºæƒ…å ±ã‚’ä¿æŒ
                filtered_row = {
                    'frame': row['frame'],
                    'person_id': row['person_id'],
                    'x1': row['x1'],
                    'y1': row['y1'], 
                    'x2': row['x2'],
                    'y2': row['y2'],
                    'conf': row['conf'],
                    'class_name': row['class_name']
                }
            
                # 4ç‚¹ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆæƒ…å ±ã‚’è¿½åŠ 
                valid_keypoints_count = 0
            
                for kpt_name, kpt_info in available_keypoints.items():
                    x_val = row[kpt_info['x']]
                    y_val = row[kpt_info['y']]
                    conf_val = row[kpt_info['conf']]
                
                    # ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ 
                    filtered_row[f"{kpt_name}_x"] = x_val
                    filtered_row[f"{kpt_name}_y"] = y_val
                    filtered_row[f"{kpt_name}_conf"] = conf_val
                
                    # æœ‰åŠ¹æ€§ãƒã‚§ãƒƒã‚¯
                    if conf_val >= confidence_threshold and x_val > 0 and y_val > 0:
                        valid_keypoints_count += 1
            
                # ä¸è¶³ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆã¯ã‚¼ãƒ­åŸ‹ã‚
                for missing_kpt in missing_keypoints:
                    filtered_row[f"{missing_kpt}_x"] = 0.0
                    filtered_row[f"{missing_kpt}_y"] = 0.0
                    filtered_row[f"{missing_kpt}_conf"] = 0.0
            
                # æœ‰åŠ¹ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆãŒååˆ†ãªå ´åˆã®ã¿ä¿æŒ
                min_valid_keypoints = max(1, len(available_keypoints) // 2)  # æœ€ä½åŠåˆ†
                if valid_keypoints_count >= min_valid_keypoints:
                    filtered_data.append(filtered_row)
                    valid_detections += 1
            
            self.logger.info(f"ğŸ“Š ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°çµæœ: {valid_detections}/{total_detections} ({valid_detections/total_detections*100:.1f}%)")
        
            if not filtered_data:
                self.logger.error("ğŸš¨ ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°å¾Œã®ãƒ‡ãƒ¼ã‚¿ãŒç©ºã§ã™")
                self.logger.error(f"ä¿¡é ¼åº¦é–¾å€¤ {confidence_threshold} ã‚’ä¸‹ã’ã‚‹ã“ã¨ã‚’æ¤œè¨ã—ã¦ãã ã•ã„")
                raise ValueError("ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°å¾Œã®ãƒ‡ãƒ¼ã‚¿ãŒç©ºã§ã™ã€‚ä¿¡é ¼åº¦é–¾å€¤ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        
            # ğŸ¯ 4ç‚¹ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ä½œæˆ
            filtered_df = pd.DataFrame(filtered_data)
        
            # ğŸ¯ 4ç‚¹å°‚ç”¨ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨ˆç®—ï¼ˆå®Ÿãƒ‡ãƒ¼ã‚¿ç‰ˆï¼‰
            self.logger.info("ğŸ“Š 4ç‚¹å°‚ç”¨ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨ˆç®—é–‹å§‹")
            metrics_df = self._add_4point_metrics(filtered_df)
        
            # çµæœä¿å­˜
            os.makedirs(output_dir, exist_ok=True)
        
            # 4ç‚¹ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°æ¸ˆã¿CSV
            fourpoint_csv_path = os.path.join(output_dir, "4point_keypoints.csv")
            filtered_df.to_csv(fourpoint_csv_path, index=False)
        
            # 4ç‚¹ãƒ¡ãƒˆãƒªã‚¯ã‚¹ä»˜ãCSV
            metrics_csv_path = os.path.join(output_dir, "4point_metrics.csv")
            metrics_df.to_csv(metrics_csv_path, index=False)
        
            self.logger.info(f"âœ… 4ç‚¹ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°å®Œäº†")
            self.logger.info(f"ğŸ“ 4ç‚¹ãƒ‡ãƒ¼ã‚¿ä¿å­˜: {fourpoint_csv_path}")
            self.logger.info(f"ğŸ“ ãƒ¡ãƒˆãƒªã‚¯ã‚¹ä¿å­˜: {metrics_csv_path}")
        
            return {
                "success": True,
                "fourpoint_csv": fourpoint_csv_path,
                "metrics_csv": metrics_csv_path,
                "valid_detections": valid_detections,
                "total_detections": total_detections,
                "filter_rate": valid_detections / total_detections,
                "available_keypoints": list(available_keypoints.keys()),
                "missing_keypoints": missing_keypoints,
                "confidence_threshold": confidence_threshold
            }
        
        except Exception as e:
            self.logger.error(f"âŒ 4ç‚¹ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã‚¨ãƒ©ãƒ¼: {e}")
            raise

    def _add_4point_metrics(self, df):
        """4ç‚¹ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆå°‚ç”¨ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨ˆç®—ï¼ˆå®Ÿãƒ‡ãƒ¼ã‚¿ç‰ˆãƒ»ä¿®æ­£ç‰ˆï¼‰"""
        try:
            self.logger.info("ğŸ“Š 4ç‚¹ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨ˆç®—é–‹å§‹")
        
            # ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã®ã‚³ãƒ”ãƒ¼ã‚’ä½œæˆ
            metrics_df = df.copy()
        
            # ğŸ¯ åŸºæœ¬ãƒ¡ãƒˆãƒªã‚¯ã‚¹åˆæœŸåŒ–
            metrics_df['shoulder_width'] = 0.0
            metrics_df['head_center_x'] = 0.0
            metrics_df['head_center_y'] = 0.0
            metrics_df['shoulder_center_x'] = 0.0 # å·¦å³è‚©ã®ä¸­å¿ƒX
            metrics_df['shoulder_center_y'] = 0.0 # å·¦å³è‚©ã®ä¸­å¿ƒY
            metrics_df['pose_angle'] = 0.0
            metrics_df['keypoint_completeness'] = 0.0
            metrics_df['pose_confidence'] = 0.0
        
            # ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨ˆç®—çµ±è¨ˆ
            calculated_count = 0
            shoulder_width_count = 0
            head_position_count = 0
            shoulder_center_count = 0
            pose_angle_count = 0
        
            for idx, row in metrics_df.iterrows():
                try:
                    # ğŸ¯ è‚©å¹…è¨ˆç®—ï¼ˆleft_shoulder, right_shoulderï¼‰
                    if ('left_shoulder_x' in row and 'right_shoulder_x' in row and
                        'left_shoulder_y' in row and 'right_shoulder_y' in row and
                        'left_shoulder_conf' in row and 'right_shoulder_conf' in row):
                    
                        left_shoulder_conf = float(row['left_shoulder_conf'])
                        right_shoulder_conf = float(row['right_shoulder_conf'])
                    
                        if left_shoulder_conf > 0.3 and right_shoulder_conf > 0.3:
                            left_x, left_y = float(row['left_shoulder_x']), float(row['left_shoulder_y'])
                            right_x, right_y = float(row['right_shoulder_x']), float(row['right_shoulder_y'])
                        
                            if left_x > 0 and left_y > 0 and right_x > 0 and right_y > 0:
                                # è‚©å¹…è¨ˆç®—
                                shoulder_width = np.sqrt((right_x - left_x) ** 2 + (right_y - left_y) ** 2)
                                metrics_df.at[idx, 'shoulder_width'] = shoulder_width
                                shoulder_width_count += 1
                            
                                # ğŸ”§ è‚©ä¸­ç‚¹è¨ˆç®—
                                shoulder_center_x = (left_x + right_x) / 2
                                shoulder_center_y = (left_y + right_y) / 2
                                metrics_df.at[idx, 'shoulder_center_x'] = shoulder_center_x
                                metrics_df.at[idx, 'shoulder_center_y'] = shoulder_center_y
                                shoulder_center_count += 1
                
                    # ğŸ¯ é ­éƒ¨ä¸­å¿ƒä½ç½®è¨ˆç®—ï¼ˆleft_ear, right_earï¼‰
                    if ('left_ear_x' in row and 'right_ear_x' in row and
                        'left_ear_y' in row and 'right_ear_y' in row and
                        'left_ear_conf' in row and 'right_ear_conf' in row):
                    
                        left_ear_conf = float(row['left_ear_conf'])
                        right_ear_conf = float(row['right_ear_conf'])
                    
                        if left_ear_conf > 0.3 and right_ear_conf > 0.3:
                            left_x, left_y = float(row['left_ear_x']), float(row['left_ear_y'])
                            right_x, right_y = float(row['right_ear_x']), float(row['right_ear_y'])
                        
                            if left_x > 0 and left_y > 0 and right_x > 0 and right_y > 0:
                            # ğŸ”§ head_centerè¨ˆç®—ï¼ˆä¸¡è€³ã®ä¸­ç‚¹ï¼‰
                                head_center_x = (left_x + right_x) / 2
                                head_center_y = (left_y + right_y) / 2
                                metrics_df.at[idx, 'head_center_x'] = head_center_x
                                metrics_df.at[idx, 'head_center_y'] = head_center_y
                                head_position_count += 1
                
                    # ğŸ¯ å§¿å‹¢è§’åº¦è¨ˆç®—ï¼ˆè‚©ã®ãƒ©ã‚¤ãƒ³ï¼‰
                    if (metrics_df.at[idx, 'shoulder_width'] > 0 and
                        'left_shoulder_x' in row and 'right_shoulder_x' in row and
                        'left_shoulder_y' in row and 'right_shoulder_y' in row):
                    
                        left_x, left_y = float(row['left_shoulder_x']), float(row['left_shoulder_y'])
                        right_x, right_y = float(row['right_shoulder_x']), float(row['right_shoulder_y'])
                    
                        if left_x > 0 and right_x > 0:
                            # è‚©ã®ãƒ©ã‚¤ãƒ³ã®è§’åº¦è¨ˆç®—
                            angle_rad = np.arctan2(right_y - left_y, right_x - left_x)
                            angle_deg = np.degrees(angle_rad)
                            metrics_df.at[idx, 'pose_angle'] = angle_deg
                            pose_angle_count += 1
                
                    # ğŸ¯ ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆå®Œå…¨æ€§ã‚¹ã‚³ã‚¢
                    available_keypoints = ['left_ear', 'right_ear', 'left_shoulder', 'right_shoulder']
                    valid_keypoints = 0
                    total_keypoints = len(available_keypoints)
                
                    for kpt in available_keypoints:
                        x_col, y_col, conf_col = f"{kpt}_x", f"{kpt}_y", f"{kpt}_conf"
                        if (x_col in row and y_col in row and conf_col in row):
                            if float(row[conf_col]) > 0.3 and float(row[x_col]) > 0 and float(row[y_col]) > 0:
                                valid_keypoints += 1
                
                    completeness = valid_keypoints / total_keypoints
                    metrics_df.at[idx, 'keypoint_completeness'] = completeness
                
                    # ğŸ¯ ãƒãƒ¼ã‚ºä¿¡é ¼åº¦ï¼ˆåŸºæœ¬æ¤œå‡ºä¿¡é ¼åº¦ Ã— ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆå®Œå…¨æ€§ï¼‰
                    pose_confidence = float(row['conf']) * completeness
                    metrics_df.at[idx, 'pose_confidence'] = pose_confidence
                
                    calculated_count += 1
                
                except Exception as row_error:
                    self.logger.debug(f"è¡Œ {idx} ã®ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨ˆç®—ã‚¨ãƒ©ãƒ¼: {row_error}")
                    continue
        
            # è¨ˆç®—çµæœçµ±è¨ˆ
            total_rows = len(metrics_df)
            self.logger.info(f"ğŸ“Š ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨ˆç®—å®Œäº†:")
            self.logger.info(f"  å‡¦ç†è¡Œæ•°: {calculated_count}/{total_rows}")
            self.logger.info(f"  è‚©å¹…è¨ˆç®—: {shoulder_width_count}è¡Œ")
            self.logger.info(f"  é ­éƒ¨ä½ç½®(head_center): {head_position_count}è¡Œ")  # ğŸ”§ ä¿®æ­£
            self.logger.info(f"  è‚©ä¸­ç‚¹è¨ˆç®—: {shoulder_center_count}è¡Œ")
            self.logger.info(f"  å§¿å‹¢è§’åº¦: {pose_angle_count}è¡Œ")
        
            # çµ±è¨ˆã‚µãƒãƒªãƒ¼
            if calculated_count > 0:
                avg_shoulder_width = metrics_df[metrics_df['shoulder_width'] > 0]['shoulder_width'].mean()
                avg_completeness = metrics_df['keypoint_completeness'].mean()
                avg_pose_conf = metrics_df['pose_confidence'].mean()
            
                self.logger.info(f"ğŸ“Š ãƒ¡ãƒˆãƒªã‚¯ã‚¹çµ±è¨ˆ:")
                self.logger.info(f"  å¹³å‡è‚©å¹…: {avg_shoulder_width:.1f}px")
                self.logger.info(f"  å¹³å‡å®Œå…¨æ€§: {avg_completeness:.2f}")
                self.logger.info(f"  å¹³å‡ãƒãƒ¼ã‚ºä¿¡é ¼åº¦: {avg_pose_conf:.2f}")
        
            return metrics_df
        
        except Exception as e:
            self.logger.error(f"âŒ 4ç‚¹ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨ˆç®—ã‚¨ãƒ©ãƒ¼: {e}")
            # ã‚¨ãƒ©ãƒ¼æ™‚ã¯åŸºæœ¬ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’è¿”ã™
            return df

    def create_4point_visualization(self, csv_path, video_path, output_dir):
        """4ç‚¹ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆå°‚ç”¨å¯è¦–åŒ–ç”Ÿæˆï¼ˆæ—¥æ™‚ä»˜ããƒ•ã‚©ãƒ«ãƒ€å¯¾å¿œç‰ˆï¼‰"""
        try:
            import cv2
            import pandas as pd
            from pathlib import Path
            from datetime import datetime

            self.logger.info("ğŸ¨ 4ç‚¹å¯è¦–åŒ–ç”Ÿæˆé–‹å§‹ï¼ˆæ—¥æ™‚ä»˜ããƒ•ã‚©ãƒ«ãƒ€å¯¾å¿œï¼‰")

            # ğŸ”§ æ—¥æ™‚ä»˜ãå¯è¦–åŒ–ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            vis_dir = Path(output_dir) / f"visualized_frames_4points_{timestamp}"
            vis_dir.mkdir(exist_ok=True)

            self.logger.info(f"ğŸ“ 4ç‚¹å¯è¦–åŒ–ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {vis_dir}")

            # CSVèª­ã¿è¾¼ã¿
            df = pd.read_csv(csv_path)

            if df.empty:
                self.logger.warning("âš ï¸ 4ç‚¹CSVãƒ‡ãƒ¼ã‚¿ãŒç©ºã§ã™")
                return {"success": False, "error": "Empty CSV data"}

            self.logger.info(f"ğŸ“‹ CSVåˆ—å: {df.columns.tolist()}")
            self.logger.info(f"ğŸ“‹ CSVãƒ‡ãƒ¼ã‚¿å½¢çŠ¶: {df.shape}")

            # ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ç¢ºèª
            frames_dir = Path(output_dir) / "frames"
            if not frames_dir.exists():
                self.logger.error(f"âŒ ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒå­˜åœ¨ã—ã¾ã›ã‚“: {frames_dir}")
                return {"success": False, "error": "Frames directory not found"}

            frame_files = sorted(frames_dir.glob("*.jpg"))
            if not frame_files:
                self.logger.error("âŒ ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                return {"success": False, "error": "No frame files found"}

            self.logger.info(f"ğŸ“ ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {len(frame_files)}")
            self.logger.info(f"ğŸ“ ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ•ã‚¡ã‚¤ãƒ«ä¾‹: {[f.name for f in frame_files[:3]]}")

            # ãƒ•ãƒ¬ãƒ¼ãƒ ç•ªå·ã®å¯¾å¿œãƒ†ãƒ¼ãƒ–ãƒ«ä½œæˆ
            frame_mapping = {}
            for i, frame_file in enumerate(frame_files):
                frame_num_from_file = i
                frame_identifier = frame_file.name
                frame_mapping[frame_identifier] = frame_num_from_file
                frame_mapping[frame_num_from_file] = frame_identifier

            self.logger.info(f"ğŸ“‹ ãƒ•ãƒ¬ãƒ¼ãƒ å¯¾å¿œä¾‹: {list(frame_mapping.items())[:5]}")

            # ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆåˆ—ã®ç¢ºèª
            keypoint_columns = {
                'left_ear': {'x': 'left_ear_x', 'y': 'left_ear_y', 'conf': 'left_ear_conf'},
                'right_ear': {'x': 'right_ear_x', 'y': 'right_ear_y', 'conf': 'right_ear_conf'},
                'left_shoulder': {'x': 'left_shoulder_x', 'y': 'left_shoulder_y', 'conf': 'left_shoulder_conf'},
                'right_shoulder': {'x': 'right_shoulder_x', 'y': 'right_shoulder_y', 'conf': 'right_shoulder_conf'}
            }

            # åˆ—ã®å­˜åœ¨ç¢ºèª
            missing_columns = []
            for kpt_name, cols in keypoint_columns.items():
                for col_type, col_name in cols.items():
                    if col_name not in df.columns:
                        missing_columns.append(col_name)

            if missing_columns:
                self.logger.warning(f"âš ï¸ ä¸è¶³åˆ—: {missing_columns}")

            saved_count = 0
            total_detections = 0
            processed_frames = 0
            debug_info = []

            # å„ãƒ•ãƒ¬ãƒ¼ãƒ ã«å¯¾ã™ã‚‹å‡¦ç†
            for frame_file in frame_files:
                processed_frames += 1
                frame_identifier = frame_file.name
    
                # è¤‡æ•°ã®æ–¹æ³•ã§CSVãƒ‡ãƒ¼ã‚¿ã‚’æ¤œç´¢
                frame_data = None
    
                # æ–¹æ³•1: å®Œå…¨ãªãƒ•ã‚¡ã‚¤ãƒ«åã§ãƒãƒƒãƒ
                frame_data = df[df['frame'] == frame_identifier]
    
                # æ–¹æ³•2: ãƒ•ãƒ¬ãƒ¼ãƒ ç•ªå·ã§ãƒãƒƒãƒï¼ˆ0ã‹ã‚‰å§‹ã¾ã‚‹é€£ç•ªï¼‰
                if frame_data.empty:
                    frame_index = processed_frames - 1
                    numeric_frame_data = df[df['frame'] == frame_index]
                    if not numeric_frame_data.empty:
                        frame_data = numeric_frame_data
    
                # æ–¹æ³•3: ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹é †åºã§ãƒãƒƒãƒ
                if frame_data.empty and processed_frames <= len(df):
                    frame_data = df.iloc[[processed_frames - 1]]
    
                if not frame_data.empty:
                    # ãƒ•ãƒ¬ãƒ¼ãƒ ç”»åƒèª­ã¿è¾¼ã¿
                    frame = cv2.imread(str(frame_file))
                    if frame is None:
                        self.logger.warning(f"âš ï¸ ãƒ•ãƒ¬ãƒ¼ãƒ èª­ã¿è¾¼ã¿å¤±æ•—: {frame_file}")
                        continue
        
                    frame_height, frame_width = frame.shape[:2]
                    temp_frame = frame.copy()
                    frame_detections = 0
        
                    for idx, row in frame_data.iterrows():
                        # ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆãƒ‡ãƒ¼ã‚¿ã®æŠ½å‡ºã¨æ¤œè¨¼
                        keypoints = {}
                        valid_keypoint_count = 0
            
                        for kpt_name, cols in keypoint_columns.items():
                            try:
                                x = float(row.get(cols['x'], 0))
                                y = float(row.get(cols['y'], 0))
                                conf = float(row.get(cols['conf'], 1.0))
                    
                                # åº§æ¨™ã®æœ‰åŠ¹æ€§ãƒã‚§ãƒƒã‚¯ï¼ˆç·©ã„æ¡ä»¶ï¼‰
                                if (0 <= x <= frame_width and 
                                   0 <= y <= frame_height and 
                                    conf > 0.1):  # ä¿¡é ¼åº¦é–¾å€¤ã‚’0.3ã‹ã‚‰0.1ã«ç·©å’Œ
                                    keypoints[kpt_name] = (int(x), int(y), conf)
                                    valid_keypoint_count += 1
                            except (ValueError, TypeError) as e:
                                continue
            
                        # ãƒ‡ãƒãƒƒã‚°æƒ…å ±è¨˜éŒ²
                        if processed_frames <= 3:  # æœ€åˆã®3ãƒ•ãƒ¬ãƒ¼ãƒ ã®ãƒ‡ãƒãƒƒã‚°
                            debug_info.append({
                                'frame': frame_identifier,
                                'valid_keypoints': valid_keypoint_count,
                                'keypoints': keypoints,
                                'row_data': {k: row.get(k) for k in ['left_ear_x', 'left_ear_y', 'left_ear_conf']}
                            })
            
                        # 1ç‚¹ã§ã‚‚æœ‰åŠ¹ãªã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆãŒã‚ã‚Œã°æç”»
                        if valid_keypoint_count >= 1:  # 4ã‹ã‚‰1ã«æ¡ä»¶ç·©å’Œ
                            temp_frame = self.draw_4point_keypoints_robust(temp_frame, keypoints, row)
                            frame_detections += 1
        
                    # 1ã¤ã§ã‚‚æ¤œå‡ºãŒã‚ã‚Œã°ä¿å­˜
                    if frame_detections > 0:
                        output_filename = f"4pt_{frame_file.name}"
                        output_path = vis_dir / output_filename
                        success = cv2.imwrite(str(output_path), temp_frame)
            
                        if success:
                            saved_count += 1
                            total_detections += frame_detections
                
                            # æœ€åˆã®5æšã®ä¿å­˜æˆåŠŸã‚’ãƒ­ã‚°
                            if saved_count <= 5:
                                self.logger.info(f"âœ… 4ç‚¹ç”»åƒä¿å­˜æˆåŠŸ: {output_filename} (æ¤œå‡º: {frame_detections})")
                        else:
                            self.logger.warning(f"âŒ ç”»åƒä¿å­˜å¤±æ•—: {output_path}")
    
                # é€²æ—è¡¨ç¤ºï¼ˆé »åº¦ã‚’ä¸‹ã’ã‚‹ï¼‰
                if processed_frames % 100 == 0:
                    self.logger.info(f"ğŸ¨ 4ç‚¹å¯è¦–åŒ–é€²æ—: {processed_frames}ãƒ•ãƒ¬ãƒ¼ãƒ  (ä¿å­˜æ¸ˆã¿: {saved_count})")

            # ãƒ‡ãƒãƒƒã‚°æƒ…å ±å‡ºåŠ›
            if debug_info:
                self.logger.info("ğŸ”§ ãƒ‡ãƒãƒƒã‚°æƒ…å ±ï¼ˆæœ€åˆã®3ãƒ•ãƒ¬ãƒ¼ãƒ ï¼‰:")
                for info in debug_info:
                    self.logger.info(f"  ãƒ•ãƒ¬ãƒ¼ãƒ : {info['frame']}, æœ‰åŠ¹ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆ: {info['valid_keypoints']}")
                    self.logger.info(f"  ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿: {info['row_data']}")

            self.logger.info(f"âœ… 4ç‚¹å¯è¦–åŒ–å®Œäº†: {saved_count}ãƒ•ãƒ¬ãƒ¼ãƒ ä¿å­˜ (æ¤œå‡ºæ•°: {total_detections})")
            self.logger.info(f"ğŸ“Š å‡¦ç†çµ±è¨ˆ: {processed_frames}ãƒ•ãƒ¬ãƒ¼ãƒ å‡¦ç†, æˆåŠŸç‡: {(saved_count/processed_frames)*100:.1f}%")
    
            return {
                "success": True, 
                "frames_saved": saved_count, 
                "total_detections": total_detections,
                "processed_frames": processed_frames,
                "output_dir": str(vis_dir),
                "timestamp": timestamp,  # ğŸ”§ è¿½åŠ : ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—
                "debug_info": debug_info
                }
    
        except Exception as e:
            self.logger.error(f"âŒ 4ç‚¹å¯è¦–åŒ–ã‚¨ãƒ©ãƒ¼: {e}")
            import traceback
            self.logger.error(f"ğŸ”§ è©³ç´°ã‚¨ãƒ©ãƒ¼: {traceback.format_exc()}")
            return {"success": False, "error": str(e)}

    def draw_4point_keypoints_robust(self, frame, keypoints, row):
        """4ç‚¹ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆæç”»ï¼ˆæ¤œå‡ºæ ï¼‹IDè¡¨ç¤ºä»˜ãã€æ–‡å­—ãƒ©ãƒ™ãƒ«ãªã—ï¼‰"""
        try:
            import cv2

            # ğŸ¨ ã‚·ãƒ³ãƒ—ãƒ«2è‰²è¨­å®š
            ear_color = (100, 180, 100)         # è½ã¡ç€ã„ãŸã‚°ãƒªãƒ¼ãƒ³ï¼ˆè€³ï¼‰
            shoulder_color = (100, 100, 180)    # è½ã¡ç€ã„ãŸãƒ¬ãƒƒãƒ‰ï¼ˆè‚©ï¼‰
            center_color = (255, 200, 0)        # ã‚´ãƒ¼ãƒ«ãƒ‰ï¼ˆä¸­ç‚¹ï¼‰
            line_color = (0, 255, 255)          # ã‚·ã‚¢ãƒ³ï¼ˆæ¥ç¶šç·šï¼‰
        
            # æç”»è¨­å®š
            point_radius = 5         # ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆã®ã‚µã‚¤ã‚º
            center_radius = 8        # ä¸­ç‚¹ã®ã‚µã‚¤ã‚ºï¼ˆå°‘ã—å¤§ããï¼‰
            outer_radius = 7         # ç™½ã„å¤–æ 
            line_thickness = 2       # æ¥ç¶šç·šã®å¤ªã•
        
            drawn_points = 0

            # ğŸ”² æ¤œå‡ºæ ã®æç”»
            try:
                if hasattr(row, 'get'):
                    x1 = int(row.get('x1', 0))
                    y1 = int(row.get('y1', 0))
                    x2 = int(row.get('x2', 0))
                    y2 = int(row.get('y2', 0))
                    person_id = row.get('person_id', '?')
                    conf = float(row.get('conf', 0))
                
                    if x1 > 0 and y1 > 0 and x2 > x1 and y2 > y1:
                        # æ¤œå‡ºæ ã®æç”»ï¼ˆç·‘è‰²ï¼‰
                        cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)
                    
                        # ğŸ·ï¸ IDï¼‹ä¿¡é ¼åº¦è¡¨ç¤ºï¼ˆèƒŒæ™¯ä»˜ãï¼‰
                        id_text = f"ID:{person_id} ({conf:.2f})"
                        text_size = 0.6
                        text_thickness = 1
                    
                        # ãƒ†ã‚­ã‚¹ãƒˆã‚µã‚¤ã‚ºè¨ˆç®—
                        (text_w, text_h), baseline = cv2.getTextSize(id_text, cv2.FONT_HERSHEY_SIMPLEX, text_size, text_thickness)
                    
                        # èƒŒæ™¯çŸ©å½¢
                        bg_x1 = x1
                        bg_y1 = y1 - text_h - 10
                        bg_x2 = x1 + text_w + 10
                        bg_y2 = y1
                    
                        # èƒŒæ™¯æç”»ï¼ˆåŠé€æ˜é»’ï¼‰
                        overlay = frame.copy()
                        cv2.rectangle(overlay, (bg_x1, bg_y1), (bg_x2, bg_y2), (0, 0, 0), -1)
                        cv2.addWeighted(overlay, 0.6, frame, 0.4, 0, frame)
                    
                        # ãƒ†ã‚­ã‚¹ãƒˆæç”»ï¼ˆç™½ï¼‰
                        cv2.putText(frame, id_text, (x1 + 5, y1 - 5), 
                                cv2.FONT_HERSHEY_SIMPLEX, text_size, (255, 255, 255), text_thickness)
            except Exception as e:
                self.logger.debug(f"æ¤œå‡ºæ æç”»ã‚¨ãƒ©ãƒ¼: {e}")

            # ğŸ¯ å„ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆã®æç”»
            ear_points = []
            shoulder_points = []

            for kpt_name, (x, y, conf) in keypoints.items():
                # è‚©ã¨è€³ã§è‰²åˆ†ã‘
                if 'ear' in kpt_name:
                    color = ear_color
                elif 'shoulder' in kpt_name:
                    color = shoulder_color
                else:
                    color = (128, 128, 128)  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚°ãƒ¬ãƒ¼
            
                try:
                    # ãƒ¡ã‚¤ãƒ³ã®ç‚¹
                    cv2.circle(frame, (x, y), point_radius, color, -1)
                
                    # ç™½ã„å¤–æ ï¼ˆè¦‹ã‚„ã™ã•ã®ãŸã‚ï¼‰
                    cv2.circle(frame, (x, y), outer_radius, (255, 255, 255), 1)
                
                    drawn_points += 1
                
                except Exception as e:
                    self.logger.debug(f"ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆæç”»ã‚¹ã‚­ãƒƒãƒ—: {kpt_name} - {e}")
                    continue

            # ğŸ”— æ¥ç¶šç·šã®æç”»
            try:
                # è‚©ã®ãƒ©ã‚¤ãƒ³ï¼ˆè‚©ã®è‰²ã§ï¼‰
                if len(shoulder_points) == 2:
                    cv2.line(frame, shoulder_points[0], shoulder_points[1], 
                            shoulder_color, line_thickness)
            
                # è€³ã®ãƒ©ã‚¤ãƒ³ï¼ˆè€³ã®è‰²ã§ã€ç´°ã‚ï¼‰
                if len(ear_points) == 2:
                    cv2.line(frame, ear_points[0], ear_points[1], 
                            ear_color, 1)  # ã‚ˆã‚Šç´°ã„ç·š
            except:
                pass

            # ğŸ”§ ä¸­ç‚¹ã®è¨ˆç®—ã¨æç”»ï¼ˆhead_centerçµ±ä¸€ç‰ˆï¼‰
            try:
                # ğŸ¯ head_centerï¼ˆä¸¡è€³ä¸­ç‚¹ï¼‰ã®æç”»
                if len(ear_points) == 2:
                    head_center_x = (ear_points[0][0] + ear_points[1][0]) // 2
                    head_center_y = (ear_points[0][1] + ear_points[1][1]) // 2
                
                    # ä¸­ç‚¹æç”»ï¼ˆã‚´ãƒ¼ãƒ«ãƒ‰è‰²ã€ã‚„ã‚„å¤§ãã‚ï¼‰
                    cv2.circle(frame, (head_center_x, head_center_y), center_radius, center_color, -1)
                    cv2.circle(frame, (head_center_x, head_center_y), center_radius + 2, (255, 255, 255), 1)
                
                    # ğŸ”§ ãƒ©ãƒ™ãƒ«ä¿®æ­£: H-Cï¼ˆHead Centerï¼‰
                    cv2.putText(frame, "H-C", (head_center_x + 10, head_center_y - 10),
                            cv2.FONT_HERSHEY_SIMPLEX, 0.4, center_color, 1)
            
                # ğŸ¯ è‚©ä¸­ç‚¹ã®æç”»
                if len(shoulder_points) == 2:
                    shoulder_center_x = (shoulder_points[0][0] + shoulder_points[1][0]) // 2
                    shoulder_center_y = (shoulder_points[0][1] + shoulder_points[1][1]) // 2
                
                    # ä¸­ç‚¹æç”»ï¼ˆã‚´ãƒ¼ãƒ«ãƒ‰è‰²ã€ã‚„ã‚„å¤§ãã‚ï¼‰
                    cv2.circle(frame, (shoulder_center_x, shoulder_center_y), center_radius, center_color, -1)
                    cv2.circle(frame, (shoulder_center_x, shoulder_center_y), center_radius + 2, (255, 255, 255), 1)
                
                    # ãƒ©ãƒ™ãƒ«æç”»
                    cv2.putText(frame, "S-C", (shoulder_center_x + 10, shoulder_center_y - 10),
                            cv2.FONT_HERSHEY_SIMPLEX, 0.4, center_color, 1)
                
                # ğŸ”§ head_centerã¨è‚©ä¸­ç‚¹ã‚’çµã¶ç·šï¼ˆä½“è»¸ã®å¯è¦–åŒ–ï¼‰
                if len(ear_points) == 2 and len(shoulder_points) == 2:
                    head_center = ((ear_points[0][0] + ear_points[1][0]) // 2, 
                                  (ear_points[0][1] + ear_points[1][1]) // 2)
                    shoulder_center = ((shoulder_points[0][0] + shoulder_points[1][0]) // 2,
                                     (shoulder_points[0][1] + shoulder_points[1][1]) // 2)
                
                    # ä½“è»¸ç·šã®æç”»ï¼ˆç ´ç·šé¢¨ï¼‰
                    cv2.line(frame, head_center, shoulder_center, line_color, 2)
                
            except Exception as e:
                self.logger.debug(f"ä¸­ç‚¹æç”»ã‚¨ãƒ©ãƒ¼: {e}")

            return frame

        except Exception as e:
            self.logger.error(f"âŒ ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆæç”»ã‚¨ãƒ©ãƒ¼: {e}")
            return frame

    def draw_4point_keypoints_dynamic(self, frame, keypoint_data, row):
        """å‹•çš„4ç‚¹ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆæç”»"""
        try:
            import cv2
            import numpy as np
        
            # âš¡ ã‚ˆã‚Šç›®ç«‹ã¤è‰²ã¨ã‚µã‚¤ã‚º
            ear_color = (0, 255, 0)       # ç·‘ï¼ˆè€³ï¼‰
            shoulder_color = (0, 100, 255) # ã‚ªãƒ¬ãƒ³ã‚¸ï¼ˆè‚©ï¼‰
            line_color = (0, 255, 255)     # é»„ï¼ˆç·šï¼‰
            text_color = (255, 255, 255)   # ç™½ï¼ˆãƒ†ã‚­ã‚¹ãƒˆï¼‰
        
            # âš¡ ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆæç”»
            ear_points = []
            shoulder_points = []
        
            for name, (x, y, conf) in keypoint_data.items():
                color = ear_color if 'ear' in name else shoulder_color
            
                # âš¡ å¤§ããªå††ã§æç”»
                cv2.circle(frame, (x, y), 8, color, -1)  
                cv2.circle(frame, (x, y), 12, text_color, 2)
            
                # âš¡ ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆåã¨ä¿¡é ¼åº¦
                cv2.putText(frame, f"{name.split('_')[0]}:{conf:.2f}", 
                        (x + 10, y - 10),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)
            
                # ç‚¹ã‚’åˆ†é¡
                if 'ear' in name:
                    ear_points.append((x, y))
                elif 'shoulder' in name:
                    shoulder_points.append((x, y))
        
            # âš¡ è‚©ãƒ©ã‚¤ãƒ³
            if len(shoulder_points) == 2:
                cv2.line(frame, shoulder_points[0], shoulder_points[1], line_color, 4)
        
            # âš¡ é ­éƒ¨ä¸­å¿ƒ
            if len(ear_points) == 2:
                head_x = (ear_points[0][0] + ear_points[1][0]) // 2
                head_y = (ear_points[0][1] + ear_points[1][1]) // 2
                cv2.circle(frame, (head_x, head_y), 6, line_color, -1)
        
            # äººç‰©IDè¡¨ç¤º
            person_id = row.get('person_id', -1)
            if person_id != -1 and keypoint_data:
                all_points = list(keypoint_data.values())
                center_x = int(np.mean([p[0] for p in all_points]))
                center_y = int(np.mean([p[1] for p in all_points])) - 30
            
                cv2.putText(frame, f"ID:{person_id}", (center_x, center_y),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, text_color, 2)
        
            return frame
        
        except Exception as e:
            self.logger.warning(f"å‹•çš„æç”»ã‚¨ãƒ©ãƒ¼: {e}")
            return frame

    @handle_errors(error_category=ErrorCategory.EXPERIMENT)
    def run_experiment(self, video_path: str, experiment_type: str) -> Dict[str, Any]:
        """
        å®Ÿé¨“åˆ†æå®Ÿè¡Œï¼ˆå®Œå…¨çµ±åˆç‰ˆï¼‰

        Args:
            video_path: åˆ†æå¯¾è±¡å‹•ç”»ã®ãƒ‘ã‚¹
            experiment_type: å®Ÿé¨“ã‚¿ã‚¤ãƒ—

        Returns:
            å®Ÿé¨“çµæœè¾æ›¸
        """
        if ERROR_HANDLER_AVAILABLE:
            context_manager = ErrorContext(f"å®Ÿé¨“åˆ†æ: {experiment_type}", 
                                        logger=self.logger, raise_on_error=False)
        else:
            context_manager = self._basic_context(f"å®Ÿé¨“åˆ†æ: {experiment_type}")

        with context_manager as ctx:
            video_path = Path(video_path)
            video_name = video_path.stem

            self.logger.info(f"ğŸ§ª å®Ÿé¨“åˆ†æé–‹å§‹: {experiment_type} - {video_name}")

            if hasattr(ctx, 'add_info'):
                ctx.add_info("video_path", str(video_path))
                ctx.add_info("experiment_type", experiment_type)
                ctx.add_info("depth_enabled", self.depth_enabled)

            try:
                # å®Ÿé¨“ç”¨å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
                output_dir = Path("outputs/experiments") / experiment_type / video_name
                output_dir.mkdir(parents=True, exist_ok=True)

                self.logger.info(f"ğŸ“ å®Ÿé¨“å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {output_dir}")

                # å®Ÿé¨“è¨­å®šã®å–å¾—
                if hasattr(self.config, 'get_experiment_config'):
                    experiment_config = self.config.get_experiment_config(experiment_type)
                else:
                    experiment_config = {"type": experiment_type, "basic_mode": True}

                self.logger.info(f"âš™ï¸ å®Ÿé¨“è¨­å®š: {experiment_config}")

                # ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³çµæœã¨ã®æ¯”è¼ƒç”¨ã«ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³å®Ÿè¡Œ
                self.logger.info("ğŸ“Š ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³çµæœå–å¾—ä¸­...")
                baseline_result = self.run_baseline_analysis(video_path)
                
                if not baseline_result.get("success", False):
                    raise VideoProcessingError("ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³åˆ†æã«å¤±æ•—ã—ã¾ã—ãŸ")

                self.logger.info("âœ… ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³çµæœå–å¾—å®Œäº†")

                # å®Ÿé¨“ç‰¹æœ‰ã®å‡¦ç†
                experiment_result = {
                    "success": True,
                    "experiment_type": experiment_type,
                    "video_name": video_name,
                    "baseline_comparison": baseline_result.get("data", {}),
                    "experiment_config": experiment_config,
                    "depth_enabled": self.depth_enabled,
                    "output_directory": str(output_dir),
                    "processing_timestamp": datetime.now().isoformat(),
                    "system_info": {
                        "evaluator_type": type(self.evaluator).__name__,
                        "processor_type": type(self.processor).__name__,
                        "analyzer_type": type(self.analyzer).__name__
                    }
                }

                # æ”¹å–„åˆ†æ
                try:
                    self.logger.info("ğŸ“ˆ æ”¹å–„åˆ†æé–‹å§‹...")
                    improvement_analysis = self.analyzer.analyze_improvements({
                        "baseline": baseline_result.get("data", {}),
                        "experiment": experiment_result
                    })
                    experiment_result["improvement_analysis"] = improvement_analysis
                    self.logger.info("âœ… æ”¹å–„åˆ†æå®Œäº†")
                except Exception as e:
                    self.logger.warning(f"âš ï¸ æ”¹å–„åˆ†æã‚¨ãƒ©ãƒ¼ï¼ˆå‡¦ç†ç¶™ç¶šï¼‰: {e}")
                    experiment_result["improvement_analysis"] = {"error": str(e)}

                # çµæœä¿å­˜
                result_file = output_dir / f"{video_name}_{experiment_type}_result.json"
                with open(result_file, 'w', encoding='utf-8') as f:
                    json.dump(experiment_result, f, indent=2, ensure_ascii=False)

                if hasattr(ctx, 'add_info'):
                    ctx.add_info("result_file", str(result_file))

                self.logger.info(f"ğŸ‰ å®Ÿé¨“åˆ†æå®Œäº†: {experiment_type} - {video_name}")
                self.logger.info(f"ğŸ“„ çµæœãƒ•ã‚¡ã‚¤ãƒ«: {result_file}")
                return ResponseBuilder.success(data=experiment_result)

            except Exception as e:
                self.logger.error(f"âŒ å®Ÿé¨“åˆ†æã‚¨ãƒ©ãƒ¼: {e}")
                if hasattr(ctx, 'add_info'):
                    ctx.add_info("error_type", type(e).__name__)
                    ctx.add_info("error_message", str(e))
                return ResponseBuilder.error(e, suggestions=[
                    f"å®Ÿé¨“ã‚¿ã‚¤ãƒ— '{experiment_type}' ã®è¨­å®šã‚’ç¢ºèªã—ã¦ãã ã•ã„",
                    "ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³åˆ†æãŒæ­£å¸¸ã«å‹•ä½œã™ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„"
                ])

    def generate_error_report(self) -> Dict[str, Any]:
        """ã‚¨ãƒ©ãƒ¼ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆï¼ˆå®Œå…¨ç‰ˆï¼‰"""
        try:
            self.logger.info("ğŸ“‹ ã‚¨ãƒ©ãƒ¼ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆé–‹å§‹")
            
            error_report = {
                "timestamp": datetime.now().isoformat(),
                "total_errors": len(self.error_collector),
                "errors": self.error_collector.copy(),
                "system_info": {
                    "depth_enabled": self.depth_enabled,
                    "evaluator_type": type(self.evaluator).__name__,
                    "processor_type": type(self.processor).__name__,
                    "analyzer_type": type(self.analyzer).__name__,
                    "config_type": type(self.config).__name__
                },
                "module_availability": {
                    "error_handler": ERROR_HANDLER_AVAILABLE,
                    "evaluator": EVALUATOR_AVAILABLE,
                    "comprehensive_evaluator": COMPREHENSIVE_EVALUATOR_AVAILABLE,
                    "depth_evaluator": DEPTH_EVALUATOR_AVAILABLE,
                    "video_processor": VIDEO_PROCESSOR_AVAILABLE,
                    "metrics_analyzer": METRICS_ANALYZER_AVAILABLE,
                    "config": CONFIG_AVAILABLE,
                    "logger": LOGGER_AVAILABLE
                },
                "performance_info": {
                    "processing_stats": getattr(self.processor, 'processing_stats', {}),
                    "error_count_by_type": self._categorize_errors()
                }
            }
            
            # ã‚¨ãƒ©ãƒ¼ãƒ¬ãƒãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
            report_file = Path("logs") / f"error_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
            report_file.parent.mkdir(exist_ok=True)
            
            with open(report_file, 'w', encoding='utf-8') as f:
                json.dump(error_report, f, indent=2, ensure_ascii=False)
                
            self.logger.info(f"âœ… ã‚¨ãƒ©ãƒ¼ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆå®Œäº†: {report_file}")
            return error_report
            
        except Exception as e:
            self.logger.error(f"âŒ ã‚¨ãƒ©ãƒ¼ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆå¤±æ•—: {e}")
            return {"error": str(e)}

    def _categorize_errors(self) -> Dict[str, int]:
        """ã‚¨ãƒ©ãƒ¼ã®åˆ†é¡ï¼ˆå®Œå…¨ç‰ˆï¼‰"""
        categories = {
            "video_processing": 0,
            "model_loading": 0,
            "evaluation": 0,
            "configuration": 0,
            "depth_processing": 0,
            "io_operations": 0,
            "other": 0
        }
        
        for error in self.error_collector:
            error_lower = error.lower()
            if any(keyword in error_lower for keyword in ["video", "frame", "opencv", "mp4", "avi"]):
                categories["video_processing"] += 1
            elif any(keyword in error_lower for keyword in ["model", "yolo", "loading", "pt", "weights"]):
                categories["model_loading"] += 1
            elif any(keyword in error_lower for keyword in ["evaluation", "csv", "analysis", "metrics"]):
                categories["evaluation"] += 1
            elif any(keyword in error_lower for keyword in ["config", "setting", "yaml", "json"]):
                categories["configuration"] += 1
            elif any(keyword in error_lower for keyword in ["depth", "midas", "disparity"]):
                categories["depth_processing"] += 1
            elif any(keyword in error_lower for keyword in ["file", "directory", "path", "permission"]):
                categories["io_operations"] += 1
            else:
                categories["other"] += 1
        
        return categories

    def get_video_files(self) -> List[Path]:
        """å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«å–å¾—ï¼ˆä¿®æ­£ç‰ˆãƒ»åŸºæœ¬æ¨è«–å„ªå…ˆï¼‰"""
        try:
            # ğŸ”§ --video ã‚ªãƒ—ã‚·ãƒ§ãƒ³ãŒæŒ‡å®šã•ã‚ŒãŸå ´åˆã¯ã€ãã®ãƒ•ã‚¡ã‚¤ãƒ«ã®ã¿å‡¦ç†
            if hasattr(sys, 'argv') and '--video' in ' '.join(sys.argv):
                # ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°ã‹ã‚‰å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç›´æ¥å–å¾—ã™ã‚‹å ´åˆã¯
                # ãƒ¡ã‚¤ãƒ³é–¢æ•°ã§å‡¦ç†ã•ã‚Œã‚‹ã®ã§ã€ã“ã“ã§ã¯ç©ºãƒªã‚¹ãƒˆã‚’è¿”ã™
                return []
        
            # é€šå¸¸ã®å‹•ç”»ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ¤œç´¢
            if hasattr(self.config, 'video_dir'):
                video_dir = Path(self.config.video_dir)
            else:
                video_dir = Path(self.config.get("video_dir", "videos"))
            
            self.logger.info(f"ğŸ¥ å‹•ç”»ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ¤œç´¢: {video_dir}")
            
            if not video_dir.exists():
                self.logger.warning(f"âš ï¸ å‹•ç”»ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒå­˜åœ¨ã—ã¾ã›ã‚“: {video_dir}")
                return []
            
            # ã‚µãƒãƒ¼ãƒˆã™ã‚‹å‹•ç”»å½¢å¼
            video_extensions = ['.mp4', '.avi', '.mov', '.mkv', '.wmv', '.flv', '.webm']
            video_files = []
        
            for ext in video_extensions:
                found_files = list(video_dir.glob(f"*{ext}"))
                found_files.extend(video_dir.glob(f"*{ext.upper()}"))
                video_files.extend(found_files)
            
            video_files = sorted(set(video_files))
        
            if not video_files:
                self.logger.warning(f"âš ï¸ å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {video_dir}")
                return []
        
            self.logger.info(f"âœ… å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ç™ºè¦‹: {len(video_files)}å€‹")
            for video_file in video_files:
                file_size_mb = video_file.stat().st_size / 1024 / 1024
                self.logger.debug(f"  ğŸ“¹ {video_file.name} ({file_size_mb:.1f}MB)")
            
            return video_files
        
        except Exception as e:
            self.logger.error(f"âŒ å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            return []

def main():
    """
    ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°ï¼ˆ4ç‚¹ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆå¯¾å¿œå®Œå…¨ä¿®æ­£ç‰ˆï¼‰
    """
    # ã‚¢ã‚¹ã‚­ãƒ¼ã‚¢ãƒ¼ãƒˆã¨ãƒãƒ¼ã‚¸ãƒ§ãƒ³æƒ…å ±
    print("""
    â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
    â•‘                     ğŸ¯ YOLO11 å§¿å‹¢åˆ†æã‚·ã‚¹ãƒ†ãƒ  v2.1                    â•‘
    â•‘                        ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆæ¤œå‡ºãƒ»è¿½è·¡ãƒ»è§£æ                        â•‘
    â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """)

    # ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°ãƒ‘ãƒ¼ã‚µãƒ¼ã®è¨­å®š
    parser = argparse.ArgumentParser(
        description="ğŸ¯ YOLO11å§¿å‹¢åˆ†æã‚·ã‚¹ãƒ†ãƒ  - å‹•ç”»ã‹ã‚‰äººç‰©ã®å§¿å‹¢ã‚’åˆ†æã—ã¾ã™",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ä¾‹:
    # åŸºæœ¬çš„ãªå§¿å‹¢åˆ†æ
    python improved_main.py input.mp4

    # 4ç‚¹ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆåˆ†æï¼ˆé«˜ç²¾åº¦ï¼‰
    python improved_main.py input.mp4 --use-4points --keypoint-threshold 0.5

    # æ·±åº¦æ¨å®šä»˜ãåˆ†æ
    python improved_main.py input.mp4 --enable-depth --depth-model dpt_hybrid

    # ã‚«ã‚¹ã‚¿ãƒ è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ä½¿ç”¨
    python improved_main.py input.mp4 --config custom_config.yaml

    # é«˜è§£åƒåº¦å‡¦ç†
    python improved_main.py input.mp4 --resolution 1920x1080 --quality high
        """
    )

    # å¿…é ˆå¼•æ•°
    parser.add_argument(
        'video_path',
        type=str,
        help='ğŸ¬ åˆ†æå¯¾è±¡ã®å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹'
    )

    # ã‚ªãƒ—ã‚·ãƒ§ãƒ³å¼•æ•°
    parser.add_argument(
        '--config',
        type=str,
        default=None,
        help='âš™ï¸ è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ï¼ˆYAML/JSONå½¢å¼ï¼‰'
    )

    parser.add_argument(
        '--output-dir',
        type=str,
        default=None,
        help='ğŸ“ å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: results/å‹•ç”»å_YYYYMMDD_HHMMSSï¼‰'
    )

    # ğŸ¯ 4ç‚¹ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆé–¢é€£ã‚ªãƒ—ã‚·ãƒ§ãƒ³
    parser.add_argument(
        '--use-4points',
        action='store_true',
        help='ğŸ¦´ 4ç‚¹ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆãƒ¢ãƒ¼ãƒ‰ã‚’æœ‰åŠ¹åŒ–ï¼ˆè€³2ç‚¹ + è‚©2ç‚¹ï¼‰'
    )

    parser.add_argument(
        '--keypoint-threshold',
        type=float,
        default=0.3,
        help='ğŸ¯ ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆä¿¡é ¼åº¦é–¾å€¤ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 0.3ï¼‰'
    )

    parser.add_argument(
        '--disable-shoulder-metrics',
        action='store_true',
        help='ğŸš« è‚©å¹…ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’ç„¡åŠ¹åŒ–'
    )

    parser.add_argument(
        '--disable-head-tracking',
        action='store_true',
        help='ğŸš« é ­éƒ¨è¿½è·¡æ©Ÿèƒ½ã‚’ç„¡åŠ¹åŒ–'
    )

    # æ·±åº¦æ¨å®šã‚ªãƒ—ã‚·ãƒ§ãƒ³
    parser.add_argument(
        '--enable-depth',
        action='store_true',
        help='ğŸŒŠ æ·±åº¦æ¨å®šæ©Ÿèƒ½ã‚’æœ‰åŠ¹åŒ–'
    )

    parser.add_argument(
        '--depth-model',
        type=str,
        default='dpt_hybrid',
        choices=['dpt_hybrid', 'midas', 'dpt_large'],
        help='ğŸ§  æ·±åº¦æ¨å®šãƒ¢ãƒ‡ãƒ«ã®é¸æŠ'
    )

    # å‡¦ç†ã‚ªãƒ—ã‚·ãƒ§ãƒ³
    parser.add_argument(
        '--resolution',
        type=str,
        default=None,
        help='ğŸ“ å‡¦ç†è§£åƒåº¦ï¼ˆä¾‹: 1920x1080, 1280x720ï¼‰'
    )

    parser.add_argument(
        '--fps',
        type=int,
        default=None,
        help='ğŸ¬ å‡¦ç†FPSï¼ˆãƒ•ãƒ¬ãƒ¼ãƒ é–“å¼•ãç”¨ï¼‰'
    )

    parser.add_argument(
        '--quality',
        type=str,
        default='medium',
        choices=['low', 'medium', 'high', 'ultra'],
        help='ğŸ¨ å‡¦ç†å“è³ªãƒ¬ãƒ™ãƒ«'
    )

    parser.add_argument(
        '--skip-frames',
        type=int,
        default=0,
        help='â­ï¸ ã‚¹ã‚­ãƒƒãƒ—ãƒ•ãƒ¬ãƒ¼ãƒ æ•°ï¼ˆå‡¦ç†é«˜é€ŸåŒ–ç”¨ï¼‰'
    )

    # ãƒ‡ãƒãƒƒã‚°ã‚ªãƒ—ã‚·ãƒ§ãƒ³
    parser.add_argument(
        '--debug',
        action='store_true',
        help='ğŸ› ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰ã‚’æœ‰åŠ¹åŒ–'
    )

    parser.add_argument(
        '--log-level',
        type=str,
        default='INFO',
        choices=['DEBUG', 'INFO', 'WARNING', 'ERROR'],
        help='ğŸ“ ãƒ­ã‚°ãƒ¬ãƒ™ãƒ«'
    )

    parser.add_argument(
        '--save-intermediate',
        action='store_true',
        help='ğŸ’¾ ä¸­é–“ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜'
    )

    # ãƒ¢ãƒ‡ãƒ«ã‚ªãƒ—ã‚·ãƒ§ãƒ³
    parser.add_argument(
        '--model-size',
        type=str,
        default='x',
        choices=['n', 's', 'm', 'l', 'x'],
        help='ğŸ¯ YOLOãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºï¼ˆn=nano, s=small, m=medium, l=large, x=xlargeï¼‰'
    )

    parser.add_argument(
        '--confidence-threshold',
        type=float,
        default=0.3,
        help='ğŸ¯ æ¤œå‡ºä¿¡é ¼åº¦é–¾å€¤'
    )

    parser.add_argument(
        '--iou-threshold',
        type=float,
        default=0.45,
        help='ğŸ“ IoUé–¾å€¤ï¼ˆé‡è¤‡æ¤œå‡ºé™¤å»ç”¨ï¼‰'
    )

    # å‡ºåŠ›ã‚ªãƒ—ã‚·ãƒ§ãƒ³
    parser.add_argument(
        '--disable-visualization',
        action='store_true',
        help='ğŸš« å¯è¦–åŒ–å‡ºåŠ›ã‚’ç„¡åŠ¹åŒ–'
    )

    parser.add_argument(
        '--output-format',
        type=str,
        default='csv',
        choices=['csv', 'json', 'both'],
        help='ğŸ“Š å‡ºåŠ›ãƒ‡ãƒ¼ã‚¿å½¢å¼'
    )

    # å¼•æ•°è§£æ
    args = parser.parse_args()

    # ğŸ”§ ãƒ­ã‚°ãƒ¬ãƒ™ãƒ«è¨­å®š
    log_level = getattr(logging, args.log_level.upper())
    logging.basicConfig(
        level=log_level,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        handlers=[
            logging.StreamHandler(),
            logging.FileHandler('yolo_pose_analysis.log', encoding='utf-8')
        ]
    )
    logger = logging.getLogger(__name__)

    # ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰è¨­å®š
    if args.debug:
        logger.setLevel(logging.DEBUG)
        logger.info("ğŸ› ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰ãŒæœ‰åŠ¹åŒ–ã•ã‚Œã¾ã—ãŸ")

    try:
        # ğŸ”§ å…¥åŠ›æ¤œè¨¼
        if not Path(args.video_path).exists():
            logger.error(f"âŒ å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {args.video_path}")
            return 1

        video_path = Path(args.video_path)
        logger.info(f"ğŸ¬ å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«: {video_path}")

        # ğŸ”§ å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªè¨­å®š
        if args.output_dir:
            output_dir = Path(args.output_dir)
        else:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            video_name = video_path.stem
            output_dir = Path("results") / f"{video_name}_{timestamp}"

        output_dir.mkdir(parents=True, exist_ok=True)
        logger.info(f"ğŸ“ å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {output_dir}")

        # ğŸ¯ ã‚¢ãƒŠãƒ©ã‚¤ã‚¶ãƒ¼åˆæœŸåŒ–
        try:
            # ğŸ”§ ä¿®æ­£: æ­£ã—ã„ã‚¯ãƒ©ã‚¹åã¨åˆæœŸåŒ–ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
            analyzer = ImprovedYOLOAnalyzer(
                config_path=args.config or "configs/default.yaml"
            )
            # ğŸ”§ æ·±åº¦æ¨å®šè¨­å®šã®é©ç”¨
            if args.enable_depth:
                analyzer.depth_enabled = True
                logger.info("ğŸ” æ·±åº¦æ¨å®šæ©Ÿèƒ½ã‚’æœ‰åŠ¹åŒ–")
            
            logger.info("âœ… ã‚¢ãƒŠãƒ©ã‚¤ã‚¶ãƒ¼åˆæœŸåŒ–å®Œäº†")
        except Exception as e:
            logger.error(f"âŒ ã‚¢ãƒŠãƒ©ã‚¤ã‚¶ãƒ¼åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
            import traceback
            logger.error(f"ğŸ”§ è©³ç´°ã‚¨ãƒ©ãƒ¼: {traceback.format_exc()}")
            return 1

        # ğŸ¯ ä¿®æ­£: 4ç‚¹ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆè¨­å®šã®ç¢ºå®Ÿãªé©ç”¨
        if args.use_4points:
            try:
                # ğŸ”§ ä¿®æ­£: è¨­å®šã‚ªãƒ¼ãƒãƒ¼ãƒ©ã‚¤ãƒ‰ã‚’å¼·åŒ–
                if hasattr(analyzer, 'config') and hasattr(analyzer.config, 'data') and isinstance(analyzer.config.data, dict):
                    analyzer.config.data.setdefault('processing', {})
                    
                    # ğŸ”§ ä¿®æ­£: ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆå‡¦ç†è¨­å®šã‚’ç¢ºå®Ÿã«é©ç”¨
                    analyzer.config.data['processing']['use_4point_keypoints'] = True
                    analyzer.config.data['processing']['keypoint_confidence_threshold'] = args.keypoint_threshold
                    analyzer.config.data['processing']['force_pose_model'] = True  # ğŸ”§ è¿½åŠ 
                    analyzer.config.data['processing']['verify_keypoint_columns'] = True  # ğŸ”§ è¿½åŠ 
                    
                    # ğŸ”§ ä¿®æ­£: trackerè¨­å®šã‚‚ç¢ºå®Ÿã«è¨­å®š
                    analyzer.config.data['processing'].setdefault('tracking', {})
                    analyzer.config.data['processing']['tracking']['config'] = 'bytetrack.yaml'
                    
                    # ğŸ”§ ä¿®æ­£: è‚©ãƒ»é ­éƒ¨è¨­å®šã®é©ç”¨
                    if args.disable_shoulder_metrics:
                        analyzer.config.data['processing']['enable_shoulder_metrics'] = False
                        logger.info("ğŸ”§ è‚©ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’ç„¡åŠ¹åŒ–")
                    else:
                        analyzer.config.data['processing']['enable_shoulder_metrics'] = True
                        
                    if args.disable_head_tracking:
                        analyzer.config.data['processing']['enable_head_tracking'] = False
                        logger.info("ğŸ”§ é ­éƒ¨è¿½è·¡ã‚’ç„¡åŠ¹åŒ–")
                    else:
                        analyzer.config.data['processing']['enable_head_tracking'] = True
                        
                    logger.info("ğŸ”§ è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’4ç‚¹ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆãƒ¢ãƒ¼ãƒ‰ç”¨ã«ç¢ºå®Ÿã«æ›´æ–°")
                    logger.info(f"   ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆä¿¡é ¼åº¦é–¾å€¤: {args.keypoint_threshold}")
                    logger.info(f"   è‚©ãƒ¡ãƒˆãƒªã‚¯ã‚¹: {'ç„¡åŠ¹' if args.disable_shoulder_metrics else 'æœ‰åŠ¹'}")
                    logger.info(f"   é ­éƒ¨è¿½è·¡: {'ç„¡åŠ¹' if args.disable_head_tracking else 'æœ‰åŠ¹'}")
                    
                else:
                    # ğŸ”§ ä¿®æ­£: è¨­å®šãŒãªã„å ´åˆã®å‡¦ç†ã‚’å¼·åŒ–
                    logger.error("âŒ è¨­å®šã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆãŒä¸æ­£ã§ã™")
                    logger.error("ğŸ”§ ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ4ç‚¹è¨­å®šã‚’ç›´æ¥é©ç”¨ã—ã¾ã™")
                    
                    # ç›´æ¥è¨­å®šã‚’ä½œæˆ
                    fallback_config = {
                        'processing': {
                            'use_4point_keypoints': True,
                            'keypoint_confidence_threshold': args.keypoint_threshold,
                            'force_pose_model': True,
                            'verify_keypoint_columns': True,
                            'tracking': {'config': 'bytetrack.yaml'},
                            'enable_shoulder_metrics': not args.disable_shoulder_metrics,
                            'enable_head_tracking': not args.disable_head_tracking
                        }
                    }
                    
                    if hasattr(analyzer, 'config'):
                        analyzer.config.data = fallback_config
                        logger.info("âœ… ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯è¨­å®šã‚’é©ç”¨")
                    else:
                        logger.error("ğŸš¨ è¨­å®šã®é©ç”¨ã«å®Œå…¨ã«å¤±æ•—ã—ã¾ã—ãŸ")
                        logger.error("ğŸš¨ 4ç‚¹ãƒ¢ãƒ¼ãƒ‰ã§ã®å‡¦ç†ãŒæ­£å¸¸ã«å‹•ä½œã—ãªã„å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™")
                        
            except Exception as config_error:
                logger.error(f"âŒ 4ç‚¹ãƒ¢ãƒ¼ãƒ‰è¨­å®šã‚¨ãƒ©ãƒ¼: {config_error}")
                logger.warning("âš ï¸ ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šã§å‡¦ç†ã‚’ç¶šè¡Œã—ã¾ã™")

        # ğŸ”§ å“è³ªè¨­å®šã®é©ç”¨
        quality_configs = {
            'low': {'resolution': '640x480', 'skip_frames': 2},
            'medium': {'resolution': '1280x720', 'skip_frames': 1},
            'high': {'resolution': '1920x1080', 'skip_frames': 0},
            'ultra': {'resolution': '1920x1080', 'skip_frames': 0}
        }

        if args.quality in quality_configs:
            quality_config = quality_configs[args.quality]
            if not args.resolution:
                args.resolution = quality_config['resolution']
            if args.skip_frames == 0:
                args.skip_frames = quality_config['skip_frames']

        # ğŸ”§ è§£åƒåº¦è¨­å®š
        if args.resolution:
            try:
                width, height = map(int, args.resolution.split('x'))
                if hasattr(analyzer.config, 'data'):
                    analyzer.config.data.setdefault('processing', {})
                    analyzer.config.data['processing']['target_width'] = width
                    analyzer.config.data['processing']['target_height'] = height
                logger.info(f"ğŸ“ è§£åƒåº¦è¨­å®š: {width}x{height}")
            except ValueError:
                logger.warning(f"âš ï¸ ä¸æ­£ãªè§£åƒåº¦å½¢å¼: {args.resolution}")

        # ğŸ”§ ãã®ä»–ã®å‡¦ç†è¨­å®š
        if hasattr(analyzer.config, 'data') and analyzer.config.data:
            processing_config = analyzer.config.data.setdefault('processing', {})
            
            # ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°ã‹ã‚‰è¨­å®šã‚’æ›´æ–°
            processing_config['confidence_threshold'] = args.confidence_threshold
            processing_config['iou_threshold'] = args.iou_threshold
            
            if args.fps:
                processing_config['target_fps'] = args.fps
                
            processing_config['skip_frames'] = args.skip_frames
            processing_config['save_intermediate'] = args.save_intermediate
            processing_config['enable_visualization'] = not args.disable_visualization
            
            # ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºè¨­å®š
            model_size_map = {
                'n': 'nano', 's': 'small', 'm': 'medium', 
                'l': 'large', 'x': 'xlarge'
            }
            processing_config['model_size'] = model_size_map.get(args.model_size, 'xlarge')

        # ğŸ¯ ãƒ¡ã‚¤ãƒ³åˆ†æå‡¦ç†å®Ÿè¡Œ
        logger.info("ğŸš€ ========== å§¿å‹¢åˆ†æå‡¦ç†é–‹å§‹ ==========")
        
        start_time = time.time()
        
        try:
            # ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³åˆ†æå®Ÿè¡Œ
            result = analyzer.run_baseline_analysis(str(video_path))
            
            if not result.get("success", False):
                error_msg = result.get("error", "ä¸æ˜ãªã‚¨ãƒ©ãƒ¼")
                logger.error(f"âŒ åˆ†æå‡¦ç†å¤±æ•—: {error_msg}")
                return 1
                
            processing_time = time.time() - start_time
            logger.info(f"â±ï¸ ç·å‡¦ç†æ™‚é–“: {processing_time:.2f}ç§’")
            
            # ğŸ¯ çµæœã®ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
            data = result.get("data", {})
            
            # ğŸ”§ ä¿®æ­£: å®Ÿéš›ã®çµ±è¨ˆã‚’æ­£ã—ãå–å¾—
            if result and isinstance(result, dict):
                result_data = result.get("data", {})
            
                # CSVãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰å®Ÿéš›ã®çµ±è¨ˆã‚’å–å¾—
                csv_path = result_data.get("csv_path")
                if csv_path and Path(csv_path).exists():
                    import pandas as pd
                    df = pd.read_csv(csv_path)
                    total_detections = len(df)
                    total_frames = len(df['frame'].unique()) if 'frame' in df.columns else 0
                    unique_ids = len(df['person_id'].unique()) if 'person_id' in df.columns else 0
                else:
                    # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: åŸºæœ¬çµ±è¨ˆã‹ã‚‰å–å¾—
                    total_detections = data.get("total_detections", 0)
                    total_frames = data.get("total_frames", 0)
                    unique_ids = data.get("unique_ids", 0)
            else:
                # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: åŸºæœ¬çµ±è¨ˆã‹ã‚‰å–å¾—
                total_detections = data.get("total_detections", 0)
                total_frames = data.get("total_frames", 0)
                unique_ids = data.get("unique_ids", 0)
        
            logger.info("ğŸ“Š ========== å‡¦ç†çµæœã‚µãƒãƒªãƒ¼ ==========")
            logger.info(f"ğŸ¬ ç·ãƒ•ãƒ¬ãƒ¼ãƒ æ•°: {total_frames}")
            logger.info(f"ğŸ¯ ç·æ¤œå‡ºæ•°: {total_detections}")
            logger.info(f"ğŸ‘¥ ãƒ¦ãƒ‹ãƒ¼ã‚¯äººç‰©ID: {unique_ids}")
        
            if total_frames > 0:
                detection_rate = total_detections / total_frames
                logger.info(f"ğŸ“ˆ ãƒ•ãƒ¬ãƒ¼ãƒ å½“ãŸã‚Šæ¤œå‡ºæ•°: {detection_rate:.2f}")
        
            # ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆçµ±è¨ˆï¼ˆ4ç‚¹ãƒ¢ãƒ¼ãƒ‰ã®å ´åˆï¼‰
            if args.use_4points:
                keypoint_stats = data.get("keypoint_stats", {})
                if keypoint_stats:
                    keypoint_frames = keypoint_stats.get("frames_with_keypoints", 0)
                    keypoint_rate = keypoint_frames / total_frames if total_frames > 0 else 0
                
                    logger.info("ğŸ¦´ ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆçµ±è¨ˆ:")
                    logger.info(f"  ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆæ¤œå‡ºãƒ•ãƒ¬ãƒ¼ãƒ : {keypoint_frames} ({keypoint_rate:.1%})")
                    logger.info(f"  ç·ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆæ•°: {keypoint_stats.get('total_keypoints', 0)}")
                
                    avg_keypoints = keypoint_stats.get('avg_keypoints_per_person', 0)
                    if avg_keypoints > 0:
                        logger.info(f"  å¹³å‡ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆ/äºº: {avg_keypoints:.1f}")
        
            # å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§
            output_files = data.get("output_files", [])
            if output_files:
                logger.info("ğŸ“ ç”Ÿæˆãƒ•ã‚¡ã‚¤ãƒ«:")
                for file_path in output_files:
                    if Path(file_path).exists():
                        size_mb = Path(file_path).stat().st_size / (1024 * 1024)
                        logger.info(f"  âœ… {file_path} ({size_mb:.2f}MB)")
                    else:
                        logger.warning(f"  âš ï¸ {file_path} (ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“)")
        
            # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹çµ±è¨ˆ
            fps = total_frames / processing_time if processing_time > 0 else 0
            logger.info(f"âš¡ å‡¦ç†æ€§èƒ½: {fps:.2f} FPS")
            
            # ã‚¨ãƒ©ãƒ¼å ±å‘Š
            if hasattr(analyzer, 'error_collector') and analyzer.error_collector:
                logger.warning(f"âš ï¸ å‡¦ç†ä¸­ã®ã‚¨ãƒ©ãƒ¼: {len(analyzer.error_collector)}ä»¶")
                for i, error in enumerate(analyzer.error_collector[:5], 1):
                    logger.warning(f"  {i}. {error}")
                if len(analyzer.error_collector) > 5:
                    logger.warning(f"  ... ä»– {len(analyzer.error_collector) - 5}ä»¶")
            
            logger.info("ğŸ¯ ========== å‡¦ç†å®Œäº† ==========")
            
            # æˆåŠŸæ™‚ã®è¿½åŠ æƒ…å ±
            if args.use_4points:
                logger.info("ğŸ’¡ 4ç‚¹ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’ç¢ºèªã—ã¦ãã ã•ã„:")
                logger.info("   - 4point_keypoints.csv: ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿")
                logger.info("   - 4point_metrics.csv: å§¿å‹¢ãƒ¡ãƒˆãƒªã‚¯ã‚¹ä»˜ããƒ‡ãƒ¼ã‚¿")
            
            if args.enable_depth:
                logger.info("ğŸ’¡ æ·±åº¦æ¨å®šãƒ‡ãƒ¼ã‚¿ã‚’ç¢ºèªã—ã¦ãã ã•ã„:")
                logger.info("   - depth_analysis/ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…ã®æ·±åº¦ãƒãƒƒãƒ—")
                
            return 0
            
        except Exception as e:
            logger.error(f"âŒ åˆ†æå‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ: {e}")
            import traceback
            logger.error(f"ğŸ”§ ãƒˆãƒ¬ãƒ¼ã‚¹ãƒãƒƒã‚¯:\n{traceback.format_exc()}")
            return 1

    except KeyboardInterrupt:
        logger.warning("â¸ï¸ ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ã‚ˆã‚‹å‡¦ç†ä¸­æ–­")
        return 130
        
    except Exception as e:
        logger.error(f"âŒ äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        logger.error(f"ğŸ”§ ãƒˆãƒ¬ãƒ¼ã‚¹ãƒãƒƒã‚¯:\n{traceback.format_exc()}")
        return 1


if __name__ == "__main__":
    # ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±å‡ºåŠ›
    print(f"ğŸ Python: {sys.version}")
    print(f"ğŸ’» Platform: {platform.platform()}")
    print(f"ğŸ§  CPU Count: {os.cpu_count()}")
    
    # GPUæƒ…å ±ç¢ºèª
    try:
        import torch
        if torch.cuda.is_available():
            print(f"ğŸš€ CUDA: {torch.version.cuda}")
            print(f"ğŸ® GPU: {torch.cuda.get_device_name(0)}")
        else:
            print("ğŸ’» GPU: CUDAåˆ©ç”¨ä¸å¯ï¼ˆCPUå‡¦ç†ï¼‰")
    except ImportError:
        print("âš ï¸ PyTorchæœªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«")
    
    print()
    
    # ãƒ¡ã‚¤ãƒ³å‡¦ç†å®Ÿè¡Œ
    sys.exit(main())