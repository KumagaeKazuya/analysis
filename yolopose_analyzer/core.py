"""
ãƒ¡ã‚¤ãƒ³åˆ†æé–¢æ•°ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ï¼ˆXLargeãƒ¢ãƒ‡ãƒ«ç¢ºå®Ÿä½¿ç”¨ç‰ˆãƒ»å®Ÿéš›ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«å®Œå…¨ãƒ­ã‚°å¯¾å¿œç‰ˆãƒ»ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆå‡¦ç†ä¿®æ­£ç‰ˆï¼‰
"""

import os
import cv2
import csv
import time
import numpy as np
import logging
import gc
import torch
import psutil
from pathlib import Path
from typing import Dict, Any, Optional, Tuple
from utils.camera_calibration import undistort_with_json

# ğŸ”§ çµ±ä¸€ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ã‹ã‚‰ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from utils.error_handler import (
    ModelInitializationError,
    ResourceExhaustionError,
    VideoProcessingError,
    ResponseBuilder,
    handle_errors,
    ErrorContext,
    ErrorCategory
)

from .system import safe_model_initialization
from .validation import validate_frame_directory
from .memory import MemoryEfficientProcessor
from .visualization import draw_detections_ultralytics

logger = logging.getLogger(__name__)


def log_actual_model_usage(model, requested_path: str, logger: logging.Logger) -> Dict[str, Any]:
    """å®Ÿéš›ã«ä½¿ç”¨ã•ã‚Œã¦ã„ã‚‹ãƒ¢ãƒ‡ãƒ«ã®è©³ç´°ã‚’ãƒ­ã‚°ã«è¨˜éŒ²"""
    try:
        model_info = {
            "requested_path": requested_path,
            "actual_model_file": None,
            "model_size_mb": 0,
            "parameter_count": 0,
            "estimated_type": "UNKNOWN",
            "verification_passed": False,
            "file_exists": False
        }
        
        # 1. ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã®ç‰¹å®š
        actual_file = None
        if hasattr(model, 'ckpt_path') and model.ckpt_path:
            actual_file = str(model.ckpt_path)
        elif hasattr(model, 'model_path') and model.model_path:
            actual_file = str(model.model_path)
        elif hasattr(model, 'cfg') and hasattr(model.cfg, 'model_path'):
            actual_file = str(model.cfg.model_path)
        else:
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: è¦æ±‚ã•ã‚ŒãŸãƒ‘ã‚¹ã§ç¢ºèª
            actual_file = requested_path
        
        model_info["actual_model_file"] = actual_file
        
        # 2. ãƒ•ã‚¡ã‚¤ãƒ«å­˜åœ¨ç¢ºèªã¨ã‚µã‚¤ã‚º
        if actual_file and Path(actual_file).exists():
            model_info["file_exists"] = True
            size_bytes = Path(actual_file).stat().st_size
            model_info["model_size_mb"] = round(size_bytes / (1024 * 1024), 2)
        else:
            logger.warning(f"âš ï¸ ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {actual_file}")
        
        # 3. ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ç¢ºèªï¼ˆæœ€ã‚‚ç¢ºå®Ÿãªæ–¹æ³•ï¼‰
        try:
            if hasattr(model, 'model') and hasattr(model.model, 'parameters'):
                total_params = sum(p.numel() for p in model.model.parameters())
                model_info["parameter_count"] = total_params
                
                # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ã«ã‚ˆã‚‹å®Ÿéš›ã®ãƒ¢ãƒ‡ãƒ«ã‚¿ã‚¤ãƒ—åˆ¤å®šï¼ˆYOLO11ã®å®Ÿéš›ã®å€¤ï¼‰
                if total_params < 3_200_000:  # ~3.2M
                    model_info["estimated_type"] = "NANO"
                elif total_params < 12_000_000:  # ~11M
                    model_info["estimated_type"] = "SMALL"
                elif total_params < 26_000_000:  # ~25M
                    model_info["estimated_type"] = "MEDIUM"
                elif total_params < 44_000_000:  # ~43M
                    model_info["estimated_type"] = "LARGE"
                else:  # ~57M+
                    model_info["estimated_type"] = "XLARGE"
        except Exception as param_error:
            logger.warning(f"âš ï¸ ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°å–å¾—ã‚¨ãƒ©ãƒ¼: {param_error}")
        
        # 4. è¦æ±‚vså®Ÿéš›ã®æ¤œè¨¼
        requested_type = "UNKNOWN"
        if "11x" in requested_path or "yolo11x" in requested_path:
            requested_type = "XLARGE"
        elif "11l" in requested_path:
            requested_type = "LARGE"
        elif "11m" in requested_path:
            requested_type = "MEDIUM"
        elif "11s" in requested_path:
            requested_type = "SMALL"
        elif "11n" in requested_path:
            requested_type = "NANO"
        
        model_info["requested_type"] = requested_type
        model_info["verification_passed"] = (requested_type == model_info["estimated_type"])
        
        # 5. è©³ç´°ãƒ­ã‚°å‡ºåŠ›
        logger.info("ğŸ” ========== å®Ÿéš›ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«æ¤œè¨¼çµæœ ==========")
        logger.info(f"ğŸ“ è¦æ±‚ãƒ¢ãƒ‡ãƒ«ãƒ‘ã‚¹: {requested_path}")
        logger.info(f"ğŸ“‚ å®Ÿéš›ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«: {model_info['actual_model_file']}")
        logger.info(f"ğŸ“Š ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: {model_info['model_size_mb']}MB")
        logger.info(f"ğŸ”¢ ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: {model_info['parameter_count']:,}")
        logger.info(f"ğŸ¯ è¦æ±‚ãƒ¢ãƒ‡ãƒ«ã‚¿ã‚¤ãƒ—: {requested_type}")
        logger.info(f"ğŸ¯ å®Ÿéš›ãƒ¢ãƒ‡ãƒ«ã‚¿ã‚¤ãƒ—: {model_info['estimated_type']}")
        logger.info(f"ğŸ“ ãƒ•ã‚¡ã‚¤ãƒ«å­˜åœ¨: {'âœ…' if model_info['file_exists'] else 'âŒ'}")
        
        if model_info["verification_passed"]:
            logger.info("âœ… ãƒ¢ãƒ‡ãƒ«æ¤œè¨¼: è¦æ±‚é€šã‚Šã®ãƒ¢ãƒ‡ãƒ«ãŒä½¿ç”¨ã•ã‚Œã¦ã„ã¾ã™")
        else:
            logger.error("âŒ ãƒ¢ãƒ‡ãƒ«ä¸ä¸€è‡´: è¦æ±‚ã¨ç•°ãªã‚‹ãƒ¢ãƒ‡ãƒ«ãŒä½¿ç”¨ã•ã‚Œã¦ã„ã¾ã™!")
            logger.error(f"   âš ï¸  æœŸå¾…: {requested_type} â†’ å®Ÿéš›: {model_info['estimated_type']}")
            
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ãŒç™ºç”Ÿã—ãŸã“ã¨ã‚’æ˜ç¢ºã«ãƒ­ã‚°
            if requested_type == "XLARGE" and model_info['estimated_type'] == "NANO":
                logger.error("ğŸ”´ é‡å¤§: XLARGEã‚’è¦æ±‚ã—ãŸãŒNANOãŒä½¿ç”¨ã•ã‚Œã¦ã„ã¾ã™!")
                logger.error("ğŸ”´ ã“ã‚Œã«ã‚ˆã‚Šæ¤œå‡ºç²¾åº¦ãŒå¤§å¹…ã«ä½ä¸‹ã—ã¦ã„ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™")
        
        logger.info("ğŸ” ============================================")
        
        return model_info
        
    except Exception as e:
        logger.error(f"âŒ ãƒ¢ãƒ‡ãƒ«ä½¿ç”¨ãƒ­ã‚°è¨˜éŒ²ã‚¨ãƒ©ãƒ¼: {e}")
        return {
            "requested_path": requested_path,
            "error": str(e),
            "verification_passed": False
        }


def load_model_with_verification(model_path: str, force_exact_model: bool = True) -> Tuple[Any, Dict[str, Any]]:
    """ç¢ºå®Ÿãªãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰ + ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«æ¤œè¨¼"""
    logger.info(f"ğŸš€ ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰é–‹å§‹: {model_path}")
    logger.info(f"ğŸ¯ å³å¯†ãƒ¢ãƒ¼ãƒ‰: {'æœ‰åŠ¹' if force_exact_model else 'ç„¡åŠ¹'}")
    
    # 1. ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«å­˜åœ¨ç¢ºèª
    if not Path(model_path).exists():
        if force_exact_model:
            error_msg = f"æŒ‡å®šãƒ¢ãƒ‡ãƒ«ãŒå­˜åœ¨ã—ã¾ã›ã‚“: {model_path}"
            logger.error(f"âŒ {error_msg}")
            
            # åˆ©ç”¨å¯èƒ½ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ã‚°å‡ºåŠ›
            models_dir = Path(model_path).parent
            if models_dir.exists():
                available_models = list(models_dir.glob("*.pt"))
                if available_models:
                    logger.info(f"ğŸ“‚ åˆ©ç”¨å¯èƒ½ãƒ¢ãƒ‡ãƒ«:")
                    for model_file in available_models:
                        size_mb = model_file.stat().st_size / (1024 * 1024)
                        logger.info(f"  {model_file.name} ({size_mb:.1f}MB)")
                else:
                    logger.error(f"âŒ {models_dir} ã«ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            
            raise FileNotFoundError(error_msg)
        else:
            logger.warning(f"âš ï¸ æŒ‡å®šãƒ¢ãƒ‡ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {model_path}")
            logger.info("ğŸ”„ ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç†ã‚’é–‹å§‹...")
    
    # 2. ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰å®Ÿè¡Œ
    try:
        from ultralytics import YOLO
        
        start_time = time.time()
        
        # ã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒ¢ãƒªç¢ºèª
        memory_info = psutil.virtual_memory()
        available_memory_gb = memory_info.available / (1024 ** 3)
        logger.info(f"ğŸ§  åˆ©ç”¨å¯èƒ½ãƒ¡ãƒ¢ãƒª: {available_memory_gb:.1f}GB")
        
        # XLargeãƒ¢ãƒ‡ãƒ«ã«ã¯æœ€ä½4GBå¿…è¦
        if "11x" in model_path and available_memory_gb < 4.0:
            logger.warning(f"âš ï¸ XLargeãƒ¢ãƒ‡ãƒ«ã«ã¯4GBä»¥ä¸Šæ¨å¥¨ï¼ˆç¾åœ¨: {available_memory_gb:.1f}GBï¼‰")
        
        logger.info(f"ğŸ“¥ ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰ä¸­: {model_path}")
        model = YOLO(model_path)
        load_time = time.time() - start_time
        
        logger.info(f"âœ… ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰å®Œäº†: {load_time:.2f}ç§’")
        
        # 3. å®Ÿéš›ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«ã®æ¤œè¨¼ã¨ãƒ­ã‚°è¨˜éŒ²
        verification_result = log_actual_model_usage(model, model_path, logger)
        verification_result["load_time_seconds"] = load_time
        verification_result["available_memory_gb"] = available_memory_gb
        
        return model, verification_result
        
    except Exception as e:
        logger.error(f"âŒ ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼: {e}")
        if force_exact_model:
            raise
        else:
            logger.warning("ğŸ”„ ç·Šæ€¥ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚’è©¦è¡Œ...")
            # æœ€å¾Œã®æ‰‹æ®µ: NANOãƒ¢ãƒ‡ãƒ«
            fallback_models = [
                "models/yolo/yolo11n-pose.pt",
                "models/yolo11n-pose.pt", 
                "yolo11n-pose.pt"
            ]
            
            for fallback_path in fallback_models:
                try:
                    logger.warning(f"ğŸ“¥ ç·Šæ€¥ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯è©¦è¡Œ: {fallback_path}")
                    from ultralytics import YOLO
                    model = YOLO(fallback_path)
                    verification_result = log_actual_model_usage(model, fallback_path, logger)
                    verification_result["emergency_fallback"] = True
                    verification_result["original_requested"] = model_path
                    return model, verification_result
                except Exception as fallback_error:
                    logger.warning(f"âš ï¸ ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å¤±æ•—: {fallback_path} - {fallback_error}")
                    continue
            
            # å…¨ã¦ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ãŒå¤±æ•—
            raise ModelInitializationError(f"å…¨ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰ã«å¤±æ•—: {e}")


def create_detection_visualization(frame, results, output_path: str, frame_file: str, config: Dict[str, Any]) -> bool:
    """æ¤œå‡ºæ ä»˜ãç”»åƒç”Ÿæˆï¼ˆæç”»å°‚ç”¨ï¼‰"""
    try:
        if frame is None or results is None:
            logger.warning(f"ãƒ•ãƒ¬ãƒ¼ãƒ ã¾ãŸã¯çµæœãŒç„¡åŠ¹: {frame_file}")
            return False

        vis_frame = frame.copy()
        detection_count = 0
        
        # æ¤œå‡ºçµæœã‚’æç”»
        for r in results:
            if r.boxes is not None:
                boxes = r.boxes.xyxy.cpu().numpy()
                confidences = r.boxes.conf.cpu().numpy()
                
                # ã‚¯ãƒ©ã‚¹æƒ…å ±
                if r.boxes.cls is not None:
                    classes = r.boxes.cls.cpu().numpy()
                else:
                    classes = [0] * len(boxes)
                
                # ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°ID
                if r.boxes.id is not None:
                    track_ids = r.boxes.id.cpu().numpy().astype(int)
                else:
                    track_ids = list(range(len(boxes)))
                
                # ğŸ¯ ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆæç”»ï¼ˆãƒ‡ãƒ¼ã‚¿æŠ½å‡ºã§ã¯ãªãæç”»ã®ã¿ï¼‰
                if r.keypoints is not None:
                    keypoints = r.keypoints.data.cpu().numpy()
                    # ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆã‚’ç”»åƒã«æç”»
                    for i, kpts in enumerate(keypoints):
                        if i < len(boxes) and confidences[i] >= config.get("confidence_threshold", 0.3):
                            # 17ç‚¹ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆã‚’æç”»
                            for j, (x, y, conf) in enumerate(kpts):
                                if conf > 0.5:  # å¯è¦–æ€§é–¾å€¤
                                    cv2.circle(vis_frame, (int(x), int(y)), 3, (0, 0, 255), -1)
                
                # ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹æç”»
                for i, (box, conf, cls_id) in enumerate(zip(boxes, confidences, classes)):
                    if conf < config.get("confidence_threshold", 0.3):
                        continue
                        
                    x1, y1, x2, y2 = map(int, box)
                    track_id = track_ids[i] if i < len(track_ids) else i
                    
                    # æ¤œå‡ºæ æç”»
                    cv2.rectangle(vis_frame, (x1, y1), (x2, y2), (0, 255, 0), 3)
                    
                    # ãƒ©ãƒ™ãƒ«ä½œæˆ
                    class_name = config.get("class_names", {}).get(int(cls_id), "person")
                    label = f"ID:{track_id} {class_name} {conf:.2f}"
                    
                    # ãƒ©ãƒ™ãƒ«æç”»
                    label_size = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2)[0]
                    cv2.rectangle(vis_frame, (x1, y1 - label_size[1] - 10), 
                                (x1 + label_size[0], y1), (0, 255, 0), -1)
                    cv2.putText(vis_frame, label, (x1, y1 - 5), 
                              cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 0), 2)
                    
                    detection_count += 1
        
        # ãƒ•ãƒ¬ãƒ¼ãƒ æƒ…å ±æç”»
        frame_info = f"Frame: {frame_file} | Detections: {detection_count}"
        cv2.putText(vis_frame, frame_info, (10, 30), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
        
        # ğŸš¨ é‡è¦: æ¤œå‡ºæ ä»˜ãç”»åƒä¿å­˜æ™‚ã®ãƒ­ã‚°
        success = cv2.imwrite(output_path, vis_frame)
        if success:
            logger.debug(f"âœ… æ¤œå‡ºæ ä»˜ãç”»åƒä¿å­˜: {output_path}")
        else:
            logger.error(f"âŒ æ¤œå‡ºæ ä»˜ãç”»åƒä¿å­˜å¤±æ•—: {output_path}")
        
        return success
        
    except Exception as e:
        logger.error(f"âŒ å¯è¦–åŒ–ç”Ÿæˆã‚¨ãƒ©ãƒ¼ {frame_file}: {e}")
        return False


@handle_errors(logger=logger, error_category=ErrorCategory.PROCESSING, suppress_exceptions=False)
def analyze_frames_with_tracking_memory_efficient(
    frame_dir: str,
    result_dir: str,
    model_path: str = "models/yolo/yolo11x-pose.pt",
    config: Optional[Dict[str, Any]] = None,
    pre_loaded_model: Optional[Any] = None,
    model_verification: Optional[Dict[str, Any]] = None,
    force_exact_model: bool = True
) -> Dict[str, Any]:
    """ãƒ¡ãƒ¢ãƒªåŠ¹ç‡çš„ãªãƒ•ãƒ¬ãƒ¼ãƒ è§£æï¼ˆæ­ªã¿è£œæ­£ä¸€è²«é©ç”¨ç‰ˆï¼‰"""
    from utils.camera_calibration import undistort_with_json

    with ErrorContext("XLargeãƒ¢ãƒ‡ãƒ«ç¢ºå®Ÿä½¿ç”¨ãƒ•ãƒ¬ãƒ¼ãƒ è§£æå‡¦ç†", logger=logger, raise_on_error=True) as ctx:
        # ãƒ¢ãƒ‡ãƒ«ãƒ‘ã‚¹ãƒ»è¨­å®šåˆæœŸåŒ–ï¼ˆæ—¢å­˜ã‚³ãƒ¼ãƒ‰ï¼‰
        logger.info("ğŸ¯ ========== ãƒ¢ãƒ‡ãƒ«ä½¿ç”¨é–‹å§‹ ==========")
        logger.info(f"ğŸ“ è¦æ±‚ãƒ¢ãƒ‡ãƒ«ãƒ‘ã‚¹: {model_path}")
        logger.info(f"ğŸ”§ å³å¯†ãƒ¢ãƒ¼ãƒ‰: {'æœ‰åŠ¹' if force_exact_model else 'ç„¡åŠ¹'}")
        logger.info("ğŸ¯ ====================================")

        if config is None:
            config = {
                "confidence_threshold": 0.3,
                "tracking_config": "bytetrack.yaml",
                "save_visualizations": True,
                "save_detection_frames": True,
                "batch_size": 16,
                "max_memory_gb": 6.0,
                "streaming_output": True,
                "device": "auto",
                "class_names": {0: "person"},
                "force_pose_task": True,
                "keypoint_processing_enabled": True
            }
        else:
            config = config.copy()
            config.setdefault("tracking_config", "bytetrack.yaml")
            config.setdefault("save_visualizations", True)
            config.setdefault("save_detection_frames", True)
            config.setdefault("class_names", {0: "person"})
            config.setdefault("force_pose_task", True)
            config.setdefault("keypoint_processing_enabled", True)
            if "11x" in model_path:
                config.setdefault("batch_size", 16)
                config.setdefault("max_memory_gb", 6.0)

        if not config.get("tracking_config") or config.get("tracking_config") == "":
            config["tracking_config"] = "bytetrack.yaml"
            logger.info("ğŸ”§ trackerè¨­å®šã‚’ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã«ä¿®æ­£")

        os.makedirs(result_dir, exist_ok=True)
        vis_dir = os.path.join(result_dir, "visualized_frames")
        os.makedirs(vis_dir, exist_ok=True)
        processor = MemoryEfficientProcessor(config)

        ctx.add_info("result_dir", result_dir)
        ctx.add_info("vis_dir", vis_dir)
        ctx.add_info("batch_size", config.get("batch_size", 16))
        ctx.add_info("save_visualizations", config.get("save_visualizations", True))
        ctx.add_info("force_exact_model", force_exact_model)

        try:
            # ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–
            if pre_loaded_model:
                logger.info("âœ… äº‹å‰ãƒ­ãƒ¼ãƒ‰æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨")
                model = pre_loaded_model
                verification_info = model_verification or {}
            else:
                logger.info("ğŸ”„ æ–°è¦ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰")
                model, verification_info = load_model_with_verification(model_path, force_exact_model)

            logger.info("ğŸ¯ ========== æœ€çµ‚ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«ç¢ºèª ==========")
            if verification_info.get("verification_passed"):
                logger.info(f"âœ… è¦æ±‚é€šã‚Šã®ãƒ¢ãƒ‡ãƒ«ã§å‡¦ç†å®Ÿè¡Œ")
                logger.info(f"   ãƒ¢ãƒ‡ãƒ«ã‚¿ã‚¤ãƒ—: {verification_info.get('estimated_type', 'UNKNOWN')}")
                logger.info(f"   ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: {verification_info.get('parameter_count', 0):,}")
                logger.info(f"   ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: {verification_info.get('model_size_mb', 0)}MB")
            else:
                logger.error(f"âŒ ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ãƒ¢ãƒ‡ãƒ«ã§å‡¦ç†å®Ÿè¡Œ")
                logger.error(f"   è¦æ±‚ã‚¿ã‚¤ãƒ—: {verification_info.get('requested_type', 'UNKNOWN')}")
                logger.error(f"   å®Ÿéš›ã‚¿ã‚¤ãƒ—: {verification_info.get('estimated_type', 'UNKNOWN')}")
                if verification_info.get("emergency_fallback"):
                    logger.error("ğŸš¨ ç·Šæ€¥ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ãŒç™ºç”Ÿã—ã¾ã—ãŸ!")
                    logger.error(f"   å…ƒè¦æ±‚: {verification_info.get('original_requested', 'ä¸æ˜')}")
            logger.info("ğŸ¯ ==========================================")
            ctx.add_info("model_verification", verification_info)

            # ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ¤œè¨¼
            frame_validation = validate_frame_directory(frame_dir)
            if not frame_validation.get("success", False):
                raise VideoProcessingError(
                    "ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®æ¤œè¨¼ã«å¤±æ•—ã—ã¾ã—ãŸ",
                    details=frame_validation.get("error", {})
                )

            frame_data = frame_validation["data"]
            frame_files = sorted([
                f for f in os.listdir(frame_dir)
                if f.lower().endswith(('.jpg', '.jpeg', '.png'))
            ])
            total_frames = len(frame_files)
            ctx.add_info("total_frames", total_frames)

            logger.info(f"ğŸ“Š å‡¦ç†å¯¾è±¡: {total_frames}ãƒ•ãƒ¬ãƒ¼ãƒ  ({frame_data['total_size_mb']:.1f}MB)")
            logger.info(f"ğŸ¨ å¯è¦–åŒ–ä¿å­˜: {config.get('save_visualizations', True)}")
            logger.info(f"ğŸ“ å¯è¦–åŒ–ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {vis_dir}")
            logger.info(f"ğŸ¯ ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«: {verification_info.get('estimated_type', 'UNKNOWN')}")

            # CSVæº–å‚™
            csv_path = os.path.join(result_dir, "detections_streaming.csv")
            base_headers = ["frame", "person_id", "x1", "y1", "x2", "y2", "conf", "class_name"]
            coco_names = ['nose', 'left_eye', 'right_eye', 'left_ear', 'right_ear',
                          'left_shoulder', 'right_shoulder', 'left_elbow', 'right_elbow',
                          'left_wrist', 'right_wrist', 'left_hip', 'right_hip',
                          'left_knee', 'right_knee', 'left_ankle', 'right_ankle']
            keypoint_headers = []
            for name in coco_names:
                keypoint_headers.extend([f'{name}_x', f'{name}_y', f'{name}_conf'])
            full_headers = base_headers + keypoint_headers

            stats = {
                "total_frames": total_frames,
                "processed_frames": 0,
                "successful_frames": 0,
                "failed_frames": 0,
                "total_detections": 0,
                "unique_ids": set(),
                "memory_peaks": [],
                "batch_times": [],
                "visualization_stats": {
                    "generated": 0,
                    "failed": 0,
                    "skipped": 0
                },
                "keypoint_stats": {
                    "frames_with_keypoints": 0,
                    "total_keypoints_detected": 0,
                    "keypoints_per_person": []
                },
                "model_verification": verification_info
            }

            batch_size = config.get("batch_size", 16)
            if verification_info.get('estimated_type') == 'XLARGE':
                logger.info("ğŸš€ XLARGEãƒ¢ãƒ‡ãƒ«ã§ã®é«˜ç²¾åº¦å‡¦ç†ã‚’é–‹å§‹ã—ã¾ã™")
                logger.info(f"   äºˆæƒ³å‡¦ç†æ™‚é–“: é€šå¸¸ã®2-3å€")
                logger.info(f"   äºˆæƒ³ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡: 4-8GB")

            with open(csv_path, 'w', newline='', encoding='utf-8') as csv_file:
                csv_writer = csv.writer(csv_file)
                csv_writer.writerow(full_headers)
                logger.info(f"ğŸ“‹ CSVå‡ºåŠ›æº–å‚™å®Œäº†:")
                logger.info(f"   åŸºæœ¬åˆ—: {len(base_headers)}å€‹")
                logger.info(f"   ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆåˆ—: {len(keypoint_headers)}å€‹")
                logger.info(f"   ç·åˆ—æ•°: {len(full_headers)}å€‹")

                try:
                    for batch_start in range(0, total_frames, batch_size):
                        batch_end = min(batch_start + batch_size, total_frames)
                        batch_files = frame_files[batch_start:batch_end]
                        batch_start_time = time.time()
                        batch_detections = []

                        logger.info(f"ğŸ“¦ ãƒãƒƒãƒå‡¦ç† {batch_start//batch_size + 1}/{(total_frames-1)//batch_size + 1}: "
                                    f"{len(batch_files)}ãƒ•ãƒ¬ãƒ¼ãƒ  (ãƒ¢ãƒ‡ãƒ«: {verification_info.get('estimated_type', 'UNKNOWN')})")

                        for frame_file in batch_files:
                            frame_path = os.path.join(frame_dir, frame_file)
                            try:
                                if processor.check_memory_threshold():
                                    logger.warning("âš ï¸ ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ãŒé–¾å€¤ã‚’è¶…éã€‚ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã‚’å®Ÿè¡Œ...")
                                    processor.force_memory_cleanup()

                                tracker_config = config.get("tracking_config")
                                if not tracker_config or tracker_config == "":
                                    tracker_config = "bytetrack.yaml"
                                    logger.debug(f"ğŸ”§ trackerè¨­å®šã‚’ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã«ä¿®æ­£: {tracker_config}")

                                # ğŸ¯ æ­ªã¿è£œæ­£ã‚’æ¨è«–å‰ã«é©ç”¨
                                frame = cv2.imread(frame_path)
                                if frame is None:
                                    logger.warning(f"âš ï¸ ãƒ•ãƒ¬ãƒ¼ãƒ èª­ã¿è¾¼ã¿å¤±æ•—: {frame_file}")
                                    stats["visualization_stats"]["failed"] += 1
                                    continue
                                frame = undistort_with_json(frame, calib_path="configs/camera_params.json")

                                # ğŸ¯ æ¨è«–å®Ÿè¡Œï¼ˆç”»åƒãƒ‡ãƒ¼ã‚¿ã‚’ç›´æ¥æ¸¡ã™ï¼‰
                                inference_params = {
                                    "source": frame,
                                    "persist": True,
                                    "tracker": tracker_config,
                                    "conf": config.get("confidence_threshold", 0.3),
                                    "task": "pose",
                                    "verbose": False,
                                    "save": False,
                                    "show": False
                                }
                                if config.get("force_pose_task", True):
                                    inference_params["task"] = "pose"

                                logger.info(f"ğŸ¯ æ¨è«–ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿: tracker={tracker_config}, task=pose")
                                results = model.track(**inference_params)

                                frame_detections = 0
                                frame_has_keypoints = False

                                for r in results:
                                    if r.boxes is not None:
                                        boxes = r.boxes.xyxy.cpu().numpy()
                                        confidences = r.boxes.conf.cpu().numpy()
                                        if r.boxes.id is not None:
                                            track_ids = r.boxes.id.cpu().numpy().astype(int)
                                        else:
                                            track_ids = list(range(len(boxes)))
                                        if r.keypoints is not None:
                                            try:
                                                keypoints = r.keypoints.data.cpu().numpy()
                                                frame_has_keypoints = True
                                                logger.debug(f"ğŸ¦´ ãƒ•ãƒ¬ãƒ¼ãƒ  {frame_file}: ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆæ¤œå‡º {keypoints.shape}")
                                                for i, (box, conf, kpts) in enumerate(zip(boxes, confidences, keypoints)):
                                                    if conf < config.get("confidence_threshold", 0.3):
                                                        continue
                                                    track_id = track_ids[i] if i < len(track_ids) else i
                                                    x1, y1, x2, y2 = box
                                                    detection_row = [
                                                        frame_file, int(track_id),
                                                        float(x1), float(y1), float(x2), float(y2),
                                                        float(conf), "person"
                                                    ]
                                                    valid_keypoints = 0
                                                    for j, name in enumerate(coco_names):
                                                        if j < len(kpts):
                                                            kpt_x, kpt_y, kpt_conf = kpts[j]
                                                            if np.isnan(kpt_x) or np.isinf(kpt_x):
                                                                kpt_x = 0.0
                                                            if np.isnan(kpt_y) or np.isinf(kpt_y):
                                                                kpt_y = 0.0
                                                            if np.isnan(kpt_conf) or np.isinf(kpt_conf):
                                                                kpt_conf = 0.0
                                                            detection_row.extend([
                                                                float(kpt_x),
                                                                float(kpt_y),
                                                                float(kpt_conf)
                                                            ])
                                                            if kpt_conf > 0.5:
                                                                valid_keypoints += 1
                                                        else:
                                                            detection_row.extend([0.0, 0.0, 0.0])
                                                    if len(detection_row) != len(full_headers):
                                                        logger.error(f"âŒ åˆ—æ•°ä¸ä¸€è‡´: æœŸå¾…{len(full_headers)}, å®Ÿéš›{len(detection_row)}")
                                                        logger.error(f"   ãƒ•ãƒ¬ãƒ¼ãƒ : {frame_file}")
                                                        logger.error(f"   æ¤œå‡ºãƒ‡ãƒ¼ã‚¿: {detection_row[:10]}...")
                                                        continue
                                                    batch_detections.append(detection_row)
                                                    frame_detections += 1
                                                    stats["unique_ids"].add(track_id)
                                                    stats["keypoint_stats"]["total_keypoints_detected"] += valid_keypoints
                                                    stats["keypoint_stats"]["keypoints_per_person"].append(valid_keypoints)
                                            except Exception as keypoint_error:
                                                logger.error(f"âŒ ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆå‡¦ç†ã‚¨ãƒ©ãƒ¼ {frame_file}: {keypoint_error}")
                                                frame_has_keypoints = False
                                        else:
                                            logger.warning(f"âš ï¸ ãƒ•ãƒ¬ãƒ¼ãƒ  {frame_file}: ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆæœªæ¤œå‡º")
                                            for i, (box, conf) in enumerate(zip(boxes, confidences)):
                                                if conf < config.get("confidence_threshold", 0.3):
                                                    continue
                                                track_id = track_ids[i] if i < len(track_ids) else i
                                                x1, y1, x2, y2 = box
                                                detection_row = [
                                                    frame_file, int(track_id),
                                                    float(x1), float(y1), float(x2), float(y2),
                                                    float(conf), "person"
                                                ]
                                                for _ in range(len(keypoint_headers)):
                                                    detection_row.append(0.0)
                                                if len(detection_row) != len(full_headers):
                                                    logger.error(f"âŒ ã‚¼ãƒ­ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°åˆ—æ•°ä¸ä¸€è‡´: æœŸå¾…{len(full_headers)}, å®Ÿéš›{len(detection_row)}")
                                                    continue
                                                batch_detections.append(detection_row)
                                                frame_detections += 1
                                                stats["unique_ids"].add(track_id)

                                if frame_has_keypoints:
                                    stats["keypoint_stats"]["frames_with_keypoints"] += 1
                                stats["total_detections"] += frame_detections
                                stats["successful_frames"] += 1

                                # ğŸ¨ æ¤œå‡ºæ ä»˜ãç”»åƒç”Ÿæˆ
                                if config.get("save_visualizations", True):
                                    try:
                                        # è£œæ­£æ¸ˆã¿frameã‚’ãã®ã¾ã¾å¯è¦–åŒ–ã«æ¸¡ã™
                                        vis_filename = f"vis_{frame_file}"
                                        vis_output_path = os.path.join(vis_dir, vis_filename)
                                        success = create_detection_visualization(
                                            frame, results, vis_output_path, frame_file, config
                                        )
                                        if success:
                                            stats["visualization_stats"]["generated"] += 1
                                            logger.debug(f"âœ… å¯è¦–åŒ–ç”Ÿæˆ: {vis_filename}")
                                        else:
                                            stats["visualization_stats"]["failed"] += 1
                                    except Exception as vis_error:
                                        logger.warning(f"âŒ å¯è¦–åŒ–ã‚¨ãƒ©ãƒ¼ {frame_file}: {vis_error}")
                                        stats["visualization_stats"]["failed"] += 1
                                else:
                                    stats["visualization_stats"]["skipped"] += 1

                                del results

                            except Exception as frame_error:
                                logger.error(f"âŒ ãƒ•ãƒ¬ãƒ¼ãƒ å‡¦ç†ã‚¨ãƒ©ãƒ¼ {frame_file}: {frame_error}", exc_info=True)
                                stats["failed_frames"] += 1
                                continue

                            stats["processed_frames"] += 1

                        if batch_detections:
                            try:
                                csv_writer.writerows(batch_detections)
                                csv_file.flush()
                                batch_keypoint_count = sum(1 for row in batch_detections
                                                           if any(row[8+i] != 0.0 for i in range(0, len(keypoint_headers), 3)))
                                logger.debug(f"ğŸ“Š ãƒãƒƒãƒCSVæ›¸ãè¾¼ã¿å®Œäº†: æ¤œå‡º{len(batch_detections)}å€‹, ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆä»˜ã{batch_keypoint_count}å€‹")
                            except Exception as csv_error:
                                logger.error(f"âŒ CSVæ›¸ãè¾¼ã¿ã‚¨ãƒ©ãƒ¼: {csv_error}")
                                raise

                        del batch_detections
                        processor.force_memory_cleanup()
                        batch_time = time.time() - batch_start_time
                        current_memory = processor.get_memory_usage()
                        stats["batch_times"].append(batch_time)
                        stats["memory_peaks"].append(current_memory)
                        progress = (batch_end / total_frames) * 100
                        vis_progress = stats["visualization_stats"]["generated"]
                        keypoint_frames = stats["keypoint_stats"]["frames_with_keypoints"]
                        logger.info(f"ğŸ“Š é€²æ—: {progress:.1f}% (ãƒ¡ãƒ¢ãƒª: {current_memory:.2f}GB, "
                                    f"ãƒãƒƒãƒæ™‚é–“: {batch_time:.1f}s, å¯è¦–åŒ–: {vis_progress}å€‹, "
                                    f"ãƒ¢ãƒ‡ãƒ«: {verification_info.get('estimated_type', 'UNKNOWN')})")

                except Exception as e:
                    logger.error(f"âŒ ãƒãƒƒãƒå‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
                    raise VideoProcessingError(f"ãƒãƒƒãƒå‡¦ç†ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}", original_exception=e)

            stats["unique_ids"] = len(stats["unique_ids"])
            stats["success_rate"] = stats["successful_frames"] / total_frames if total_frames > 0 else 0
            stats["avg_batch_time"] = np.mean(stats["batch_times"]) if stats["batch_times"] else 0
            stats["peak_memory_gb"] = max(stats["memory_peaks"]) if stats["memory_peaks"] else 0
            keypoint_stats = stats["keypoint_stats"]
            keypoint_frame_rate = keypoint_stats["frames_with_keypoints"] / total_frames if total_frames > 0 else 0
            avg_keypoints_per_person = np.mean(keypoint_stats["keypoints_per_person"]) if keypoint_stats["keypoints_per_person"] else 0
            vis_stats = stats["visualization_stats"]
            vis_success_rate = vis_stats["generated"] / total_frames if total_frames > 0 else 0

            ctx.add_info("total_detections", stats["total_detections"])
            ctx.add_info("success_rate", stats["success_rate"])
            ctx.add_info("peak_memory_gb", stats["peak_memory_gb"])
            ctx.add_info("visualization_generated", vis_stats["generated"])
            ctx.add_info("visualization_success_rate", vis_success_rate)
            ctx.add_info("keypoint_frame_rate", keypoint_frame_rate)
            ctx.add_info("avg_keypoints_per_person", avg_keypoints_per_person)
            ctx.add_info("model_type_used", verification_info.get('estimated_type', 'UNKNOWN'))

            logger.info("ğŸ¯ ========== å‡¦ç†å®Œäº†ã‚µãƒãƒªãƒ¼ ==========")
            logger.info(f"ğŸ“Š å‡¦ç†å®Œäº†çµ±è¨ˆ:")
            logger.info(f"  âœ… æˆåŠŸç‡: {stats['success_rate']:.1%}")
            logger.info(f"  ğŸ¯ ç·æ¤œå‡ºæ•°: {stats['total_detections']}")
            logger.info(f"  ğŸ‘¥ ãƒ¦ãƒ‹ãƒ¼ã‚¯ID: {stats['unique_ids']}")
            logger.info(f"  ğŸ§  ãƒ”ãƒ¼ã‚¯ãƒ¡ãƒ¢ãƒª: {stats['peak_memory_gb']:.2f}GB")
            logger.info(f"  â±ï¸  å¹³å‡ãƒãƒƒãƒæ™‚é–“: {stats['avg_batch_time']:.1f}s")
            logger.info(f"  ğŸ¨ å¯è¦–åŒ–ç”Ÿæˆ: {vis_stats['generated']}å€‹ (æˆåŠŸç‡: {vis_success_rate:.1%})")
            logger.info(f"  ğŸ“ å¯è¦–åŒ–ä¿å­˜å…ˆ: {vis_dir}")
            logger.info(f"ğŸ¦´ ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆçµ±è¨ˆ:")
            logger.info(f"  ğŸ“Š ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆä»˜ããƒ•ãƒ¬ãƒ¼ãƒ : {keypoint_stats['frames_with_keypoints']} ({keypoint_frame_rate:.1%})")
            logger.info(f"  ğŸ¯ ç·ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆæ¤œå‡ºæ•°: {keypoint_stats['total_keypoints_detected']}")
            logger.info(f"  ğŸ‘¤ å¹³å‡ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆ/äºº: {avg_keypoints_per_person:.1f}")
            logger.info(f"  ğŸ“‹ å‡ºåŠ›CSVåˆ—æ•°: {len(full_headers)} (åŸºæœ¬: {len(base_headers)}, ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆ: {len(keypoint_headers)})")
            logger.info(f"ğŸ¯ ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«æœ€çµ‚ç¢ºèª:")
            logger.info(f"  ğŸ“ è¦æ±‚: {verification_info.get('requested_type', 'UNKNOWN')}")
            logger.info(f"  âœ… å®Ÿéš›: {verification_info.get('estimated_type', 'UNKNOWN')}")
            logger.info(f"  ğŸ”§ æ¤œè¨¼çµæœ: {'æˆåŠŸ' if verification_info.get('verification_passed') else 'ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯'}")
            logger.info("ğŸ¯ ====================================")

            return ResponseBuilder.success(
                data={
                    "csv_path": csv_path,
                    "visualization_dir": vis_dir,
                    "processing_stats": stats,
                    "config_used": config,
                    "model_path": model_path,
                    "model_verification": verification_info,
                    "result_dir": result_dir,
                    "memory_efficient": True,
                    "visualization_enabled": True,
                    "keypoint_processing_enabled": True,
                    "csv_columns": len(full_headers),
                    "keypoint_columns": len(keypoint_headers),
                    "xlarge_model_verified": verification_info.get('verification_passed', False)
                },
                message=f"ãƒ•ãƒ¬ãƒ¼ãƒ è§£æå®Œäº†ï¼ˆ{verification_info.get('estimated_type', 'UNKNOWN')}ãƒ¢ãƒ‡ãƒ«ä½¿ç”¨ãƒ»ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆå‡¦ç†ä»˜ããƒ»æ¤œå‡ºæ ä»˜ãç”»åƒç”Ÿæˆä»˜ãï¼‰"
            )

        except ModelInitializationError as e:
            logger.error(f"âŒ ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–å¤±æ•—: {e}")
            return ResponseBuilder.error(
                message="ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸ",
                details={"error": str(e), "model_path": model_path}
            )

        except ResourceExhaustionError as e:
            logger.error(f"âŒ ãƒªã‚½ãƒ¼ã‚¹ä¸è¶³: {e}")
            return ResponseBuilder.error(
                message="ã‚·ã‚¹ãƒ†ãƒ ãƒªã‚½ãƒ¼ã‚¹ãŒä¸è¶³ã—ã¦ã„ã¾ã™",
                details={"error": str(e)}
            )

        except VideoProcessingError as e:
            logger.error(f"âŒ å‹•ç”»å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
            return ResponseBuilder.error(
                message="å‹•ç”»å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ",
                details={"error": str(e)}
            )

        except Exception as e:
            logger.error(f"âŒ äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
            return ResponseBuilder.error(
                message="äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ",
                details={"error": str(e)}
            )


@handle_errors(logger=logger, error_category=ErrorCategory.PROCESSING)
def analyze_frames_with_tracking_enhanced(
    frame_dir: str,
    result_dir: str,
    model_path: str = "models/yolo/yolo11x-pose.pt",
    config: Optional[Dict[str, Any]] = None,
    force_exact_model: bool = True
) -> Dict[str, Any]:
    """æ‹¡å¼µç‰ˆãƒ•ãƒ¬ãƒ¼ãƒ è§£æï¼ˆå®Œå…¨ä¿®æ­£ç‰ˆï¼‰"""
    with ErrorContext("XLargeæ‹¡å¼µãƒ•ãƒ¬ãƒ¼ãƒ è§£æ", logger=logger) as ctx:
        ctx.add_info("frame_dir", frame_dir)
        ctx.add_info("model_path", model_path)
        ctx.add_info("force_exact_model", force_exact_model)

        # è¨­å®šã‹ã‚‰ãƒ¢ãƒ‡ãƒ«ãƒ‘ã‚¹å–å¾—
        final_model_path = model_path
        if config:
            config_model_path = config.get("models", {}).get("pose")
            if config_model_path:
                final_model_path = config_model_path
                logger.info(f"ğŸ“‹ è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ãƒ¢ãƒ‡ãƒ«ãƒ‘ã‚¹å–å¾—: {final_model_path}")
        
        logger.info(f"ğŸ¯ æœ€çµ‚æ±ºå®šãƒ¢ãƒ‡ãƒ«ãƒ‘ã‚¹: {final_model_path}")
        
        # ã‚¿ã‚¤ãƒ«æ¨è«–ã®åˆ¤å®š
        if config and config.get("tile_inference", {}).get("enabled", False):
            logger.info("ğŸ”² ã‚¿ã‚¤ãƒ«æ¨è«–ãƒ¢ãƒ¼ãƒ‰ã§å®Ÿè¡Œ")
            try:
                from .tile_inference import analyze_frames_with_tile_inference
                return analyze_frames_with_tile_inference(
                    frame_dir, result_dir, final_model_path, config, force_exact_model
                )
            except ImportError:
                logger.warning("âš ï¸ ã‚¿ã‚¤ãƒ«æ¨è«–ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚é€šå¸¸æ¨è«–ã«åˆ‡ã‚Šæ›¿ãˆã¾ã™")
        
        # ç¢ºå®Ÿãªãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰
        try:
            model, verification_result = load_model_with_verification(
                final_model_path, force_exact_model
            )
            
            ctx.add_info("model_verification", verification_result)
            
            # é€šå¸¸æ¨è«–å®Ÿè¡Œ
            return analyze_frames_with_tracking_memory_efficient(
                frame_dir, result_dir, final_model_path, config, 
                pre_loaded_model=model,
                model_verification=verification_result,
                force_exact_model=force_exact_model
            )
            
        except Exception as e:
            logger.error(f"âŒ ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰ã¾ãŸã¯å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
            if force_exact_model:
                return ResponseBuilder.error(
                    message=f"æŒ‡å®šãƒ¢ãƒ‡ãƒ«ï¼ˆ{final_model_path}ï¼‰ã®å‡¦ç†ã«å¤±æ•—ã—ã¾ã—ãŸ",
                    details={"error": str(e), "model_path": final_model_path}
                )
            else:
                logger.warning("ğŸ”„ ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ãƒ¢ãƒ¼ãƒ‰ã§å†è©¦è¡Œ...")
                return analyze_frames_with_tracking_memory_efficient(
                    frame_dir, result_dir, final_model_path, config,
                    force_exact_model=False
                )