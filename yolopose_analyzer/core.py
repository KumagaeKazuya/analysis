"""
ãƒ¡ã‚¤ãƒ³åˆ†æé–¢æ•°ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ï¼ˆçµ±ä¸€ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°å¯¾å¿œç‰ˆï¼‰
"""

import os
import cv2
import csv
import time
import numpy as np
import logging
import gc
from pathlib import Path
from typing import Dict, Any, Optional

# ğŸ”§ çµ±ä¸€ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ã‹ã‚‰ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from utils.error_handler import (
    ModelInitializationError,
    ResourceExhaustionError,
    VideoProcessingError,
    ResponseBuilder,
    handle_errors,
    ErrorContext,
    ErrorCategory
)

from .system import safe_model_initialization
from .validation import validate_frame_directory
from .memory import MemoryEfficientProcessor
from .visualization import draw_detections_ultralytics

logger = logging.getLogger(__name__)


@handle_errors(logger=logger, error_category=ErrorCategory.PROCESSING, suppress_exceptions=False)
def analyze_frames_with_tracking_memory_efficient(
    frame_dir: str,
    result_dir: str,
    model_path: str = "models/yolo11n-pose.pt",
    config: Optional[Dict[str, Any]] = None
) -> Dict[str, Any]:
    """
    ãƒ¡ãƒ¢ãƒªåŠ¹ç‡çš„ãªãƒ•ãƒ¬ãƒ¼ãƒ è§£æï¼ˆçµ±ä¸€ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°å¯¾å¿œç‰ˆï¼‰

    Args:
        frame_dir: ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        result_dir: çµæœå‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        model_path: YOLOãƒ¢ãƒ‡ãƒ«ãƒ‘ã‚¹
        config: å‡¦ç†è¨­å®š

    Returns:
        ResponseBuilderå½¢å¼ã®å‡¦ç†çµæœ
    """
    with ErrorContext("ãƒ•ãƒ¬ãƒ¼ãƒ è§£æå‡¦ç†", logger=logger, raise_on_error=True) as ctx:
        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®š
        if config is None:
            config = {
                "confidence_threshold": 0.3,
                "tracking_config": "bytetrack.yaml",
                "save_visualizations": True,
                "batch_size": 32,
                "max_memory_gb": 4.0,
                "streaming_output": True,
                "device": "auto"
            }

        os.makedirs(result_dir, exist_ok=True)
        processor = MemoryEfficientProcessor(config)

        ctx.add_info("result_dir", result_dir)
        ctx.add_info("batch_size", config.get("batch_size", 32))

        try:
            # ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–
            model = safe_model_initialization(model_path, config)

            # ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ¤œè¨¼
            frame_validation = validate_frame_directory(frame_dir)
            if not frame_validation.get("success", False):
                raise VideoProcessingError(
                    "ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®æ¤œè¨¼ã«å¤±æ•—ã—ã¾ã—ãŸ",
                    details=frame_validation.get("error", {})
                )

            frame_data = frame_validation["data"]
            frame_files = sorted([
                f for f in os.listdir(frame_dir)
                if f.lower().endswith(('.jpg', '.jpeg', '.png'))
            ])

            total_frames = len(frame_files)
            ctx.add_info("total_frames", total_frames)

            logger.info(f"å‡¦ç†å¯¾è±¡: {total_frames}ãƒ•ãƒ¬ãƒ¼ãƒ  ({frame_data['total_size_mb']:.1f}MB)")

            # CSVæº–å‚™
            csv_path = os.path.join(result_dir, "detections_streaming.csv")

            # çµ±è¨ˆåˆæœŸåŒ–
            stats = {
                "total_frames": total_frames,
                "processed_frames": 0,
                "successful_frames": 0,
                "failed_frames": 0,
                "total_detections": 0,
                "unique_ids": set(),
                "memory_peaks": [],
                "batch_times": []
            }

            batch_size = config.get("batch_size", 32)

            # ãƒãƒƒãƒå‡¦ç†
            with open(csv_path, 'w', newline='', encoding='utf-8') as csv_file:
                csv_writer = csv.writer(csv_file)
                csv_writer.writerow(["frame", "person_id", "x1", "y1", "x2", "y2", "conf", "class_name"])

                try:
                    for batch_start in range(0, total_frames, batch_size):
                        batch_end = min(batch_start + batch_size, total_frames)
                        batch_files = frame_files[batch_start:batch_end]

                        batch_start_time = time.time()
                        batch_detections = []

                        logger.info(f"ãƒãƒƒãƒå‡¦ç† {batch_start//batch_size + 1}/{(total_frames-1)//batch_size + 1}: "
                                f"{len(batch_files)}ãƒ•ãƒ¬ãƒ¼ãƒ ")

                        for frame_file in batch_files:
                            frame_path = os.path.join(frame_dir, frame_file)

                            try:
                                # ãƒ¡ãƒ¢ãƒªãƒã‚§ãƒƒã‚¯
                                if processor.check_memory_threshold():
                                    logger.warning("ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ãŒé–¾å€¤ã‚’è¶…éã€‚ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã‚’å®Ÿè¡Œ...")
                                    processor.force_memory_cleanup()

                                # ãƒˆãƒ©ãƒƒã‚«ãƒ¼è¨­å®šã®å®‰å…¨æ€§ãƒã‚§ãƒƒã‚¯
                                tracker_config = config.get("tracking_config")
                                if tracker_config is None or not tracker_config:
                                    tracker_config = "bytetrack.yaml"
                                    logger.debug(f"trackerè¨­å®šãŒç©ºã ã£ãŸãŸã‚ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’ä½¿ç”¨: {tracker_config}")

                                # æ¨è«–å®Ÿè¡Œ
                                results = model.track(
                                    frame_path,
                                    persist=True,
                                    tracker=tracker_config,
                                    conf=config.get("confidence_threshold", 0.3),
                                    verbose=False
                                )

                                # çµæœå‡¦ç†
                                frame_detections = 0
                                for r in results:
                                    if r.boxes is not None:
                                        boxes = r.boxes.xyxy.cpu().numpy()
                                        confidences = r.boxes.conf.cpu().numpy()

                                        # ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°IDã®å‡¦ç†
                                        if r.boxes.id is not None:
                                            track_ids = r.boxes.id.cpu().numpy().astype(int)
                                        else:
                                            track_ids = list(range(len(boxes)))

                                        for i, (box, conf) in enumerate(zip(boxes, confidences)):
                                            track_id = track_ids[i] if i < len(track_ids) else i
                                            x1, y1, x2, y2 = box
                                            detection_row = [
                                                frame_file, track_id,
                                                float(x1), float(y1), float(x2), float(y2),
                                                float(conf), "person"
                                            ]
                                            batch_detections.append(detection_row)
                                            frame_detections += 1
                                            stats["unique_ids"].add(track_id)

                                stats["total_detections"] += frame_detections
                                stats["successful_frames"] += 1

                                # å¯è¦–åŒ–ï¼ˆãƒ¡ãƒ¢ãƒªåŠ¹ç‡è€ƒæ…®ï¼‰
                                if config.get("save_visualizations", False) and frame_detections > 0:
                                    try:
                                        frame = cv2.imread(frame_path)
                                        if frame is not None:
                                            vis_frame = draw_detections_ultralytics(frame, results)
                                            # vis_ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹ã‚’è¿½åŠ 
                                            vis_filename = f"vis_{frame_file}"
                                            output_path = os.path.join(result_dir, vis_filename)
                                            cv2.imwrite(output_path, vis_frame)
                                            logger.debug(f"å¯è¦–åŒ–ä¿å­˜: {output_path}")
                                            del frame, vis_frame
                                    except Exception as vis_error:
                                        logger.warning(f"å¯è¦–åŒ–ã‚¨ãƒ©ãƒ¼ {frame_file}: {vis_error}")

                                # çµæœã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’è§£æ”¾
                                del results

                            except Exception as frame_error:
                                logger.error(f"ãƒ•ãƒ¬ãƒ¼ãƒ å‡¦ç†ã‚¨ãƒ©ãƒ¼ {frame_file}: {frame_error}", exc_info=True)
                                stats["failed_frames"] += 1
                                continue

                            stats["processed_frames"] += 1

                        # ãƒãƒƒãƒã®æ¤œå‡ºçµæœã‚’CSVã«æ›¸ãè¾¼ã¿
                        if batch_detections:
                            csv_writer.writerows(batch_detections)
                            csv_file.flush()  # å³åº§ã«ãƒ‡ã‚£ã‚¹ã‚¯ã«æ›¸ãè¾¼ã¿

                        # ãƒãƒƒãƒå‡¦ç†å®Œäº†å¾Œã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
                        del batch_detections
                        processor.force_memory_cleanup()

                        # çµ±è¨ˆæ›´æ–°
                        batch_time = time.time() - batch_start_time
                        current_memory = processor.get_memory_usage()
                        stats["batch_times"].append(batch_time)
                        stats["memory_peaks"].append(current_memory)

                        # é€²æ—å ±å‘Š
                        progress = (batch_end / total_frames) * 100
                        logger.info(f"é€²æ—: {progress:.1f}% (ãƒ¡ãƒ¢ãƒª: {current_memory:.2f}GB, "
                                f"ãƒãƒƒãƒæ™‚é–“: {batch_time:.1f}s)")

                except Exception as e:
                    logger.error(f"ãƒãƒƒãƒå‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
                    raise VideoProcessingError(f"ãƒãƒƒãƒå‡¦ç†ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}", original_exception=e)

            # æœ€çµ‚çµ±è¨ˆã®è¨ˆç®—
            stats["unique_ids"] = len(stats["unique_ids"])
            stats["success_rate"] = stats["successful_frames"] / total_frames if total_frames > 0 else 0
            stats["avg_batch_time"] = np.mean(stats["batch_times"]) if stats["batch_times"] else 0
            stats["peak_memory_gb"] = max(stats["memory_peaks"]) if stats["memory_peaks"] else 0

            ctx.add_info("total_detections", stats["total_detections"])
            ctx.add_info("success_rate", stats["success_rate"])
            ctx.add_info("peak_memory_gb", stats["peak_memory_gb"])

            # çµæœã‚µãƒãƒªãƒ¼ã®ãƒ­ã‚°å‡ºåŠ›
            logger.info(f"âœ… å‡¦ç†å®Œäº†çµ±è¨ˆ:")
            logger.info(f"  æˆåŠŸç‡: {stats['success_rate']:.1%}")
            logger.info(f"  ç·æ¤œå‡ºæ•°: {stats['total_detections']}")
            logger.info(f"  ãƒ¦ãƒ‹ãƒ¼ã‚¯ID: {stats['unique_ids']}")
            logger.info(f"  ãƒ”ãƒ¼ã‚¯ãƒ¡ãƒ¢ãƒª: {stats['peak_memory_gb']:.2f}GB")
            logger.info(f"  å¹³å‡ãƒãƒƒãƒæ™‚é–“: {stats['avg_batch_time']:.1f}s")

            return ResponseBuilder.success(
                data={
                    "csv_path": csv_path,
                    "processing_stats": stats,
                    "config_used": config,
                    "model_path": model_path,
                    "result_dir": result_dir,
                    "memory_efficient": True
                },
                message="ãƒ•ãƒ¬ãƒ¼ãƒ è§£æå®Œäº†"
            )

        except ModelInitializationError as e:
            logger.error(f"ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–å¤±æ•—: {e}")
            return ResponseBuilder.error(
                message="ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸ",
                details={"error": str(e), "model_path": model_path}
            )

        except ResourceExhaustionError as e:
            logger.error(f"ãƒªã‚½ãƒ¼ã‚¹ä¸è¶³: {e}")
            return ResponseBuilder.error(
                message="ã‚·ã‚¹ãƒ†ãƒ ãƒªã‚½ãƒ¼ã‚¹ãŒä¸è¶³ã—ã¦ã„ã¾ã™",
                details={"error": str(e)}
            )

        except VideoProcessingError as e:
            logger.error(f"å‹•ç”»å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
            return ResponseBuilder.error(
                message="å‹•ç”»å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ",
                details={"error": str(e)}
            )

        except Exception as e:
            logger.error(f"äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
            return ResponseBuilder.error(
                message="äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ",
                details={"error": str(e)}
            )


@handle_errors(logger=logger, error_category=ErrorCategory.PROCESSING)
def analyze_frames_with_tracking_enhanced(
    frame_dir: str,
    result_dir: str,
    model_path: str = "models/yolo11n-pose.pt",
    config: Optional[Dict[str, Any]] = None
) -> Dict[str, Any]:
    """
    æ‹¡å¼µç‰ˆãƒ•ãƒ¬ãƒ¼ãƒ è§£æï¼ˆã‚¿ã‚¤ãƒ«æ¨è«–ã‚ªãƒ—ã‚·ãƒ§ãƒ³ä»˜ãï¼‰

    è¨­å®šã§tile_inference.enabled=Trueã®å ´åˆã€ã‚¿ã‚¤ãƒ«æ¨è«–ã‚’ä½¿ç”¨ã€‚
    ãã‚Œä»¥å¤–ã¯é€šå¸¸ã®ãƒ¡ãƒ¢ãƒªåŠ¹ç‡ç‰ˆã‚’ä½¿ç”¨ã€‚

    Args:
        frame_dir: ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        result_dir: çµæœå‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        model_path: YOLOãƒ¢ãƒ‡ãƒ«ãƒ‘ã‚¹
        config: å‡¦ç†è¨­å®šï¼ˆtile_inferenceè¨­å®šã‚’å«ã‚€å¯èƒ½æ€§ã‚ã‚Šï¼‰

    Returns:
        ResponseBuilderå½¢å¼ã®å‡¦ç†çµæœ
    """
    with ErrorContext("æ‹¡å¼µãƒ•ãƒ¬ãƒ¼ãƒ è§£æ", logger=logger) as ctx:
        ctx.add_info("frame_dir", frame_dir)
        ctx.add_info("model_path", model_path)

        if config and config.get("tile_inference", {}).get("enabled", False):
            # ã‚¿ã‚¤ãƒ«æ¨è«–ãƒ¢ãƒ¼ãƒ‰ã¸
            logger.info("ğŸ”² ã‚¿ã‚¤ãƒ«æ¨è«–ãƒ¢ãƒ¼ãƒ‰ã§å®Ÿè¡Œ")
            try:
                from .tile_inference import analyze_frames_with_tile_inference
                return analyze_frames_with_tile_inference(frame_dir, result_dir, model_path, config)
            except ImportError:
                logger.warning("ã‚¿ã‚¤ãƒ«æ¨è«–ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚é€šå¸¸æ¨è«–ã«åˆ‡ã‚Šæ›¿ãˆã¾ã™")
                return analyze_frames_with_tracking_memory_efficient(
                    frame_dir, result_dir, model_path, config
                )
        else:
            # é€šå¸¸æ¨è«–ï¼ˆãƒ¡ãƒ¢ãƒªåŠ¹ç‡ç‰ˆï¼‰
            logger.info("ğŸ’» é€šå¸¸æ¨è«–ï¼ˆãƒ¡ãƒ¢ãƒªåŠ¹ç‡ç‰ˆï¼‰ã§å®Ÿè¡Œ")
            return analyze_frames_with_tracking_memory_efficient(
                frame_dir, result_dir, model_path, config
            )