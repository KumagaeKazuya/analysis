"""
ãƒ¡ã‚¤ãƒ³åˆ†æé–¢æ•°ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ« (ä¿®æ­£ç‰ˆãƒ»å®Œå…¨ç‰ˆ)

ğŸ”§ ä¸»ãªä¿®æ­£ç‚¹:
1. trackerè¨­å®šã®å®‰å…¨æ€§ãƒã‚§ãƒƒã‚¯è¿½åŠ 
2. å…¨ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã«ã‚¹ã‚¿ãƒƒã‚¯ãƒˆãƒ¬ãƒ¼ã‚¹å‡ºåŠ›è¿½åŠ 
3. ãƒ¡ãƒ¢ãƒªåŠ¹ç‡çš„ãªãƒãƒƒãƒå‡¦ç†

å…ƒã® yolopose_analyzer.py ã‹ã‚‰å®Œå…¨ã«ç§»æ¤
"""

import os
import cv2
import csv
import time
import numpy as np
import logging
import gc
from pathlib import Path
from typing import Dict, Any, Optional

from .system import safe_model_initialization, ModelInitializationError, ResourceExhaustionError
from .validation import validate_frame_directory
from .memory import MemoryEfficientProcessor
from .visualization import draw_detections_ultralytics

logger = logging.getLogger(__name__)


def analyze_frames_with_tracking_memory_efficient(
    frame_dir: str,
    result_dir: str,
    model_path: str = "models/yolo11n-pose.pt",
    config: Optional[Dict[str, Any]] = None
) -> Dict[str, Any]:
    """
    ãƒ¡ãƒ¢ãƒªåŠ¹ç‡ã‚’è€ƒæ…®ã—ãŸãƒ•ãƒ¬ãƒ¼ãƒ è§£æï¼ˆä¿®æ­£ç‰ˆï¼‰
    
    ãƒãƒƒãƒå‡¦ç†ã€ãƒ¡ãƒ¢ãƒªç®¡ç†ã€ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å‡ºåŠ›ã€å¯è¦–åŒ–ã‚’å«ã‚€å®Œå…¨å®Ÿè£…ã€‚
    
    Args:
        frame_dir: ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        result_dir: çµæœå‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        model_path: YOLOãƒ¢ãƒ‡ãƒ«ãƒ‘ã‚¹
        config: å‡¦ç†è¨­å®š
        
    Returns:
        å‡¦ç†çµæœã®è¾æ›¸ {
            "csv_path": str,
            "processing_stats": dict,
            "success": bool,
            ...
        }
    """
    
    # ===== ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®š =====
    if config is None:
        config = {
            "confidence_threshold": 0.3,
            "tracking_config": "bytetrack.yaml",
            "save_visualizations": True,
            "batch_size": 32,
            "max_memory_gb": 4.0,
            "streaming_output": True,
            "device": "auto"
        }

    os.makedirs(result_dir, exist_ok=True)
    processor = MemoryEfficientProcessor(config)

    try:
        # ===== ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ– =====
        model = safe_model_initialization(model_path, config)
        
        # ===== ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ¤œè¨¼ =====
        frame_validation = validate_frame_directory(frame_dir)
        if not frame_validation["valid"]:
            return {
                "error": "frame_validation_failed",
                "details": frame_validation["errors"],
                "suggestions": frame_validation.get("suggestions", []),
                "frame_dir": frame_dir,
                "success": False
            }

        frame_files = sorted([
            f for f in os.listdir(frame_dir)
            if f.lower().endswith(('.jpg', '.jpeg', '.png'))
        ])

        total_frames = len(frame_files)
        logger.info(f"å‡¦ç†å¯¾è±¡: {total_frames}ãƒ•ãƒ¬ãƒ¼ãƒ  ({frame_validation['total_size_mb']:.1f}MB)")

        # ===== ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å‡ºåŠ›ç”¨CSVæº–å‚™ =====
        csv_path = os.path.join(result_dir, "detections_streaming.csv")

        # ===== å‡¦ç†çµ±è¨ˆã®åˆæœŸåŒ– =====
        stats = {
            "total_frames": total_frames,
            "processed_frames": 0,
            "successful_frames": 0,
            "failed_frames": 0,
            "total_detections": 0,
            "unique_ids": set(),
            "memory_peaks": [],
            "batch_times": []
        }

        # ===== ãƒãƒƒãƒã‚µã‚¤ã‚ºã®è¨­å®š =====
        batch_size = config.get("batch_size", 32)

        # ===== ãƒ¡ã‚¤ãƒ³å‡¦ç†ãƒ«ãƒ¼ãƒ— =====
        with open(csv_path, 'w', newline='', encoding='utf-8') as csv_file:
            csv_writer = csv.writer(csv_file)
            csv_writer.writerow(["frame", "person_id", "x1", "y1", "x2", "y2", "conf", "class_name"])

            try:
                # ----- ãƒãƒƒãƒã”ã¨ã«å‡¦ç† -----
                for batch_start in range(0, total_frames, batch_size):
                    batch_end = min(batch_start + batch_size, total_frames)
                    batch_files = frame_files[batch_start:batch_end]

                    batch_start_time = time.time()
                    batch_detections = []

                    logger.info(f"ãƒãƒƒãƒå‡¦ç† {batch_start//batch_size + 1}/{(total_frames-1)//batch_size + 1}: "
                              f"{len(batch_files)}ãƒ•ãƒ¬ãƒ¼ãƒ ")

                    # ----- ãƒãƒƒãƒå†…ã®ãƒ•ãƒ¬ãƒ¼ãƒ å‡¦ç† -----
                    for frame_file in batch_files:
                        frame_path = os.path.join(frame_dir, frame_file)

                        try:
                            # ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ãƒã‚§ãƒƒã‚¯
                            if processor.check_memory_threshold():
                                logger.warning("ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ãŒé–¾å€¤ã‚’è¶…éã€‚ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã‚’å®Ÿè¡Œ...")
                                processor.force_memory_cleanup()

                            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                            # ğŸ”§ ä¿®æ­£5: trackerè¨­å®šã®å®‰å…¨æ€§ãƒã‚§ãƒƒã‚¯
                            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                            tracker_config = config.get("tracking_config")
                            
                            # Noneãƒã‚§ãƒƒã‚¯
                            if tracker_config is None or not tracker_config:
                                tracker_config = "bytetrack.yaml"
                                logger.debug(f"trackerè¨­å®šãŒç©ºã ã£ãŸãŸã‚ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’ä½¿ç”¨: {tracker_config}")

                            # æ¨è«–å®Ÿè¡Œ
                            results = model.track(
                                frame_path,
                                persist=True,
                                tracker=tracker_config,  # â† ç¢ºå®Ÿã«æ–‡å­—åˆ—ãŒå…¥ã‚‹
                                conf=config.get("confidence_threshold", 0.3),
                                verbose=False
                            )

                            # ----- çµæœå‡¦ç† -----
                            frame_detections = 0
                            for r in results:
                                if r.boxes is not None:
                                    boxes = r.boxes.xyxy.cpu().numpy()
                                    confidences = r.boxes.conf.cpu().numpy()

                                    # ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°IDã®å‡¦ç†
                                    if r.boxes.id is not None:
                                        track_ids = r.boxes.id.cpu().numpy().astype(int)
                                    else:
                                        track_ids = list(range(len(boxes)))

                                    for i, (box, conf) in enumerate(zip(boxes, confidences)):
                                        track_id = track_ids[i] if i < len(track_ids) else i
                                        x1, y1, x2, y2 = box
                                        detection_row = [
                                            frame_file, track_id, 
                                            float(x1), float(y1), float(x2), float(y2), 
                                            float(conf), "person"
                                        ]
                                        batch_detections.append(detection_row)
                                        frame_detections += 1
                                        stats["unique_ids"].add(track_id)

                            stats["total_detections"] += frame_detections
                            stats["successful_frames"] += 1

                            # ----- å¯è¦–åŒ–ï¼ˆãƒ¡ãƒ¢ãƒªåŠ¹ç‡è€ƒæ…®ï¼‰ -----
                            if config.get("save_visualizations", False) and frame_detections > 0:
                                try:
                                    frame = cv2.imread(frame_path)
                                    if frame is not None:
                                        vis_frame = draw_detections_ultralytics(frame, results)
                                        # vis_ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹ã‚’è¿½åŠ 
                                        vis_filename = f"vis_{frame_file}"
                                        output_path = os.path.join(result_dir, vis_filename)
                                        cv2.imwrite(output_path, vis_frame)
                                        logger.debug(f"å¯è¦–åŒ–ä¿å­˜: {output_path}")
                                        del frame, vis_frame
                                except Exception as vis_error:
                                    logger.warning(f"å¯è¦–åŒ–ã‚¨ãƒ©ãƒ¼ {frame_file}: {vis_error}")

                            # çµæœã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’è§£æ”¾
                            del results

                        except Exception as frame_error:
                            # ğŸ”§ ä¿®æ­£6: ãƒ•ãƒ¬ãƒ¼ãƒ ã‚¨ãƒ©ãƒ¼ã®è©³ç´°å‡ºåŠ›
                            logger.error(
                                f"ãƒ•ãƒ¬ãƒ¼ãƒ å‡¦ç†ã‚¨ãƒ©ãƒ¼ {frame_file}: {frame_error}", 
                                exc_info=True  # â† ã‚¹ã‚¿ãƒƒã‚¯ãƒˆãƒ¬ãƒ¼ã‚¹å‡ºåŠ›
                            )
                            stats["failed_frames"] += 1
                            continue

                        stats["processed_frames"] += 1

                    # ----- ãƒãƒƒãƒã®æ¤œå‡ºçµæœã‚’CSVã«æ›¸ãè¾¼ã¿ -----
                    if batch_detections:
                        csv_writer.writerows(batch_detections)
                        csv_file.flush()  # å³åº§ã«ãƒ‡ã‚£ã‚¹ã‚¯ã«æ›¸ãè¾¼ã¿

                    # ----- ãƒãƒƒãƒå‡¦ç†å®Œäº†å¾Œã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ— -----
                    del batch_detections
                    processor.force_memory_cleanup()

                    # ----- çµ±è¨ˆæ›´æ–° -----
                    batch_time = time.time() - batch_start_time
                    current_memory = processor.get_memory_usage()
                    stats["batch_times"].append(batch_time)
                    stats["memory_peaks"].append(current_memory)

                    # ----- é€²æ—å ±å‘Š -----
                    progress = (batch_end / total_frames) * 100
                    logger.info(f"é€²æ—: {progress:.1f}% (ãƒ¡ãƒ¢ãƒª: {current_memory:.2f}GB, "
                            f"ãƒãƒƒãƒæ™‚é–“: {batch_time:.1f}s)")

            except Exception as e:
                # ğŸ”§ ä¿®æ­£7: ãƒãƒƒãƒå‡¦ç†ã‚¨ãƒ©ãƒ¼ã®è©³ç´°å‡ºåŠ›
                logger.error(f"ãƒãƒƒãƒå‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
                return {"error": f"batch_processing_failed: {e}", "success": False}

        # ===== æœ€çµ‚çµ±è¨ˆã®è¨ˆç®— =====
        stats["unique_ids"] = len(stats["unique_ids"])
        stats["success_rate"] = stats["successful_frames"] / total_frames if total_frames > 0 else 0
        stats["avg_batch_time"] = np.mean(stats["batch_times"]) if stats["batch_times"] else 0
        stats["peak_memory_gb"] = max(stats["memory_peaks"]) if stats["memory_peaks"] else 0

        # ===== çµæœã‚µãƒãƒªãƒ¼ã®ãƒ­ã‚°å‡ºåŠ› =====
        logger.info(f"âœ… å‡¦ç†å®Œäº†çµ±è¨ˆ:")
        logger.info(f"  æˆåŠŸç‡: {stats['success_rate']:.1%}")
        logger.info(f"  ç·æ¤œå‡ºæ•°: {stats['total_detections']}")
        logger.info(f"  ãƒ¦ãƒ‹ãƒ¼ã‚¯ID: {stats['unique_ids']}")
        logger.info(f"  ãƒ”ãƒ¼ã‚¯ãƒ¡ãƒ¢ãƒª: {stats['peak_memory_gb']:.2f}GB")
        logger.info(f"  å¹³å‡ãƒãƒƒãƒæ™‚é–“: {stats['avg_batch_time']:.1f}s")

        return {
            "csv_path": csv_path,
            "processing_stats": stats,
            "config_used": config,
            "model_path": model_path,
            "result_dir": result_dir,
            "memory_efficient": True,
            "success": True
        }

    except ModelInitializationError as e:
        logger.error(f"ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–å¤±æ•—: {e}")
        return {"error": "model_initialization_failed", "details": str(e), "success": False}

    except ResourceExhaustionError as e:
        logger.error(f"ãƒªã‚½ãƒ¼ã‚¹ä¸è¶³: {e}")
        return {"error": "resource_exhaustion", "details": str(e), "success": False}

    except Exception as e:
        # ğŸ”§ ä¿®æ­£8: äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼ã®è©³ç´°å‡ºåŠ›
        logger.error(f"äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
        return {"error": "unexpected_error", "details": str(e), "success": False}


def analyze_frames_with_tracking_enhanced(
    frame_dir: str,
    result_dir: str,
    model_path: str = "models/yolo11n-pose.pt",
    config: Optional[Dict[str, Any]] = None
) -> Dict[str, Any]:
    """
    æ‹¡å¼µç‰ˆãƒ•ãƒ¬ãƒ¼ãƒ è§£æï¼ˆã‚¿ã‚¤ãƒ«æ¨è«–ã‚ªãƒ—ã‚·ãƒ§ãƒ³ä»˜ãï¼‰
    
    è¨­å®šã§tile_inference.enabled=Trueã®å ´åˆã€ã‚¿ã‚¤ãƒ«æ¨è«–ã‚’ä½¿ç”¨ã€‚
    ãã‚Œä»¥å¤–ã¯é€šå¸¸ã®ãƒ¡ãƒ¢ãƒªåŠ¹ç‡ç‰ˆã‚’ä½¿ç”¨ã€‚
    
    Args:
        frame_dir: ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        result_dir: çµæœå‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        model_path: YOLOãƒ¢ãƒ‡ãƒ«ãƒ‘ã‚¹
        config: å‡¦ç†è¨­å®šï¼ˆtile_inferenceè¨­å®šã‚’å«ã‚€å¯èƒ½æ€§ã‚ã‚Šï¼‰
        
    Returns:
        å‡¦ç†çµæœã®è¾æ›¸
    """
    
    if config and config.get("tile_inference", {}).get("enabled", False):
        # ã‚¿ã‚¤ãƒ«æ¨è«–ãƒ¢ãƒ¼ãƒ‰ã¸
        from .tile_inference import analyze_frames_with_tile_inference
        return analyze_frames_with_tile_inference(frame_dir, result_dir, model_path, config)
    else:
        # é€šå¸¸æ¨è«–ï¼ˆãƒ¡ãƒ¢ãƒªåŠ¹ç‡ç‰ˆï¼‰
        return analyze_frames_with_tracking_memory_efficient(
            frame_dir, result_dir, model_path, config
        )