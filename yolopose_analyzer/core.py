"""
ãƒ¡ã‚¤ãƒ³åˆ†æé–¢æ•°ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ï¼ˆçµ±ä¸€ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°å¯¾å¿œç‰ˆãƒ»æ¤œå‡ºæ ä»˜ãç”»åƒç”Ÿæˆä¿è¨¼ç‰ˆï¼‰
"""

import os
import cv2
import csv
import time
import numpy as np
import logging
import gc
from pathlib import Path
from typing import Dict, Any, Optional

# ğŸ”§ çµ±ä¸€ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ã‹ã‚‰ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from utils.error_handler import (
    ModelInitializationError,
    ResourceExhaustionError,
    VideoProcessingError,
    ResponseBuilder,
    handle_errors,
    ErrorContext,
    ErrorCategory
)

from .system import safe_model_initialization
from .validation import validate_frame_directory
from .memory import MemoryEfficientProcessor
from .visualization import draw_detections_ultralytics

logger = logging.getLogger(__name__)


def create_detection_visualization(frame, results, output_path: str, frame_file: str, config: Dict[str, Any]) -> bool:
    """
    æ¤œå‡ºæ ä»˜ãç”»åƒç”Ÿæˆï¼ˆå®Œå…¨ç‰ˆï¼‰
    
    Args:
        frame: OpenCVã§èª­ã¿è¾¼ã‚“ã ãƒ•ãƒ¬ãƒ¼ãƒ 
        results: YOLOæ¨è«–çµæœ
        output_path: å‡ºåŠ›ãƒ‘ã‚¹
        frame_file: ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ•ã‚¡ã‚¤ãƒ«å
        config: è¨­å®šè¾æ›¸
        
    Returns:
        bool: ä¿å­˜æˆåŠŸãƒ•ãƒ©ã‚°
    """
    try:
        if frame is None or results is None:
            logger.warning(f"ãƒ•ãƒ¬ãƒ¼ãƒ ã¾ãŸã¯çµæœãŒç„¡åŠ¹: {frame_file}")
            return False

        # ãƒ•ãƒ¬ãƒ¼ãƒ ã‚³ãƒ”ãƒ¼ã‚’ä½œæˆï¼ˆå…ƒãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ä¿è­·ï¼‰
        vis_frame = frame.copy()
        detection_count = 0
        
        # æ¤œå‡ºçµæœã‚’æç”»
        for r in results:
            if r.boxes is not None and len(r.boxes) > 0:
                boxes = r.boxes.xyxy.cpu().numpy()
                confidences = r.boxes.conf.cpu().numpy()
                
                # ã‚¯ãƒ©ã‚¹æƒ…å ±
                if r.boxes.cls is not None:
                    classes = r.boxes.cls.cpu().numpy()
                else:
                    classes = [0] * len(boxes)  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚¯ãƒ©ã‚¹
                
                # ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°ID
                if r.boxes.id is not None:
                    track_ids = r.boxes.id.cpu().numpy().astype(int)
                else:
                    track_ids = list(range(len(boxes)))
                
                # å„æ¤œå‡ºã«å¯¾ã—ã¦æç”»
                for i, (box, conf, cls_id) in enumerate(zip(boxes, confidences, classes)):
                    if conf < config.get("confidence_threshold", 0.3):
                        continue
                        
                    x1, y1, x2, y2 = map(int, box)
                    track_id = track_ids[i] if i < len(track_ids) else i
                    
                    # ğŸ¯ æ¤œå‡ºæ æç”»ï¼ˆç·‘è‰²ãƒ»å¤ªç·šï¼‰
                    cv2.rectangle(vis_frame, (x1, y1), (x2, y2), (0, 255, 0), 3)
                    
                    # ğŸ·ï¸ ãƒ©ãƒ™ãƒ«ä½œæˆ
                    class_name = config.get("class_names", {}).get(int(cls_id), "person")
                    label = f"ID:{track_id} {class_name} {conf:.2f}"
                    
                    # ğŸ“ ãƒ©ãƒ™ãƒ«èƒŒæ™¯
                    label_size = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2)[0]
                    cv2.rectangle(vis_frame, 
                                (x1, y1 - label_size[1] - 10), 
                                (x1 + label_size[0], y1), 
                                (0, 255, 0), -1)
                    
                    # ğŸ“ ãƒ©ãƒ™ãƒ«ãƒ†ã‚­ã‚¹ãƒˆ
                    cv2.putText(vis_frame, label, (x1, y1 - 5), 
                              cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 0), 2)
                    
                    detection_count += 1
        
        # ğŸ–¼ï¸ ãƒ•ãƒ¬ãƒ¼ãƒ æƒ…å ±ã‚’å·¦ä¸Šã«æç”»
        frame_info = f"Frame: {frame_file} | Detections: {detection_count}"
        cv2.putText(vis_frame, frame_info, (10, 30), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
        
        # â° ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‚’å³ä¸Šã«æç”»
        timestamp = time.strftime("%Y-%m-%d %H:%M:%S")
        timestamp_size = cv2.getTextSize(timestamp, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1)[0]
        cv2.putText(vis_frame, timestamp, 
                   (vis_frame.shape[1] - timestamp_size[0] - 10, 25), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
        
        # ğŸ’¾ ç”»åƒä¿å­˜
        success = cv2.imwrite(output_path, vis_frame)
        if success:
            logger.debug(f"âœ… æ¤œå‡ºæ ä»˜ãç”»åƒä¿å­˜: {output_path}")
            return True
        else:
            logger.error(f"âŒ ç”»åƒä¿å­˜å¤±æ•—: {output_path}")
            return False
            
    except Exception as e:
        logger.error(f"âŒ å¯è¦–åŒ–ç”Ÿæˆã‚¨ãƒ©ãƒ¼ {frame_file}: {e}")
        return False


@handle_errors(logger=logger, error_category=ErrorCategory.PROCESSING, suppress_exceptions=False)
def analyze_frames_with_tracking_memory_efficient(
    frame_dir: str,
    result_dir: str,
    model_path: str = "models/yolo11n-pose.pt",
    config: Optional[Dict[str, Any]] = None
) -> Dict[str, Any]:
    """
    ãƒ¡ãƒ¢ãƒªåŠ¹ç‡çš„ãªãƒ•ãƒ¬ãƒ¼ãƒ è§£æï¼ˆçµ±ä¸€ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°å¯¾å¿œç‰ˆãƒ»æ¤œå‡ºæ ä»˜ãç”»åƒç”Ÿæˆä¿è¨¼ç‰ˆï¼‰

    Args:
        frame_dir: ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        result_dir: çµæœå‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        model_path: YOLOãƒ¢ãƒ‡ãƒ«ãƒ‘ã‚¹
        config: å‡¦ç†è¨­å®š

    Returns:
        ResponseBuilderå½¢å¼ã®å‡¦ç†çµæœ
    """
    with ErrorContext("ãƒ•ãƒ¬ãƒ¼ãƒ è§£æå‡¦ç†", logger=logger, raise_on_error=True) as ctx:
        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šï¼ˆğŸ”§ æ¤œå‡ºæ ä»˜ãç”»åƒã‚’ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§æœ‰åŠ¹åŒ–ï¼‰
        if config is None:
            config = {
                "confidence_threshold": 0.3,
                "tracking_config": "bytetrack.yaml",
                "save_visualizations": True,           # ğŸ”§ ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆTrue
                "save_detection_frames": True,         # ğŸ”§ æ¤œå‡ºãƒ•ãƒ¬ãƒ¼ãƒ ä¿å­˜æœ‰åŠ¹
                "batch_size": 32,
                "max_memory_gb": 4.0,
                "streaming_output": True,
                "device": "auto",
                "class_names": {0: "person"}           # ã‚¯ãƒ©ã‚¹åè¾æ›¸
            }
        else:
            # ğŸ”§ æ—¢å­˜è¨­å®šã§ã‚‚å¯è¦–åŒ–ã‚’å¼·åˆ¶æœ‰åŠ¹åŒ–
            config = config.copy()
            config.setdefault("save_visualizations", True)
            config.setdefault("save_detection_frames", True)
            config.setdefault("class_names", {0: "person"})

        os.makedirs(result_dir, exist_ok=True)
        
        # ğŸ”§ å¯è¦–åŒ–å°‚ç”¨ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
        vis_dir = os.path.join(result_dir, "visualized_frames")
        os.makedirs(vis_dir, exist_ok=True)
        
        processor = MemoryEfficientProcessor(config)

        ctx.add_info("result_dir", result_dir)
        ctx.add_info("vis_dir", vis_dir)
        ctx.add_info("batch_size", config.get("batch_size", 32))
        ctx.add_info("save_visualizations", config.get("save_visualizations", True))

        try:
            # ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–
            model = safe_model_initialization(model_path, config)

            # ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ¤œè¨¼
            frame_validation = validate_frame_directory(frame_dir)
            if not frame_validation.get("success", False):
                raise VideoProcessingError(
                    "ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®æ¤œè¨¼ã«å¤±æ•—ã—ã¾ã—ãŸ",
                    details=frame_validation.get("error", {})
                )

            frame_data = frame_validation["data"]
            frame_files = sorted([
                f for f in os.listdir(frame_dir)
                if f.lower().endswith(('.jpg', '.jpeg', '.png'))
            ])

            total_frames = len(frame_files)
            ctx.add_info("total_frames", total_frames)

            logger.info(f"å‡¦ç†å¯¾è±¡: {total_frames}ãƒ•ãƒ¬ãƒ¼ãƒ  ({frame_data['total_size_mb']:.1f}MB)")
            logger.info(f"ğŸ¨ å¯è¦–åŒ–ä¿å­˜: {config.get('save_visualizations', True)}")
            logger.info(f"ğŸ“ å¯è¦–åŒ–ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {vis_dir}")

            # CSVæº–å‚™
            csv_path = os.path.join(result_dir, "detections_streaming.csv")

            # çµ±è¨ˆåˆæœŸåŒ–
            stats = {
                "total_frames": total_frames,
                "processed_frames": 0,
                "successful_frames": 0,
                "failed_frames": 0,
                "total_detections": 0,
                "unique_ids": set(),
                "memory_peaks": [],
                "batch_times": [],
                "visualization_stats": {
                    "generated": 0,
                    "failed": 0,
                    "skipped": 0
                }
            }

            batch_size = config.get("batch_size", 32)

            # ãƒãƒƒãƒå‡¦ç†
            with open(csv_path, 'w', newline='', encoding='utf-8') as csv_file:
                csv_writer = csv.writer(csv_file)
                csv_writer.writerow(["frame", "person_id", "x1", "y1", "x2", "y2", "conf", "class_name"])

                try:
                    for batch_start in range(0, total_frames, batch_size):
                        batch_end = min(batch_start + batch_size, total_frames)
                        batch_files = frame_files[batch_start:batch_end]

                        batch_start_time = time.time()
                        batch_detections = []

                        logger.info(f"ãƒãƒƒãƒå‡¦ç† {batch_start//batch_size + 1}/{(total_frames-1)//batch_size + 1}: "
                                f"{len(batch_files)}ãƒ•ãƒ¬ãƒ¼ãƒ ")

                        for frame_file in batch_files:
                            frame_path = os.path.join(frame_dir, frame_file)

                            try:
                                # ãƒ¡ãƒ¢ãƒªãƒã‚§ãƒƒã‚¯
                                if processor.check_memory_threshold():
                                    logger.warning("ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ãŒé–¾å€¤ã‚’è¶…éã€‚ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã‚’å®Ÿè¡Œ...")
                                    processor.force_memory_cleanup()

                                # ãƒˆãƒ©ãƒƒã‚«ãƒ¼è¨­å®šã®å®‰å…¨æ€§ãƒã‚§ãƒƒã‚¯
                                tracker_config = config.get("tracking_config")
                                if tracker_config is None or not tracker_config:
                                    tracker_config = "bytetrack.yaml"
                                    logger.debug(f"trackerè¨­å®šãŒç©ºã ã£ãŸãŸã‚ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’ä½¿ç”¨: {tracker_config}")

                                # æ¨è«–å®Ÿè¡Œ
                                results = model.track(
                                    frame_path,
                                    persist=True,
                                    tracker=tracker_config,
                                    conf=config.get("confidence_threshold", 0.3),
                                    verbose=False
                                )

                                # çµæœå‡¦ç†
                                frame_detections = 0
                                for r in results:
                                    if r.boxes is not None:
                                        boxes = r.boxes.xyxy.cpu().numpy()
                                        confidences = r.boxes.conf.cpu().numpy()

                                        # ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°IDã®å‡¦ç†
                                        if r.boxes.id is not None:
                                            track_ids = r.boxes.id.cpu().numpy().astype(int)
                                        else:
                                            track_ids = list(range(len(boxes)))

                                        for i, (box, conf) in enumerate(zip(boxes, confidences)):
                                            track_id = track_ids[i] if i < len(track_ids) else i
                                            x1, y1, x2, y2 = box
                                            detection_row = [
                                                frame_file, track_id,
                                                float(x1), float(y1), float(x2), float(y2),
                                                float(conf), "person"
                                            ]
                                            batch_detections.append(detection_row)
                                            frame_detections += 1
                                            stats["unique_ids"].add(track_id)

                                stats["total_detections"] += frame_detections
                                stats["successful_frames"] += 1

                                # ğŸ¨ æ¤œå‡ºæ ä»˜ãç”»åƒç”Ÿæˆï¼ˆå¿…é ˆï¼‰
                                if config.get("save_visualizations", True):
                                    try:
                                        frame = cv2.imread(frame_path)
                                        if frame is not None:
                                            # vis_ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹ã‚’è¿½åŠ ã—ãŸãƒ•ã‚¡ã‚¤ãƒ«å
                                            vis_filename = f"vis_{frame_file}"
                                            vis_output_path = os.path.join(vis_dir, vis_filename)
                                            
                                            # ğŸ”§ å®Œå…¨ç‰ˆå¯è¦–åŒ–é–¢æ•°ã‚’ä½¿ç”¨
                                            success = create_detection_visualization(
                                                frame, results, vis_output_path, frame_file, config
                                            )
                                            
                                            if success:
                                                stats["visualization_stats"]["generated"] += 1
                                                logger.debug(f"âœ… å¯è¦–åŒ–ç”Ÿæˆ: {vis_filename}")
                                            else:
                                                stats["visualization_stats"]["failed"] += 1
                                                
                                            del frame
                                        else:
                                            logger.warning(f"âš ï¸ ãƒ•ãƒ¬ãƒ¼ãƒ èª­ã¿è¾¼ã¿å¤±æ•—: {frame_file}")
                                            stats["visualization_stats"]["failed"] += 1
                                            
                                    except Exception as vis_error:
                                        logger.warning(f"âŒ å¯è¦–åŒ–ã‚¨ãƒ©ãƒ¼ {frame_file}: {vis_error}")
                                        stats["visualization_stats"]["failed"] += 1
                                else:
                                    stats["visualization_stats"]["skipped"] += 1

                                # çµæœã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’è§£æ”¾
                                del results

                            except Exception as frame_error:
                                logger.error(f"ãƒ•ãƒ¬ãƒ¼ãƒ å‡¦ç†ã‚¨ãƒ©ãƒ¼ {frame_file}: {frame_error}", exc_info=True)
                                stats["failed_frames"] += 1
                                continue

                            stats["processed_frames"] += 1

                        # ãƒãƒƒãƒã®æ¤œå‡ºçµæœã‚’CSVã«æ›¸ãè¾¼ã¿
                        if batch_detections:
                            csv_writer.writerows(batch_detections)
                            csv_file.flush()  # å³åº§ã«ãƒ‡ã‚£ã‚¹ã‚¯ã«æ›¸ãè¾¼ã¿

                        # ãƒãƒƒãƒå‡¦ç†å®Œäº†å¾Œã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
                        del batch_detections
                        processor.force_memory_cleanup()

                        # çµ±è¨ˆæ›´æ–°
                        batch_time = time.time() - batch_start_time
                        current_memory = processor.get_memory_usage()
                        stats["batch_times"].append(batch_time)
                        stats["memory_peaks"].append(current_memory)

                        # é€²æ—å ±å‘Š
                        progress = (batch_end / total_frames) * 100
                        vis_progress = stats["visualization_stats"]["generated"]
                        logger.info(f"é€²æ—: {progress:.1f}% (ãƒ¡ãƒ¢ãƒª: {current_memory:.2f}GB, "
                                f"ãƒãƒƒãƒæ™‚é–“: {batch_time:.1f}s, å¯è¦–åŒ–: {vis_progress}å€‹)")

                except Exception as e:
                    logger.error(f"ãƒãƒƒãƒå‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
                    raise VideoProcessingError(f"ãƒãƒƒãƒå‡¦ç†ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}", original_exception=e)

            # æœ€çµ‚çµ±è¨ˆã®è¨ˆç®—
            stats["unique_ids"] = len(stats["unique_ids"])
            stats["success_rate"] = stats["successful_frames"] / total_frames if total_frames > 0 else 0
            stats["avg_batch_time"] = np.mean(stats["batch_times"]) if stats["batch_times"] else 0
            stats["peak_memory_gb"] = max(stats["memory_peaks"]) if stats["memory_peaks"] else 0
            
            # ğŸ¨ å¯è¦–åŒ–çµ±è¨ˆã®è¿½åŠ 
            vis_stats = stats["visualization_stats"]
            vis_success_rate = vis_stats["generated"] / total_frames if total_frames > 0 else 0

            ctx.add_info("total_detections", stats["total_detections"])
            ctx.add_info("success_rate", stats["success_rate"])
            ctx.add_info("peak_memory_gb", stats["peak_memory_gb"])
            ctx.add_info("visualization_generated", vis_stats["generated"])
            ctx.add_info("visualization_success_rate", vis_success_rate)

            # çµæœã‚µãƒãƒªãƒ¼ã®ãƒ­ã‚°å‡ºåŠ›
            logger.info(f"âœ… å‡¦ç†å®Œäº†çµ±è¨ˆ:")
            logger.info(f"  æˆåŠŸç‡: {stats['success_rate']:.1%}")
            logger.info(f"  ç·æ¤œå‡ºæ•°: {stats['total_detections']}")
            logger.info(f"  ãƒ¦ãƒ‹ãƒ¼ã‚¯ID: {stats['unique_ids']}")
            logger.info(f"  ãƒ”ãƒ¼ã‚¯ãƒ¡ãƒ¢ãƒª: {stats['peak_memory_gb']:.2f}GB")
            logger.info(f"  å¹³å‡ãƒãƒƒãƒæ™‚é–“: {stats['avg_batch_time']:.1f}s")
            logger.info(f"  ğŸ¨ å¯è¦–åŒ–ç”Ÿæˆ: {vis_stats['generated']}å€‹ (æˆåŠŸç‡: {vis_success_rate:.1%})")
            logger.info(f"  ğŸ“ å¯è¦–åŒ–ä¿å­˜å…ˆ: {vis_dir}")

            return ResponseBuilder.success(
                data={
                    "csv_path": csv_path,
                    "visualization_dir": vis_dir,
                    "processing_stats": stats,
                    "config_used": config,
                    "model_path": model_path,
                    "result_dir": result_dir,
                    "memory_efficient": True,
                    "visualization_enabled": True
                },
                message="ãƒ•ãƒ¬ãƒ¼ãƒ è§£æå®Œäº†ï¼ˆæ¤œå‡ºæ ä»˜ãç”»åƒç”Ÿæˆä»˜ãï¼‰"
            )

        except ModelInitializationError as e:
            logger.error(f"ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–å¤±æ•—: {e}")
            return ResponseBuilder.error(
                message="ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸ",
                details={"error": str(e), "model_path": model_path}
            )

        except ResourceExhaustionError as e:
            logger.error(f"ãƒªã‚½ãƒ¼ã‚¹ä¸è¶³: {e}")
            return ResponseBuilder.error(
                message="ã‚·ã‚¹ãƒ†ãƒ ãƒªã‚½ãƒ¼ã‚¹ãŒä¸è¶³ã—ã¦ã„ã¾ã™",
                details={"error": str(e)}
            )

        except VideoProcessingError as e:
            logger.error(f"å‹•ç”»å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
            return ResponseBuilder.error(
                message="å‹•ç”»å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ",
                details={"error": str(e)}
            )

        except Exception as e:
            logger.error(f"äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
            return ResponseBuilder.error(
                message="äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ",
                details={"error": str(e)}
            )


@handle_errors(logger=logger, error_category=ErrorCategory.PROCESSING)
def analyze_frames_with_tracking_enhanced(
    frame_dir: str,
    result_dir: str,
    model_path: str = "models/yolo11n-pose.pt",
    config: Optional[Dict[str, Any]] = None
) -> Dict[str, Any]:
    """
    æ‹¡å¼µç‰ˆãƒ•ãƒ¬ãƒ¼ãƒ è§£æï¼ˆã‚¿ã‚¤ãƒ«æ¨è«–ã‚ªãƒ—ã‚·ãƒ§ãƒ³ä»˜ããƒ»æ¤œå‡ºæ ä»˜ãç”»åƒç”Ÿæˆä¿è¨¼ç‰ˆï¼‰

    è¨­å®šã§tile_inference.enabled=Trueã®å ´åˆã€ã‚¿ã‚¤ãƒ«æ¨è«–ã‚’ä½¿ç”¨ã€‚
    ãã‚Œä»¥å¤–ã¯é€šå¸¸ã®ãƒ¡ãƒ¢ãƒªåŠ¹ç‡ç‰ˆã‚’ä½¿ç”¨ã€‚

    Args:
        frame_dir: ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        result_dir: çµæœå‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        model_path: YOLOãƒ¢ãƒ‡ãƒ«ãƒ‘ã‚¹
        config: å‡¦ç†è¨­å®šï¼ˆtile_inferenceè¨­å®šã‚’å«ã‚€å¯èƒ½æ€§ã‚ã‚Šï¼‰

    Returns:
        ResponseBuilderå½¢å¼ã®å‡¦ç†çµæœ
    """
    with ErrorContext("æ‹¡å¼µãƒ•ãƒ¬ãƒ¼ãƒ è§£æ", logger=logger) as ctx:
        ctx.add_info("frame_dir", frame_dir)
        ctx.add_info("model_path", model_path)

        if config and config.get("tile_inference", {}).get("enabled", False):
            # ã‚¿ã‚¤ãƒ«æ¨è«–ãƒ¢ãƒ¼ãƒ‰ã¸
            logger.info("ğŸ”² ã‚¿ã‚¤ãƒ«æ¨è«–ãƒ¢ãƒ¼ãƒ‰ã§å®Ÿè¡Œ")
            try:
                from .tile_inference import analyze_frames_with_tile_inference
                return analyze_frames_with_tile_inference(frame_dir, result_dir, model_path, config)
            except ImportError:
                logger.warning("ã‚¿ã‚¤ãƒ«æ¨è«–ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚é€šå¸¸æ¨è«–ã«åˆ‡ã‚Šæ›¿ãˆã¾ã™")
                return analyze_frames_with_tracking_memory_efficient(
                    frame_dir, result_dir, model_path, config
                )
        else:
            # é€šå¸¸æ¨è«–ï¼ˆãƒ¡ãƒ¢ãƒªåŠ¹ç‡ç‰ˆãƒ»æ¤œå‡ºæ ä»˜ãç”»åƒç”Ÿæˆä¿è¨¼ç‰ˆï¼‰
            logger.info("ğŸ’» é€šå¸¸æ¨è«–ï¼ˆãƒ¡ãƒ¢ãƒªåŠ¹ç‡ç‰ˆãƒ»æ¤œå‡ºæ ä»˜ãç”»åƒç”Ÿæˆä¿è¨¼ç‰ˆï¼‰ã§å®Ÿè¡Œ")
            return analyze_frames_with_tracking_memory_efficient(
                frame_dir, result_dir, model_path, config
            )