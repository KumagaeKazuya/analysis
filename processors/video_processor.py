"""
å‹•ç”»å‡¦ç†ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ï¼ˆçµ±ä¸€ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°å®Œå…¨å¯¾å¿œç‰ˆï¼‰

ğŸ”§ ä¸»ãªæ”¹å–„ç‚¹:
1. å…¨ãƒ¡ã‚½ãƒƒãƒ‰ã«çµ±ä¸€ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ãƒ‡ã‚³ãƒ¬ãƒ¼ã‚¿é©ç”¨
2. ResponseBuilderå½¢å¼ã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹çµ±ä¸€
3. ErrorContextã«ã‚ˆã‚‹è©³ç´°ãªã‚¨ãƒ©ãƒ¼ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°
4. ã‚«ã‚¹ã‚¿ãƒ ã‚¨ãƒ©ãƒ¼ã‚¯ãƒ©ã‚¹ã®ä½¿ç”¨
5. ã‚¹ã‚¿ãƒƒã‚¯ãƒˆãƒ¬ãƒ¼ã‚¹è‡ªå‹•è¨˜éŒ²
6. æ·±åº¦æ¨å®š (MiDaS) çµ±åˆæ©Ÿèƒ½
"""

import os
import cv2
import logging
import pandas as pd
from pathlib import Path
from typing import Dict, Any, Optional, List
from processors.depth_processor import ClassroomDepthProcessor

# ğŸ”§ çµ±ä¸€ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ã‹ã‚‰ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from utils.error_handler import (
    VideoProcessingError,
    FileIOError,
    ConfigurationError,
    ValidationError,
    ModelInitializationError,
    ResponseBuilder,
    handle_errors,
    validate_inputs,
    ErrorContext,
    ErrorCategory,
    ErrorSeverity
)

logger = logging.getLogger(__name__)


class VideoProcessor:
    """å‹•ç”»å‡¦ç†ã‚¯ãƒ©ã‚¹ï¼ˆçµ±ä¸€ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°å®Œå…¨å¯¾å¿œç‰ˆ + æ·±åº¦æ¨å®šçµ±åˆï¼‰"""

    @handle_errors(logger=logger, error_category=ErrorCategory.INITIALIZATION)
    def __init__(self, config):
        """
        åˆæœŸåŒ–ï¼ˆçµ±ä¸€ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°å¯¾å¿œç‰ˆï¼‰

        Args:
            config: è¨­å®šã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
        """
        with ErrorContext("VideoProcessoråˆæœŸåŒ–", logger=logger) as ctx:
            if not config:
                raise ConfigurationError(
                    "è¨­å®šã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆãŒNullã§ã™",
                    details={"config": str(config)}
                )

            self.config = config
            self.logger = logging.getLogger(__name__)

            # ã‚¿ã‚¤ãƒ«æ¨è«–ã®æœ‰åŠ¹æ€§ãƒã‚§ãƒƒã‚¯
            self.tile_enabled = config.get('processing.tile_inference.enabled', False)

            # æ·±åº¦æ¨å®šã®æœ‰åŠ¹æ€§ãƒã‚§ãƒƒã‚¯ (æ–°è¦è¿½åŠ )
            self.depth_enabled = config.get('processing.depth_estimation.enabled', False)
            self.depth_processor = None

            # çœŸç¥–æ¨å®šãƒ—ãƒ­ã‚»ãƒƒã‚µãƒ¼ã®åˆæœŸåŒ–
            if self.depth_enabled:
                try:
                    from processors.depth_processor import ClassroomDepthProcessor
                    self.depth_processor = ClassroomDepthProcessor(config)
                    self.logger.info("âœ… æ·±åº¦æ¨å®šãƒ—ãƒ­ã‚»ãƒƒã‚µãƒ¼åˆæœŸåŒ–å®Œäº†")
                    ctx.add_info("depth_processor_initialized", True)
                except ImportError as e:
                    self.logger.warning(f"âš ï¸ æ·±åº¦æ¨å®šãƒ—ãƒ­ã‚»ãƒƒã‚µãƒ¼ã®åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
                    self.depth_enabled = False
                    ctx.add_info("depth_processor_failed", str(e))

            # å¿…è¦ãªè¨­å®šé …ç›®ã®å­˜åœ¨ç¢ºèª
            required_configs = ['video_dir', 'model_dir', 'output_dir']
            missing_configs = []

            for req_config in required_configs:
                if not hasattr(config, req_config) or not getattr(config, req_config):
                    missing_configs.append(req_config)

            if missing_configs:
                raise ConfigurationError(
                    f"å¿…è¦ãªè¨­å®šãŒä¸è¶³ã—ã¦ã„ã¾ã™: {missing_configs}",
                    details={"missing_configs": missing_configs}
                )

            ctx.add_info("tile_enabled", self.tile_enabled)
            ctx.add_info("depth_enabled", self.depth_enabled)
            ctx.add_info("video_dir", getattr(config, 'video_dir', 'N/A'))

            # åˆæœŸåŒ–å®Œäº†ãƒ­ã‚°
            features = []
            if self.tile_enabled:
                features.append("ã‚¿ã‚¤ãƒ«æ¨è«–")
            if self.depth_enabled:
                features.append("æ·±åº¦æ¨å®š")

            if features:
                self.logger.info(f"ğŸš€ VideoProcessoråˆæœŸåŒ–å®Œäº† (æ©Ÿèƒ½: {', '.join(features)})")
            else:
                self.logger.info("ğŸ“‹ VideoProcessoråˆæœŸåŒ–å®Œäº† (é€šå¸¸ãƒ¢ãƒ¼ãƒ‰)")

    @validate_inputs(
        video_path=lambda x: isinstance(x, (str, Path)),
        output_dir=lambda x: isinstance(x, (str, Path))
    )
    @handle_errors(logger=logger, error_category=ErrorCategory.PROCESSING)
    def extract_frames(
        self,
        video_path: Path,
        output_dir: Path,
        **kwargs
    ) -> Dict[str, Any]:
        """
        å‹•ç”»ã‹ã‚‰ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’æŠ½å‡ºï¼ˆçµ±ä¸€ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°å¯¾å¿œç‰ˆï¼‰

        Args:
            video_path: å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
            output_dir: ãƒ•ãƒ¬ãƒ¼ãƒ å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
            **kwargs: interval_sec ãªã©ã®è¿½åŠ è¨­å®š

        Returns:
            ResponseBuilderå½¢å¼ã®çµæœè¾æ›¸
        """
        with ErrorContext(f"ãƒ•ãƒ¬ãƒ¼ãƒ æŠ½å‡º: {Path(video_path).name}", logger=self.logger) as ctx:
            # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
            output_dir = Path(output_dir)
            output_dir.mkdir(parents=True, exist_ok=True)

            interval_sec = kwargs.get(
                'interval_sec',
                self.config.get('processing.frame_sampling.interval_sec', 2)
            )

            ctx.add_info("video_path", str(video_path))
            ctx.add_info("output_dir", str(output_dir))
            ctx.add_info("interval_sec", interval_sec)

            # å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã®å­˜åœ¨ç¢ºèª
            video_path = Path(video_path)
            if not video_path.exists():
                raise FileIOError(
                    f"å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {video_path}",
                    details={"video_path": str(video_path)},
                    suggestions=["ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ãŒæ­£ã—ã„ã‹ç¢ºèªã—ã¦ãã ã•ã„"]
                )

            # ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºãƒã‚§ãƒƒã‚¯
            file_size = video_path.stat().st_size
            if file_size < 1024:  # 1KBæœªæº€
                raise VideoProcessingError(
                    f"å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚µã‚¤ã‚ºãŒç•°å¸¸ã«å°ã•ã„ã§ã™: {file_size} bytes",
                    details={"video_path": str(video_path), "file_size": file_size}
                )

            ctx.add_info("file_size_mb", file_size / (1024*1024))
            self.logger.info(f"ãƒ•ãƒ¬ãƒ¼ãƒ æŠ½å‡ºé–‹å§‹: {video_path.name} ({file_size/(1024*1024):.1f}MB)")

            # ãƒ•ãƒ¬ãƒ¼ãƒ æŠ½å‡ºå®Ÿè¡Œ
            try:
                # æ—¢å­˜ã®frame_samplerã‚’ä½¿ç”¨
                from frame_sampler import sample_frames
                sample_frames(str(video_path), str(output_dir), interval_sec=interval_sec)

            except ImportError:
                self.logger.warning("frame_samplerãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚å†…è”µå®Ÿè£…ã‚’ä½¿ç”¨")
                self._sample_frames_builtin(str(video_path), str(output_dir), interval_sec)

            # æŠ½å‡ºã•ã‚ŒãŸãƒ•ãƒ¬ãƒ¼ãƒ ç¢ºèª
            frame_files = list(output_dir.glob("*.jpg"))

            if not frame_files:
                raise VideoProcessingError(
                    "ãƒ•ãƒ¬ãƒ¼ãƒ æŠ½å‡ºã«å¤±æ•—ã—ã¾ã—ãŸï¼ˆãƒ•ãƒ¬ãƒ¼ãƒ ãŒ0ä»¶ï¼‰",
                    details={
                        "video_path": str(video_path),
                        "output_dir": str(output_dir),
                        "interval_sec": interval_sec
                    },
                    severity=ErrorSeverity.ERROR,
                    suggestions=[
                        "å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ãŒç ´æã—ã¦ã„ãªã„ã‹ç¢ºèªã—ã¦ãã ã•ã„",
                        "interval_secã®å€¤ã‚’ç¢ºèªã—ã¦ãã ã•ã„",
                        "å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®æ›¸ãè¾¼ã¿æ¨©é™ã‚’ç¢ºèªã—ã¦ãã ã•ã„"
                    ]
                )

            ctx.add_info("frame_count", len(frame_files))
            self.logger.info(f"ãƒ•ãƒ¬ãƒ¼ãƒ æŠ½å‡ºå®Œäº†: {len(frame_files)}ãƒ•ãƒ¬ãƒ¼ãƒ ")

            return ResponseBuilder.success(
                data={
                    "video_path": str(video_path),
                    "output_dir": str(output_dir),
                    "frame_count": len(frame_files),
                    "interval_sec": interval_sec,
                    "frame_files": [f.name for f in frame_files[:5]],  # ã‚µãƒ³ãƒ—ãƒ«è¡¨ç¤º
                    "file_size_mb": file_size / (1024*1024)
                },
                message=f"ãƒ•ãƒ¬ãƒ¼ãƒ æŠ½å‡ºå®Œäº†: {len(frame_files)}ãƒ•ãƒ¬ãƒ¼ãƒ "
            )

    @handle_errors(logger=logger, error_category=ErrorCategory.IO, suppress_exceptions=False)
    def _sample_frames_builtin(self, video_path: str, save_dir: str, interval_sec: int = 2):
        """
        å†…è”µãƒ•ãƒ¬ãƒ¼ãƒ æŠ½å‡ºå®Ÿè£…ï¼ˆçµ±ä¸€ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°å¯¾å¿œç‰ˆï¼‰

        Args:
            video_path: å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
            save_dir: ä¿å­˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
            interval_sec: ãƒ•ãƒ¬ãƒ¼ãƒ æŠ½å‡ºé–“éš”ï¼ˆç§’ï¼‰
        """
        with ErrorContext("å†…è”µãƒ•ãƒ¬ãƒ¼ãƒ æŠ½å‡º", logger=self.logger) as ctx:
            os.makedirs(save_dir, exist_ok=True)
            cap = cv2.VideoCapture(video_path)

            if not cap.isOpened():
                raise VideoProcessingError(
                    f"å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é–‹ã‘ã¾ã›ã‚“: {video_path}",
                    details={"video_path": video_path},
                    suggestions=[
                        "ãƒ•ã‚¡ã‚¤ãƒ«ãŒç ´æã—ã¦ã„ãªã„ã‹ç¢ºèªã—ã¦ãã ã•ã„",
                        "å¯¾å¿œå½¢å¼(.mp4, .avi, .movç­‰)ã‹ç¢ºèªã—ã¦ãã ã•ã„"
                    ]
                )

            # å‹•ç”»æƒ…å ±å–å¾—
            fps = cap.get(cv2.CAP_PROP_FPS)
            total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
            duration = total_frames / fps if fps > 0 else 0

            frame_interval = int(fps * interval_sec) if fps > 0 else 30
            frame_count = 0
            saved_count = 0

            ctx.add_info("fps", fps)
            ctx.add_info("total_frames", total_frames)
            ctx.add_info("duration_sec", duration)
            ctx.add_info("frame_interval", frame_interval)

            self.logger.info(f"å‹•ç”»æƒ…å ±: FPS={fps:.1f}, ç·ãƒ•ãƒ¬ãƒ¼ãƒ æ•°={total_frames}, é•·ã•={duration:.1f}ç§’")

            while True:
                ret, frame = cap.read()
                if not ret:
                    break

                if frame_count % frame_interval == 0:
                    filename = os.path.join(
                        save_dir,
                        f"{os.path.basename(video_path)}_frame{frame_count:06d}.jpg"
                    )
                    success = cv2.imwrite(filename, frame)

                    if not success:
                        self.logger.warning(f"ãƒ•ãƒ¬ãƒ¼ãƒ ä¿å­˜å¤±æ•—: {filename}")
                    else:
                        saved_count += 1

                frame_count += 1

            cap.release()

            ctx.add_info("total_frames_processed", frame_count)
            ctx.add_info("saved_frames", saved_count)

            if saved_count == 0:
                raise VideoProcessingError(
                    "ãƒ•ãƒ¬ãƒ¼ãƒ ä¿å­˜ã«å®Œå…¨ã«å¤±æ•—ã—ã¾ã—ãŸ",
                    details={
                        "processed_frames": frame_count,
                        "saved_frames": saved_count,
                        "save_dir": save_dir
                    }
                )

            self.logger.info(f"å†…è”µå®Ÿè£…ã§ãƒ•ãƒ¬ãƒ¼ãƒ æŠ½å‡ºå®Œäº†: {saved_count}ãƒ•ãƒ¬ãƒ¼ãƒ ")

    @validate_inputs(
        frame_dir=lambda x: isinstance(x, (str, Path)),
        video_name=lambda x: isinstance(x, str) and len(x) > 0
    )
    @handle_errors(logger=logger, error_category=ErrorCategory.PROCESSING)
    def run_detection_tracking(
        self,
        frame_dir: Path,
        video_name: str,
        **kwargs
    ) -> Dict[str, Any]:
        """
        æ¤œå‡ºãƒ»è¿½è·¡å‡¦ç†ã‚’å®Ÿè¡Œï¼ˆé€šå¸¸ç‰ˆï¼‰

        Args:
            frame_dir: ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
            video_name: å‹•ç”»å
            **kwargs: è¿½åŠ è¨­å®š

        Returns:
            ResponseBuilderå½¢å¼ã®å‡¦ç†çµæœ
        """
        # æ·±åº¦æ¨å®šãŒæœ‰åŠ¹ãªå ´åˆã¯æ·±åº¦çµ±åˆç‰ˆã‚’å‘¼ã³å‡ºã—
        if self.depth_enabled and self.depth_processor:
            return self._run_detection_tracking_with_depth(
                frame_dir, video_name, **kwargs
            )
        
        # é€šå¸¸ç‰ˆå‡¦ç†
        return self._run_detection_tracking_normal(
            frame_dir, video_name, **kwargs
        )

    @validate_inputs(
        frame_dir=lambda x: isinstance(x, (str, Path)),
        video_name=lambda x: isinstance(x, str) and len(x) > 0
    )
    @handle_errors(logger=logger, error_category=ErrorCategory.PROCESSING)
    def run_detection_tracking_with_depth(
        self,
        frame_dir: Path,
        video_name: str,
        **kwargs
    ) -> Dict[str, Any]:
        """
        æ·±åº¦æ¨å®šçµ±åˆç‰ˆã®æ¤œå‡ºãƒ»è¿½è·¡å‡¦ç†ï¼ˆæ–°è¦è¿½åŠ ï¼‰

        Args:
            frame_dir: ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
            video_name: å‹•ç”»å
            **kwargs: è¿½åŠ è¨­å®š

        Returns:
            ResponseBuilderå½¢å¼ã®å‡¦ç†çµæœ
        """
        with ErrorContext(f"æ·±åº¦çµ±åˆæ¤œå‡ºãƒ»è¿½è·¡: {video_name}", logger=self.logger) as ctx:
            self.logger.info(f"ğŸ”ğŸ¯ æ·±åº¦çµ±åˆæ¤œå‡ºãƒ»è¿½è·¡é–‹å§‹: {video_name}")

            # åŸºæœ¬ã®æ¤œå‡ºãƒ»è¿½è·¡å‡¦ç†ã‚’å®Ÿè¡Œ
            detection_results = self._run_detection_tracking_normal(frame_dir, video_name, **kwargs)

            if not detection_results.get("success", False):
                self.logger.warning("åŸºæœ¬æ¤œå‡ºãƒ»è¿½è·¡ãŒå¤±æ•—ã—ãŸãŸã‚ã€æ·±åº¦çµ±åˆã‚’ã‚¹ã‚­ãƒƒãƒ—")
                return detection_results

            # æ·±åº¦æ¨å®šãƒ—ãƒ­ã‚»ãƒƒã‚µãƒ¼ã®ç¢ºèª
            if not self.depth_processor:
                self.logger.warning("æ·±åº¦æ¨å®šãƒ—ãƒ­ã‚»ãƒƒã‚µãƒ¼ãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“")
                return detection_results

            try:
                # æ·±åº¦æƒ…å ±ã‚’è¿½åŠ 
                enhanced_results = self._add_depth_information(
                    detection_results, frame_dir, video_name
                )

                ctx.add_info("depth_integration_success", True)
                self.logger.info(f"âœ… æ·±åº¦çµ±åˆæ¤œå‡ºãƒ»è¿½è·¡å®Œäº†: {video_name}")

                return enhanced_results

            except Exception as e:
                self.logger.error(f"æ·±åº¦æƒ…å ±è¿½åŠ ã‚¨ãƒ©ãƒ¼: {e}")
                ctx.add_info("depth_integration_failed", str(e))

                # æ·±åº¦çµ±åˆã«å¤±æ•—ã—ãŸå ´åˆã¯åŸºæœ¬çµæœã‚’è¿”ã™
                return detection_results

    @handle_errors(logger=logger, error_category=ErrorCategory.PROCESSING)
    def _run_detection_tracking_normal(
        self,
        frame_dir: Path,
        video_name: str,
        **kwargs
    ) -> Dict[str, Any]:
        """
        é€šå¸¸ã®æ¤œå‡ºãƒ»è¿½è·¡å‡¦ç†ï¼ˆæ·±åº¦çµ±åˆã‹ã‚‰åˆ†é›¢ï¼‰

        Args:
            frame_dir: ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
            video_name: å‹•ç”»å
            **kwargs: è¿½åŠ è¨­å®š

        Returns:
            ResponseBuilderå½¢å¼ã®å‡¦ç†çµæœ
        """
        with ErrorContext(f"æ¤œå‡ºãƒ»è¿½è·¡: {video_name}", logger=self.logger) as ctx:
            self.logger.info(f"ğŸ” æ¤œå‡ºãƒ»è¿½è·¡é–‹å§‹: {video_name}")

            # ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®å­˜åœ¨ç¢ºèª
            frame_dir = Path(frame_dir)
            if not frame_dir.exists():
                raise FileIOError(
                    f"ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {frame_dir}",
                    details={"frame_dir": str(frame_dir)},
                    suggestions=["ãƒ•ãƒ¬ãƒ¼ãƒ æŠ½å‡ºãŒæ­£å¸¸ã«å®Œäº†ã—ã¦ã„ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„"]
                )

            # ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ•ã‚¡ã‚¤ãƒ«ã®ç¢ºèª
            frame_files = list(frame_dir.glob("*.jpg"))
            if not frame_files:
                raise VideoProcessingError(
                    f"å‡¦ç†å¯¾è±¡ã®ãƒ•ãƒ¬ãƒ¼ãƒ ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {frame_dir}",
                    details={
                        "frame_dir": str(frame_dir),
                        "available_files": list(frame_dir.glob("*"))[:10]  # ä»–ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚‚è¡¨ç¤º
                    },
                    suggestions=[
                        "ãƒ•ãƒ¬ãƒ¼ãƒ æŠ½å‡ºãŒæ­£å¸¸ã«å®Œäº†ã—ã¦ã„ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„",
                        "ãƒ•ã‚¡ã‚¤ãƒ«æ‹¡å¼µå­ãŒ.jpgã‹ç¢ºèªã—ã¦ãã ã•ã„"
                    ]
                )

            # çµæœãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ãƒ‘ã‚¹ã‚’æ˜ç¢ºã«æŒ‡å®š
            video_base_dir = frame_dir.parent
            result_dir = video_base_dir / "results"
            result_dir.mkdir(parents=True, exist_ok=True)

            ctx.add_info("frame_dir", str(frame_dir))
            ctx.add_info("result_dir", str(result_dir))
            ctx.add_info("frame_count", len(frame_files))

            self.logger.info(f"ğŸ“‚ çµæœä¿å­˜å…ˆ: {result_dir}")
            self.logger.info(f"ğŸ“Š å‡¦ç†å¯¾è±¡: {len(frame_files)}ãƒ•ãƒ¬ãƒ¼ãƒ ")

            # å‡¦ç†è¨­å®šã‚’æ§‹ç¯‰
            processing_config = self._build_processing_config(kwargs)
            ctx.add_info("tile_enabled", self.tile_enabled)
            ctx.add_info("config_keys", list(processing_config.keys()))

            # ã‚¿ã‚¤ãƒ«æ¨è«–ãŒæœ‰åŠ¹ãªå ´åˆ
            if self.tile_enabled:
                result = self._run_tile_inference(
                    frame_dir, result_dir, video_name, processing_config
                )
            else:
                result = self._run_normal_inference(
                    frame_dir, result_dir, video_name, processing_config
                )

            # çµæœã®æ¤œè¨¼
            if not result.get("success", False):
                error_info = result.get("error", {})
                error_message = error_info.get('message', 'unknown error') if isinstance(error_info, dict) else str(error_info)

                raise VideoProcessingError(
                    f"æ¤œå‡ºãƒ»è¿½è·¡å‡¦ç†ãŒå¤±æ•—ã—ã¾ã—ãŸ: {error_message}",
                    details=result,
                    suggestions=[
                        "ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ã€èª­ã¿è¾¼ã¿å¯èƒ½ã‹ç¢ºèªã—ã¦ãã ã•ã„",
                        "ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ã‚¢ã‚¯ã‚»ã‚¹å¯èƒ½ã‹ç¢ºèªã—ã¦ãã ã•ã„",
                        "ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã‚’ç¢ºèªã—ã¦ãã ã•ã„"
                    ]
                )

            # CSVãƒ‘ã‚¹ã‚’ãƒ­ã‚°å‡ºåŠ›
            csv_path = result.get("data", {}).get("csv_path") or result.get("csv_path")
            if csv_path and Path(csv_path).exists():
                csv_size = Path(csv_path).stat().st_size
                self.logger.info(f"âœ… CSVä¿å­˜å®Œäº†: {csv_path} ({csv_size} bytes)")
            else:
                self.logger.warning("âš ï¸ CSVç”Ÿæˆã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ")

            return result

    @handle_errors(logger=logger, error_category=ErrorCategory.PROCESSING)
    def _add_depth_information(
        self,
        detection_results: Dict[str, Any],
        frame_dir: Path,
        video_name: str
    ) -> Dict[str, Any]:
        """
        æ¤œå‡ºçµæœã«æ·±åº¦æƒ…å ±ã‚’è¿½åŠ ï¼ˆæ–°è¦è¿½åŠ ï¼‰

        Args:
            detection_results: åŸºæœ¬æ¤œå‡ºçµæœ
            frame_dir: ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
            video_name: å‹•ç”»å

        Returns:
            æ·±åº¦æƒ…å ±ãŒçµ±åˆã•ã‚ŒãŸæ¤œå‡ºçµæœ
        """
        with ErrorContext(f"æ·±åº¦æƒ…å ±çµ±åˆ: {video_name}", logger=self.logger) as ctx:
            result_data = detection_results.get("data", {})
            csv_path = result_data.get("csv_path")

            if not csv_path or not Path(csv_path).exists():
                raise ValidationError(
                    "æ¤œå‡ºçµæœCSVãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“",
                    details={"csv_path": csv_path, "video_name": video_name}
                )

            ctx.add_info("original_csv", csv_path)

            # CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
            try:
                df = pd.read_csv(csv_path)
                if df.empty:
                    raise ValidationError(
                        "æ¤œå‡ºçµæœCSVãŒç©ºã§ã™",
                        details={"csv_path": csv_path}
                    )

                ctx.add_info("detection_count", len(df))
                self.logger.info(f"ğŸ“Š æ¤œå‡ºçµæœèª­ã¿è¾¼ã¿: {len(df)}ä»¶")

            except Exception as e:
                raise FileIOError(
                    f"æ¤œå‡ºçµæœCSVèª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}",
                    details={"csv_path": csv_path},
                    original_exception=e
                )

            # ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒãƒƒãƒ”ãƒ³ã‚°ä½œæˆ
            frame_files = {f.stem: f for f in frame_dir.glob("*.jpg")}
            ctx.add_info("available_frames", len(frame_files))

            # æ·±åº¦æƒ…å ±ã‚’è¿½åŠ ã—ãŸæ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ 
            enhanced_rows = []
            processed_frames = set()

            for idx, row in df.iterrows():
                try:
                    frame_name = f"{video_name}_frame{int(row['frame']):06d}"

                    if frame_name not in frame_files:
                        # ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤
                        enhanced_row = row.to_dict()
                        enhanced_row.update({
                            'depth_distance': -1,
                            'depth_zone': 'unknown',
                            'depth_confidence': 0.0,
                            'depth_error': 'frame_not_found'
                        })
                        enhanced_rows.append(enhanced_row)
                        continue

                    # ãƒ•ãƒ¬ãƒ¼ãƒ ç”»åƒã‚’èª­ã¿è¾¼ã¿ï¼ˆå¿…è¦ãªå ´åˆã®ã¿ï¼‰
                    if frame_name not in processed_frames:
                        frame_path = frame_files[frame_name]
                        frame_image = cv2.imread(str(frame_path))

                        if frame_image is None:
                            self.logger.warning(f"ãƒ•ãƒ¬ãƒ¼ãƒ èª­ã¿è¾¼ã¿å¤±æ•—: {frame_path}")
                            depth_info = {
                                'depth_distance': -1,
                                'depth_zone': 'unknown',
                                'depth_confidence': 0.0,
                                'depth_error': 'frame_read_failed'
                            }
                        else:
                            # æ·±åº¦æ¨å®šå®Ÿè¡Œ
                            depth_map = self.depth_processor.estimate_depth(frame_image)
                            processed_frames.add(frame_name)

                            # ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹ã®æ·±åº¦æ¨å®š
                            bbox = (int(row['x1']), int(row['y1']), int(row['x2']), int(row['y2']))
                            depth_info = self.depth_processor.estimate_object_distance(depth_map, bbox)

                            # æ·±åº¦ãƒãƒƒãƒ—ä¿å­˜ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
                            if self.config.get('processing.depth_estimation.save_depth_maps', False):
                                depth_dir = frame_dir.parent / "depth_maps"
                                depth_dir.mkdir(exist_ok=True)
                                depth_map_path = depth_dir / f"{frame_name}_depth.jpg"
                                cv2.imwrite(str(depth_map_path), depth_map)

                    # è¡Œã«ãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ 
                    enhanced_row = row.to_dict()
                    enhanced_row.update({
                        'depth_distance': depth_info.get('distance', -1),
                        'depth_zone': depth_info.get('zone', 'unknown'),
                        'depth_confidence': depth_info.get('confidence', 0.0),
                        'depth_mean': depth_info.get('mean_distance', -1),
                        'depth_std': depth_info.get('distance_std', -1)
                    })
                    enhanced_rows.append(enhanced_row)

                except Exception as e:
                    self.logger.warning(f"ãƒ•ãƒ¬ãƒ¼ãƒ {row.get('frame', 'unknown')}ã®æ·±åº¦å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
                    # ã‚¨ãƒ©ãƒ¼ã®å ´åˆã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã§ç¶™ç¶š
                    enhanced_row = row.to_dict()
                    enhanced_row.update({
                        'depth_distance': -1,
                        'depth_zone': 'error',
                        'depth_confidence': 0.0,
                        'depth_error': str(e)
                    })
                    enhanced_rows.append(enhanced_row)

            # æ‹¡å¼µãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ä½œæˆ
            enhanced_df = pd.DataFrame(enhanced_rows)

            # æ‹¡å¼µCSVã‚’ä¿å­˜
            enhanced_csv_path = str(csv_path).replace('.csv', '_enhanced.csv')
            enhanced_df.to_csv(enhanced_csv_path, index=False)

            ctx.add_info("enhanced_csv", enhanced_csv_path)
            ctx.add_info("processed_frames", len(processed_frames))

            # æ·±åº¦çµ±è¨ˆ
            valid_depths = enhanced_df[enhanced_df['depth_distance'] >= 0]
            depth_stats = {
                "total_detections": len(enhanced_df),
                "valid_depth_detections": len(valid_depths),
                "depth_success_rate": len(valid_depths) / len(enhanced_df) if len(enhanced_df) > 0 else 0,
                "zone_distribution": enhanced_df['depth_zone'].value_counts().to_dict()
            }

            ctx.add_info("depth_stats", depth_stats)
            self.logger.info(f"ğŸ” æ·±åº¦çµ±åˆå®Œäº†: {len(valid_depths)}/{len(enhanced_df)}ä»¶æˆåŠŸ")

            # çµæœã‚’æ›´æ–°
            updated_result_data = result_data.copy()
            updated_result_data.update({
                "enhanced_csv_path": enhanced_csv_path,
                "original_csv_path": csv_path,
                "depth_enabled": True,
                "depth_statistics": depth_stats
            })

            return ResponseBuilder.success(
                data=updated_result_data,
                message=f"æ·±åº¦çµ±åˆæ¤œå‡ºãƒ»è¿½è·¡å®Œäº†: {video_name}"
            )

    @handle_errors(logger=logger, error_category=ErrorCategory.VALIDATION)
    def _build_processing_config(self, kwargs: Dict) -> Dict[str, Any]:
        """
        å‡¦ç†è¨­å®šã®æ§‹ç¯‰ï¼ˆçµ±ä¸€ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°å¯¾å¿œç‰ˆï¼‰

        ğŸ”§ ä¿®æ­£ãƒã‚¤ãƒ³ãƒˆ: Noneå€¤ã‚’ç¢ºå®Ÿã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯

        Args:
            kwargs: è¿½åŠ è¨­å®š

        Returns:
            å®Œå…¨ãªå‡¦ç†è¨­å®šã®è¾æ›¸
        """
        with ErrorContext("å‡¦ç†è¨­å®šæ§‹ç¯‰", logger=self.logger) as ctx:
            # ãƒ¢ãƒ‡ãƒ«ãƒ‘ã‚¹ã®ç¢ºèª
            model_path = getattr(self.config, 'pose_model', None)
            if not model_path:
                raise ConfigurationError(
                    "pose_modelãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“",
                    details={"config_keys": list(vars(self.config).keys())}
                )

            # åŸºæœ¬è¨­å®š
            config = {
                # æ¤œå‡ºè¨­å®š
                "confidence_threshold": self.config.get(
                    'processing.detection.confidence_threshold', 0.3
                ),

                # tracking_configã®Noneå¯¾ç­–
                "tracking_config": self.config.get('models.tracking_config') or 'bytetrack.yaml',

                # å¯è¦–åŒ–è¨­å®š
                "save_visualizations": kwargs.get('save_visualizations', True),

                # ãƒ¢ãƒ‡ãƒ«ãƒ‘ã‚¹
                "model_path": model_path,

                # deviceã®Noneå¯¾ç­–
                "device": self.config.get('processing.device') or 'cpu',

                # ãƒ¡ãƒ¢ãƒªãƒ»ãƒãƒƒãƒè¨­å®š
                "batch_size": self.config.get('processing.batch_size', 8),
                "max_memory_gb": self.config.get('processing.max_memory_gb', 3.0),
                "streaming_output": self.config.get('processing.streaming_output', True),

                # ğŸ” æ·±åº¦æ¨å®šè¨­å®šï¼ˆæ–°è¦è¿½åŠ ï¼‰
                "depth_estimation": {
                    "enabled": self.depth_enabled,
                    "save_depth_maps": self.config.get('processing.depth_estimation.save_depth_maps', False)
                }
            }

            # ã‚¿ã‚¤ãƒ«æ¨è«–è¨­å®šã‚’è¿½åŠ 
            if self.tile_enabled:
                tile_config = self.config.get('processing.tile_inference', {})
                config["tile_inference"] = {
                    "enabled": True,
                    "tile_size": tuple(tile_config.get('tile_size', [640, 640])),
                    "overlap_ratio": tile_config.get('overlap_ratio', 0.2),
                    "use_adaptive": tile_config.get('use_adaptive', False),
                    "max_tiles_per_frame": tile_config.get('max_tiles_per_frame', 16),
                    "nms_threshold": tile_config.get('nms_threshold', 0.5)
                }

            # è¨­å®šå€¤ã®æ¤œè¨¼
            if config["confidence_threshold"] < 0 or config["confidence_threshold"] > 1:
                self.logger.warning(f"confidence_thresholdå€¤ãŒç•°å¸¸: {config['confidence_threshold']}")
                config["confidence_threshold"] = 0.3

            if config["batch_size"] <= 0:
                self.logger.warning(f"batch_sizeå€¤ãŒç•°å¸¸: {config['batch_size']}")
                config["batch_size"] = 8

            ctx.add_info("config_keys", list(config.keys()))
            ctx.add_info("confidence_threshold", config["confidence_threshold"])
            ctx.add_info("batch_size", config["batch_size"])
            ctx.add_info("depth_enabled", self.depth_enabled)

            return config

    @handle_errors(logger=logger, error_category=ErrorCategory.PROCESSING)
    def _run_tile_inference(
        self,
        frame_dir: Path,
        result_dir: Path,
        video_name: str,
        config: Dict
    ) -> Dict[str, Any]:
        """
        ã‚¿ã‚¤ãƒ«æ¨è«–å®Ÿè¡Œï¼ˆçµ±ä¸€ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°å¯¾å¿œç‰ˆï¼‰

        Args:
            frame_dir: ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
            result_dir: çµæœå‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
            video_name: å‹•ç”»å
            config: å‡¦ç†è¨­å®š

        Returns:
            ResponseBuilderå½¢å¼ã®å‡¦ç†çµæœ
        """
        with ErrorContext("ã‚¿ã‚¤ãƒ«æ¨è«–", logger=self.logger) as ctx:
            try:
                from yolopose_analyzer import analyze_frames_with_tile_inference

                ctx.add_info("inference_type", "tile")

                result = analyze_frames_with_tile_inference(
                    str(frame_dir),
                    str(result_dir),
                    config["model_path"],
                    config
                )

                # ResponseBuilderå½¢å¼ã¸ã®å¤‰æ›
                if isinstance(result, dict):
                    if result.get("success", False):
                        # æˆåŠŸæ™‚
                        result_data = result.get("data", result)
                        result_data["video_name"] = video_name
                        result_data["inference_type"] = "tile"

                        return ResponseBuilder.success(
                            data=result_data,
                            message="ã‚¿ã‚¤ãƒ«æ¨è«–å®Œäº†"
                        )
                    elif "error" in result:
                        # ã‚¨ãƒ©ãƒ¼æ™‚
                        return result  # ã™ã§ã«ResponseBuilderå½¢å¼
                    else:
                        # å¾“æ¥å½¢å¼ï¼ˆsuccess/errorã‚­ãƒ¼ãªã—ï¼‰
                        result["video_name"] = video_name
                        result["inference_type"] = "tile"

                        return ResponseBuilder.success(
                            data=result,
                            message="ã‚¿ã‚¤ãƒ«æ¨è«–å®Œäº†"
                        )
                else:
                    raise VideoProcessingError(
                        "ã‚¿ã‚¤ãƒ«æ¨è«–ã®çµæœãŒä¸æ­£ãªå½¢å¼ã§ã™",
                        details={"result_type": type(result).__name__}
                    )

            except ImportError as e:
                raise VideoProcessingError(
                    "ã‚¿ã‚¤ãƒ«æ¨è«–é–¢æ•°ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆã«å¤±æ•—ã—ã¾ã—ãŸ",
                    details={
                        "error": str(e),
                        "module": "yolopose_analyzer",
                        "function": "analyze_frames_with_tile_inference"
                    },
                    suggestions=[
                        "yolopose_analyzer.py ãŒå­˜åœ¨ã—ã€analyze_frames_with_tile_inferenceé–¢æ•°ãŒå®šç¾©ã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„",
                        "é€šå¸¸æ¨è«–ã«åˆ‡ã‚Šæ›¿ãˆã‚‹ã“ã¨ã‚’æ¤œè¨ã—ã¦ãã ã•ã„"
                    ],
                    original_exception=e
                )

    # Line 815-860ã®_run_normal_inferenceãƒ¡ã‚½ãƒƒãƒ‰ã‚’ä»¥ä¸‹ã«ç½®æ›:

    @handle_errors(logger=logger, error_category=ErrorCategory.PROCESSING)
    def _run_normal_inference(
        self,
        frame_dir: Path,
        result_dir: Path,
        video_name: str,
        config: Dict
    ) -> Dict[str, Any]:
        """
        é€šå¸¸æ¨è«–å®Ÿè¡Œï¼ˆãƒ¢ãƒ‡ãƒ«ãƒ‘ã‚¹ä¿®æ­£ç‰ˆï¼‰

        Args:
            frame_dir: ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
            result_dir: çµæœå‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
            video_name: å‹•ç”»å
            config: å‡¦ç†è¨­å®š

        Returns:
            ResponseBuilderå½¢å¼ã®å‡¦ç†çµæœ
        """
        with ErrorContext("é€šå¸¸æ¨è«–", logger=self.logger) as ctx:
            try:
                # âš¡ ãƒ¢ãƒ‡ãƒ«ãƒ‘ã‚¹å–å¾—ãƒ»ä¿®æ­£
                models_config = self.config.get('models', {}) if hasattr(self.config, 'get') else {}
                pose_model_path = models_config.get('pose', 'models/yolo11x-pose.pt')
                
                # ãƒ‘ã‚¹é‡è¤‡ä¿®æ­£
                if pose_model_path.startswith('models/models/'):
                    pose_model_path = pose_model_path.replace('models/models/', 'models/')
                
                self.logger.info(f"ğŸ¯ ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«: {pose_model_path}")
                ctx.add_info("model_path", pose_model_path)
                
                from yolopose_analyzer import analyze_frames_with_tracking_memory_efficient

                ctx.add_info("inference_type", "normal")

                # âš¡ ä¿®æ­£æ¸ˆã¿ãƒ‘ã‚¹ã‚’æ˜ç¤ºçš„ã«æ¸¡ã™
                result = analyze_frames_with_tracking_memory_efficient(
                    str(frame_dir),
                    str(result_dir),
                    model_path=pose_model_path,  # âš¡ ä¿®æ­£æ¸ˆã¿ãƒ‘ã‚¹ã‚’ä½¿ç”¨
                    config=config
                )

                # ResponseBuilderå½¢å¼ã¸ã®å¤‰æ›
                if isinstance(result, dict):
                    if result.get("success", False):
                        # æˆåŠŸæ™‚
                        result_data = result.get("data", result)
                        result_data["video_name"] = video_name
                        result_data["inference_type"] = "normal"

                        return ResponseBuilder.success(
                            data=result_data,
                            message="é€šå¸¸æ¨è«–å®Œäº†"
                        )
                    elif "error" in result:
                        # ã‚¨ãƒ©ãƒ¼æ™‚ï¼ˆã™ã§ã«ResponseBuilderå½¢å¼ï¼‰
                        return result
                    else:
                        # å¾“æ¥å½¢å¼ï¼ˆsuccess/errorã‚­ãƒ¼ãªã—ï¼‰
                        result["video_name"] = video_name
                        result["inference_type"] = "normal"

                        return ResponseBuilder.success(
                            data=result,
                            message="é€šå¸¸æ¨è«–å®Œäº†"
                        )
                else:
                    raise VideoProcessingError(
                        "é€šå¸¸æ¨è«–ã®çµæœãŒä¸æ­£ãªå½¢å¼ã§ã™",
                        details={"result_type": type(result).__name__}
                    )

            except ImportError as e:
                raise VideoProcessingError(
                    "yolopose_analyzerãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆã«å¤±æ•—ã—ã¾ã—ãŸ",
                    details={
                        "error": str(e),
                        "module": "yolopose_analyzer",
                        "function": "analyze_frames_with_tracking_memory_efficient"
                    },
                    suggestions=[
                        "yolopose_analyzer.py ãŒå­˜åœ¨ã™ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¦ãã ã•ã„",
                        "å¿…è¦ãªä¾å­˜é–¢ä¿‚ãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„"
                    ],
                    original_exception=e
                )

    @handle_errors(logger=logger, error_category=ErrorCategory.PROCESSING)
    def get_processing_stats(self) -> Dict[str, Any]:
        """
        å‡¦ç†çµ±è¨ˆã‚’å–å¾—ï¼ˆçµ±ä¸€ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°å¯¾å¿œç‰ˆï¼‰

        Returns:
            çµ±è¨ˆæƒ…å ±ã®è¾æ›¸
        """
        with ErrorContext("å‡¦ç†çµ±è¨ˆå–å¾—", logger=self.logger) as ctx:
            stats = {
                "tile_enabled": self.tile_enabled,
                "depth_enabled": self.depth_enabled,  # æ–°è¦è¿½åŠ 
                "config_summary": {
                    "video_dir": getattr(self.config, 'video_dir', 'N/A'),
                    "model_dir": getattr(self.config, 'model_dir', 'N/A'),
                    "output_dir": getattr(self.config, 'output_dir', 'N/A'),
                    "pose_model": getattr(self.config, 'pose_model', 'N/A')
                },
                "processing_capabilities": {
                    "frame_sampling": True,
                    "detection_tracking": True,
                    "tile_inference": self.tile_enabled,
                    "depth_estimation": self.depth_enabled,  # æ–°è¦è¿½åŠ 
                    "memory_efficient": True
                }
            }

            # ğŸ” æ·±åº¦æ¨å®šé–¢é€£çµ±è¨ˆï¼ˆæ–°è¦è¿½åŠ ï¼‰
            if self.depth_enabled and self.depth_processor:
                stats["depth_processor_info"] = {
                    "model_type": "midas",
                    "classroom_mode": getattr(self.depth_processor, 'classroom_mode', False),
                    "camera_height": getattr(self.depth_processor, 'camera_height', 'N/A'),
                    "camera_angle": getattr(self.depth_processor, 'camera_angle', 'N/A')
                }

            ctx.add_info("stats_collected", True)
            ctx.add_info("features_enabled", [k for k, v in stats["processing_capabilities"].items() if v])

            return stats