from ultralytics import YOLO
import cv2
import os
import pandas as pd
import numpy as np
import logging
from pathlib import Path
import traceback
import torch
from typing import Dict, Any, Optional, List
import time
import psutil
import csv
import gc
from collections import deque

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# ğŸ†• ã‚¿ã‚¤ãƒ«æ¨è«–ã‚¯ãƒ©ã‚¹ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆï¼ˆã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°å¼·åŒ–ï¼‰
try:
    from processors.tile_processor import TileProcessor, TileConfig, AdaptiveTileProcessor
    TILE_INFERENCE_AVAILABLE = True
    logger.info("âœ… ã‚¿ã‚¤ãƒ«æ¨è«–ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«èª­ã¿è¾¼ã¿æˆåŠŸ")
except ImportError as e:
    TILE_INFERENCE_AVAILABLE = False
    logger.warning(f"âš ï¸ ã‚¿ã‚¤ãƒ«æ¨è«–ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {e}")
    logger.info("é€šå¸¸æ¨è«–ã®ã¿åˆ©ç”¨å¯èƒ½ã§ã™ã€‚processors/tile_processor.py ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚")

    # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”¨ã®ãƒ€ãƒŸãƒ¼ã‚¯ãƒ©ã‚¹
    class TileProcessor:
        def __init__(self, *args, **kwargs):
            raise ImportError("TileProcessor ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“")

    class TileConfig:
        def __init__(self, *args, **kwargs):
            raise ImportError("TileConfig ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“")

    class AdaptiveTileProcessor:
        def __init__(self, *args, **kwargs):
            raise ImportError("AdaptiveTileProcessor ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“")

# ã‚¨ãƒ©ãƒ¼ã‚¯ãƒ©ã‚¹å®šç¾©
class ModelInitializationError(Exception):
    """ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼"""
    pass

class VideoProcessingError(Exception):
    """å‹•ç”»å‡¦ç†ã‚¨ãƒ©ãƒ¼"""
    pass

class ResourceExhaustionError(Exception):
    """ãƒªã‚½ãƒ¼ã‚¹ä¸è¶³ã‚¨ãƒ©ãƒ¼"""
    pass

def check_system_resources() -> Dict[str, Any]:
    """ã‚·ã‚¹ãƒ†ãƒ ãƒªã‚½ãƒ¼ã‚¹ã®ç¢ºèª"""
    try:
        memory = psutil.virtual_memory()

        # ãƒ‡ã‚£ã‚¹ã‚¯ä½¿ç”¨é‡ç¢ºèªï¼ˆWindowsã§ã‚‚ã‚¯ãƒ­ã‚¹ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ å¯¾å¿œï¼‰
        try:
            if os.name == 'nt':  # Windows
                disk = psutil.disk_usage('C:')
            else:  # Unix/Linux/Mac
                disk = psutil.disk_usage('/')
        except:
            disk = None

        # âœ… GPUæ¤œå‡ºã‚’æ”¹å–„ï¼ˆCUDA + MPSå¯¾å¿œï¼‰
        gpu_available = False
        gpu_type = "none"
        gpu_count = 0
        gpu_name = "N/A"

        # CUDA (NVIDIA GPU) ãƒã‚§ãƒƒã‚¯
        if torch.cuda.is_available():
            gpu_available = True
            gpu_type = "cuda"
            gpu_count = torch.cuda.device_count()
            if gpu_count > 0:
                gpu_name = torch.cuda.get_device_name(0)
        # MPS (Apple Silicon GPU) ãƒã‚§ãƒƒã‚¯
        elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
            gpu_available = True
            gpu_type = "mps"
            gpu_count = 1  # MPSã¯å¸¸ã«1ãƒ‡ãƒã‚¤ã‚¹
            gpu_name = "Apple Silicon GPU (MPS)"

        result = {
            "memory_total_gb": memory.total / (1024**3),
            "memory_available_gb": memory.available / (1024**3),
            "memory_percent": memory.percent,
            "cpu_count": psutil.cpu_count(),
            "gpu_available": torch.cuda.is_available(),
            "gpu_type": gpu_type,
            "gpu_count": gpu_count,
            "gpu_name": gpu_name
        }

        if disk:
            result["disk_free_gb"] = disk.free / (1024**3)

        return result
    except Exception as e:
        logger.warning(f"ã‚·ã‚¹ãƒ†ãƒ ãƒªã‚½ãƒ¼ã‚¹ç¢ºèªã‚¨ãƒ©ãƒ¼: {e}")
        return {"error": str(e)}

def validate_model_file(model_path: str) -> Dict[str, Any]:
    """ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã®è©³ç´°æ¤œè¨¼"""
    validation_result = {
        "valid": False,
        "errors": [],
        "warnings": [],
        "suggestions": []
    }

    # ãƒ•ã‚¡ã‚¤ãƒ«å­˜åœ¨ç¢ºèª
    if not os.path.exists(model_path):
        validation_result["errors"].append(f"ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ã¾ã›ã‚“: {model_path}")

        # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ææ¡ˆ
        model_name = os.path.basename(model_path)
        if model_name.startswith("yolo11"):
            validation_result["suggestions"].append(
                f"ä»¥ä¸‹ã®æ–¹æ³•ã§ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã§ãã¾ã™:\n"
                f"1. ã‚³ãƒãƒ³ãƒ‰: python -c \"from ultralytics import YOLO; YOLO('{model_name}')\"\n"
                f"2. ã¾ãŸã¯å…¬å¼ã‚µã‚¤ãƒˆã‹ã‚‰ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰"
            )
        return validation_result

    # ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºç¢ºèª
    try:
        file_size = os.path.getsize(model_path)
        if file_size < 1024:  # 1KBæœªæº€ã¯ç•°å¸¸
            validation_result["errors"].append(f"ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚µã‚¤ã‚ºãŒç•°å¸¸ã«å°ã•ã„ã§ã™: {file_size} bytes")
            return validation_result
        elif file_size < 1024*1024:  # 1MBæœªæº€ã¯è­¦å‘Š
            validation_result["warnings"].append(f"ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãŒå°ã•ã™ãã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™: {file_size/1024:.1f} KB")
    except Exception as e:
        validation_result["errors"].append(f"ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºç¢ºèªã‚¨ãƒ©ãƒ¼: {e}")
        return validation_result

    # èª­ã¿è¾¼ã¿ãƒ†ã‚¹ãƒˆ
    try:
        # PyTorch 2.8å¯¾ç­–: weights_onlyã‚’å¼·åˆ¶çš„ã«Falseã«
        import torch
        _original_torch_load = torch.load
        torch.load = lambda *args, **kwargs: _original_torch_load(*args, **{**kwargs, 'weights_only': False})

        test_model = YOLO(model_path)

        # å…ƒã«æˆ»ã™
        torch.load = _original_torch_load

        validation_result["valid"] = True
        validation_result["warnings"].append("ãƒ¢ãƒ‡ãƒ«æ¤œè¨¼å®Œäº†")
    except Exception as e:
        validation_result["errors"].append(f"ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿ãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
        validation_result["suggestions"].append(
            "ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãŒç ´æã—ã¦ã„ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚å†ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã‚’è©¦ã—ã¦ãã ã•ã„ã€‚"
        )

    return validation_result

def safe_model_initialization(model_path: str, config: Dict[str, Any]) -> YOLO:
    """å®‰å…¨ãªãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–"""
    # ã‚·ã‚¹ãƒ†ãƒ ãƒªã‚½ãƒ¼ã‚¹ç¢ºèª
    resources = check_system_resources()
    if "error" not in resources:
        logger.info(f"ã‚·ã‚¹ãƒ†ãƒ ãƒªã‚½ãƒ¼ã‚¹: ãƒ¡ãƒ¢ãƒª {resources['memory_available_gb']:.1f}GB åˆ©ç”¨å¯èƒ½")

        if resources["memory_available_gb"] < 2.0:
            logger.warning("åˆ©ç”¨å¯èƒ½ãƒ¡ãƒ¢ãƒªãŒ2GBæœªæº€ã§ã™ã€‚å‡¦ç†ãŒé…ããªã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚")

        # âœ… GPUæƒ…å ±ã®å‡ºåŠ›ã‚’æ”¹å–„
        if resources["gpu_available"]:
            gpu_type = resources.get("gpu_type", "unknown")
            gpu_name = resources.get("gpu_name", "N/A")
            gpu_count = resources.get("gpu_count", 0)

            if gpu_type == "mps":
                logger.info(f"ğŸ Apple Silicon GPU (MPS) åˆ©ç”¨å¯èƒ½")
            elif gpu_type == "cuda":
                logger.info(f"ğŸš€ NVIDIA GPU (CUDA) åˆ©ç”¨å¯èƒ½: {gpu_count}å€‹ã®ãƒ‡ãƒã‚¤ã‚¹")
                if gpu_name != "N/A":
                    logger.info(f"   GPUå: {gpu_name}")
            else:
                logger.info(f"GPUåˆ©ç”¨å¯èƒ½: {gpu_type.upper()}")
        else:
            logger.info("ğŸ’» GPUåˆ©ç”¨ä¸å¯ã€‚CPUã§å‡¦ç†ã—ã¾ã™ã€‚")

    # ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«æ¤œè¨¼
    validation = validate_model_file(model_path)
    if not validation["valid"]:
        error_msg = "\n".join(validation["errors"])
        suggestions = "\n".join(validation["suggestions"])
        raise ModelInitializationError(f"{error_msg}\n\næ¨å¥¨å¯¾å¿œ:\n{suggestions}")

    if validation["warnings"]:
        for warning in validation["warnings"]:
            logger.info(warning)


        # PyTorch 2.6ä»¥é™ã®weights_onlyå¯¾ç­–
        import torch.serialization
        try:
            # Ultralyticsã®ã‚¯ãƒ©ã‚¹ã‚’safe_globalsã«è¿½åŠ 
            torch.serialization.add_safe_globals([
                'ultralytics.nn.tasks.PoseModel',
                'ultralytics.nn.tasks.DetectionModel'
            ])
        except AttributeError:
            # å¤ã„PyTorchãƒãƒ¼ã‚¸ãƒ§ãƒ³ã§ã¯ç„¡è¦–
            pass

    try:
        # PyTorch 2.8å¯¾ç­–: weights_onlyã‚’å¼·åˆ¶çš„ã«Falseã«
        import torch
        _original_torch_load = torch.load
        torch.load = lambda *args, **kwargs: _original_torch_load(*args, **{**kwargs, 'weights_only': False})

        # ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–
        model = YOLO(model_path)

        # torch.loadã‚’å…ƒã«æˆ»ã™
        torch.load = _original_torch_load

        # âœ… ãƒ‡ãƒã‚¤ã‚¹è¨­å®šã‚’æ”¹å–„
        device = config.get("device", "auto")
        
        if device == "auto":
            # è‡ªå‹•æ¤œå‡º
            if torch.cuda.is_available():
                device = "cuda"
            elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
                device = "mps"
            else:
                device = "cpu"

        try:
            model.to(device)
        except Exception as e:
            logger.warning(f"ãƒ‡ãƒã‚¤ã‚¹è¨­å®šã‚¨ãƒ©ãƒ¼: {e}. CPUã‚’ä½¿ç”¨ã—ã¾ã™ã€‚")
            device = "cpu"
            model.to(device)

        # âœ… ãƒ‡ãƒã‚¤ã‚¹æƒ…å ±ã®å‡ºåŠ›ã‚’æ”¹å–„
        if device == "mps":
            logger.info(f"ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–å®Œäº†: {model_path} on ğŸ {device.upper()}")
        elif device == "cuda":
            logger.info(f"ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–å®Œäº†: {model_path} on ğŸš€ {device.upper()}")
        else:
            logger.info(f"ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–å®Œäº†: {model_path} on ğŸ’» {device.upper()}")

        # GPUä½¿ç”¨æ™‚ã®è¿½åŠ è¨­å®š
        if device == "cuda" and torch.cuda.is_available():
            try:
                # GPU ãƒ¡ãƒ¢ãƒªç¢ºèª
                gpu_memory = torch.cuda.get_device_properties(0).total_memory / (1024**3)
                logger.info(f"GPU ãƒ¡ãƒ¢ãƒª: {gpu_memory:.1f}GB")

                # åŠç²¾åº¦æ¼”ç®—è¨­å®šï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
                if config.get("use_half_precision", False):
                    model.half()
                    logger.info("åŠç²¾åº¦æ¼”ç®—ã‚’æœ‰åŠ¹åŒ–")

            except Exception as e:
                logger.warning(f"GPUè¨­å®šè­¦å‘Š: {e}")

        return model

    except Exception as e:
        logger.error(f"ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
        logger.error(f"è©³ç´°: {traceback.format_exc()}")
        raise ModelInitializationError(f"ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")

def validate_frame_directory(frame_dir: str) -> Dict[str, Any]:
    """ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®æ¤œè¨¼"""
    validation_result = {
        "valid": False,
        "frame_count": 0,
        "total_size_mb": 0,
        "errors": [],
        "warnings": []
    }

    if not os.path.exists(frame_dir):
        validation_result["errors"].append(f"ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒå­˜åœ¨ã—ã¾ã›ã‚“: {frame_dir}")
        return validation_result

    try:
        frame_files = [f for f in os.listdir(frame_dir) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]
        validation_result["frame_count"] = len(frame_files)

        if len(frame_files) == 0:
            validation_result["errors"].append("ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            validation_result["suggestions"] = [
                "ãƒ•ãƒ¬ãƒ¼ãƒ æŠ½å‡ºãŒæ­£å¸¸ã«å®Ÿè¡Œã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„",
                "å¯¾å¿œå½¢å¼: .jpg, .jpeg, .png"
            ]
            return validation_result

        # ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºç¢ºèª
        total_size = 0
        corrupted_files = []

        sample_size = min(10, len(frame_files))
        for frame_file in frame_files[:sample_size]:
            file_path = os.path.join(frame_dir, frame_file)
            try:
                size = os.path.getsize(file_path)
                total_size += size

                # OpenCVã§èª­ã¿è¾¼ã¿ãƒ†ã‚¹ãƒˆ
                img = cv2.imread(file_path)
                if img is None:
                    corrupted_files.append(frame_file)

            except Exception as e:
                corrupted_files.append(f"{frame_file} (ã‚¨ãƒ©ãƒ¼: {e})")

        # å…¨ä½“ã‚µã‚¤ã‚ºæ¨å®š
        if sample_size > 0:
            avg_size = total_size / sample_size
            estimated_total_mb = (avg_size * len(frame_files)) / (1024*1024)
            validation_result["total_size_mb"] = estimated_total_mb

        if corrupted_files:
            validation_result["warnings"].append(f"ç ´æãƒ•ã‚¡ã‚¤ãƒ«: {corrupted_files[:3]}")

        if validation_result["total_size_mb"] > 1000:  # 1GBä»¥ä¸Š
            validation_result["warnings"].append(f"å¤§é‡ã®ãƒ•ãƒ¬ãƒ¼ãƒ  ({validation_result['total_size_mb']:.1f}MB)")

        validation_result["valid"] = True

    except Exception as e:
        validation_result["errors"].append(f"ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ¤œè¨¼ã‚¨ãƒ©ãƒ¼: {e}")

    return validation_result

class MemoryEfficientProcessor:
    """ãƒ¡ãƒ¢ãƒªåŠ¹ç‡ã‚’è€ƒæ…®ã—ãŸå‡¦ç†ã‚¯ãƒ©ã‚¹"""

    def __init__(self, config: Dict[str, Any]):
        self.config = config
        self.logger = logging.getLogger(__name__)

        # ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡åˆ¶é™
        self.max_memory_gb = config.get("max_memory_gb", 4.0)
        self.batch_size = config.get("batch_size", 32)
        self.streaming_output = config.get("streaming_output", True)

    def get_memory_usage(self) -> float:
        """ç¾åœ¨ã®ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã‚’å–å¾—ï¼ˆGBï¼‰"""
        try:
            process = psutil.Process()
            return process.memory_info().rss / (1024**3)
        except Exception as e:
            self.logger.warning(f"ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            return 0.0

    def check_memory_threshold(self) -> bool:
        """ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ãŒé–¾å€¤ã‚’è¶…ãˆã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯"""
        current_memory = self.get_memory_usage()
        return current_memory > self.max_memory_gb

    def force_memory_cleanup(self):
        """å¼·åˆ¶çš„ãªãƒ¡ãƒ¢ãƒªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
        try:
            gc.collect()
            if torch.cuda.is_available():
                torch.cuda.empty_cache()
        except Exception as e:
            self.logger.warning(f"ãƒ¡ãƒ¢ãƒªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã‚¨ãƒ©ãƒ¼: {e}")

        # ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã‚’ãƒ­ã‚°å‡ºåŠ›
        memory_after = self.get_memory_usage()
        self.logger.info(f"ãƒ¡ãƒ¢ãƒªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å®Ÿè¡Œå¾Œ: {memory_after:.2f}GB")

# ğŸ†• ã‚¿ã‚¤ãƒ«æ¨è«–çµ±åˆãƒ¡ã‚¤ãƒ³é–¢æ•°
def analyze_frames_with_tile_inference(
    frame_dir: str,
    result_dir: str,
    model_path: str = "models/yolo11n-pose.pt",
    config: Optional[Dict[str, Any]] = None
) -> Dict[str, Any]:
    """
    ã‚¿ã‚¤ãƒ«æ¨è«–ã‚’ä½¿ç”¨ã—ãŸãƒ•ãƒ¬ãƒ¼ãƒ è§£æ
    """

    # ã‚¿ã‚¤ãƒ«æ¨è«–ãŒåˆ©ç”¨ä¸å¯ã®å ´åˆã¯æ—¢å­˜é–¢æ•°ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
    if not TILE_INFERENCE_AVAILABLE:
        logger.warning("ã‚¿ã‚¤ãƒ«æ¨è«–ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚é€šå¸¸æ¨è«–ã‚’å®Ÿè¡Œã—ã¾ã™ã€‚")
        return analyze_frames_with_tracking_memory_efficient(
            frame_dir, result_dir, model_path, config
        )

    # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šï¼ˆã‚¿ã‚¤ãƒ«æ¨è«–å¯¾å¿œï¼‰
    if config is None:
        config = {
            "confidence_threshold": 0.3,
            "tracking_config": "bytetrack.yaml",
            "save_visualizations": True,
            "tile_inference": {
                "enabled": True,
                "tile_size": (640, 640),
                "overlap_ratio": 0.2,
                "use_adaptive": False,
                "max_tiles_per_frame": 16
            }
        }

    os.makedirs(result_dir, exist_ok=True)

    try:
        # ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–
        model = safe_model_initialization(model_path, config)
        logger.info(f"ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿å®Œäº†: {model_path}")

        # ã‚¿ã‚¤ãƒ«æ¨è«–ã®è¨­å®šç¢ºèª
        tile_config_data = config.get("tile_inference", {})
        tile_enabled = tile_config_data.get("enabled", False)

        if tile_enabled:
            # ã‚¿ã‚¤ãƒ«æ¨è«–ãƒ—ãƒ­ã‚»ãƒƒã‚µã‚’åˆæœŸåŒ–
            tile_config = TileConfig(
                tile_size=tuple(tile_config_data.get("tile_size", (640, 640))),
                overlap_ratio=tile_config_data.get("overlap_ratio", 0.2),
                min_confidence=config.get("confidence_threshold", 0.3),
                max_tiles_per_frame=tile_config_data.get("max_tiles_per_frame", 16)
            )

            use_adaptive = tile_config_data.get("use_adaptive", False)
            if use_adaptive:
                tile_processor = AdaptiveTileProcessor(model, tile_config)
                logger.info("ğŸ”² é©å¿œçš„ã‚¿ã‚¤ãƒ«æ¨è«–ã‚’ä½¿ç”¨")
            else:
                tile_processor = TileProcessor(model, tile_config)
                logger.info("ğŸ”² æ¨™æº–ã‚¿ã‚¤ãƒ«æ¨è«–ã‚’ä½¿ç”¨")
        else:
            tile_processor = None
            logger.info("ğŸ“‹ é€šå¸¸æ¨è«–ã‚’ä½¿ç”¨")

        # ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ¤œè¨¼
        frame_validation = validate_frame_directory(frame_dir)
        if not frame_validation["valid"]:
            return {
                "error": "frame_validation_failed",
                "details": frame_validation["errors"],
                "suggestions": frame_validation.get("suggestions", []),
                "frame_dir": frame_dir
            }

        frame_files = sorted([
            f for f in os.listdir(frame_dir)
            if f.lower().endswith(('.jpg', '.jpeg', '.png'))
        ])

        total_frames = len(frame_files)
        logger.info(f"å‡¦ç†å¯¾è±¡: {total_frames}ãƒ•ãƒ¬ãƒ¼ãƒ ")

        # çµæœä¿å­˜ç”¨CSVæº–å‚™
        csv_path = os.path.join(result_dir, "detections_enhanced.csv")
        csv_columns = ["frame", "person_id", "x1", "y1", "x2", "y2", "conf", "class_name"]

        # ã‚¿ã‚¤ãƒ«æ¨è«–ã®å ´åˆã¯è¿½åŠ æƒ…å ±ã‚‚ä¿å­˜
        if tile_processor:
            csv_columns.extend(["tile_source", "tile_count", "nms_reduction"])

        # å‡¦ç†çµ±è¨ˆ
        stats = {
            "total_frames": total_frames,
            "processed_frames": 0,
            "successful_frames": 0,
            "failed_frames": 0,
            "total_detections": 0,
            "unique_ids": set(),
            "tile_stats": {
                "total_tiles_processed": 0,
                "avg_tiles_per_frame": 0,
                "avg_nms_reduction": 0
            } if tile_processor else None
        }

        with open(csv_path, 'w', newline='', encoding='utf-8') as csv_file:
            csv_writer = csv.writer(csv_file)
            csv_writer.writerow(csv_columns)

            for frame_idx, frame_file in enumerate(frame_files):
                frame_path = os.path.join(frame_dir, frame_file)

                try:
                    # ãƒ•ãƒ¬ãƒ¼ãƒ èª­ã¿è¾¼ã¿
                    frame = cv2.imread(frame_path)
                    if frame is None:
                        logger.warning(f"ãƒ•ãƒ¬ãƒ¼ãƒ èª­ã¿è¾¼ã¿å¤±æ•—: {frame_file}")
                        stats["failed_frames"] += 1
                        continue

                    # ğŸ”² ã‚¿ã‚¤ãƒ«æ¨è«– ã¾ãŸã¯ ğŸ“‹ é€šå¸¸æ¨è«–
                    if tile_processor:
                        # ã‚¿ã‚¤ãƒ«æ¨è«–å®Ÿè¡Œ
                        try:
                            if hasattr(tile_processor, 'process_frame_with_adaptive_tiles'):
                                detection_result = tile_processor.process_frame_with_adaptive_tiles(frame, frame_idx)
                            else:
                                detection_result = tile_processor.process_frame_with_tiles(frame)

                            boxes = detection_result["boxes"]
                            confidences = detection_result["confidences"]
                            tile_sources = detection_result.get("tile_sources", [])
                            tile_count = detection_result.get("processing_stats", {}).get("num_tiles", 0)
                            nms_reduction = detection_result.get("nms_reduction_rate", 0)

                            # çµ±è¨ˆæ›´æ–°
                            if stats["tile_stats"]:
                                stats["tile_stats"]["total_tiles_processed"] += tile_count
                                stats["tile_stats"]["avg_nms_reduction"] += nms_reduction

                        except Exception as e:
                            logger.error(f"ã‚¿ã‚¤ãƒ«æ¨è«–ã‚¨ãƒ©ãƒ¼ {frame_file}: {e}")
                            stats["failed_frames"] += 1
                            continue

                    else:
                        # é€šå¸¸æ¨è«–ï¼ˆãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°ä»˜ãï¼‰
                        try:
                            results = model.track(
                                frame,
                                persist=True,
                                tracker=config.get("tracking_config", "bytetrack.yaml"),
                                conf=config.get("confidence_threshold", 0.3),
                                verbose=False
                            )

                            # çµæœå¤‰æ›
                            if results and results[0].boxes is not None:
                                boxes = results[0].boxes.xyxy.cpu().numpy()
                                confidences = results[0].boxes.conf.cpu().numpy()
                                # ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°IDãŒã‚ã‚Œã°ä½¿ç”¨
                                if results[0].boxes.id is not None:
                                    track_ids = results[0].boxes.id.cpu().numpy().astype(int)
                                else:
                                    track_ids = list(range(len(boxes)))
                            else:
                                boxes = np.array([]).reshape(0, 4)
                                confidences = np.array([])
                                track_ids = []

                            tile_sources = [0] * len(boxes)  # é€šå¸¸æ¨è«–ã§ã¯å…¨ã¦0
                            tile_count = 1
                            nms_reduction = 0

                        except Exception as e:
                            logger.error(f"é€šå¸¸æ¨è«–ã‚¨ãƒ©ãƒ¼ {frame_file}: {e}")
                            stats["failed_frames"] += 1
                            continue

                    # æ¤œå‡ºçµæœã‚’CSVã«ä¿å­˜
                    if len(boxes) > 0:
                        for i, (box, conf) in enumerate(zip(boxes, confidences)):
                            if tile_processor:
                                # ã‚¿ã‚¤ãƒ«æ¨è«–ã®å ´åˆã¯ã‚·ãƒ³ãƒ—ãƒ«ãªID
                                person_id = f"tile_{frame_idx}_{i}"
                            else:
                                # é€šå¸¸æ¨è«–ã®å ´åˆã¯ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°ID
                                person_id = track_ids[i] if i < len(track_ids) else f"det_{frame_idx}_{i}"

                            row_data = [
                                frame_file, person_id,
                                float(box[0]), float(box[1]), float(box[2]), float(box[3]),
                                float(conf), "person"
                            ]

                            # ã‚¿ã‚¤ãƒ«æ¨è«–ã®å ´åˆã¯è¿½åŠ æƒ…å ±
                            if tile_processor:
                                tile_src = tile_sources[i] if i < len(tile_sources) else -1
                                row_data.extend([int(tile_src), int(tile_count), float(nms_reduction)])

                            csv_writer.writerow(row_data)
                            stats["unique_ids"].add(person_id)

                    # å¯è¦–åŒ–ä¿å­˜
                    if config.get("save_visualizations", False) and len(boxes) > 0:
                        try:
                            vis_frame = _draw_detections_enhanced(
                                frame, boxes, confidences, tile_sources if tile_processor else None
                            )
                            output_path = os.path.join(result_dir, f"vis_{frame_file}")
                            cv2.imwrite(output_path, vis_frame)
                        except Exception as e:
                            logger.warning(f"å¯è¦–åŒ–ä¿å­˜ã‚¨ãƒ©ãƒ¼ {frame_file}: {e}")

                    stats["total_detections"] += len(boxes)
                    stats["processed_frames"] += 1
                    stats["successful_frames"] += 1

                    # é€²æ—è¡¨ç¤º
                    if (frame_idx + 1) % 50 == 0 or (frame_idx + 1) == total_frames:
                        progress = (frame_idx + 1) / total_frames * 100
                        logger.info(f"é€²æ—: {progress:.1f}% ({frame_idx + 1}/{total_frames})")

                except Exception as e:
                    logger.error(f"ãƒ•ãƒ¬ãƒ¼ãƒ å‡¦ç†ã‚¨ãƒ©ãƒ¼ {frame_file}: {e}")
                    stats["failed_frames"] += 1
                    continue

        # æœ€çµ‚çµ±è¨ˆè¨ˆç®—
        stats["unique_ids"] = len(stats["unique_ids"])

        if stats["tile_stats"] and stats["processed_frames"] > 0:
            stats["tile_stats"]["avg_tiles_per_frame"] = (
                stats["tile_stats"]["total_tiles_processed"] / stats["processed_frames"]
            )
            stats["tile_stats"]["avg_nms_reduction"] = (
                stats["tile_stats"]["avg_nms_reduction"] / stats["processed_frames"]
            )

        # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹çµ±è¨ˆ
        performance_stats = {}
        if tile_processor:
            try:
                performance_stats = tile_processor.get_performance_stats()
            except Exception as e:
                logger.warning(f"ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹çµ±è¨ˆå–å¾—ã‚¨ãƒ©ãƒ¼: {e}")

        logger.info("âœ… å‡¦ç†å®Œäº†")
        logger.info(f"  ç·æ¤œå‡ºæ•°: {stats['total_detections']}")
        logger.info(f"  ãƒ¦ãƒ‹ãƒ¼ã‚¯ID: {stats['unique_ids']}")
        logger.info(f"  æˆåŠŸç‡: {stats['successful_frames']}/{stats['total_frames']} ({stats['successful_frames']/stats['total_frames']*100:.1f}%)")

        if stats["tile_stats"]:
            logger.info(f"  ğŸ”² å¹³å‡ã‚¿ã‚¤ãƒ«æ•°/ãƒ•ãƒ¬ãƒ¼ãƒ : {stats['tile_stats']['avg_tiles_per_frame']:.1f}")
            logger.info(f"  ğŸ”² å¹³å‡NMSå‰Šæ¸›ç‡: {stats['tile_stats']['avg_nms_reduction']:.1%}")

        return {
            "csv_path": csv_path,
            "processing_stats": stats,
            "performance_stats": performance_stats,
            "config_used": config,
            "model_path": model_path,
            "result_dir": result_dir,
            "tile_inference_enabled": tile_processor is not None,
            "success": True
        }

    except Exception as e:
        logger.error(f"å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
        logger.error(f"è©³ç´°: {traceback.format_exc()}")
        return {"error": "processing_failed", "details": str(e), "success": False}

def _draw_detections_enhanced(frame: np.ndarray,
                            boxes: np.ndarray,
                            confidences: np.ndarray,
                            tile_sources: Optional[List[int]] = None) -> np.ndarray:
    """
    æ‹¡å¼µç‰ˆæ¤œå‡ºçµæœæç”»ï¼ˆã‚¿ã‚¤ãƒ«æƒ…å ±ä»˜ãï¼‰
    """
    vis_frame = frame.copy()

    # ã‚¿ã‚¤ãƒ«åˆ¥ã®è‰²å®šç¾©
    tile_colors = [
        (0, 255, 0),    # ç·‘
        (255, 0, 0),    # é’
        (0, 0, 255),    # èµ¤
        (255, 255, 0),  # ã‚·ã‚¢ãƒ³
        (255, 0, 255),  # ãƒã‚¼ãƒ³ã‚¿
        (0, 255, 255),  # é»„è‰²
        (128, 0, 255),  # ç´«
        (255, 128, 0),  # ã‚ªãƒ¬ãƒ³ã‚¸
    ]

    for i, (box, conf) in enumerate(zip(boxes, confidences)):
        try:
            x1, y1, x2, y2 = map(int, box)

            # ã‚¿ã‚¤ãƒ«ã‚½ãƒ¼ã‚¹ã«å¿œã˜ã¦è‰²ã‚’é¸æŠ
            if tile_sources and i < len(tile_sources):
                tile_idx = tile_sources[i]
                color = tile_colors[tile_idx % len(tile_colors)]
            else:
                color = (0, 255, 0)  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆç·‘

            # ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹æç”»
            cv2.rectangle(vis_frame, (x1, y1), (x2, y2), color, 2)

            # ä¿¡é ¼åº¦è¡¨ç¤º
            conf_text = f"{conf:.2f}"
            cv2.putText(vis_frame, conf_text, (x1, y1-5),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1)

            # ã‚¿ã‚¤ãƒ«ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹è¡¨ç¤ºï¼ˆã‚¿ã‚¤ãƒ«æ¨è«–ã®å ´åˆï¼‰
            if tile_sources and i < len(tile_sources):
                tile_text = f"T{tile_sources[i]}"
                cv2.putText(vis_frame, tile_text, (x1, y2+15),
                            cv2.FONT_HERSHEY_SIMPLEX, 0.4, color, 1)
        except Exception as e:
            logger.warning(f"æç”»ã‚¨ãƒ©ãƒ¼ (box {i}): {e}")
            continue

    return vis_frame

# ğŸ†• ã‚¿ã‚¤ãƒ«æ¨è«–çµ±åˆç‰ˆã®æ‹¡å¼µé–¢æ•°
def analyze_frames_with_tracking_enhanced(
    frame_dir: str,
    result_dir: str,
    model_path: str = "models/yolo11n-pose.pt",
    config: Optional[Dict[str, Any]] = None
) -> Dict[str, Any]:
    """
    æ—¢å­˜ã®analyze_frames_with_tracking_memory_efficientã®æ”¹è‰¯ç‰ˆ
    ã‚¿ã‚¤ãƒ«æ¨è«–ã‚ªãƒ—ã‚·ãƒ§ãƒ³ä»˜ã
    """

    # è¨­å®šã«ã‚¿ã‚¤ãƒ«æ¨è«–ãŒå«ã¾ã‚Œã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
    if config and config.get("tile_inference", {}).get("enabled", False):
        return analyze_frames_with_tile_inference(frame_dir, result_dir, model_path, config)
    else:
        return analyze_frames_with_tracking_memory_efficient(frame_dir, result_dir, model_path, config)

# ğŸ†• æ¯”è¼ƒå®Ÿé¨“ç”¨é–¢æ•°
def compare_tile_vs_normal_inference(
    frame_dir: str,
    result_dir: str,
    model_path: str = "models/yolo11n-pose.pt",
    sample_frames: int = 10
) -> Dict[str, Any]:
    """
    ã‚¿ã‚¤ãƒ«æ¨è«–ã¨é€šå¸¸æ¨è«–ã®æ¯”è¼ƒå®Ÿé¨“
    """
    if not TILE_INFERENCE_AVAILABLE:
        logger.error("ã‚¿ã‚¤ãƒ«æ¨è«–ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“")
        return {"error": "tile_inference_not_available", "success": False}

    os.makedirs(result_dir, exist_ok=True)

    # ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ•ã‚¡ã‚¤ãƒ«å–å¾—
    try:
        frame_files = sorted([
            f for f in os.listdir(frame_dir)
            if f.lower().endswith(('.jpg', '.jpeg', '.png'))
        ])[:sample_frames]

        if not frame_files:
            return {"error": "no_frames_found", "success": False}
    except Exception as e:
        return {"error": f"frame_directory_error: {e}", "success": False}


    try:
        # ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–
        model = safe_model_initialization(model_path, {})

        # ã‚¿ã‚¤ãƒ«æ¨è«–è¨­å®š
        tile_config = TileConfig(
            tile_size=(640, 640),
            overlap_ratio=0.2,
            min_confidence=0.3
        )
        tile_processor = TileProcessor(model, tile_config)

        comparison_results = {
            "normal_inference": {"total_detections": 0, "processing_times": []},
            "tile_inference": {"total_detections": 0, "processing_times": []},
            "frame_comparisons": []
        }

        for frame_file in frame_files:
            frame_path = os.path.join(frame_dir, frame_file)
            frame = cv2.imread(frame_path)

            if frame is None:
                logger.warning(f"ãƒ•ãƒ¬ãƒ¼ãƒ èª­ã¿è¾¼ã¿å¤±æ•—: {frame_file}")
                continue

            frame_comparison = {"frame": frame_file}

            # 1. é€šå¸¸æ¨è«–
            try:
                start_time = time.time()
                normal_results = model(frame, conf=0.3, verbose=False)
                normal_time = time.time() - start_time

                normal_boxes = []
                if normal_results and normal_results[0].boxes is not None:
                    normal_boxes = normal_results[0].boxes.xyxy.cpu().numpy()

                frame_comparison["normal"] = {
                    "detections": len(normal_boxes),
                    "processing_time": normal_time
                }
                comparison_results["normal_inference"]["total_detections"] += len(normal_boxes)
                comparison_results["normal_inference"]["processing_times"].append(normal_time)
            except Exception as e:
                logger.error(f"é€šå¸¸æ¨è«–ã‚¨ãƒ©ãƒ¼ {frame_file}: {e}")
                frame_comparison["normal"] = {
                    "detections": 0,
                    "processing_time": 0,
                    "error": str(e)
                }

            # 2. ã‚¿ã‚¤ãƒ«æ¨è«–
            try:
                start_time = time.time()
                tile_results = tile_processor.process_frame_with_tiles(frame)
                tile_time = time.time() - start_time

                tile_boxes = tile_results["boxes"]

                frame_comparison["tile"] = {
                    "detections": len(tile_boxes),
                    "processing_time": tile_time,
                    "num_tiles": tile_results.get("processing_stats", {}).get("num_tiles", 0),
                    "nms_reduction": tile_results.get("nms_reduction_rate", 0)
                }
                comparison_results["tile_inference"]["total_detections"] += len(tile_boxes)
                comparison_results["tile_inference"]["processing_times"].append(tile_time)
            except Exception as e:
                logger.error(f"ã‚¿ã‚¤ãƒ«æ¨è«–ã‚¨ãƒ©ãƒ¼ {frame_file}: {e}")
                frame_comparison["tile"] = {
                    "detections": 0,
                    "processing_time": 0,
                    "num_tiles": 0,
                    "nms_reduction": 0,
                    "error": str(e)
                }

            # 3. æ¤œå‡ºæ•°æ”¹å–„ç‡è¨ˆç®—
            normal_det = frame_comparison["normal"]["detections"]
            tile_det = frame_comparison["tile"]["detections"]

            improvement = tile_det - normal_det
            improvement_rate = improvement / normal_det if normal_det > 0 else 0

            frame_comparison["improvement"] = {
                "detection_difference": improvement,
                "improvement_rate": improvement_rate,
                "time_overhead": frame_comparison["tile"]["processing_time"] - frame_comparison["normal"]["processing_time"]
            }

            comparison_results["frame_comparisons"].append(frame_comparison)

            # æ¯”è¼ƒå¯è¦–åŒ–ä¿å­˜
            try:
                if normal_det > 0 or tile_det > 0:
                    normal_boxes = normal_boxes if 'normal_boxes' in locals() else np.array([]).reshape(0, 4)
                    tile_boxes_array = tile_boxes if isinstance(tile_boxes, np.ndarray) else np.array([]).reshape(0, 4)

                    _save_comparison_visualization(
                        frame, normal_boxes, tile_boxes_array,
                        os.path.join(result_dir, f"comparison_{frame_file}")
                    )
            except Exception as e:
                logger.warning(f"æ¯”è¼ƒå¯è¦–åŒ–ä¿å­˜ã‚¨ãƒ©ãƒ¼ {frame_file}: {e}")

        # å…¨ä½“çµ±è¨ˆè¨ˆç®—
        if comparison_results["frame_comparisons"]:
            frame_comparisons = comparison_results["frame_comparisons"]

            # ã‚¨ãƒ©ãƒ¼ãŒãªã„ãƒ•ãƒ¬ãƒ¼ãƒ ã®ã¿ã§çµ±è¨ˆè¨ˆç®—
            valid_normal = [fc["normal"] for fc in frame_comparisons if "error" not in fc["normal"]]
            valid_tile = [fc["tile"] for fc in frame_comparisons if "error" not in fc["tile"]]

            comparison_results["summary"] = {
                "total_frames": len(frame_comparisons),
                "valid_normal_frames": len(valid_normal),
                "valid_tile_frames": len(valid_tile),
                "avg_normal_detections": np.mean([f["detections"] for f in valid_normal]) if valid_normal else 0,
                "avg_tile_detections": np.mean([f["detections"] for f in valid_tile]) if valid_tile else 0,
                "avg_normal_time": np.mean([f["processing_time"] for f in valid_normal]) if valid_normal else 0,
                "avg_tile_time": np.mean([f["processing_time"] for f in valid_tile]) if valid_tile else 0,
                "overall_detection_improvement": (
                    comparison_results["tile_inference"]["total_detections"] - 
                    comparison_results["normal_inference"]["total_detections"]
                ),
                "overall_improvement_rate": (
                    (comparison_results["tile_inference"]["total_detections"] - 
                    comparison_results["normal_inference"]["total_detections"]) /
                    comparison_results["normal_inference"]["total_detections"]
                    if comparison_results["normal_inference"]["total_detections"] > 0 else 0
                )
            }
        else:
            comparison_results["summary"] = {
                "error": "no_valid_comparisons"
            }

        # çµæœä¿å­˜
        import json
        with open(os.path.join(result_dir, "tile_comparison.json"), 'w') as f:
            json.dump(comparison_results, f, indent=2, default=str)

        logger.info("æ¯”è¼ƒå®Ÿé¨“å®Œäº†")
        if "error" not in comparison_results["summary"]:
            logger.info(f"æ¤œå‡ºæ•°æ”¹å–„: {comparison_results['summary']['overall_improvement_rate']:.1%}")
            logger.info(f"å‡¦ç†æ™‚é–“ã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰: {comparison_results['summary']['avg_tile_time'] - comparison_results['summary']['avg_normal_time']:.2f}ç§’")

        comparison_results["success"] = True
        return comparison_results

    except Exception as e:
        logger.error(f"æ¯”è¼ƒå®Ÿé¨“ã‚¨ãƒ©ãƒ¼: {e}")
        return {"error": f"comparison_experiment_failed: {e}", "success": False}

def _save_comparison_visualization(frame: np.ndarray,
                                normal_boxes: np.ndarray,
                                tile_boxes: np.ndarray,
                                output_path: str):
    """æ¯”è¼ƒå¯è¦–åŒ–ã®ä¿å­˜"""
    try:
        # 2ã¤ã®çµæœã‚’å·¦å³ã«ä¸¦ã¹ã¦è¡¨ç¤º
        height, width = frame.shape[:2]
        comparison_frame = np.zeros((height, width * 2, 3), dtype=np.uint8)

        # å·¦å´ï¼šé€šå¸¸æ¨è«–çµæœ
        left_frame = frame.copy()
        if len(normal_boxes) > 0:
            for box in normal_boxes:
                x1, y1, x2, y2 = map(int, box)
                cv2.rectangle(left_frame, (x1, y1), (x2, y2), (0, 255, 0), 2)

        comparison_frame[:, :width] = left_frame

        # å³å´ï¼šã‚¿ã‚¤ãƒ«æ¨è«–çµæœ
        right_frame = frame.copy()
        if len(tile_boxes) > 0:
            for box in tile_boxes:
                x1, y1, x2, y2 = map(int, box)
                cv2.rectangle(right_frame, (x1, y1), (x2, y2), (0, 0, 255), 2)

        comparison_frame[:, width:] = right_frame

        # ãƒ©ãƒ™ãƒ«è¿½åŠ 
        cv2.putText(comparison_frame, f"Normal ({len(normal_boxes)})",
                    (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)
        cv2.putText(comparison_frame, f"Tile ({len(tile_boxes)})",
                    (width + 10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)

        cv2.imwrite(output_path, comparison_frame)
    except Exception as e:
        logger.warning(f"æ¯”è¼ƒå¯è¦–åŒ–ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")

# ========== æ—¢å­˜ã®é–¢æ•°ç¾¤ï¼ˆã‚¨ãƒ©ãƒ¼ä¿®æ­£ç‰ˆï¼‰ ==========

def analyze_frames_with_tracking_memory_efficient(
    frame_dir: str,
    result_dir: str,
    model_path: str = "models/yolo11n-pose.pt",
    config: Optional[Dict[str, Any]] = None
) -> Dict[str, Any]:
    """
    ãƒ¡ãƒ¢ãƒªåŠ¹ç‡ã‚’è€ƒæ…®ã—ãŸãƒ•ãƒ¬ãƒ¼ãƒ è§£æï¼ˆæ—¢å­˜é–¢æ•°ãƒ»ã‚¨ãƒ©ãƒ¼ä¿®æ­£ç‰ˆï¼‰
    """

    # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®š
    if config is None:
        config = {
            "confidence_threshold": 0.3,
            "tracking_config": "bytetrack.yaml",
            "save_visualizations": True,
            "batch_size": 32,
            "max_memory_gb": 4.0,
            "streaming_output": True
        }

    os.makedirs(result_dir, exist_ok=True)

    # ãƒ¡ãƒ¢ãƒªåŠ¹ç‡ãƒ—ãƒ­ã‚»ãƒƒã‚µã‚’åˆæœŸåŒ–
    processor = MemoryEfficientProcessor(config)

    try:
        # ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–ï¼ˆã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°å¼·åŒ–ç‰ˆï¼‰
        model = safe_model_initialization(model_path, config)

        # ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ¤œè¨¼
        frame_validation = validate_frame_directory(frame_dir)
        if not frame_validation["valid"]:
            return {
                "error": "frame_validation_failed",
                "details": frame_validation["errors"],
                "suggestions": frame_validation.get("suggestions", []),
                "frame_dir": frame_dir,
                "success": False
            }

        frame_files = sorted([
            f for f in os.listdir(frame_dir)
            if f.lower().endswith(('.jpg', '.jpeg', '.png'))
        ])

        total_frames = len(frame_files)
        logger.info(f"å‡¦ç†å¯¾è±¡: {total_frames}ãƒ•ãƒ¬ãƒ¼ãƒ  ({frame_validation['total_size_mb']:.1f}MB)")

        # ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å‡ºåŠ›ç”¨ã®CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’é–‹ã
        csv_path = os.path.join(result_dir, "detections_streaming.csv")

        # å‡¦ç†çµ±è¨ˆ
        stats = {
            "total_frames": total_frames,
            "processed_frames": 0,
            "successful_frames": 0,
            "failed_frames": 0,
            "total_detections": 0,
            "unique_ids": set(),
            "memory_peaks": [],
            "batch_times": []
        }

        # ãƒãƒƒãƒå‡¦ç†ã§ãƒ¡ãƒ¢ãƒªåŠ¹ç‡åŒ–
        batch_size = config.get("batch_size", 32)

        with open(csv_path, 'w', newline='', encoding='utf-8') as csv_file:
            csv_writer = csv.writer(csv_file)
            csv_writer.writerow(["frame", "person_id", "x1", "y1", "x2", "y2", "conf", "class_name"])

            try:
                for batch_start in range(0, total_frames, batch_size):
                    batch_end = min(batch_start + batch_size, total_frames)
                    batch_files = frame_files[batch_start:batch_end]

                    batch_start_time = time.time()
                    batch_detections = []

                    logger.info(f"ãƒãƒƒãƒå‡¦ç† {batch_start//batch_size + 1}/{(total_frames-1)//batch_size + 1}: "
                            f"{len(batch_files)}ãƒ•ãƒ¬ãƒ¼ãƒ ")

                    # ãƒãƒƒãƒå†…ã®ãƒ•ãƒ¬ãƒ¼ãƒ å‡¦ç†
                    for frame_file in batch_files:
                        frame_path = os.path.join(frame_dir, frame_file)

                        try:
                            # ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ãƒã‚§ãƒƒã‚¯
                            if processor.check_memory_threshold():
                                logger.warning("ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ãŒé–¾å€¤ã‚’è¶…éã€‚ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã‚’å®Ÿè¡Œ...")
                                processor.force_memory_cleanup()

                            # æ¨è«–å®Ÿè¡Œ
                            results = model.track(
                                frame_path,
                                persist=True,
                                tracker=config.get("tracking_config", "bytetrack.yaml"),
                                conf=config.get("confidence_threshold", 0.3),
                                verbose=False
                            )

                            # çµæœå‡¦ç†
                            frame_detections = 0
                            for r in results:
                                if r.boxes is not None:
                                    boxes = r.boxes.xyxy.cpu().numpy()
                                    confidences = r.boxes.conf.cpu().numpy()

                                    # ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°IDã®å‡¦ç†
                                    if r.boxes.id is not None:
                                        track_ids = r.boxes.id.cpu().numpy().astype(int)
                                    else:
                                        track_ids = list(range(len(boxes)))

                                    for i, (box, conf) in enumerate(zip(boxes, confidences)):
                                        track_id = track_ids[i] if i < len(track_ids) else i
                                        x1, y1, x2, y2 = box
                                        detection_row = [frame_file, track_id, float(x1), float(y1), float(x2), float(y2), float(conf), "person"]
                                        batch_detections.append(detection_row)
                                        frame_detections += 1
                                        stats["unique_ids"].add(track_id)

                            stats["total_detections"] += frame_detections
                            stats["successful_frames"] += 1

                            # å¯è¦–åŒ–ï¼ˆãƒ¡ãƒ¢ãƒªåŠ¹ç‡è€ƒæ…®ï¼‰
                            if config.get("save_visualizations", False) and frame_detections > 0:
                                try:
                                    frame = cv2.imread(frame_path)
                                    if frame is not None:
                                        vis_frame = draw_detections_ultralytics(frame, results)
                                        # âœ… vis_ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹ã‚’è¿½åŠ 
                                        vis_filename = f"vis_{frame_file}"
                                        output_path = os.path.join(result_dir, vis_filename)
                                        cv2.imwrite(output_path, vis_frame)
                                        logger.debug(f"å¯è¦–åŒ–ä¿å­˜: {output_path}")
                                        del frame, vis_frame
                                except Exception as vis_error:
                                    logger.warning(f"å¯è¦–åŒ–ã‚¨ãƒ©ãƒ¼ {frame_file}: {vis_error}")

                            # çµæœã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’è§£æ”¾
                            del results

                        except Exception as frame_error:
                            logger.error(f"ãƒ•ãƒ¬ãƒ¼ãƒ å‡¦ç†ã‚¨ãƒ©ãƒ¼ {frame_file}: {frame_error}")
                            stats["failed_frames"] += 1
                            continue

                        stats["processed_frames"] += 1

                    # ãƒãƒƒãƒã®æ¤œå‡ºçµæœã‚’CSVã«æ›¸ãè¾¼ã¿ï¼ˆã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ï¼‰
                    if batch_detections:
                        csv_writer.writerows(batch_detections)
                        csv_file.flush()  # å³åº§ã«ãƒ‡ã‚£ã‚¹ã‚¯ã«æ›¸ãè¾¼ã¿

                    # ãƒãƒƒãƒå‡¦ç†å®Œäº†å¾Œã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
                    del batch_detections
                    processor.force_memory_cleanup()

                    # çµ±è¨ˆæ›´æ–°
                    batch_time = time.time() - batch_start_time
                    current_memory = processor.get_memory_usage()
                    stats["batch_times"].append(batch_time)
                    stats["memory_peaks"].append(current_memory)

                    # é€²æ—å ±å‘Š
                    progress = (batch_end / total_frames) * 100
                    logger.info(f"é€²æ—: {progress:.1f}% (ãƒ¡ãƒ¢ãƒª: {current_memory:.2f}GB, "
                            f"ãƒãƒƒãƒæ™‚é–“: {batch_time:.1f}s)")

            except Exception as e:
                logger.error(f"ãƒãƒƒãƒå‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
                return {"error": f"batch_processing_failed: {e}", "success": False}

        # æœ€çµ‚çµ±è¨ˆã®è¨ˆç®—
        stats["unique_ids"] = len(stats["unique_ids"])
        stats["success_rate"] = stats["successful_frames"] / total_frames if total_frames > 0 else 0
        stats["avg_batch_time"] = np.mean(stats["batch_times"]) if stats["batch_times"] else 0
        stats["peak_memory_gb"] = max(stats["memory_peaks"]) if stats["memory_peaks"] else 0

        logger.info(f"âœ… å‡¦ç†å®Œäº†çµ±è¨ˆ:")
        logger.info(f"  æˆåŠŸç‡: {stats['success_rate']:.1%}")
        logger.info(f"  ç·æ¤œå‡ºæ•°: {stats['total_detections']}")
        logger.info(f"  ãƒ¦ãƒ‹ãƒ¼ã‚¯ID: {stats['unique_ids']}")
        logger.info(f"  ãƒ”ãƒ¼ã‚¯ãƒ¡ãƒ¢ãƒª: {stats['peak_memory_gb']:.2f}GB")
        logger.info(f"  å¹³å‡ãƒãƒƒãƒæ™‚é–“: {stats['avg_batch_time']:.1f}s")

        return {
            "csv_path": csv_path,
            "processing_stats": stats,
            "config_used": config,
            "model_path": model_path,
            "result_dir": result_dir,
            "memory_efficient": True,
            "success": True
        }

    except ModelInitializationError as e:
        logger.error(f"ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–å¤±æ•—: {e}")
        return {"error": "model_initialization_failed", "details": str(e), "success": False}

    except ResourceExhaustionError as e:
        logger.error(f"ãƒªã‚½ãƒ¼ã‚¹ä¸è¶³: {e}")
        return {"error": "resource_exhaustion", "details": str(e), "success": False}

    except Exception as e:
        logger.error(f"äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼: {e}")
        logger.error(f"è©³ç´°: {traceback.format_exc()}")
        return {"error": "unexpected_error", "details": str(e), "success": False}

# ========== æ—¢å­˜ã®utilsé–¢æ•°ç¾¤ï¼ˆä¿®æ­£ç‰ˆï¼‰ ==========

def draw_detections(frame, results, online_targets=None):
    """æ—¢å­˜ã®æç”»é–¢æ•°ï¼ˆäº’æ›æ€§ç¶­æŒï¼‰"""
    try:
        # ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹æç”»
        for r in results:
            if r.boxes is not None:
                boxes = r.boxes.xyxy.cpu().numpy()
                confidences = r.boxes.conf.cpu().numpy()

                for box, conf in zip(boxes, confidences):
                    x1, y1, x2, y2 = map(int, box)
                    cv2.rectangle(frame, (x1, y1), (x2, y2), (0,255,0), 2)
                    cv2.putText(frame, f"{conf:.2f}", (x1, y1-5),
                                cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,255,0), 1)

        # IDè¡¨ç¤º
        if online_targets:
            for t in online_targets:
                x1, y1, x2, y2 = map(int, t.tlbr)
                track_id = t.track_id
                cv2.putText(frame, f"ID:{track_id}", (x1, y1-20),
                            cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0,0,255), 2)
    except Exception as e:
        logger.warning(f"æç”»ã‚¨ãƒ©ãƒ¼: {e}")

    return frame

def draw_detections_ultralytics(frame, results):
    """Ultralyticsçµ„ã¿è¾¼ã¿ãƒˆãƒ©ãƒƒã‚«ãƒ¼ç”¨ã®æç”»é–¢æ•°"""
    try:
        for r in results:
            if r.boxes is not None:
                boxes = r.boxes.xyxy.cpu().numpy()
                confidences = r.boxes.conf.cpu().numpy()

                # ãƒˆãƒ©ãƒƒã‚¯IDãŒã‚ã‚‹å ´åˆ
                if r.boxes.id is not None:
                    track_ids = r.boxes.id.cpu().numpy().astype(int)

                    for box, conf, track_id in zip(boxes, confidences, track_ids):
                        x1, y1, x2, y2 = map(int, box)

                        # ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹æç”»
                        cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)

                        # ä¿¡é ¼åº¦è¡¨ç¤º
                        cv2.putText(frame, f"{conf:.2f}", (x1, y1-5),
                                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)

                        # ãƒˆãƒ©ãƒƒã‚¯IDè¡¨ç¤º
                        cv2.putText(frame, f"ID:{track_id}", (x1, y1-25),
                                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)
                else:
                    # ãƒˆãƒ©ãƒƒã‚¯IDãŒãªã„å ´åˆï¼ˆé€šå¸¸ã®æ¤œå‡ºçµæœï¼‰
                    for box, conf in zip(boxes, confidences):
                        x1, y1, x2, y2 = map(int, box)
                        cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)
                        cv2.putText(frame, f"{conf:.2f}", (x1, y1-5),
                                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)

            # ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆãŒã‚ã‚‹å ´åˆã®æç”»
            if hasattr(r, 'keypoints') and r.keypoints is not None:
                keypoints = r.keypoints.xy.cpu().numpy()
                for kpts in keypoints:
                    for x, y in kpts:
                        if x > 0 and y > 0:  # æœ‰åŠ¹ãªã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆã®ã¿
                            cv2.circle(frame, (int(x), int(y)), 3, (255, 0, 0), -1)
    except Exception as e:
        logger.warning(f"Ultralyticsæç”»ã‚¨ãƒ©ãƒ¼: {e}")

    return frame

# ========== ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œéƒ¨ï¼ˆãƒ†ã‚¹ãƒˆç”¨ï¼‰ ==========

if __name__ == "__main__":
    # ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°è§£æ
    import argparse

    parser = argparse.ArgumentParser(description='YOLO11 ãƒ•ãƒ¬ãƒ¼ãƒ è§£æï¼ˆã‚¿ã‚¤ãƒ«æ¨è«–å¯¾å¿œï¼‰')
    parser.add_argument('--frame-dir', required=True, help='ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª')
    parser.add_argument('--output-dir', required=True, help='å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª')
    parser.add_argument('--model', default='models/yolo11n-pose.pt', help='ãƒ¢ãƒ‡ãƒ«ãƒ‘ã‚¹')
    parser.add_argument('--tile', action='store_true', help='ã‚¿ã‚¤ãƒ«æ¨è«–ã‚’æœ‰åŠ¹åŒ–')
    parser.add_argument('--adaptive', action='store_true', help='é©å¿œçš„ã‚¿ã‚¤ãƒ«æ¨è«–ã‚’ä½¿ç”¨')
    parser.add_argument('--compare', action='store_true', help='æ¯”è¼ƒå®Ÿé¨“å®Ÿè¡Œ')
    parser.add_argument('--tile-size', type=int, nargs=2, default=[640, 640], 
                    help='ã‚¿ã‚¤ãƒ«ã‚µã‚¤ã‚º [width height]')
    parser.add_argument('--overlap', type=float, default=0.2, help='é‡è¤‡ç‡')
    parser.add_argument('--confidence', type=float, default=0.3, help='ä¿¡é ¼åº¦é–¾å€¤')

    args = parser.parse_args()

    # çµæœãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
    os.makedirs(args.output_dir, exist_ok=True)

    try:
        if args.compare:
            # æ¯”è¼ƒå®Ÿé¨“
            print("ğŸ”¬ ã‚¿ã‚¤ãƒ«æ¨è«– vs é€šå¸¸æ¨è«– æ¯”è¼ƒå®Ÿé¨“")
            results = compare_tile_vs_normal_inference(
                args.frame_dir,
                args.output_dir,
                args.model,
                sample_frames=20
            )

            if results.get("success", False):
                print("âœ… æ¯”è¼ƒå®Ÿé¨“å®Œäº†")
                summary = results.get("summary", {})
                if "error" not in summary:
                    print(f"ğŸ“Š æ¤œå‡ºæ•°æ”¹å–„ç‡: {summary.get('overall_improvement_rate', 0):.1%}")
                    print(f"â±ï¸ å‡¦ç†æ™‚é–“ã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰: {summary.get('avg_tile_time', 0) - summary.get('avg_normal_time', 0):.2f}ç§’")
                else:
                    print(f"âš ï¸ æ¯”è¼ƒå®Ÿé¨“ã§å•é¡Œç™ºç”Ÿ: {summary['error']}")
            else:
                print(f"âŒ æ¯”è¼ƒå®Ÿé¨“ã‚¨ãƒ©ãƒ¼: {results.get('error', 'unknown_error')}")

        elif args.tile:
            # ã‚¿ã‚¤ãƒ«æ¨è«–å®Ÿè¡Œ
            print("ğŸ”² ã‚¿ã‚¤ãƒ«æ¨è«–å®Ÿè¡Œ")

            config = {
                "tile_inference": {
                    "enabled": True,
                    "tile_size": tuple(args.tile_size),
                    "overlap_ratio": args.overlap,
                    "use_adaptive": args.adaptive
                },
                "save_visualizations": True,
                "confidence_threshold": args.confidence
            }

            results = analyze_frames_with_tile_inference(
                args.frame_dir,
                args.output_dir,
                args.model,
                config
            )

            if results.get("success", False):
                print("âœ… ã‚¿ã‚¤ãƒ«æ¨è«–å®Œäº†")
                stats = results.get("processing_stats", {})
                print(f"ğŸ“Š ç·æ¤œå‡ºæ•°: {stats.get('total_detections', 0)}")
                print(f"ğŸ‘¥ ãƒ¦ãƒ‹ãƒ¼ã‚¯ID: {stats.get('unique_ids', 0)}")
                tile_stats = stats.get("tile_stats")
                if tile_stats:
                    print(f"ğŸ”² å¹³å‡ã‚¿ã‚¤ãƒ«æ•°/ãƒ•ãƒ¬ãƒ¼ãƒ : {tile_stats.get('avg_tiles_per_frame', 0):.1f}")
            else:
                print(f"âŒ ã‚¿ã‚¤ãƒ«æ¨è«–ã‚¨ãƒ©ãƒ¼: {results.get('error', 'unknown_error')}")

        else:
            # é€šå¸¸æ¨è«–å®Ÿè¡Œ
            print("ğŸ“‹ é€šå¸¸æ¨è«–å®Ÿè¡Œ")

            config = {
                "save_visualizations": True,
                "confidence_threshold": args.confidence
            }

            results = analyze_frames_with_tracking_memory_efficient(
                args.frame_dir,
                args.output_dir,
                args.model,
                config
            )

            if results.get("success", False):
                print("âœ… é€šå¸¸æ¨è«–å®Œäº†")
                stats = results.get("processing_stats", {})
                print(f"ğŸ“Š ç·æ¤œå‡ºæ•°: {stats.get('total_detections', 0)}")
                print(f"ğŸ‘¥ ãƒ¦ãƒ‹ãƒ¼ã‚¯ID: {stats.get('unique_ids', 0)}")
                print(f"ğŸ“ˆ æˆåŠŸç‡: {stats.get('success_rate', 0):.1%}")
            else:
                print(f"âŒ é€šå¸¸æ¨è«–ã‚¨ãƒ©ãƒ¼: {results.get('error', 'unknown_error')}")

    except Exception as e:
        print(f"âŒ å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
        logger.error(f"ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {traceback.format_exc()}")
