#!/usr/bin/env python3
"""
ğŸ”§ è·é›¢æ­£è¦åŒ–é–¢æ•°åˆ†æ å®Ÿè¡Œã‚¹ã‚¯ãƒªãƒ—ãƒˆ

ã‚«ãƒ¡ãƒ©è·é›¢ã«ã‚ˆã‚‹è‚©å¹…å¤‰åŒ–ã‚’åˆ†æã—ã€æ­£è¦åŒ–é–¢æ•°ã‚’ç”Ÿæˆã™ã‚‹ãƒ„ãƒ¼ãƒ«

ä½¿ç”¨ä¾‹:
    # ãƒ‡ãƒ¼ã‚¿ç¢ºèª
    python run_normalization_analysis.py check "outputs/baseline/11æœˆ12æ—¥ 1/4point_metrics.csv"
    
    # 1ãƒ•ãƒ¬ãƒ¼ãƒ åˆ†æ
    python run_normalization_analysis.py analyze_one "outputs/baseline/11æœˆ12æ—¥ 1/4point_metrics.csv" "11æœˆ12æ—¥ 1.mp4_frame0.jpg"
    
    # å…¨ãƒ•ãƒ¬ãƒ¼ãƒ åˆ†æ
    python run_normalization_analysis.py analyze_all "outputs/baseline/11æœˆ12æ—¥ 1/4point_metrics.csv"
    
    # ã‚µãƒ³ãƒ—ãƒ«åˆ†æ
    python run_normalization_analysis.py
"""

import sys
import argparse
from pathlib import Path
from typing import Dict, List, Optional
import traceback
import os
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
from datetime import datetime
from scipy.optimize import curve_fit
import json

# --- æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆè¨­å®šï¼ˆMacç”¨ï¼‰ ---
plt.rcParams['font.family'] = 'AppleGothic'
# Windowsã®å ´åˆã¯ 'MS Gothic' ã‚„ 'Meiryo' ãªã©ã«å¤‰æ›´ã—ã¦ãã ã•ã„

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
sys.path.append(str(Path(__file__).parent.parent))

try:
    from normalization_analysis.distance_normalization import DistanceNormalizationAnalyzer, check_available_data
except ImportError as e:
    print(f"âŒ ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
    print("ğŸ“ ç¾åœ¨ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ç¢ºèªã—ã¦ãã ã•ã„")
    sys.exit(1)

def print_header():
    """ğŸ¨ ãƒ˜ãƒƒãƒ€ãƒ¼è¡¨ç¤º"""
    print("ğŸ”§" + "=" * 60 + "ğŸ”§")
    print("ğŸ“Š      è·é›¢æ­£è¦åŒ–é–¢æ•°åˆ†æãƒ„ãƒ¼ãƒ« v1.0")
    print("ğŸ¯      ã‚«ãƒ¡ãƒ©è·é›¢ã«ã‚ˆã‚‹è‚©å¹…å¤‰åŒ–ã®å®šé‡åŒ–")
    print("ğŸ”§" + "=" * 60 + "ğŸ”§")

def get_file_emoji(file_type: str) -> str:
    """ğŸ“ ãƒ•ã‚¡ã‚¤ãƒ«ã‚¿ã‚¤ãƒ—åˆ¥çµµæ–‡å­—"""
    emoji_map = {
        'visualization': 'ğŸ“Š',
        'report': 'ğŸ“', 
        'function_data': 'ğŸ“‹',
        'normalization_code': 'ğŸ”§'
    }
    return emoji_map.get(file_type, 'ğŸ“„')

def extract_column_assignments_from_csv(csv_path):
    """
    CSVã®column_positionåˆ—ã‹ã‚‰è‡ªå‹•ã§ {åˆ—ç•ªå·: [person_id, ...]} ã‚’æŠ½å‡º
    -1ã‚„Noneã¯é™¤å¤–
    """
    df = pd.read_csv(csv_path, encoding='utf-8-sig')
    col_dict = {}
    for _, row in df.iterrows():
        try:
            col = int(float(row['column_position']))
            pid = int(row['person_id'])
            if col > 0:
                col_dict.setdefault(col, []).append(pid)
        except Exception:
            continue
    # é‡è¤‡é™¤å»
    for k in col_dict:
        col_dict[k] = sorted(list(set(col_dict[k])))
    return col_dict

def create_analysis_output_dir(base_dir):
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    output_dir = os.path.join(base_dir, f"analysis_{timestamp}")
    os.makedirs(output_dir, exist_ok=True)
    return output_dir

from datetime import datetime
import os
import json
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from scipy.optimize import curve_fit

def plot_shoulder_width_vs_column_with_fit(csv_path, output_dir):
    """
    è·é›¢-è‚©å¹…é–¢ä¿‚ã‚°ãƒ©ãƒ•ã‚’ç”Ÿæˆ
    - æ¨ªè»¸: åˆ—ä½ç½® (column_position)
    - ç¸¦è»¸: è‚©å¹… (shoulder_width)
    - å€‹äººãƒ‡ãƒ¼ã‚¿: ç‚¹
    - åˆ—å¹³å‡: èµ¤ã„è±å½¢
    - æœ€é©æŒ‡æ•°æ¸›è¡°é–¢æ•°: æ›²ç·šï¼ˆé’ï¼‰
    - æœ€é©ç›´ç·šè¿‘ä¼¼: ç›´ç·šï¼ˆç·‘ç‚¹ç·šï¼‰
    - ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¯åˆ¥ã€…ã®jsonã«ä¿å­˜
    - æ­£è¦åŒ–é–¢æ•°ã‚³ãƒ¼ãƒ‰ã‚‚åˆ¥ã€…ã®pythonãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
    """
    group_size = 1200
    interval = 40

    df = pd.read_csv(csv_path, encoding='utf-8-sig')
    df = df[df['column_position'].apply(lambda x: pd.notnull(x) and float(x) > 0)]
    if 'column_position' not in df.columns or 'shoulder_width' not in df.columns or 'frame' not in df.columns:
        print("âŒ å¿…è¦ãªã‚«ãƒ©ãƒ ãŒã‚ã‚Šã¾ã›ã‚“")
        return

    df['frame_num'] = df['frame'].apply(lambda x: int(''.join(filter(str.isdigit, str(x))))
                                        if isinstance(x, str) else int(x))
    df = df.sort_values('frame_num')
    max_frame = df['frame_num'].max()
    group_starts = list(range(0, max_frame + 1, group_size))
    columns = sorted(df['column_position'].unique())

    # å„åˆ—ã”ã¨ã«ã‚°ãƒ«ãƒ¼ãƒ—ä¸­å¤®å€¤ãƒªã‚¹ãƒˆ
    col_group_medians = {col: [] for col in columns}

    # ã‚°ãƒ«ãƒ¼ãƒ—ã”ã¨ã®ä¸­å¤®å€¤ï¼ˆç°è‰²ç‚¹ï¼‰ã‚’é›†è¨ˆ
    for start in group_starts:
        end = start + group_size - 1
        group_df = df[(df['frame_num'] >= start) & (df['frame_num'] <= end)]
        required_count = group_size // interval
        if len(group_df) < required_count:
            continue
        for col in columns:
            col_df = group_df[group_df['column_position'] == col]
            if len(col_df) < required_count // len(columns):
                continue
            q1 = col_df['shoulder_width'].quantile(0.25)
            q3 = col_df['shoulder_width'].quantile(0.75)
            iqr_df = col_df[(col_df['shoulder_width'] >= q1) & (col_df['shoulder_width'] <= q3)]
            if iqr_df.empty:
                continue
            median = iqr_df['shoulder_width'].median()
            col_group_medians[col].append(median)

    # ã‚°ãƒ©ãƒ•æç”»
    plt.figure(figsize=(10, 7))
    # ã‚°ãƒ«ãƒ¼ãƒ—ã”ã¨ã®ä¸­å¤®å€¤ï¼ˆç°è‰²ç‚¹ï¼‰
    for col in columns:
        for median in col_group_medians[col]:
            plt.scatter(col, median, color='gray', alpha=0.7, label='ã‚°ãƒ«ãƒ¼ãƒ—ä¸­å¤®å€¤' if col == columns[0] and median == col_group_medians[columns[0]][0] else None)

    # å„åˆ—ã”ã¨ã®ã‚°ãƒ«ãƒ¼ãƒ—ä¸­å¤®å€¤å¹³å‡ï¼ˆèµ¤è±ãƒ»å°ã•ã‚ï¼‰
    xdata = []
    ydata = []
    for col in columns:
        medians = col_group_medians[col]
        if len(medians) > 0:
            xdata.append(col)
            ydata.append(np.mean(medians))
            plt.scatter(col, np.mean(medians), color='red', marker='D', s=40, label='åˆ—ã”ã¨ä¸­å¤®å€¤å¹³å‡' if col == columns[0] else None)

    xdata = np.array(xdata)
    ydata = np.array(ydata)

    # --- è¿‘ä¼¼ ---
    # æŒ‡æ•°æ¸›è¡°é–¢æ•°
    def exp_decay(x, a, b, c):
        return a * np.exp(-b * x) + c

    fit_params_exp = None
    fit_params_lin = None
    try:
        popt_exp, pcov_exp = curve_fit(exp_decay, xdata, ydata, p0=(ydata.max(), 0.1, ydata.min()))
        fit_params_exp = popt_exp
        x_fit = np.linspace(xdata.min(), xdata.max(), 100)
        y_fit_exp = exp_decay(x_fit, *popt_exp)
        plt.plot(x_fit, y_fit_exp, color='blue', linewidth=2, label='æŒ‡æ•°æ¸›è¡°ãƒ•ã‚£ãƒƒãƒˆï¼ˆé’ï¼‰')
    except Exception as e:
        print(f"æŒ‡æ•°æ¸›è¡°ãƒ•ã‚£ãƒƒãƒˆå¤±æ•—: {e}")

    try:
        popt_lin = np.polyfit(xdata, ydata, 1)
        a_lin, b_lin = popt_lin
        fit_params_lin = (a_lin, b_lin, 0)
        y_fit_lin = a_lin * x_fit + b_lin
        plt.plot(x_fit, y_fit_lin, color='green', linestyle='dashed', linewidth=2, label='ç›´ç·šãƒ•ã‚£ãƒƒãƒˆï¼ˆç·‘ç‚¹ç·šï¼‰')
    except Exception as e:
        print(f"ç›´ç·šãƒ•ã‚£ãƒƒãƒˆå¤±æ•—: {e}")

    plt.xlabel('åˆ—ä½ç½® (column_position)', fontsize=13)
    plt.ylabel('è‚©å¹… (px)', fontsize=13)
    plt.title('è·é›¢-è‚©å¹…é–¢ä¿‚ï¼ˆæŒ‡æ•°ãƒ»ç›´ç·šãƒ•ã‚£ãƒƒãƒˆï¼‰', fontsize=15)
    plt.legend()
    plt.grid(True, alpha=0.3)

    ymin = min([min(medians) for medians in col_group_medians.values() if medians]) if col_group_medians else 0
    ymax = max([max(medians) for medians in col_group_medians.values() if medians]) if col_group_medians else 100
    plt.ylim(ymin - 20, ymax + 40)
    plt.xticks([int(c) for c in columns])

    output_path = os.path.join(output_dir, "shoulder_width_vs_column_fit.png")
    plt.tight_layout()
    plt.savefig(output_path, dpi=300)
    plt.close()
    print(f"âœ… è·é›¢-è‚©å¹…é–¢ä¿‚ã‚°ãƒ©ãƒ•ã‚’ {output_path} ã«ä¿å­˜ã—ã¾ã—ãŸ")

    info_path = os.path.join(output_dir, "analysis_info.txt")
    with open(info_path, "w", encoding="utf-8-sig") as f:
        f.write(f"åˆ†ææ—¥æ™‚: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
        f.write(f"ä½¿ç”¨CSV: {os.path.abspath(csv_path)}\n")
        f.write(f"åˆ—ç•ªå·: {', '.join([str(c) for c in columns])}\n")
        f.write(f"ã‚°ãƒ«ãƒ¼ãƒ—åˆ†å‰²ãƒ•ãƒ¬ãƒ¼ãƒ æ•°: {group_size}\n")
        f.write(f"æŠ½å‡ºé–“éš”ãƒ•ãƒ¬ãƒ¼ãƒ æ•°: {interval}\n")
    print(f"âœ… åˆ†ææƒ…å ±ã‚’ {info_path} ã«ä¿å­˜ã—ã¾ã—ãŸ")

    # --- ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ä¿å­˜ï¼ˆjsonã‚’åˆ†ã‘ã‚‹ï¼‰ ---
    if fit_params_exp is not None:
        params_exp = {
            "a": fit_params_exp[0],
            "b": fit_params_exp[1],
            "c": fit_params_exp[2],
            "formula": "f(x) = a * exp(-b * x) + c"
        }
        with open(os.path.join(output_dir, "function_parameters_exp.json"), "w", encoding="utf-8-sig") as f:
            json.dump(params_exp, f, ensure_ascii=False, indent=2)
        print(f"âœ… æŒ‡æ•°æ¸›è¡°ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ function_parameters_exp.json ã«ä¿å­˜ã—ã¾ã—ãŸ")

    if fit_params_lin is not None:
        params_lin = {
            "a": fit_params_lin[0],
            "b": fit_params_lin[1],
            "c": fit_params_lin[2],
            "formula": "f(x) = a * x + b + c"
        }
        with open(os.path.join(output_dir, "function_parameters_linear.json"), "w", encoding="utf-8-sig") as f:
            json.dump(params_lin, f, ensure_ascii=False, indent=2)
        print(f"âœ… ç›´ç·šãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ function_parameters_linear.json ã«ä¿å­˜ã—ã¾ã—ãŸ")

    # --- æ­£è¦åŒ–é–¢æ•°ã‚³ãƒ¼ãƒ‰ã‚‚åˆ†ã‘ã¦ä¿å­˜ ---
    if fit_params_exp is not None:
        normalization_code_exp = f"""# è·é›¢æ­£è¦åŒ–é–¢æ•°ï¼ˆæŒ‡æ•°æ¸›è¡°ï¼‰
import numpy as np

def distance_normalization_function_exp(column_position):
    \"\"\"
    æŒ‡æ•°æ¸›è¡°é–¢æ•°ã«ã‚ˆã‚‹è‚©å¹…äºˆæ¸¬
    f(x) = {fit_params_exp[0]:.6f} * exp(-{fit_params_exp[1]:.6f} * x) + {fit_params_exp[2]:.6f}
    \"\"\"
    return {fit_params_exp[0]:.6f} * np.exp(-{fit_params_exp[1]:.6f} * column_position) + {fit_params_exp[2]:.6f}

def normalize_shoulder_width_exp(measured_width, column_position, reference_column=1):
    \"\"\"
    å®Ÿæ¸¬è‚©å¹…ã‚’åŸºæº–åˆ—ã§æ­£è¦åŒ–ï¼ˆæŒ‡æ•°æ¸›è¡°ï¼‰
    \"\"\"
    predicted_width = distance_normalization_function_exp(column_position)
    reference_width = distance_normalization_function_exp(reference_column)
    normalization_factor = reference_width / predicted_width
    return measured_width * normalization_factor
"""
        with open(os.path.join(output_dir, "normalization_function_exp.py"), "w", encoding="utf-8-sig") as f:
            f.write(normalization_code_exp)
        print(f"âœ… æ­£è¦åŒ–é–¢æ•°ã‚³ãƒ¼ãƒ‰ï¼ˆæŒ‡æ•°ï¼‰ã‚’ normalization_function_exp.py ã«ä¿å­˜ã—ã¾ã—ãŸ")

    if fit_params_lin is not None:
        normalization_code_lin = f"""# è·é›¢æ­£è¦åŒ–é–¢æ•°ï¼ˆç›´ç·šè¿‘ä¼¼ï¼‰
def distance_normalization_function_linear(column_position):
    \"\"\"
    ç›´ç·šè¿‘ä¼¼ã«ã‚ˆã‚‹è‚©å¹…äºˆæ¸¬
    f(x) = {fit_params_lin[0]:.6f} * x + {fit_params_lin[1]:.6f} + {fit_params_lin[2]:.6f}
    \"\"\"
    return {fit_params_lin[0]:.6f} * column_position + {fit_params_lin[1]:.6f} + {fit_params_lin[2]:.6f}

def normalize_shoulder_width_linear(measured_width, column_position, reference_column=1):
    \"\"\"
    å®Ÿæ¸¬è‚©å¹…ã‚’åŸºæº–åˆ—ã§æ­£è¦åŒ–ï¼ˆç›´ç·šè¿‘ä¼¼ï¼‰
    \"\"\"
    predicted_width = distance_normalization_function_linear(column_position)
    reference_width = distance_normalization_function_linear(reference_column)
    normalization_factor = reference_width / predicted_width
    return measured_width * normalization_factor
"""
        with open(os.path.join(output_dir, "normalization_function_linear.py"), "w", encoding="utf-8-sig") as f:
            f.write(normalization_code_lin)
        print(f"âœ… æ­£è¦åŒ–é–¢æ•°ã‚³ãƒ¼ãƒ‰ï¼ˆç›´ç·šï¼‰ã‚’ normalization_function_linear.py ã«ä¿å­˜ã—ã¾ã—ãŸ")

# ...existing code...

def plot_shoulder_width_vs_column_with_fit_iqr(csv_path, output_dir):
    """
    è·é›¢-è‚©å¹…é–¢ä¿‚ã‚°ãƒ©ãƒ•ï¼ˆIQRå¤–ã‚Œå€¤é™¤å»ç‰ˆï¼‰ã‚’ç”Ÿæˆ
    - æ¨ªè»¸: åˆ—ä½ç½® (column_position)
    - ç¸¦è»¸: è‚©å¹… (shoulder_width)
    - å€‹äººãƒ‡ãƒ¼ã‚¿: å››åˆ†ä½ç¯„å›²å†…ã®ã¿ç‚¹è¡¨ç¤º
    - åˆ—å¹³å‡: èµ¤ã„è±å½¢
    - æœ€é©æŒ‡æ•°æ¸›è¡°é–¢æ•°: æ›²ç·š
    - é–¢æ•°ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿jsonä¿å­˜
    - æ­£è¦åŒ–é–¢æ•°ã‚³ãƒ¼ãƒ‰ã‚‚è‡ªå‹•ç”Ÿæˆ
    """
    df = pd.read_csv(csv_path, encoding='utf-8-sig')
    df = df[df['column_position'].apply(lambda x: pd.notnull(x) and float(x) > 0)]
    if 'column_position' not in df.columns or 'shoulder_width' not in df.columns:
        print("âŒ å¿…è¦ãªã‚«ãƒ©ãƒ ãŒã‚ã‚Šã¾ã›ã‚“")
        return

    # IQRå¤–ã‚Œå€¤é™¤å»
    iqr_mask = np.zeros(len(df), dtype=bool)
    for col in df['column_position'].unique():
        col_df = df[df['column_position'] == col]
        q1 = col_df['shoulder_width'].quantile(0.25)
        q3 = col_df['shoulder_width'].quantile(0.75)
        mask = (df['column_position'] == col) & (df['shoulder_width'] >= q1) & (df['shoulder_width'] <= q3)
        iqr_mask |= mask
    df_iqr = df[iqr_mask]

    plt.figure(figsize=(10, 7))
    plt.scatter(df_iqr['column_position'], df_iqr['shoulder_width'], alpha=0.5, label='IQRå†…å€‹äººãƒ‡ãƒ¼ã‚¿')

    mean_df = df_iqr.groupby('column_position')['shoulder_width'].mean().reset_index()
    plt.scatter(mean_df['column_position'], mean_df['shoulder_width'], 
                color='red', marker='D', s=80, label='IQRå†…åˆ—å¹³å‡')

    def exp_decay(x, a, b, c):
        return a * np.exp(-b * x) + c

    xdata = mean_df['column_position']
    ydata = mean_df['shoulder_width']
    fit_params = None
    try:
        popt, pcov = curve_fit(exp_decay, xdata, ydata, p0=(ydata.max(), 0.1, ydata.min()))
        fit_params = popt
        x_fit = np.linspace(df['column_position'].min(), df['column_position'].max(), 100)
        y_fit = exp_decay(x_fit, *popt)
        plt.plot(x_fit, y_fit, color='blue', linewidth=2, label='æŒ‡æ•°æ¸›è¡°ãƒ•ã‚£ãƒƒãƒˆ')
    except Exception as e:
        print(f"æŒ‡æ•°æ¸›è¡°ãƒ•ã‚£ãƒƒãƒˆå¤±æ•—: {e}")

    plt.xlabel('åˆ—ä½ç½® (column_position)', fontsize=13)
    plt.ylabel('è‚©å¹… (px)', fontsize=13)
    plt.title('è·é›¢-è‚©å¹…é–¢ä¿‚ï¼ˆIQRå¤–ã‚Œå€¤é™¤å»ï¼‰ã¨æ­£è¦åŒ–é–¢æ•°', fontsize=15)
    plt.legend()
    plt.grid(True, alpha=0.3)

    output_path = os.path.join(output_dir, "shoulder_width_vs_column_fit_iqr.png")
    plt.tight_layout()
    plt.savefig(output_path, dpi=300)
    plt.close()
    print(f"âœ… è·é›¢-è‚©å¹…é–¢ä¿‚ã‚°ãƒ©ãƒ•ï¼ˆIQRå¤–ã‚Œå€¤é™¤å»ï¼‰ã‚’ {output_path} ã«ä¿å­˜ã—ã¾ã—ãŸ")

def plot_angle_boxplot_by_column(csv_path, output_dir):
    """
    åˆ—ä½ç½®ã”ã¨ã®ãªã™è§’åˆ†å¸ƒï¼ˆç®±ã²ã’å›³ï¼‰ã‚’å‡ºåŠ›
    è‚©å¹…ã¯å€‹äººã”ã¨ã«å›ºå®šã—ã€ä¸¡è‚©ã®ä¸­ç‚¹â†’ä¸¡è€³ã®ä¸­ç‚¹ãƒ™ã‚¯ãƒˆãƒ«ã¨è‚©ãƒ™ã‚¯ãƒˆãƒ«ã®ãªã™è§’ã‚’è¨ˆç®—
    """
    df = pd.read_csv(csv_path, encoding='utf-8-sig')
    # -1ã‚„Noneã¯é™¤å¤–ï¼ˆfloatå‹ã«ã‚‚å¯¾å¿œï¼‰
    df = df[df['column_position'].apply(lambda x: pd.notnull(x) and float(x) > 0)]
    required_cols = [
        'column_position', 'person_id', 'shoulder_width',
        'left_shoulder_x', 'left_shoulder_y', 'right_shoulder_x', 'right_shoulder_y',
        'left_ear_x', 'left_ear_y', 'right_ear_x', 'right_ear_y'
    ]
    if not all(col in df.columns for col in required_cols):
        print("âŒ å¿…è¦ãªã‚«ãƒ©ãƒ ãŒã‚ã‚Šã¾ã›ã‚“")
        return

    # è‚©å¹…ã‚’å€‹äººã”ã¨ã«å›ºå®š
    shoulder_width_dict = df.groupby('person_id')['shoulder_width'].mean().to_dict()

    def calc_angle_by_fixed_shoulder(row):
        pid = row['person_id']
        shoulder_width = shoulder_width_dict.get(pid, np.nan)
        lx, ly = row['left_shoulder_x'], row['left_shoulder_y']
        rx, ry = row['right_shoulder_x'], row['right_shoulder_y']
        center_x = (lx + rx) / 2
        center_y = (ly + ry) / 2
        shoulder_mid = np.array([center_x, center_y])
        shoulder_vec = np.array([shoulder_width, 0])  # æ°´å¹³æ–¹å‘ã«è‚©å¹…åˆ†

        le_x, le_y = row['left_ear_x'], row['left_ear_y']
        re_x, re_y = row['right_ear_x'], row['right_ear_y']
        ear_mid = np.array([(le_x + re_x) / 2, (le_y + re_y) / 2])
        mid_vec = ear_mid - shoulder_mid

        dot = np.dot(shoulder_vec, mid_vec)
        norm_shoulder = np.linalg.norm(shoulder_vec)
        norm_mid = np.linalg.norm(mid_vec)
        if norm_shoulder == 0 or norm_mid == 0:
            return np.nan
        cos_theta = dot / (norm_shoulder * norm_mid)
        cos_theta = np.clip(cos_theta, -1, 1)
        return np.degrees(np.arccos(cos_theta))

    df['shoulder_head_angle_fixed'] = df.apply(calc_angle_by_fixed_shoulder, axis=1)

    grouped = df.groupby('column_position')['shoulder_head_angle_fixed']
    data = []
    labels = []
    for col, group in grouped:
        values = group.dropna().values
        if len(values) > 0:
            data.append(values)
            labels.append(str(col))

    if len(data) == 0:
        print("âš ï¸ ç®±ã²ã’å›³ã‚’æç”»ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
        return

    plt.figure(figsize=(10, 6))
    plt.boxplot(data, labels=labels, patch_artist=True,
                boxprops=dict(facecolor='skyblue', color='navy'),
                medianprops=dict(color='red'))
    plt.title('åˆ—ä½ç½®ã”ã¨ã®ãªã™è§’åˆ†å¸ƒï¼ˆè‚©å¹…å›ºå®šãƒ»åº§æ¨™ãƒ™ãƒ¼ã‚¹ãƒ»ç®±ã²ã’å›³ï¼‰', fontsize=15)
    plt.xlabel('åˆ—ä½ç½® (column_position)', fontsize=13)
    plt.ylabel('ãªã™è§’ (åº¦)', fontsize=13)
    plt.grid(True, alpha=0.3)

    output_path = os.path.join(output_dir, "angle_boxplot_by_column_fixed_vector.png")
    plt.tight_layout()
    plt.savefig(output_path, dpi=300)
    plt.close()
    print(f"âœ… åˆ—ä½ç½®ã”ã¨ã®ãªã™è§’ç®±ã²ã’å›³ï¼ˆè‚©å¹…å›ºå®šãƒ»åº§æ¨™ãƒ™ãƒ¼ã‚¹ï¼‰ã‚’ {output_path} ã«ä¿å­˜ã—ã¾ã—ãŸ")

def check_command(args) -> int:
    """ğŸ“Š ãƒ‡ãƒ¼ã‚¿ç¢ºèªã‚³ãƒãƒ³ãƒ‰"""
    print("ğŸ” åˆ©ç”¨å¯èƒ½ãƒ‡ãƒ¼ã‚¿ã®ç¢ºèªä¸­...")
    try:
        result = check_available_data(args.csv_path)
        if 'error' in result:
            print(f"âŒ ã‚¨ãƒ©ãƒ¼: {result['error']}")
            return 1
        print(f"\nâœ… ãƒ‡ãƒ¼ã‚¿ç¢ºèªçµæœ:")
        print(f"ğŸ“ CSVãƒ•ã‚¡ã‚¤ãƒ«: {args.csv_path}")
        print(f"ğŸ“Š ç·ãƒ•ãƒ¬ãƒ¼ãƒ æ•°: {result['total_frames']}")
        print(f"ğŸ“ è‚©å¹…ãƒ‡ãƒ¼ã‚¿åˆ—: {result['shoulder_width_column']}")
        print(f"\nğŸ“‹ åˆ†æå¿…è¦æ¡ä»¶:")
        req = result['minimum_requirements']
        print(f"   æœ€ä½å¿…è¦äººæ•°: {req['min_people_per_analysis']}äºº")
        print(f"   æœ€ä½å¿…è¦åˆ—æ•°: {req['min_columns']}åˆ—")
        print(f"   æ¨å¥¨äººæ•°/åˆ—: {req['recommended_people_per_column']}äºº")
        print(f"\nğŸ¯ æ¨å¥¨ãƒ•ãƒ¬ãƒ¼ãƒ ï¼ˆ{req['min_people_per_analysis']}äººä»¥ä¸Šæ¤œå‡ºï¼‰:")
        if not result['recommended_frames']:
            print("âš ï¸  æ¡ä»¶ã‚’æº€ãŸã™ãƒ•ãƒ¬ãƒ¼ãƒ ãŒã‚ã‚Šã¾ã›ã‚“")
            print("ğŸ’¡ ã‚ˆã‚Šç·©ã„æ¡ä»¶ã®ãƒ•ãƒ¬ãƒ¼ãƒ ï¼ˆä¸Šä½5ã¤ï¼‰:")
            all_frames = sorted(
                result['frame_details'].items(), 
                key=lambda x: x[1]['valid_shoulder_data'], 
                reverse=True
            )[:5]
            for frame, info in all_frames:
                print(f"   ğŸ¬ {frame}:")
                print(f"      æ¤œå‡º: {info['valid_shoulder_data']}äºº")
                print(f"      ID: {info['available_ids']}")
                if info['shoulder_width_range']:
                    print(f"      è‚©å¹…ç¯„å›²: {info['shoulder_width_range'][0]:.1f}-{info['shoulder_width_range'][1]:.1f}px")
                print()
        else:
            for frame in result['recommended_frames']:
                info = result['frame_details'][frame]
                print(f"   ğŸ¬ {frame}:")
                print(f"      æ¤œå‡º: {info['valid_shoulder_data']}äºº")
                print(f"      åˆ©ç”¨å¯èƒ½ID: {info['available_ids']}")
                print(f"      è‚©å¹…ç¯„å›²: {info['shoulder_width_range'][0]:.1f}-{info['shoulder_width_range'][1]:.1f}px")
                print()
        if result['recommended_frames']:
            frame = result['recommended_frames'][0]
            ids = result['frame_details'][frame]['available_ids']
            if len(ids) >= 6:
                ids_per_col = len(ids) // 3
                col1 = ids[:ids_per_col]
                col2 = ids[ids_per_col:ids_per_col*2] 
                col3 = ids[ids_per_col*2:]
                print(f"ğŸ’¡ æ¨å¥¨å®Ÿè¡Œã‚³ãƒãƒ³ãƒ‰ä¾‹:")
                print(f"python {Path(__file__).name} analyze_one \\")
                print(f'    "{args.csv_path}" \\')
                print(f'    "{frame}"')
        return 0
    except Exception as e:
        print(f"âŒ ç¢ºèªã‚¨ãƒ©ãƒ¼: {e}")
        traceback.print_exc()
        return 1

def analyze_one_command(args) -> int:
    """ğŸ¯ 1ãƒ•ãƒ¬ãƒ¼ãƒ åˆ†æã‚³ãƒãƒ³ãƒ‰"""
    try:
        output_dir = create_analysis_output_dir(args.output_dir)
        column_assignments = extract_column_assignments_from_csv(args.csv_path)
        if not column_assignments:
            print("âŒ ã‚¨ãƒ©ãƒ¼: column_positionåˆ—ãŒè¦‹ã¤ã‹ã‚‰ãªã„ã‹ã€å‰²ã‚Šå½“ã¦ãŒã‚ã‚Šã¾ã›ã‚“")
            return 1
        if len(column_assignments) < 2:
            print("âŒ ã‚¨ãƒ©ãƒ¼: æ­£è¦åŒ–é–¢æ•°ä½œæˆã«ã¯æœ€ä½2åˆ—å¿…è¦ã§ã™")
            return 1
        print(f"ğŸ¯ 1ãƒ•ãƒ¬ãƒ¼ãƒ åˆ†æé–‹å§‹:")
        print(f"   ğŸ“ CSV: {args.csv_path}")
        print(f"   ğŸ¬ ãƒ•ãƒ¬ãƒ¼ãƒ : {args.frame_id}")
        print(f"   ğŸ“‹ åˆ—æ§‹æˆ: {column_assignments}")
        print(f"   ğŸ“‚ å‡ºåŠ›å…ˆ: {output_dir}")
        analyzer = DistanceNormalizationAnalyzer(
            csv_path=args.csv_path,
            output_base_dir=output_dir
        )
        result = analyzer.analyze_distance_function(
            frame_id=args.frame_id,
            column_assignments=column_assignments
        )
        if result['success']:
            print(f"\nğŸ‰ åˆ†ææˆåŠŸ!")
            print(f"ğŸ“ çµæœãƒ•ã‚©ãƒ«ãƒ€: {result['analysis_info']['output_dir']}")
            plot_shoulder_width_vs_column_with_fit(args.csv_path, output_dir)
            plot_shoulder_width_vs_column_with_fit_iqr(args.csv_path, output_dir)  # â†è¿½åŠ 
            plot_angle_boxplot_by_column(args.csv_path, output_dir)
            return 0
        else:
            print(f"âŒ åˆ†æå¤±æ•—: {result.get('error', 'ä¸æ˜ãªã‚¨ãƒ©ãƒ¼')}")
            return 1
    except Exception as e:
        print(f"âŒ å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
        traceback.print_exc()
        return 1

def analyze_all_command(args) -> int:
    """ğŸ¯ å…¨ãƒ•ãƒ¬ãƒ¼ãƒ åˆ†æã‚³ãƒãƒ³ãƒ‰"""
    try:
        output_dir = create_analysis_output_dir(args.output_dir)
        column_assignments = extract_column_assignments_from_csv(args.csv_path)
        if not column_assignments:
            print("âŒ ã‚¨ãƒ©ãƒ¼: column_positionåˆ—ãŒè¦‹ã¤ã‹ã‚‰ãªã„ã‹ã€å‰²ã‚Šå½“ã¦ãŒã‚ã‚Šã¾ã›ã‚“")
            return 1
        print(f"ğŸ¯ å…¨ãƒ•ãƒ¬ãƒ¼ãƒ åˆ†æé–‹å§‹:")
        print(f"   ğŸ“ CSV: {args.csv_path}")
        print(f"   ğŸ“‹ åˆ—æ§‹æˆ: {column_assignments}")
        print(f"   ğŸ“‚ å‡ºåŠ›å…ˆ: {output_dir}")
        plot_shoulder_width_vs_column_with_fit(args.csv_path, output_dir)
        plot_shoulder_width_vs_column_with_fit_iqr(args.csv_path, output_dir)  # â†è¿½åŠ 
        plot_angle_boxplot_by_column(args.csv_path, output_dir)
        return 0
    except Exception as e:
        print(f"âŒ å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
        traceback.print_exc()
        return 1

def sample_command() -> int:
    """ğŸ”¬ ã‚µãƒ³ãƒ—ãƒ«åˆ†æã®å®Ÿè¡Œ"""
    print("ğŸ”¬ ã‚µãƒ³ãƒ—ãƒ«æ­£è¦åŒ–åˆ†æã‚’å®Ÿè¡Œ...")
    try:
        sample_csv_paths = [
            'outputs/baseline/11æœˆ12æ—¥ 1/4point_metrics.csv',
            'outputs/baseline/*/4point_metrics.csv',
            'data/4point_metrics.csv',
            '4point_metrics.csv'
        ]
        sample_csv = None
        for path_pattern in sample_csv_paths:
            if '*' in path_pattern:
                from glob import glob
                matches = glob(path_pattern)
                if matches:
                    sample_csv = matches[0]
                    break
            else:
                if Path(path_pattern).exists():
                    sample_csv = path_pattern
                    break
        if not sample_csv:
            print("âŒ ã‚µãƒ³ãƒ—ãƒ«ç”¨CSVãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            print("ğŸ’¡ ä»¥ä¸‹ã®ã„ãšã‚Œã‹ã‚’é…ç½®ã—ã¦ãã ã•ã„:")
            for path in sample_csv_paths[:3]:
                print(f"   - {path}")
            return 1
        print(f"ğŸ“ ã‚µãƒ³ãƒ—ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«: {sample_csv}")
        output_dir = create_analysis_output_dir("outputs/normalization_analysis")
        plot_shoulder_width_vs_column_with_fit(sample_csv, output_dir)
        plot_angle_boxplot_by_column(sample_csv, output_dir)
        print(f"\nâœ… ã‚µãƒ³ãƒ—ãƒ«ã‚°ãƒ©ãƒ•ã‚’ {output_dir} ã«å‡ºåŠ›ã—ã¾ã—ãŸã€‚")
        return 0
    except Exception as e:
        print(f"âŒ ã‚µãƒ³ãƒ—ãƒ«åˆ†æã‚¨ãƒ©ãƒ¼: {e}")
        traceback.print_exc()
        return 1

def main() -> int:
    """ğŸ¯ ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    print_header()
    parser = argparse.ArgumentParser(
        description='ğŸ”§ è·é›¢æ­£è¦åŒ–é–¢æ•°åˆ†æãƒ„ãƒ¼ãƒ«',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ä¾‹:
  # ãƒ‡ãƒ¼ã‚¿ç¢ºèª
  %(prog)s check "outputs/baseline/11æœˆ12æ—¥ 1/4point_metrics.csv"
  
  # 1ãƒ•ãƒ¬ãƒ¼ãƒ åˆ†æ
  %(prog)s analyze_one "data.csv" "frame.jpg"
  
  # å…¨ãƒ•ãƒ¬ãƒ¼ãƒ åˆ†æ
  %(prog)s analyze_all "data.csv"
  
  # ã‚µãƒ³ãƒ—ãƒ«åˆ†æ
  %(prog)s
        """
    )
    subparsers = parser.add_subparsers(dest='command', help='å®Ÿè¡Œã‚³ãƒãƒ³ãƒ‰')
    check_parser = subparsers.add_parser(
        'check', 
        help='ğŸ“Š åˆ©ç”¨å¯èƒ½ãƒ‡ãƒ¼ã‚¿ã®ç¢ºèª',
        description='CSVãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰åˆ†æå¯èƒ½ãªãƒ•ãƒ¬ãƒ¼ãƒ ãƒ»IDã‚’ç¢ºèª'
    )
    check_parser.add_argument('csv_path', help='4ç‚¹ãƒ¡ãƒˆãƒªã‚¯ã‚¹CSVãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹')
    analyze_one_parser = subparsers.add_parser(
        'analyze_one', 
        help='ğŸ¯ 1ãƒ•ãƒ¬ãƒ¼ãƒ åˆ†æ',
        description='æŒ‡å®šã—ãŸãƒ•ãƒ¬ãƒ¼ãƒ ã§æ­£è¦åŒ–é–¢æ•°ã‚’ç”Ÿæˆ'
    )
    analyze_one_parser.add_argument('csv_path', help='4ç‚¹ãƒ¡ãƒˆãƒªã‚¯ã‚¹CSVãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹')
    analyze_one_parser.add_argument('frame_id', help='åˆ†æå¯¾è±¡ãƒ•ãƒ¬ãƒ¼ãƒ ID')
    analyze_one_parser.add_argument('--output-dir', default='outputs/normalization_analysis',
                               help='å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: outputs/normalization_analysis)')
    analyze_all_parser = subparsers.add_parser(
        'analyze_all', 
        help='ğŸ¯ å…¨ãƒ•ãƒ¬ãƒ¼ãƒ åˆ†æ',
        description='å…¨ãƒ•ãƒ¬ãƒ¼ãƒ ã§åˆ†å¸ƒãƒ»å¹³å‡ã‚°ãƒ©ãƒ•ã‚’ç”Ÿæˆ'
    )
    analyze_all_parser.add_argument('csv_path', help='4ç‚¹ãƒ¡ãƒˆãƒªã‚¯ã‚¹CSVãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹')
    analyze_all_parser.add_argument('--output-dir', default='outputs/normalization_analysis',
                               help='å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: outputs/normalization_analysis)')
    args = parser.parse_args()
    try:
        if args.command == 'check':
            return check_command(args)
        elif args.command == 'analyze_one':
            return analyze_one_command(args)
        elif args.command == 'analyze_all':
            return analyze_all_command(args)
        else:
            print("ğŸ“ å¼•æ•°ãªã—ã§ã‚µãƒ³ãƒ—ãƒ«åˆ†æã‚’å®Ÿè¡Œã—ã¾ã™...")
            return sample_command()
    except KeyboardInterrupt:
        print("\nâ¹ï¸  ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ã‚ˆã‚‹ä¸­æ–­")
        return 130
    except Exception as e:
        print(f"\nâŒ äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼: {e}")
        traceback.print_exc()
        return 1

if __name__ == "__main__":
    sys.exit(main())

# --- ç®±ã²ã’å›³ã®è¦‹æ–¹ ---
# æ¨ªè»¸ï¼šåˆ—ä½ç½®ï¼ˆcolumn_positionï¼‰
# ç¸¦è»¸ï¼šãªã™è§’ï¼ˆåº¦ï¼‰
# ç®±ï¼šãƒ‡ãƒ¼ã‚¿ã®ä¸­å¤®50%ï¼ˆç¬¬1å››åˆ†ä½ï½ç¬¬3å››åˆ†ä½ï¼‰
# èµ¤ç·šï¼šä¸­å¤®å€¤
# ã²ã’ï¼šå¤–ã‚Œå€¤ã‚’é™¤ã„ãŸç¯„å›²
# ç‚¹ï¼šå¤–ã‚Œå€¤
# â†’ åˆ—ã”ã¨ã«å§¿å‹¢ï¼ˆãªã™è§’ï¼‰ã®ã°ã‚‰ã¤ãã‚„å‚¾å‘ãŒåˆ†ã‹ã‚Šã¾ã™