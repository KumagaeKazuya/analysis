import os
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from pathlib import Path
from typing import Dict, List, Tuple, Optional
from datetime import datetime
from scipy.stats import pearsonr, linregress
from scipy.optimize import curve_fit
import json
import warnings
warnings.filterwarnings('ignore')

class DistanceNormalizationAnalyzer:
    """è·é›¢æ­£è¦åŒ–ç”¨æ¸›å°‘é–¢æ•°åˆ†æã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, csv_path: str, output_base_dir: str = "outputs/normalization_analysis"):
        """
        Args:
            csv_path: 4ç‚¹ãƒ¡ãƒˆãƒªã‚¯ã‚¹CSVãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
            output_base_dir: çµæœä¿å­˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        """
        self.csv_path = Path(csv_path)
        self.output_base_dir = Path(output_base_dir)
        
        # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆï¼ˆã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ä»˜ãï¼‰
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        self.output_dir = self.output_base_dir / f"analysis_{timestamp}"
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
        self._load_data()
        
        print(f"âœ… è·é›¢æ­£è¦åŒ–åˆ†æå™¨åˆæœŸåŒ–å®Œäº†")
        print(f"ğŸ“ å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {self.output_dir}")
    
    def _load_data(self):
        """CSVãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ã¨æ¤œè¨¼"""
        if not self.csv_path.exists():
            raise FileNotFoundError(f"CSVãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {self.csv_path}")
        
        self.df = pd.read_csv(self.csv_path)
        
        # å¿…è¦åˆ—ã®ç¢ºèª
        required_cols = ['frame', 'person_id']
        missing = [col for col in required_cols if col not in self.df.columns]
        if missing:
            raise ValueError(f"å¿…è¦ãªåˆ—ãŒä¸è¶³: {missing}")
        
        # è‚©å¹…åˆ—ã®ç‰¹å®šï¼ˆè¤‡æ•°å€™è£œã‹ã‚‰è‡ªå‹•é¸æŠï¼‰
        shoulder_cols = ['shoulder_width', 'shoulder_width_pixels', 'shoulder_distance']
        self.shoulder_col = None
        for col in shoulder_cols:
            if col in self.df.columns:
                self.shoulder_col = col
                break
        
        if self.shoulder_col is None:
            raise ValueError(f"è‚©å¹…ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚åˆ©ç”¨å¯èƒ½åˆ—: {list(self.df.columns)}")
        
        print(f"ğŸ“Š ãƒ‡ãƒ¼ã‚¿æƒ…å ±:")
        print(f"   ç·ãƒ‡ãƒ¼ã‚¿æ•°: {len(self.df)}")
        print(f"   ãƒ•ãƒ¬ãƒ¼ãƒ æ•°: {self.df['frame'].nunique()}")
        print(f"   IDæ•°: {self.df['person_id'].nunique()}")
        print(f"   è‚©å¹…åˆ—: {self.shoulder_col}")
    
    def analyze_distance_function(
        self, 
        frame_id: str,
        column_assignments: Dict[int, List[int]],
        width_range: Tuple[float, float] = (10, 500)
    ) -> Dict:
        """
        ğŸ¯ ãƒ¡ã‚¤ãƒ³åˆ†æãƒ¡ã‚½ãƒƒãƒ‰: è·é›¢æ¸›å°‘é–¢æ•°ã®åˆ†æ
        
        Args:
            frame_id: åˆ†æå¯¾è±¡ãƒ•ãƒ¬ãƒ¼ãƒ  (ä¾‹: "11æœˆ12æ—¥ 1.mp4_frame0.jpg")
            column_assignments: {åˆ—ç•ªå·: [ID1, ID2, ...]} (ä¾‹: {1: [1,2], 2: [3,4], 3: [5,6]})
            width_range: æœ‰åŠ¹è‚©å¹…ç¯„å›² (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 10-500px)
            
        Returns:
            åˆ†æçµæœè¾æ›¸ï¼ˆæ¸›å°‘é–¢æ•°ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã€å¯è¦–åŒ–ãƒ‘ã‚¹ã€æ­£è¦åŒ–ã‚³ãƒ¼ãƒ‰å«ã‚€ï¼‰
        """
        print(f"\nğŸ¯ === è·é›¢æ­£è¦åŒ–é–¢æ•°åˆ†æé–‹å§‹ ===")
        print(f"ğŸ“… åˆ†ææ™‚åˆ»: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print(f"ğŸ¬ å¯¾è±¡ãƒ•ãƒ¬ãƒ¼ãƒ : {frame_id}")
        print(f"ğŸ“‹ åˆ—æ§‹æˆ: {column_assignments}")
        
        try:
            # ğŸ” Step 1: ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ‡ãƒ¼ã‚¿æŠ½å‡º
            frame_data = self._extract_frame_data(frame_id, width_range)
            if frame_data is None:
                return {'success': False, 'error': 'ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ‡ãƒ¼ã‚¿æŠ½å‡ºå¤±æ•—'}
            
            # ğŸ“Š Step 2: åˆ—åˆ¥ãƒ‡ãƒ¼ã‚¿æ•´ç†
            column_data = self._organize_column_data(frame_data, column_assignments)
            
            # ğŸ“ˆ Step 3: æ¸›å°‘é–¢æ•°ãƒ•ã‚£ãƒƒãƒ†ã‚£ãƒ³ã‚°
            function_results = self._fit_distance_functions(column_data)
            
            # ğŸ¨ Step 4: å¯è¦–åŒ–ä½œæˆ
            visualization_path = self._create_normalization_visualization(
                column_data, function_results, frame_id
            )
            
            # ğŸ”§ Step 5: æ­£è¦åŒ–é–¢æ•°ã‚³ãƒ¼ãƒ‰ç”Ÿæˆ
            normalization_code = self._generate_normalization_code(function_results)
            
            # ğŸ“ Step 6: è©³ç´°ãƒ¬ãƒãƒ¼ãƒˆä½œæˆ
            report_path = self._save_analysis_report(
                frame_id, column_assignments, column_data, 
                function_results, normalization_code
            )
            
            # ğŸ“Š Step 7: çµæœçµ±åˆ
            result = {
                'success': True,
                'analysis_info': {
                    'timestamp': datetime.now().isoformat(),
                    'frame_id': frame_id,
                    'column_assignments': column_assignments,
                    'output_dir': str(self.output_dir)
                },
                'column_statistics': {
                    col: {
                        'count': data['count'],
                        'mean_shoulder_width': data['mean_width'],
                        'std_shoulder_width': data['std_width']
                    } for col, data in column_data.items() if data['count'] > 0
                },
                'distance_functions': function_results,
                'normalization_code': normalization_code,
                'output_files': {
                    'visualization': visualization_path,
                    'report': report_path,
                    'function_data': str(self.output_dir / 'function_parameters.json')
                }
            }
            
            # JSONä¿å­˜
            self._save_function_parameters(function_results)
            
            print(f"\nâœ… === åˆ†æå®Œäº† ===")
            if 'best_function' in function_results:
                print(f"ğŸ“ˆ æœ€é©é–¢æ•°: {function_results['best_function']['name']}")
                print(f"ğŸ”— ç›¸é–¢ä¿‚æ•°: {function_results['correlation']['coefficient']:.3f}")
            print(f"ğŸ“ çµæœä¿å­˜: {self.output_dir}")
            
            return result
            
        except Exception as e:
            print(f"âŒ åˆ†æã‚¨ãƒ©ãƒ¼: {e}")
            return {'success': False, 'error': str(e)}
    
    def _extract_frame_data(self, frame_id: str, width_range: Tuple[float, float]) -> Optional[pd.DataFrame]:
        """ğŸ” ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ‡ãƒ¼ã‚¿ã®æŠ½å‡ºã¨æœ‰åŠ¹æ€§æ¤œè¨¼"""
        frame_data = self.df[self.df['frame'] == frame_id].copy()
        
        if frame_data.empty:
            available_frames = self.df['frame'].unique()[:10]
            print(f"âŒ ãƒ•ãƒ¬ãƒ¼ãƒ  '{frame_id}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            print(f"ğŸ“‹ åˆ©ç”¨å¯èƒ½ãƒ•ãƒ¬ãƒ¼ãƒ ä¾‹: {list(available_frames)}")
            return None
        
        # æœ‰åŠ¹è‚©å¹…ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
        min_width, max_width = width_range
        valid_mask = (
            (frame_data[self.shoulder_col] >= min_width) & 
            (frame_data[self.shoulder_col] <= max_width) &
            (frame_data[self.shoulder_col].notna())
        )
        
        frame_data = frame_data[valid_mask].copy()
        
        print(f"ğŸ“Š ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ‡ãƒ¼ã‚¿:")
        print(f"   æ¤œå‡ºäººæ•°: {len(frame_data)}")
        print(f"   æœ‰åŠ¹ID: {sorted(frame_data['person_id'].unique())}")
        print(f"   è‚©å¹…ç¯„å›²: {frame_data[self.shoulder_col].min():.1f} - {frame_data[self.shoulder_col].max():.1f}px")
        
        return frame_data
    
    def _organize_column_data(self, frame_data: pd.DataFrame, column_assignments: Dict[int, List[int]]) -> Dict:
        """ğŸ“Š åˆ—åˆ¥ãƒ‡ãƒ¼ã‚¿ã®æ•´ç†ï¼ˆçµ±è¨ˆè¨ˆç®—ä»˜ãï¼‰"""
        column_data = {}
        
        for column_num, person_ids in column_assignments.items():
            # æŒ‡å®šIDã§ãƒ‡ãƒ¼ã‚¿æŠ½å‡º
            column_df = frame_data[frame_data['person_id'].isin(person_ids)]
            
            if not column_df.empty:
                shoulder_widths = column_df[self.shoulder_col].values
                column_data[column_num] = {
                    'assigned_ids': person_ids,
                    'found_ids': column_df['person_id'].tolist(),
                    'shoulder_widths': shoulder_widths.tolist(),
                    'mean_width': float(np.mean(shoulder_widths)),
                    'std_width': float(np.std(shoulder_widths)),
                    'min_width': float(np.min(shoulder_widths)),
                    'max_width': float(np.max(shoulder_widths)),
                    'count': len(shoulder_widths)
                }
                print(f"ğŸ“‹ {column_num}åˆ—ç›®: {len(shoulder_widths)}äººæ¤œå‡º, å¹³å‡{np.mean(shoulder_widths):.1f}px")
                print(f"   å‰²ã‚Šå½“ã¦ID: {person_ids} â†’ æ¤œå‡ºID: {column_df['person_id'].tolist()}")
            else:
                # ãƒ‡ãƒ¼ã‚¿ãªã—ã®åˆ—ã‚‚è¨˜éŒ²
                column_data[column_num] = {
                    'assigned_ids': person_ids,
                    'found_ids': [],
                    'shoulder_widths': [],
                    'mean_width': 0,
                    'std_width': 0,
                    'min_width': 0,
                    'max_width': 0,
                    'count': 0
                }
                print(f"âš ï¸ {column_num}åˆ—ç›®: è©²å½“IDãªã— ({person_ids})")
        
        return column_data
    
    def _fit_distance_functions(self, column_data: Dict) -> Dict:
        """ğŸ“ˆ è¤‡æ•°ã®è·é›¢æ¸›å°‘é–¢æ•°ã§ãƒ•ã‚£ãƒƒãƒ†ã‚£ãƒ³ã‚°"""
        # æœ‰åŠ¹ãƒ‡ãƒ¼ã‚¿ã®ã‚ã‚‹åˆ—ã®ã¿ä½¿ç”¨
        valid_columns = {k: v for k, v in column_data.items() if v['count'] > 0}
        
        if len(valid_columns) < 2:
            return {'error': 'ãƒ‡ãƒ¼ã‚¿ä¸è¶³ï¼ˆ2åˆ—ä»¥ä¸Šå¿…è¦ï¼‰', 'valid_columns': len(valid_columns)}
        
        # ãƒ‡ãƒ¼ã‚¿æº–å‚™
        x_data = np.array(list(valid_columns.keys()))  # åˆ—ç•ªå· [1, 2, 3]
        y_data = np.array([valid_columns[col]['mean_width'] for col in x_data])  # å¹³å‡è‚©å¹…
        
        print(f"ğŸ“Š ãƒ•ã‚£ãƒƒãƒ†ã‚£ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿:")
        print(f"   åˆ—ä½ç½®(X): {x_data}")
        print(f"   å¹³å‡è‚©å¹…(Y): {y_data}")
        
        # åŸºæœ¬ç›¸é–¢åˆ†æ
        correlation, p_value = pearsonr(x_data, y_data)
        print(f"ğŸ”— åŸºæœ¬ç›¸é–¢: r={correlation:.3f}, p={p_value:.3f}")
        
        # ğŸ“ˆ è¤‡æ•°ã®é–¢æ•°ã§ãƒ•ã‚£ãƒƒãƒ†ã‚£ãƒ³ã‚°è©¦è¡Œ
        functions = {
            'linear': {
                'func': lambda x, a, b: a * x + b,
                'name': 'ç·šå½¢é–¢æ•°',
                'formula': 'f(x) = ax + b',
                'expected': 'right_down'  # å³è‚©ä¸‹ãŒã‚ŠæœŸå¾…
            },
            'exponential': {
                'func': lambda x, a, b, c: a * np.exp(-b * x) + c,
                'name': 'æŒ‡æ•°æ¸›è¡°é–¢æ•°',
                'formula': 'f(x) = a*exp(-bx) + c',
                'expected': 'right_down'
            },
            'power': {
                'func': lambda x, a, b, c: a / (x ** b) + c,
                'name': 'ã¹ãé–¢æ•°',
                'formula': 'f(x) = a/x^b + c',
                'expected': 'right_down'
            },
            'polynomial2': {
                'func': lambda x, a, b, c: a * x**2 + b * x + c,
                'name': '2æ¬¡å¤šé …å¼',
                'formula': 'f(x) = axÂ² + bx + c',
                'expected': 'flexible'
            }
        }
        
        fitting_results = {}
        best_fit = None
        best_r2 = -np.inf
        
        for func_name, func_info in functions.items():
            try:
                # ğŸ“Š åˆæœŸå€¤è¨­å®šï¼ˆå³è‚©ä¸‹ãŒã‚Šã‚’æƒ³å®šï¼‰
                if func_name == 'linear':
                    # ç·šå½¢: è² ã®å‚¾ãã‚’æœŸå¾…
                    slope_estimate = (y_data[-1] - y_data[0]) / (x_data[-1] - x_data[0])
                    p0 = [slope_estimate, y_data[0]]
                elif func_name == 'exponential':
                    # æŒ‡æ•°æ¸›è¡°: æ­£ã®ä¿‚æ•°ã€æ­£ã®æ¸›è¡°ç‡
                    p0 = [y_data[0] - y_data[-1], 0.5, y_data[-1]]
                elif func_name == 'power':
                    # ã¹ãé–¢æ•°: æ­£ã®ã¹ãä¹—
                    p0 = [y_data[0] * x_data[0], 1, y_data[-1]]
                elif func_name == 'polynomial2':
                    # 2æ¬¡å¤šé …å¼: ä¸‹ã«å‡¸ã‚’æƒ³å®š
                    p0 = [-1, -5, y_data[0]]
                
                # ğŸ”§ ãƒ•ã‚£ãƒƒãƒ†ã‚£ãƒ³ã‚°å®Ÿè¡Œ
                popt, pcov = curve_fit(func_info['func'], x_data, y_data, p0=p0, maxfev=2000)
                
                # ğŸ“Š äºˆæ¸¬å€¤è¨ˆç®—
                y_pred = func_info['func'](x_data, *popt)
                
                # ğŸ“ˆ è©•ä¾¡æŒ‡æ¨™è¨ˆç®—
                ss_res = np.sum((y_data - y_pred) ** 2)  # æ®‹å·®å¹³æ–¹å’Œ
                ss_tot = np.sum((y_data - np.mean(y_data)) ** 2)  # å…¨å¹³æ–¹å’Œ
                r2 = 1 - (ss_res / ss_tot)  # RÂ²æ±ºå®šä¿‚æ•°
                rmse = np.sqrt(np.mean((y_data - y_pred) ** 2))  # RMSE
                
                # ğŸ“‹ çµæœä¿å­˜
                fitting_results[func_name] = {
                    'parameters': popt.tolist(),
                    'covariance': pcov.tolist() if pcov is not None else None,
                    'r2_score': float(r2),
                    'rmse': float(rmse),
                    'predicted_values': y_pred.tolist(),
                    'formula': func_info['formula'],
                    'name': func_info['name'],
                    'slope_direction': 'decreasing' if y_pred[0] > y_pred[-1] else 'increasing'
                }
                
                # ğŸ† æœ€é©é–¢æ•°é¸æŠï¼ˆRÂ²å€¤åŸºæº–ï¼‰
                if r2 > best_r2:
                    best_r2 = r2
                    best_fit = func_name
                
                direction = "â†˜ï¸" if y_pred[0] > y_pred[-1] else "â†—ï¸"
                print(f"ğŸ”§ {func_info['name']}: RÂ²={r2:.3f}, RMSE={rmse:.1f}, å‚¾å‘={direction}")
                
            except Exception as e:
                print(f"âš ï¸ {func_info['name']}ãƒ•ã‚£ãƒƒãƒ†ã‚£ãƒ³ã‚°å¤±æ•—: {e}")
                continue
        
        return {
            'correlation': {
                'coefficient': float(correlation),
                'p_value': float(p_value),
                'interpretation': self._interpret_correlation(correlation)
            },
            'fitting_results': fitting_results,
            'best_function': {
                'name': best_fit,
                'r2_score': float(best_r2) if best_fit else 0,
                'details': fitting_results.get(best_fit, {})
            } if best_fit else {'name': None},
            'data_points': {
                'x_data': x_data.tolist(),
                'y_data': y_data.tolist()
            }
        }
    
    def _interpret_correlation(self, r: float) -> str:
        """ğŸ”— ç›¸é–¢ä¿‚æ•°ã®è§£é‡ˆ"""
        abs_r = abs(r)
        if abs_r < 0.1:
            strength = "ç›¸é–¢ãªã—"
        elif abs_r < 0.3:
            strength = "å¼±ã„ç›¸é–¢"
        elif abs_r < 0.7:
            strength = "ä¸­ç¨‹åº¦ã®ç›¸é–¢"
        else:
            strength = "å¼·ã„ç›¸é–¢"
        
        direction = "è² ã®" if r < 0 else "æ­£ã®"
        return f"{direction}{strength}"
    
    def _create_normalization_visualization(
        self, 
        column_data: Dict, 
        function_results: Dict, 
        frame_id: str
    ) -> str:
        """ğŸ¨ æ­£è¦åŒ–é–¢æ•°å¯è¦–åŒ–ã®ä½œæˆ"""
        try:
            plt.rcParams['font.sans-serif'] = ['Arial Unicode MS', 'DejaVu Sans', 'Hiragino Sans']
            
            fig, axes = plt.subplots(2, 2, figsize=(16, 12))
            fig.suptitle(
                f'è·é›¢æ­£è¦åŒ–é–¢æ•°åˆ†æ ğŸ“Š\n{frame_id}\n{datetime.now().strftime("%Y-%m-%d %H:%M")}', 
                fontsize=16
            )
            
            valid_columns = {k: v for k, v in column_data.items() if v['count'] > 0}
            
            if not valid_columns or 'data_points' not in function_results:
                for ax in axes.flat:
                    ax.text(0.5, 0.5, 'ãƒ‡ãƒ¼ã‚¿ä¸è¶³', ha='center', va='center', 
                           transform=ax.transAxes, fontsize=14)
                    ax.set_xticks([])
                    ax.set_yticks([])
                return ""
            
            x_data = np.array(function_results['data_points']['x_data'])
            y_data = np.array(function_results['data_points']['y_data'])
            
            # ğŸ¯ 1. ãƒ¡ã‚¤ãƒ³ãƒ—ãƒ­ãƒƒãƒˆ: æ•£å¸ƒå›³ + å›å¸°ç·š
            ax1 = axes[0, 0]
            
            # å€‹äººãƒ‡ãƒ¼ã‚¿ï¼ˆé»’ç‚¹ï¼‰
            for column_num, data in valid_columns.items():
                x_positions = [column_num] * data['count']
                ax1.scatter(
                    x_positions, data['shoulder_widths'], 
                    color='black', alpha=0.6, s=30,
                    label='å€‹äººãƒ‡ãƒ¼ã‚¿' if column_num == min(valid_columns.keys()) else ""
                )
            
            # åˆ—å¹³å‡ï¼ˆèµ¤ç‚¹ï¼‰
            ax1.scatter(x_data, y_data, color='red', s=100, marker='D', 
                       label='åˆ—å¹³å‡', zorder=5)
            
            # æœ€é©å›å¸°ç·š
            if function_results.get('best_function', {}).get('name') and 'fitting_results' in function_results:
                best_func_name = function_results['best_function']['name']
                best_params = function_results['fitting_results'][best_func_name]['parameters']
                
                x_smooth = np.linspace(x_data.min(), x_data.max(), 100)
                
                # é–¢æ•°åˆ¥ã®äºˆæ¸¬å€¤è¨ˆç®—
                if best_func_name == 'linear':
                    y_smooth = best_params[0] * x_smooth + best_params[1]
                elif best_func_name == 'exponential':
                    y_smooth = best_params[0] * np.exp(-best_params[1] * x_smooth) + best_params[2]
                elif best_func_name == 'power':
                    y_smooth = best_params[0] / (x_smooth ** best_params[1]) + best_params[2]
                elif best_func_name == 'polynomial2':
                    y_smooth = best_params[0] * x_smooth**2 + best_params[1] * x_smooth + best_params[2]
                
                ax1.plot(x_smooth, y_smooth, 'b-', linewidth=2, 
                        label=f'æœ€é©é–¢æ•° ({function_results["fitting_results"][best_func_name]["name"]})')
            
            ax1.set_xlabel('åˆ—ä½ç½®ï¼ˆã‚«ãƒ¡ãƒ©ã‹ã‚‰ã®è·é›¢ï¼‰')
            ax1.set_ylabel('è‚©å¹… (pixels)')
            ax1.set_title('ğŸ¯ è·é›¢-è‚©å¹…é–¢ä¿‚ã¨æ­£è¦åŒ–é–¢æ•°')
            ax1.grid(True, alpha=0.3)
            ax1.legend()
            
            # ğŸ“ˆ 2. é–¢æ•°æ¯”è¼ƒãƒ—ãƒ­ãƒƒãƒˆ
            ax2 = axes[0, 1]
            if 'fitting_results' in function_results:
                colors = ['blue', 'green', 'orange', 'purple']
                for i, (func_name, result) in enumerate(function_results['fitting_results'].items()):
                    if 'predicted_values' in result:
                        color = colors[i % len(colors)]
                        symbol = "â†˜ï¸" if result.get('slope_direction') == 'decreasing' else "â†—ï¸"
                        ax2.plot(x_data, result['predicted_values'], 'o-', 
                                color=color, linewidth=2, markersize=6,
                                label=f"{symbol}{result['name']} (RÂ²={result['r2_score']:.3f})")
                ax2.scatter(x_data, y_data, color='red', s=100, marker='D', 
                            label='å®Ÿæ¸¬å€¤', zorder=5)
            ax2.set_xlabel('åˆ—ä½ç½®')
            ax2.set_ylabel('è‚©å¹… (pixels)')
            ax2.set_title('ğŸ“Š é–¢æ•°ãƒ•ã‚£ãƒƒãƒ†ã‚£ãƒ³ã‚°æ¯”è¼ƒ')
            ax2.grid(True, alpha=0.3)
            ax2.legend()

            # å·¦ä¸‹: axes[1, 0] ã«ã€Œãªã™è§’åˆ†å¸ƒï¼ˆIDã”ã¨ã®ç‚¹ï¼‹å¹³å‡ï¼‰ã€ã‚’æç”»
            ax3 = axes[1, 0]
            col_nums = sorted(column_data.keys())
            col_labels = [f"åˆ—{col_num}" for col_num in col_nums]
            means = []
            for i, col_num in enumerate(col_nums):
                ids = column_data[col_num]['assigned_ids']
                sub_df = self.df[(self.df['frame'] == frame_id) & (self.df['person_id'].isin(ids))]
                if 'shoulder_head_angle' in sub_df.columns:
                    angles = sub_df['shoulder_head_angle'].dropna().values
                    # -180ï½+180åº¦ã«åã‚ã‚‹
                    angles = ((angles + 180) % 360) - 180
                else:
                    angles = np.array([])
                # å€‹ã€…ã®IDã”ã¨ã«ç‚¹ã‚’ãƒ—ãƒ­ãƒƒãƒˆ
                ax3.scatter([i+1]*len(angles), angles, color='black', alpha=0.7, s=30)
                # å¹³å‡å€¤
                if len(angles) > 0:
                    mean_angle = np.mean(angles)
                    means.append(mean_angle)
                    ax3.scatter(i+1, mean_angle, color='red', s=120, marker='D', label='åˆ—å¹³å‡' if i==0 else "")
                else:
                    means.append(np.nan)

            ax3.set_xticks(range(1, len(col_labels)+1))
            ax3.set_xticklabels(col_labels)
            ax3.set_title("è‚©ã®ä¸­ç‚¹ã¨é ­ä¸­å¿ƒã®ãªã™è§’åˆ†å¸ƒï¼ˆåˆ—ä½ç½®ã”ã¨ï¼‰")
            ax3.set_xlabel("åˆ—ä½ç½®")
            ax3.set_ylabel("ãªã™è§’ (åº¦)")
            ax3.set_ylim(-180, 180)
            ax3.grid(True, alpha=0.3)
            if any([len(column_data[col]['assigned_ids']) > 0 for col in col_nums]):
                ax3.legend()
            
            # ğŸ”„ 4. æ­£è¦åŒ–åŠ¹æœãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼
            ax4 = axes[1, 1]
            ax4.text(0.5, 0.5, 'ğŸ”„ æ­£è¦åŒ–åŠ¹æœ\nï¼ˆå®Ÿè£…ä¸­ï¼‰', 
                    ha='center', va='center', transform=ax4.transAxes, fontsize=14)
            ax4.set_title('ğŸ”„ æ­£è¦åŒ–åŠ¹æœæ¯”è¼ƒ')
            
            plt.tight_layout()
            
            # ğŸ’¾ ä¿å­˜
            output_path = self.output_dir / 'distance_normalization_analysis.png'
            plt.savefig(output_path, dpi=300, bbox_inches='tight')
            plt.close()
            
            print(f"âœ… å¯è¦–åŒ–ä¿å­˜: {output_path}")
            return str(output_path)
            
        except Exception as e:
            print(f"âŒ å¯è¦–åŒ–ã‚¨ãƒ©ãƒ¼: {e}")
            return ""
    
    def plot_angle_vs_column_position(self, metrics_csv_path, column_assignments, output_dir):
        """
        åˆ—ã”ã¨ã«IDã‚’æŒ‡å®šã—ã€ãªã™è§’ï¼ˆshoulder_head_angleï¼‰ã®åˆ†å¸ƒã‚’
        æ¨ªè»¸: åˆ—ä½ç½®ï¼ˆç‰©ç†çš„ãªä¸¦ã³é †ï¼‰ã€ç¸¦è»¸: ãªã™è§’ï¼ˆåº¦ï¼‰ã¨ã—ã¦ãƒ—ãƒ­ãƒƒãƒˆã™ã‚‹ã€‚
        è·é›¢-è‚©å¹…é–¢ä¿‚ã‚°ãƒ©ãƒ•ã¨åŒã˜ã‚¹ã‚¿ã‚¤ãƒ«ã§å‡ºåŠ›ã€‚
        """
        df = pd.read_csv(metrics_csv_path)

        # åˆ—ç•ªå·é †ã«ä¸¦ã¹ã‚‹
        col_nums = sorted(column_assignments.keys())
        col_labels = [f"åˆ—{col_num}" for col_num in col_nums]
        angle_data = []
        for col_num in col_nums:
            id_list = column_assignments[col_num]
            sub_df = df[df['person_id'].isin(id_list)]
            if 'shoulder_head_angle' in sub_df.columns:
                angle_data.append(sub_df['shoulder_head_angle'].dropna().values)
            else:
                angle_data.append(np.array([]))

        # ç®±ã²ã’å›³ã§åˆ†å¸ƒã‚’å¯è¦–åŒ–
        plt.figure(figsize=(10, 6))
        plt.boxplot(angle_data, labels=col_labels, patch_artist=True,
                    boxprops=dict(facecolor='skyblue', color='navy'),
                    medianprops=dict(color='red'))
        plt.title("è‚©ã®ä¸­ç‚¹ã¨é ­ä¸­å¿ƒã®ãªã™è§’åˆ†å¸ƒï¼ˆåˆ—ä½ç½®ã”ã¨ï¼‰")
        plt.xlabel("åˆ—ä½ç½®")
        plt.ylabel("ãªã™è§’ (åº¦)")
        plt.grid(True, alpha=0.3)
        plt.tight_layout()
        plt.savefig(os.path.join(output_dir, "angle_vs_column_position.png"))
        plt.close()
    
    def _generate_normalization_code(self, function_results: Dict) -> str:
        """ğŸ”§ æ­£è¦åŒ–é–¢æ•°ã®Pythonã‚³ãƒ¼ãƒ‰ç”Ÿæˆ"""
        if not function_results.get('best_function', {}).get('name'):
            return "# ã‚¨ãƒ©ãƒ¼: æœ‰åŠ¹ãªé–¢æ•°ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ"
        
        best_name = function_results['best_function']['name']
        best_result = function_results['fitting_results'][best_name]
        params = best_result['parameters']
        r2_score = best_result['r2_score']
        
        # ãƒ˜ãƒƒãƒ€ãƒ¼
        code = f'''# ğŸ”§ è·é›¢æ­£è¦åŒ–é–¢æ•°ï¼ˆè‡ªå‹•ç”Ÿæˆï¼‰
# åˆ†ææ—¥æ™‚: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
# æœ€é©é–¢æ•°: {best_result['name']} (RÂ² = {r2_score:.3f})
# æƒ³å®š: åˆ—æ•°â†‘ â†’ è·é›¢â†‘ â†’ è‚©å¹…â†“ (å³è‚©ä¸‹ãŒã‚Š)

import numpy as np

def distance_normalization_function(column_position):
    """
    ğŸ“ ã‚«ãƒ¡ãƒ©è·é›¢ã«ã‚ˆã‚‹è‚©å¹…äºˆæ¸¬é–¢æ•°
    
    Args:
        column_position (float): åˆ—ä½ç½®ï¼ˆ1=å‰åˆ—, 2=ä¸­åˆ—, 3=å¾Œåˆ—, ...ï¼‰
        
    Returns:
        float: äºˆæ¸¬è‚©å¹…å€¤ (pixels)
    """'''
        
        # é–¢æ•°åˆ¥ã®å®Ÿè£…
        if best_name == 'linear':
            a, b = params[0], params[1]
            code += f'''
    # ç·šå½¢é–¢æ•°: f(x) = {a:.3f}x + {b:.3f}
    return {a:.6f} * column_position + {b:.6f}'''
        
        elif best_name == 'exponential':
            a, b, c = params[0], params[1], params[2]
            code += f'''
    # æŒ‡æ•°æ¸›è¡°é–¢æ•°: f(x) = {a:.3f} * exp(-{b:.3f}x) + {c:.3f}
    return {a:.6f} * np.exp(-{b:.6f} * column_position) + {c:.6f}'''
        
        elif best_name == 'power':
            a, b, c = params[0], params[1], params[2]
            code += f'''
    # ã¹ãé–¢æ•°: f(x) = {a:.3f} / x^{b:.3f} + {c:.3f}
    return {a:.6f} / (column_position ** {b:.6f}) + {c:.6f}'''
        
        elif best_name == 'polynomial2':
            a, b, c = params[0], params[1], params[2]
            code += f'''
    # 2æ¬¡å¤šé …å¼: f(x) = {a:.3f}xÂ² + {b:.3f}x + {c:.3f}
    return {a:.6f} * column_position**2 + {b:.6f} * column_position + {c:.6f}'''
        
        # æ­£è¦åŒ–é–¢æ•°
        code += f'''

def normalize_shoulder_width(measured_width, column_position, reference_column=1):
    """
    ğŸ¯ å®Ÿæ¸¬è‚©å¹…ã‚’åŸºæº–åˆ—ã§æ­£è¦åŒ–
    
    Args:
        measured_width (float): å®Ÿæ¸¬è‚©å¹…å€¤ (pixels)
        column_position (float): æ¸¬å®šä½ç½®ã®åˆ—ç•ªå·
        reference_column (float): åŸºæº–åˆ—ç•ªå·ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 1=å‰åˆ—ï¼‰
        
    Returns:
        float: æ­£è¦åŒ–ã•ã‚ŒãŸè‚©å¹…å€¤ (1åˆ—ç›®ç›¸å½“)
        
    Example:
        >>> # 3åˆ—ç›®ã§æ¸¬å®šã•ã‚ŒãŸ80pxã‚’1åˆ—ç›®åŸºæº–ã§æ­£è¦åŒ–
        >>> normalized = normalize_shoulder_width(80, 3, 1)
        >>> print(f"3åˆ—ç›®80px â†’ 1åˆ—ç›®ç›¸å½“{{normalized:.1f}}px")
    """
    predicted_width = distance_normalization_function(column_position)
    reference_width = distance_normalization_function(reference_column)
    
    # æ­£è¦åŒ–å€ç‡è¨ˆç®—
    normalization_factor = reference_width / predicted_width
    return measured_width * normalization_factor

def get_normalization_factor(column_position, reference_column=1):
    """
    ğŸ“Š æ­£è¦åŒ–å€ç‡ã®ã¿ã‚’å–å¾—
    
    Returns:
        float: æ­£è¦åŒ–å€ç‡
    """
    predicted_width = distance_normalization_function(column_position)
    reference_width = distance_normalization_function(reference_column)
    return reference_width / predicted_width

# ğŸ§ª ä½¿ç”¨ä¾‹ãƒ»ãƒ†ã‚¹ãƒˆ
if __name__ == "__main__":
    print("ğŸ”§ è·é›¢æ­£è¦åŒ–é–¢æ•°ãƒ†ã‚¹ãƒˆ")
    print("=" * 40)
    
    # å„åˆ—ã®äºˆæ¸¬è‚©å¹…
    for col in [1, 2, 3]:
        predicted = distance_normalization_function(col)
        print(f"{{col}}åˆ—ç›®äºˆæ¸¬è‚©å¹…: {{predicted:.1f}}px")
    
    print("\\nğŸ“Š æ­£è¦åŒ–ä¾‹:")
    # æ­£è¦åŒ–ä¾‹
    test_cases = [
        (80, 1),  # 1åˆ—ç›®80px
        (70, 2),  # 2åˆ—ç›®70px  
        (60, 3),  # 3åˆ—ç›®60px
    ]
    
    for width, col in test_cases:
        normalized = normalize_shoulder_width(width, col, 1)
        factor = get_normalization_factor(col, 1)
        print(f"{{col}}åˆ—ç›®{{width}}px â†’ 1åˆ—ç›®ç›¸å½“{{normalized:.1f}}px (å€ç‡={{factor:.2f}})")
'''
        
        return code
    
    def _save_function_parameters(self, function_results: Dict) -> str:
        """ğŸ’¾ é–¢æ•°ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®JSONä¿å­˜"""
        try:
            output_path = self.output_dir / 'function_parameters.json'
            
            with open(output_path, 'w', encoding='utf-8') as f:
                json.dump(function_results, f, indent=2, ensure_ascii=False)
            
            return str(output_path)
            
        except Exception as e:
            print(f"âŒ ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
            return ""
    
    def _save_analysis_report(
        self,
        frame_id: str,
        column_assignments: Dict,
        column_data: Dict,
        function_results: Dict,
        normalization_code: str
    ) -> str:
        """ğŸ“ è©³ç´°ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜"""
        try:
            report_path = self.output_dir / 'normalization_analysis_report.txt'
            
            with open(report_path, 'w', encoding='utf-8') as f:
                f.write("# ğŸ”§ è·é›¢æ­£è¦åŒ–é–¢æ•°åˆ†æãƒ¬ãƒãƒ¼ãƒˆ\n")
                f.write("=" * 60 + "\n\n")
                
                # åŸºæœ¬æƒ…å ±
                f.write("## ğŸ“Š åˆ†æåŸºæœ¬æƒ…å ±\n")
                f.write(f"- åˆ†ææ—¥æ™‚: {datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S')}\n")
                f.write(f"- å¯¾è±¡ãƒ•ãƒ¬ãƒ¼ãƒ : {frame_id}\n")
                f.write(f"- ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹: {self.csv_path}\n")
                f.write(f"- è‚©å¹…ãƒ‡ãƒ¼ã‚¿åˆ—: {self.shoulder_col}\n\n")
                
                # åˆ—æ§‹æˆ
                f.write("## ğŸ¯ åˆ—æ§‹æˆè¨­å®š\n")
                for col_num, ids in column_assignments.items():
                    data = column_data.get(col_num, {})
                    f.write(f"- {col_num}åˆ—ç›®: å‰²ã‚Šå½“ã¦ID {ids}, æ¤œå‡º{data.get('count', 0)}äºº\n")
                f.write("\n")
                
                # çµ±è¨ˆæƒ…å ±
                f.write("## ğŸ“‹ åˆ—åˆ¥è©³ç´°çµ±è¨ˆ\n")
                valid_columns = {k: v for k, v in column_data.items() if v['count'] > 0}
                for col_num in sorted(valid_columns.keys()):
                    data = valid_columns[col_num]
                    f.write(f"### {col_num}åˆ—ç›®\n")
                    f.write(f"- å¹³å‡è‚©å¹…: {data['mean_width']:.2f} pixels\n")
                    f.write(f"- æ¨™æº–åå·®: {data['std_width']:.2f} pixels\n")
                    f.write(f"- ç¯„å›²: {data['min_width']:.1f} - {data['max_width']:.1f} pixels\n")
                    f.write(f"- æ¤œå‡ºäººæ•°: {data['count']}äºº\n")
                    f.write(f"- å€‹åˆ¥å€¤: {[f'{w:.1f}' for w in data['shoulder_widths']]}\n\n")
                
                # ç›¸é–¢åˆ†æçµæœ
                if 'correlation' in function_results:
                    f.write("## ğŸ”— ç›¸é–¢åˆ†æçµæœ\n")
                    corr = function_results['correlation']
                    f.write(f"- ç›¸é–¢ä¿‚æ•°: {corr['coefficient']:.3f}\n")
                    f.write(f"- på€¤: {corr['p_value']:.3f}\n")
                    f.write(f"- è§£é‡ˆ: {corr['interpretation']}\n")
                    
                    if corr['coefficient'] < 0:
                        f.write("- âœ… å³è‚©ä¸‹ãŒã‚Šå‚¾å‘ï¼ˆè·é›¢å¢—åŠ â†’è‚©å¹…æ¸›å°‘ï¼‰\n")
                    else:
                        f.write("- âš ï¸ å³è‚©ä¸ŠãŒã‚Šå‚¾å‘ï¼ˆæƒ³å®šã¨é€†ï¼‰\n")
                    f.write("\n")
                
                # é–¢æ•°ãƒ•ã‚£ãƒƒãƒ†ã‚£ãƒ³ã‚°çµæœ
                if 'fitting_results' in function_results:
                    f.write("## ğŸ“ˆ é–¢æ•°ãƒ•ã‚£ãƒƒãƒ†ã‚£ãƒ³ã‚°çµæœ\n")
                    for func_name, result in function_results['fitting_results'].items():
                        direction = "â†˜ï¸æ¸›å°‘" if result.get('slope_direction') == 'decreasing' else "â†—ï¸å¢—åŠ "
                        f.write(f"### {result['name']} {direction}\n")
                        f.write(f"- æ•°å¼: {result['formula']}\n")
                        f.write(f"- RÂ²ã‚¹ã‚³ã‚¢: {result['r2_score']:.3f}\n")
                        f.write(f"- RMSE: {result['rmse']:.2f} pixels\n")
                        f.write(f"- ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿: {[f'{p:.3f}' for p in result['parameters']]}\n\n")
                
                # æœ€é©é–¢æ•°
                if 'best_function' in function_results and function_results['best_function'].get('name'):
                    f.write("## ğŸ† é¸æŠã•ã‚ŒãŸæœ€é©é–¢æ•°\n")
                    best = function_results['best_function']
                    f.write(f"- é–¢æ•°å: {best.get('details', {}).get('name', best['name'])}\n")
                    f.write(f"- RÂ²ã‚¹ã‚³ã‚¢: {best['r2_score']:.3f}\n")
                    if 'details' in best:
                        f.write(f"- æ•°å¼: {best['details'].get('formula', 'N/A')}\n")
                        direction = best['details'].get('slope_direction', 'unknown')
                        if direction == 'decreasing':
                            f.write("- âœ… å³è‚©ä¸‹ãŒã‚Šï¼ˆæƒ³å®šé€šã‚Šï¼‰\n")
                        else:
                            f.write("- âš ï¸ å³è‚©ä¸ŠãŒã‚Šï¼ˆè¦ç¢ºèªï¼‰\n")
                f.write("\n")
                
                # ğŸ¯ æ­£è¦åŒ–ã‚³ãƒ¼ãƒ‰
                f.write("## ğŸ”§ ç”Ÿæˆã•ã‚ŒãŸæ­£è¦åŒ–é–¢æ•°ã‚³ãƒ¼ãƒ‰\n")
                f.write("```python\n")
                f.write(normalization_code)
                f.write("\n```\n\n")
                
                # ã‚µãƒãƒªãƒ¼
                f.write("## ğŸ“‹ åˆ†æã‚µãƒãƒªãƒ¼\n")
                total_analyzed = sum(data['count'] for data in column_data.values())
                columns_with_data = len(valid_columns)
                
                f.write(f"- ç·åˆ†æå¯¾è±¡: {total_analyzed}äºº\n")
                f.write(f"- ãƒ‡ãƒ¼ã‚¿æœ‰åŠ¹åˆ—æ•°: {columns_with_data}åˆ—\n")
                
                if valid_columns:
                    all_widths = []
                    for data in valid_columns.values():
                        all_widths.extend(data['shoulder_widths'])
                    f.write(f"- å…¨ä½“è‚©å¹…ç¯„å›²: {min(all_widths):.1f} - {max(all_widths):.1f} pixels\n")
                    f.write(f"- å…¨ä½“å¹³å‡è‚©å¹…: {np.mean(all_widths):.2f} pixels\n")
                
                f.write(f"\n## ğŸ“ ç”Ÿæˆãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§\n")
                f.write(f"- å¯è¦–åŒ–: distance_normalization_analysis.png\n")
                f.write(f"- é–¢æ•°ã‚³ãƒ¼ãƒ‰: normalization_function.py\n")
                f.write(f"- ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿: function_parameters.json\n")
                f.write(f"- è©³ç´°ãƒ¬ãƒãƒ¼ãƒˆ: normalization_analysis_report.txt\n")
                
                f.write(f"\nğŸ¯ åˆ†æå®Œäº†: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            
            # ğŸ’¾ æ­£è¦åŒ–é–¢æ•°ã‚³ãƒ¼ãƒ‰ã‚’åˆ¥ãƒ•ã‚¡ã‚¤ãƒ«ã§ã‚‚ä¿å­˜
            code_path = self.output_dir / 'normalization_function.py'
            with open(code_path, 'w', encoding='utf-8') as f:
                f.write(normalization_code)
            
            print(f"âœ… ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜: {report_path}")
            print(f"âœ… é–¢æ•°ã‚³ãƒ¼ãƒ‰ä¿å­˜: {code_path}")
            
            return str(report_path)
            
        except Exception as e:
            print(f"âŒ ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
            return ""


# ğŸ” ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£é–¢æ•°
def check_available_data(csv_path: str) -> Dict:
    """ğŸ“Š åˆ©ç”¨å¯èƒ½ãªãƒ•ãƒ¬ãƒ¼ãƒ ã¨IDã‚’ç¢ºèª"""
    try:
        df = pd.read_csv(csv_path)
        
        # è‚©å¹…åˆ—ã®ç‰¹å®š
        shoulder_cols = ['shoulder_width', 'shoulder_width_pixels', 'shoulder_distance']
        shoulder_col = None
        for col in shoulder_cols:
            if col in df.columns:
                shoulder_col = col
                break
        
        if shoulder_col is None:
            return {'error': f'è‚©å¹…ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚åˆ©ç”¨å¯èƒ½åˆ—: {list(df.columns)}'}
        
        # ãƒ•ãƒ¬ãƒ¼ãƒ åˆ¥IDæƒ…å ±
        frame_info = {}
        for frame in df['frame'].unique():
            frame_data = df[df['frame'] == frame]
            valid_data = frame_data[
                (frame_data[shoulder_col] >= 10) & 
                (frame_data[shoulder_col] <= 500) &
                (frame_data[shoulder_col].notna())
            ]
            
            if len(valid_data) > 0:
                frame_info[frame] = {
                    'total_detections': len(frame_data),
                    'valid_shoulder_data': len(valid_data),
                    'available_ids': sorted(valid_data['person_id'].unique()),
                    'shoulder_width_range': [
                        float(valid_data[shoulder_col].min()), 
                        float(valid_data[shoulder_col].max())
                    ]
                }
        
        # æ¨å¥¨ãƒ•ãƒ¬ãƒ¼ãƒ ï¼ˆ6äººä»¥ä¸Šå¿…è¦ï¼‰
        recommended_frames = [
            frame for frame, info in frame_info.items() 
            if info['valid_shoulder_data'] >= 6
        ][:5]  # ä¸Šä½5ãƒ•ãƒ¬ãƒ¼ãƒ 
        
        return {
            'success': True,
            'total_frames': len(frame_info),
            'shoulder_width_column': shoulder_col,
            'frame_details': frame_info,
            'recommended_frames': recommended_frames,
            'minimum_requirements': {
                'min_people_per_analysis': 6,
                'min_columns': 2,
                'recommended_people_per_column': 2
            }
        }

    except Exception as e:
        return {'error': str(e)}