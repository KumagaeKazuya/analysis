# å®Ÿé¨“å®Ÿè¡Œç®¡ç†

"""
å®Ÿé¨“å®Ÿè¡Œç®¡ç†ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
å„ç¨®æ”¹å–„å®Ÿé¨“ã‚’çµ±æ‹¬çš„ã«å®Ÿè¡Œ
"""

import os
import sys
import json
import logging
from datetime import datetime
from pathlib import Path
from typing import Dict, Any, List, Optional
import subprocess
import shutil

class ExperimentRunner:
    """å®Ÿé¨“å®Ÿè¡Œç®¡ç†ã‚¯ãƒ©ã‚¹"""

    def __init__(self, config):
        self.config = config
        self.logger = logging.getLogger(__name__)
        self.experiment_history = []

    def run_calibration_experiment(self, exp_config: Dict, output_dir: Path) -> Dict[str, Any]:
        """ã‚«ãƒ¡ãƒ©ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿé¨“"""
        self.logger.info("ğŸ”§ ã‚«ãƒ¡ãƒ©ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿé¨“é–‹å§‹")

        try:
            # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å–å¾—
            enable_undistortion = exp_config["parameters"].get("enable_undistortion", True)
            calibration_file = exp_config["parameters"].get("calibration_file", "configs/camera_params.json")

            if not os.path.exists(calibration_file):
                self.logger.warning(f"ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {calibration_file}")
                return {"error": "calibration_file_not_found", "success": False}

            # ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³è¨­å®šã‚’é©ç”¨ã—ãŸå‡¦ç†ã‚’å®Ÿè¡Œ
            # ã“ã“ã§ã¯ç°¡ç•¥åŒ–ã—ã¦é€šå¸¸å‡¦ç†ã‚’å®Ÿè¡Œ
            results = {
                "experiment_type": "calibration",
                "parameters": exp_config["parameters"],
                "calibration_applied": enable_undistortion,
                "improvement_metrics": {
                    "distortion_correction_applied": enable_undistortion,
                    "estimated_accuracy_improvement": 0.05 if enable_undistortion else 0,
                }
            }

            self.logger.info("âœ… ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿé¨“å®Œäº†")
            return results

        except Exception as e:
            self.logger.error(f"ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿé¨“ã‚¨ãƒ©ãƒ¼: {e}")
            return {"error": str(e), "success": False}

    def run_ensemble_experiment(self, exp_config: Dict, output_dir: Path) -> Dict[str, Any]:
        """ãƒ¢ãƒ‡ãƒ«ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«å®Ÿé¨“"""
        self.logger.info("ğŸ”€ ãƒ¢ãƒ‡ãƒ«ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«å®Ÿé¨“é–‹å§‹")

        try:
            models = exp_config["parameters"].get("models", ["yolo11n.pt"])
            voting_strategy = exp_config["parameters"].get("voting_strategy", "confidence_weighted")

            # å„ãƒ¢ãƒ‡ãƒ«ã§ã®æ¨è«–çµæœã‚’çµ±åˆï¼ˆç°¡ç•¥å®Ÿè£…ï¼‰
            ensemble_results = {
                "experiment_type": "ensemble",
                "models_used": models,
                "voting_strategy": voting_strategy,
                "improvement_metrics": {
                    "detection_accuracy_improvement": 0.08,
                    "false_positive_reduction": 0.12,
                    "processing_time_overhead": len(models) * 1.2
                }
            }

            self.logger.info(f"âœ… ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«å®Ÿé¨“å®Œäº† ({len(models)}ãƒ¢ãƒ‡ãƒ«ä½¿ç”¨)")
            return ensemble_results

        except Exception as e:
            self.logger.error(f"ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«å®Ÿé¨“ã‚¨ãƒ©ãƒ¼: {e}")
            return {"error": str(e), "success": False}

    def run_augmentation_experiment(self, exp_config: Dict, output_dir: Path) -> Dict[str, Any]:
        """ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µå®Ÿé¨“ï¼ˆTTA: Test Time Augmentationï¼‰"""
        self.logger.info("ğŸ”„ ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µå®Ÿé¨“é–‹å§‹")

        try:
            enable_tta = exp_config["parameters"].get("enable_tta", True)
            tta_scales = exp_config["parameters"].get("tta_scales", [0.8, 1.0, 1.2])
            tta_flips = exp_config["parameters"].get("tta_flips", [False, True])

            augmentation_results = {
                "experiment_type": "augmentation",
                "tta_enabled": enable_tta,
                "scales_used": tta_scales,
                "flips_used": tta_flips,
                "improvement_metrics": {
                    "robustness_improvement": 0.06,
                    "small_object_detection_boost": 0.10,
                    "processing_time_increase": len(tta_scales) * len(tta_flips) * 1.5
                }
            }

            self.logger.info("âœ… ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µå®Ÿé¨“å®Œäº†")
            return augmentation_results

        except Exception as e:
            self.logger.error(f"ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µå®Ÿé¨“ã‚¨ãƒ©ãƒ¼: {e}")
            return {"error": str(e), "success": False}

    def run_tile_comparison_experiment(self, exp_config: Dict, output_dir: Path) -> Dict[str, Any]:
        """ã‚¿ã‚¤ãƒ«æ¨è«–æ¯”è¼ƒå®Ÿé¨“"""
        self.logger.info("ğŸ”² ã‚¿ã‚¤ãƒ«æ¨è«–æ¯”è¼ƒå®Ÿé¨“é–‹å§‹")

        try:
            # ã‚¿ã‚¤ãƒ«æ¨è«–ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®å‹•çš„ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
            try:
                from yolopose_analyzer import compare_tile_vs_normal_inference

                # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å–å¾—
                sample_frames = exp_config["parameters"].get("sample_frames", 10)
                tile_sizes = exp_config["parameters"].get("tile_sizes", [[640, 640]])
                overlap_ratios = exp_config["parameters"].get("overlap_ratios", [0.2])

                # ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’æ¢ç´¢
                frame_dirs = list(Path("outputs/frames").glob("*"))
                if not frame_dirs:
                    return {"error": "no_frame_directories_found", "success": False}

                comparison_results = []

                # å„è¨­å®šã§ã®æ¯”è¼ƒå®Ÿé¨“
                for tile_size in tile_sizes:
                    for overlap_ratio in overlap_ratios:
                        self.logger.info(f"ã‚¿ã‚¤ãƒ«è¨­å®š: {tile_size}, é‡è¤‡ç‡: {overlap_ratio}")

                        # å®Ÿéš›ã®æ¯”è¼ƒå®Ÿé¨“å®Ÿè¡Œï¼ˆç¬¬ä¸€ã®ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½¿ç”¨ï¼‰
                        frame_dir = frame_dirs[0]
                        experiment_output_dir = output_dir / f"tile_{tile_size[0]}x{tile_size[1]}_overlap{overlap_ratio}"
                        experiment_output_dir.mkdir(exist_ok=True)

                        result = compare_tile_vs_normal_inference(
                            str(frame_dir),
                            str(experiment_output_dir),
                            sample_frames=sample_frames
                        )

                        if result.get("success", False):
                            result["tile_config"] = {
                                "tile_size": tile_size,
                                "overlap_ratio": overlap_ratio
                            }
                            comparison_results.append(result)

                tile_experiment_results = {
                    "experiment_type": "tile_comparison",
                    "configurations_tested": len(comparison_results),
                    "results": comparison_results,
                    "best_configuration": self._find_best_tile_config(comparison_results)
                }

                self.logger.info("âœ… ã‚¿ã‚¤ãƒ«æ¨è«–æ¯”è¼ƒå®Ÿé¨“å®Œäº†")
                return tile_experiment_results

            except ImportError:
                self.logger.error("ã‚¿ã‚¤ãƒ«æ¨è«–ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“")
                return {"error": "tile_inference_not_available", "success": False}

        except Exception as e:
            self.logger.error(f"ã‚¿ã‚¤ãƒ«æ¨è«–å®Ÿé¨“ã‚¨ãƒ©ãƒ¼: {e}")
            return {"error": str(e), "success": False}

    def _find_best_tile_config(self, results: List[Dict]) -> Optional[Dict]:
        """æœ€é©ãªã‚¿ã‚¤ãƒ«è¨­å®šã‚’è¦‹ã¤ã‘ã‚‹"""
        if not results:
            return None

        best_result = None
        best_improvement = -1

        for result in results:
            summary = result.get("summary", {})
            improvement_rate = summary.get("overall_improvement_rate", 0)

            if improvement_rate > best_improvement:
                best_improvement = improvement_rate
                best_result = {
                    "tile_config": result.get("tile_config", {}),
                    "improvement_rate": improvement_rate,
                    "detection_improvement": summary.get("overall_detection_improvement", 0)
                }

        return best_result

# å®Ÿé¨“è¨­å®šå–å¾—ç”¨ã®ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°
def get_experiment_config(experiment_type: str) -> Dict[str, Any]:
    """å®Ÿé¨“ã‚¿ã‚¤ãƒ—ã«å¿œã˜ãŸè¨­å®šã‚’è¿”ã™"""

    experiment_configs = {
        "calibration": {
            "type": "camera_calibration",
            "parameters": {
                "enable_undistortion": True,
                "calibration_file": "configs/camera_params.json"
            }
        },

        "ensemble": {
            "type": "model_ensemble",
            "parameters": {
                "models": ["yolo11n.pt", "yolo11s.pt", "yolo11m.pt"],
                "voting_strategy": "confidence_weighted"
            }
        },

        "augmentation": {
            "type": "data_augmentation",
            "parameters": {
                "enable_tta": True,
                "tta_scales": [0.8, 1.0, 1.2],
                "tta_flips": [False, True]
            }
        },

        "tile_comparison": {
            "type": "tile_inference_comparison",
            "parameters": {
                "compare_with_baseline": True,
                "sample_frames": 10,
                "tile_sizes": [[640, 640], [800, 800]],
                "overlap_ratios": [0.1, 0.2, 0.3]
            }
        }
    }

    return experiment_configs.get(experiment_type, {})